# JOB INTELLIGENT - SystÃ¨me de Centralisation et Recommandation d'Offres Data

![Status](https://img.shields.io/badge/Status-Active-green) ![Version](https://img.shields.io/badge/Version-1.0-blue)

**Un projet complet de Data Engineering & Analytics pour l'analyse et la recommandation d'offres d'emploi Data.**

---

## ğŸ“š Table des MatiÃ¨res

- [Objectif du Projet](#-objectif-du-projet)
- [Architecture](#-architecture)
- [Structure du Projet](#-structure-du-projet)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [DBT Models](#-dbt-models)
- [Power BI](#-power-bi)
- [Documentation](#-documentation)
- [Licence](#-licence)

---

## ğŸ¯ Objectif du Projet

**Centraliser et analyser les offres d'emploi Data** en provenance de LinkedIn (131 570 offres) pour :

1. âœ… CrÃ©er une structure analytique professionnelle (Bronze/Silver/Gold)
2. âœ… Nettoyer et transformer les donnÃ©es avec **DBT**
3. âœ… Extraire les insights business (compÃ©tences, tendances, gÃ©ographie)
4. âœ… CrÃ©er des dashboards interactifs avec **Power BI**
5. âœ… PrÃ©parer un systÃ¨me de recommandation d'offres (**Phase 2**)

### Contraintes du Projet
- âœ“ **100% Local** (pas de cloud)
- âœ“ **Sans Airflow** (orchestration manuelle/Python)
- âœ“ **Sans Docker**
- âœ“ **Sans PostgreSQL** (fichiers locaux)
- âœ“ **Transformation DBT** obligatoire
- âœ“ **BI avec Power BI**

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SOURCE LAYER                             â”‚
â”‚                    final_data.csv (131K rows)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BRONZE LAYER                               â”‚
â”‚              (Raw data + basic renaming)                        â”‚
â”‚                                                                 â”‚
â”‚  â€¢ stg_jobs_raw                                                â”‚
â”‚  â€¢ Materialization: VIEW                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SILVER LAYER                               â”‚
â”‚          (Cleaning, Normalization, Enrichment)                 â”‚
â”‚                                                                 â”‚
â”‚  â€¢ int_jobs_cleaned                                            â”‚
â”‚  â€¢ int_job_title_normalization                                â”‚
â”‚  â€¢ int_skills_extraction                                       â”‚
â”‚  â€¢ Materialization: TABLE                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      GOLD LAYER                                 â”‚
â”‚             (Analytics-ready + Star Schema)                    â”‚
â”‚                                                                 â”‚
â”‚  Dimensions:                                                   â”‚
â”‚  â€¢ dim_time (2K rows)                                          â”‚
â”‚  â€¢ dim_company (5K rows)                                       â”‚
â”‚  â€¢ dim_location (3K rows)                                      â”‚
â”‚  â€¢ dim_skills (30 rows)                                        â”‚
â”‚                                                                 â”‚
â”‚  Facts:                                                        â”‚
â”‚  â€¢ fact_job_offers (100K rows)                                 â”‚
â”‚  â€¢ fact_job_skills (500K rows)                                â”‚
â”‚                                                                 â”‚
â”‚  Aggregates:                                                   â”‚
â”‚  â€¢ agg_job_offers_by_category_time                             â”‚
â”‚  â€¢ agg_skills_demand                                           â”‚
â”‚  â€¢ agg_location_analysis                                       â”‚
â”‚                                                                 â”‚
â”‚  â€¢ Materialization: TABLE                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    POWER BI (Visualizations)                    â”‚
â”‚                                                                 â”‚
â”‚  Pages:                                                        â”‚
â”‚  â€¢ Overview Dashboard                                          â”‚
â”‚  â€¢ Job Categories Analysis                                    â”‚
â”‚  â€¢ Skills Demand                                              â”‚
â”‚  â€¢ Geographic Analysis                                        â”‚
â”‚  â€¢ Company Analysis                                           â”‚
â”‚  â€¢ Advanced Analytics                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Structure du Projet

```
lab2/
â”œâ”€â”€ ğŸ“„ final_data.csv                    # â† Source data
â”œâ”€â”€ ğŸ“„ README.md                         # â† Ce fichier
â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md                   # â† Documentation architecture
â”œâ”€â”€ ğŸ“„ POWER_BI_GUIDE.md                # â† Guide Power BI dÃ©taillÃ©
â”œâ”€â”€ ğŸ run_pipeline.py                   # â† Script orchestration Python
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/                          # â† Couche brutes
â”‚   â”‚   â””â”€â”€ final_data.csv              # (CopiÃ© automatiquement)
â”‚   â”œâ”€â”€ silver/                          # â† Couche nettoyÃ©e
â”‚   â””â”€â”€ gold/                            # â† Couche analytique (exported CSV)
â”‚       â”œâ”€â”€ dim_time.csv
â”‚       â”œâ”€â”€ dim_company.csv
â”‚       â”œâ”€â”€ dim_location.csv
â”‚       â”œâ”€â”€ dim_skills.csv
â”‚       â”œâ”€â”€ fact_job_offers.csv
â”‚       â”œâ”€â”€ fact_job_skills.csv
â”‚       â”œâ”€â”€ agg_job_offers_by_category_time.csv
â”‚       â”œâ”€â”€ agg_skills_demand.csv
â”‚       â””â”€â”€ agg_location_analysis.csv
â”‚
â””â”€â”€ dbt_project/
    â”œâ”€â”€ dbt_project.yml                  # Configuration DBT
    â”œâ”€â”€ profiles.yml                     # Connecteurs database
    â”œâ”€â”€ target/                          # DBT build output
    â”‚   â””â”€â”€ duckdb.db                   # (GÃ©nÃ©rÃ© aprÃ¨s dbt run)
    â”‚
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ bronze/
    â”‚   â”‚   â””â”€â”€ stg_jobs_raw.sql
    â”‚   â”‚
    â”‚   â”œâ”€â”€ silver/
    â”‚   â”‚   â”œâ”€â”€ int_jobs_cleaned.sql
    â”‚   â”‚   â”œâ”€â”€ int_job_title_normalization.sql
    â”‚   â”‚   â””â”€â”€ int_skills_extraction.sql
    â”‚   â”‚
    â”‚   â””â”€â”€ gold/
    â”‚       â”œâ”€â”€ dim_time.sql
    â”‚       â”œâ”€â”€ dim_company.sql
    â”‚       â”œâ”€â”€ dim_location.sql
    â”‚       â”œâ”€â”€ dim_skills.sql
    â”‚       â”œâ”€â”€ fact_job_offers.sql
    â”‚       â”œâ”€â”€ fact_job_skills.sql
    â”‚       â”œâ”€â”€ agg_job_offers_by_category_time.sql
    â”‚       â”œâ”€â”€ agg_skills_demand.sql
    â”‚       â””â”€â”€ agg_location_analysis.sql
    â”‚
    â”œâ”€â”€ tests/                          # Tests DBT
    â”œâ”€â”€ macros/                         # Macros rÃ©utilisables
    â”œâ”€â”€ analyses/                       # Analyses ad-hoc
    â””â”€â”€ docs/                           # Documentation DBT
```

---

## ğŸš€ Installation

### PrÃ©requis

```bash
# Python 3.8+
python --version

# Packages
pip install dbt-core dbt-duckdb pandas openpyxl
```

### Ã‰tapes

1. **Cloner/TÃ©lÃ©charger le projet**
   ```bash
   cd d:\lab2
   ```

2. **Installer les dÃ©pendances DBT**
   ```bash
   cd dbt_project
   dbt debug
   ```

3. **VÃ©rifier la configuration**
   ```bash
   # VÃ©rifier que final_data.csv est prÃ©sent
   ls -la final_data.csv
   ```

---

## ğŸ’» Utilisation

### Option 1 : Utiliser le script Python (RecommandÃ©)

```bash
# Depuis d:\lab2
python run_pipeline.py
```

**Ce script fait automatiquement** :
1. âœ“ VÃ©rifie les dÃ©pendances
2. âœ“ Copie les donnÃ©es source en Bronze
3. âœ“ ExÃ©cute `dbt run`
4. âœ“ ExÃ©cute les tests DBT
5. âœ“ Exporte les tables Gold en CSV
6. âœ“ GÃ©nÃ¨re un rapport final

### Option 2 : ExÃ©cution manuelle DBT

```bash
cd dbt_project

# Debug
dbt debug

# Run
dbt run

# Test (optionnel)
dbt test

# Docs (optionnel)
dbt docs generate
dbt docs serve
```

### Option 3 : PowerShell/Terminal

```powershell
# Depuis d:\lab2
cd dbt_project
dbt run --profiles-dir .
```

---

## ğŸ“Š DBT Models

### Bronze Layer
| Model | Type | Rows | Description |
|-------|------|------|-------------|
| `stg_jobs_raw` | VIEW | ~131K | Lecture brute du CSV |

### Silver Layer
| Model | Type | Rows | Description |
|-------|------|------|-------------|
| `int_jobs_cleaned` | TABLE | ~131K | Nettoyage texte + dates |
| `int_job_title_normalization` | TABLE | ~100K | Normalisation postes |
| `int_skills_extraction` | TABLE | ~500K | Extraction compÃ©tences |

### Gold Layer - Dimensions
| Model | Type | Rows | Keys |
|-------|------|------|------|
| `dim_time` | TABLE | ~2K | date_id (PK) |
| `dim_company` | TABLE | ~5K | company_id (PK) |
| `dim_location` | TABLE | ~3K | location_id (PK) |
| `dim_skills` | TABLE | ~30 | skill_id (PK) |

### Gold Layer - Facts
| Model | Type | Rows | Keys |
|-------|------|------|------|
| `fact_job_offers` | TABLE | ~100K | job_offer_id (SK), Foreign Keys |
| `fact_job_skills` | TABLE | ~500K | job_skill_id (SK), Foreign Keys |

### Gold Layer - Aggregates
| Model | Type | Purpose |
|-------|------|---------|
| `agg_job_offers_by_category_time` | TABLE | AgrÃ©gation temporelle |
| `agg_skills_demand` | TABLE | Demande de compÃ©tences |
| `agg_location_analysis` | TABLE | Analyse gÃ©ographique |

---

## ğŸ“ˆ Power BI

### Import des DonnÃ©es

1. **Ouvrir Power BI Desktop**
2. **File â†’ Open â†’ New**
3. **Get Data â†’ Text/CSV**
4. **Charger dans cet ordre** :
   - dim_time.csv
   - dim_company.csv
   - dim_location.csv
   - dim_skills.csv
   - fact_job_offers.csv
   - fact_job_skills.csv

### CrÃ©er les Relationships

| From | To | Cardinality |
|------|----|----|
| fact_job_offers[company_id] | dim_company[company_id] | Many:One |
| fact_job_offers[location_id] | dim_location[location_id] | Many:One |
| fact_job_offers[published_date_id] | dim_time[date_id] | Many:One |
| fact_job_skills[job_offer_id] | fact_job_offers[job_offer_id] | Many:One |
| fact_job_skills[skill_id] | dim_skills[skill_id] | Many:One |

### Dashboards Ã  CrÃ©er

- **ğŸ“Š Overview** : KPIs, trends, distributions
- **ğŸ’¼ Job Categories** : DÃ©tail par catÃ©gorie
- **ğŸ”§ Skills** : Top 20, tendances
- **ğŸŒ Geography** : Cartes, villes, pays
- **ğŸ¢ Companies** : Top hirers
- **ğŸ“Š Advanced** : Heatmaps, correlations

Voir [POWER_BI_GUIDE.md](POWER_BI_GUIDE.md) pour le guide complet.

---

## ğŸ“š Documentation

### Fichiers Importants

1. **[ARCHITECTURE.md](ARCHITECTURE.md)**
   - Architecture complÃ¨te
   - Description dÃ©taillÃ©e de chaque layer
   - Schema en Ã©toile
   - KPIs dÃ©finis

2. **[POWER_BI_GUIDE.md](POWER_BI_GUIDE.md)**
   - Configuration Power BI
   - Mesures DAX
   - Design des dashboards
   - Troubleshooting

3. **[run_pipeline.py](run_pipeline.py)**
   - Script d'orchestration
   - Automatisation complÃ¨te
   - Export CSV

---

## ğŸ” Exploratory Queries

### VÃ©rifier les donnÃ©es Silver

```sql
-- DuckDB Console
SELECT COUNT(*) as total_jobs FROM silver.int_job_title_normalization;

SELECT 
    job_category,
    COUNT(*) as count
FROM silver.int_job_title_normalization
GROUP BY job_category
ORDER BY count DESC;

SELECT 
    skill_name,
    COUNT(*) as count
FROM silver.int_skills_extraction
GROUP BY skill_name
ORDER BY count DESC
LIMIT 20;
```

### VÃ©rifier les donnÃ©es Gold

```sql
SELECT COUNT(*) FROM gold.fact_job_offers;
SELECT COUNT(*) FROM gold.dim_company;
SELECT COUNT(*) FROM gold.dim_location;
SELECT COUNT(*) FROM gold.dim_skills;
```

---

## ğŸ“Š Quelques Insights PrÃ©liminaires

**Ã€ dÃ©couvrir via le dashboard** :

- ğŸ“ Quels pays/villes ont le plus d'offres ?
- ğŸ”§ Quelles sont les top 10 compÃ©tences demandÃ©es ?
- ğŸ’¼ Distribution des rÃ´les (Data Engineer vs Scientist vs Analyst) ?
- ğŸŒ Quel % des postes est en remote ?
- ğŸ“ˆ Quelle est la tendance temporelle des offres ?
- ğŸ¢ Quelles entreprises recrutent le plus ?

---

## ğŸ› ï¸ Maintenance

### Mise Ã  jour des donnÃ©es

```bash
# Remplacer final_data.csv par une version plus rÃ©cente
# Puis exÃ©cuter :
python run_pipeline.py
```

### Ajouter une nouvelle compÃ©tence

Modifier `models/silver/int_skills_extraction.sql` et ajouter :
```sql
UNION ALL SELECT 'New Skill', 'pattern_regex'
```

### Modifier une normalisation

Ã‰diter `models/silver/int_job_title_normalization.sql` :
```sql
WHEN job_title_cleaned LIKE '%pattern%' THEN 'Normalized Name'
```

---

## ğŸ“‹ Checklist d'Utilisation

- [ ] Installer les dÃ©pendances
- [ ] VÃ©rifier `final_data.csv` prÃ©sent
- [ ] ExÃ©cuter `python run_pipeline.py`
- [ ] VÃ©rifier les fichiers CSV dans `data/gold/`
- [ ] Importer en Power BI
- [ ] CrÃ©er les relationships
- [ ] CrÃ©er les dashboards
- [ ] ParamÃ©trer refresh rÃ©gulier

---

## ğŸš€ Prochaines Ã‰tapes (Phase 2)

- [ ] **SystÃ¨me de recommandation** : ML model pour matcher offres/profils
- [ ] **API REST** : Servir les recommandations
- [ ] **Alertes** : Notifier des nouvelles offres matchÃ©es
- [ ] **Dashboard temps rÃ©el** : WebApp avec Streamlit/Dash
- [ ] **Integration LinkedIn** : Scraping automatisÃ© quotidien

---

## ğŸ“ Support

### Erreurs Courantes

**ProblÃ¨me** : `dbt: command not found`
```bash
# Solution
pip install dbt-core dbt-duckdb
```

**ProblÃ¨me** : Import Error DuckDB
```bash
pip install duckdb
```

**ProblÃ¨me** : final_data.csv not found
```bash
# VÃ©rifier le fichier est bien en d:\lab2\
# Ou modifier le chemin dans stg_jobs_raw.sql
```

---

## ğŸ“„ Licence

Projet personnel - Usage libre

---

## âœ¨ Auteur

**Data Engineering & Analytics Project**  
CrÃ©Ã© : Janvier 2026  
Version : 1.0

---

**Besoin d'aide ?** Consultez les fichiers de documentation ou les logs DBT en `dbt_project/logs/`.

Happy analyzing! ğŸš€
