"title","location","postedTime","publishedAt","jobUrl","companyName","companyUrl","description","applicationsCount","contractType","experienceLevel","workType","sector","salary","posterFullName","posterProfileUrl","companyId","applyUrl","applyType","benefits"
"Decision Scientist- Retail Media","Pleasanton, CA","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/decision-scientist-retail-media-at-safeway-4337006372?trk=public_jobs_topcard-title","Safeway","https://www.linkedin.com/company/safeway?trk=public_jobs_topcard-org-name","Prior to applying it is required that you inform your manager of your desire to apply for a new position.

Why choose us?

Are you ready to take the next step in your career? Join us for an exciting opportunity at Albertsons Companies, where innovation and customer service go hand-in-hand!

At Albertsons Companies, we are looking for someone who’s not just seeking a job, but someone who wants to make an impact. In this role, you’ll have the opportunity to lead, innovate, and contribute to the growth of a company that values great service and lasting customer relationships. This position offers the chance to work in a fast-paced, dynamic environment that’s constantly evolving.

Main Responsibilities

Albertson’s Companies is looking for a Decision Scientist to join our Marketing Science Research team to drive complex, high priority analytics projects that are critical to understanding and adding value to our business. The Marketing Science Research team will work directly with Data Science, Engineering, and our Senior Leadership to help answer questions that influence the direction of the business in both short & long term via data-driven insights and targeted recommendations. In this role, your focus will be designing and executing analysis around our most pressing problems to drive causal understanding of campaign performance.

You have extensive, hands-on SQL & Python knowledge that allows you to parse through large & noisy datasets to validate assumptions and uncover new paths forward. You have a passion for debunking false correlations and understand how to control for the correct variables to develop causal understanding without bias. You have strong stakeholder management skills and aren’t afraid of working with ambiguity; the success as a team depends on identifying the most valuable problems and extracting the right requirements from stakeholders across the business (Strategy, Leadership, Engineering, Innovation) while finding creative solutions to legacy problems. You will report to the Head of Marketing Science Research and act as our lead analyst responsible for causal analysis & test design to answer our business’s most pressing questions.


 * Work with our Engineering and Data Science teams to develop our incrementality testing & methodologies (Bayesian Structural Time Series, Synthetic Approaches, matched market, etc.) for in-store media.
 * Bridge Business, Engineering, and Data Science teams to translate requirements for our Retail Media business into in-store capabilities necessary for robust measurement that will be meaningful to our CPG partners.
 * Help build the story to shift the Retail Media Network Industry toward Incremental Performance Metrics by distinguishing and comparing these success metrics vs. traditional metrics like ROAS.
   
   

The position is in office and based in Pleasanton, CA -Boise, ID- or Itasca, IL.

We Are Looking For Candidates Who Possess The Following


 * A bachelor’s degree in Math, Statistics, Engineering, or an equivalent STEM degree strongly preferred.
 * 5+ years of direct experience in Data Analyst/Science roles.
 * 2+ years’ experience within Advertising/Media Data strongly preferred.
 * Expert SQL skills and robust working knowledge of Data Warehousing required.
 * Strong Python experience required.
 * Demonstrated experience working with & optimizing large, complex data sets.
 * Demonstrated experience surfacing meaningful insights and integrating strategic recommendations that directly influence business trajectory.
 * Skill with data visualization (PowerBI, ggplot, plotly, etc.) & storytelling skills to help translate complex insights to stakeholders with varying levels of data literacy.
 * Strategic bent and ability to drive, build, and optimize analyses and light-weight data products without strict guidance.
   
   

We Also Provide a Variety Of Benefits Including


 * Competitive wages paid weekly
 * Associate discounts
 * Health and financial well-being benefits for eligible associates (Medical, Dental, 401k and more!)
 * Time off (vacation, holidays, sick pay). For eligibility requirements please visit myACI Benefits
 * Leaders invested in your training, career growth and development
 * An inclusive work environment with talented colleagues who reflect the communities we serve
   
   

Our Values – Click below to view video: ACI Values

The salary range is $95,400 to $123,900 annually. Starting salary will vary based on criteria such as location, experience, and qualifications. There may be flexibility for exceptional candidates.

Benefits may include, medical, dental, vision, disability and life insurance, sick pay, PTO/Vacation pay/Flexible Time Off, paid holidays (8-9 days annually) bereavement pay and retirement benefits (such as 401(k) eligibility). Associates in this position are also eligible for a quarterly bonus.

A copy of the full job description can be made available to you.

","104 applicants","Full-time","Entry level","Engineering and Information Technology","Retail","$95,400.00/yr - $123,900.00/yr","Anna Lee","https://www.linkedin.com/in/anna-lee-2a16762","3498","https://www.linkedin.com/jobs/view/decision-scientist-retail-media-at-safeway-4337006372?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Analyst, Payments Reconciliation","New York, NY","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/data-analyst-payments-reconciliation-at-rippling-4338759046?trk=public_jobs_topcard-title","Rippling","https://www.linkedin.com/company/rippling?trk=public_jobs_topcard-org-name","About Rippling

Rippling gives businesses one place to run HR, IT, and Finance. It brings together all of the workforce systems that are normally scattered across a company, like payroll, expenses, benefits, and computers. For the first time ever, you can manage and automate every part of the employee lifecycle in a single system.

Take onboarding, for example. With Rippling, you can hire a new employee anywhere in the world and set up their payroll, corporate card, computer, benefits, and even third-party apps like Slack and Microsoft 365—all within 90 seconds.

Based in San Francisco, CA, Rippling has raised $1.4B+ from the world’s top investors—including Kleiner Perkins, Founders Fund, Sequoia, Greenoaks, and Bedrock—and was named one of America's best startup employers by Forbes.

We prioritize candidate safety. Please be aware that all official communication will only be sent from @Rippling.com addresses.

About The Role

Join our growing Payments Data & Analytics team as an experienced Data Analyst. This is an opportunity to be embedded in the engine room of our customer funds analytics —playing a critical role in reconciling customer data, improving data quality, and making our payments reconciliation platform bulletproof and more scalable. You’ll work closely with Engineering, Product, and Finance teams to ensure customers have clean, actionable data at their fingertips.

Your role will involve analyzing complex data sets, managing analytical projects, and collaborating with various teams to deliver complete and accurate analytics to ensure compliance with regulators and external parties.

You should have strong critical thinking skills, and the ability to frame and break down complex problems. You thrive under ambiguity and can operate cross functionally in a fast paced environment. You are able to operate across the data stack, and support all elements from data engineering to delivering strategic recommendations.

What You Will Do


 * Build internal tooling and processes to reconcile financial and transactional data from multiple sources to enable accurate, repeatable customer funds reporting
 * Collaborate with key stakeholders (Accounting, Compliance, Engineering, etc.) to understand business requirements and develop solutions to automate reporting and reconciliation, including internal tool development and/or implementation of third party tools.
 * Maintain strong internal controls to protect against payment errors or compliance breaches.
 * Support audits, month-end reconciliation, system implementations and special projects.
 * Leverage data analysis and AI-powered tools to identify process gaps, detect anomalies, and drive automation opportunities.
 * Improve the fidelity and performance of our DBT pipelines and help evolve our broader data architecture
   
   

What You Will Need


 * A minimum of 3 years of experience in Business Intelligence/Data Analytics within a Finance, Accounting, or Compliance function
 * Excellent verbal communication and presentation ability. You are able to frame problems, and communicate to all levels of an organization
 * Proven track record of working cross functionally and communicating findings to executive leadership
 * Experience partnering with Finance/Accounting organizations in performing detailed and data intensive reconciliations with disparate datasets.
 * Experience reconciling financial or transactional data (ideally in an e-commerce or payments environment)
 * Experience with data warehousing and reporting technologies like DBT, Snowflake, Tableau, etc.
 * Expert in SQL
 * Familiarity with business intelligence best practices and tooling
 * Familiarity with data transformation best practices and tooling (e.g. dbt projects, incremental tables, etc.)
 * Experience with data visualization tools and delivering self service reporting
   
   

Additional Information

Rippling is an equal opportunity employer. We are committed to building a diverse and inclusive workforce and do not discriminate based on race, religion, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, veteran or military status, or any other legally protected characteristics, Rippling is committed to providing reasonable accommodations for candidates with disabilities who need assistance during the hiring process. To request a reasonable accommodation, please email accomodations@rippling.com

Rippling highly values having employees working in-office to foster a collaborative work environment and company culture. For office-based employees (employees who live within a defined radius of a Rippling office), Rippling considers working in the office, at least three days a week under current policy, to be an essential function of the employee's role.

This role will receive a competitive salary + benefits + equity. The salary for US-based employees will be aligned with one of the ranges below based on location; see which tier applies to your location here.

A variety of factors are considered when determining someone’s compensation–including a candidate’s professional background, experience, and location. Final offer amounts may vary from the amounts listed below.

The pay range for this role is:

90,000 - 157,500 USD per year(US Tier 1)","Over 200 applicants","Full-time","Entry level","Information Technology","Software Development","$90,000.00/yr - $157,500.00/yr","","","17988315","https://ats.rippling.com/rippling/jobs/a51d2198-0dcf-4fca-838f-6353b61b44ec?jobSite=LinkedIn","EXTERNAL",""
"Manager, Data Analytics & BI (100453)","Torrance, CA","1 day ago","2025-12-01","https://www.linkedin.com/jobs/view/manager-data-analytics-bi-100453-at-american-honda-motor-company-inc-4348035234?trk=public_jobs_topcard-title","American Honda Motor Company, Inc.","https://www.linkedin.com/company/american-honda-motor-company-inc-?trk=public_jobs_topcard-org-name","At Honda, The Power of Dreams drives us to create intelligent products that enhance mobility and increase the joy in people’s lives.

We continue to draw inspiration from the visionary ideas of our namesake, Soichiro Honda. He saw incredible power in the freedom of mobility and used his imagination to change the world. It is this mindset that guides us to help move people forward and protect the future we all share.

We strive to earn the trust and support of the many diverse communities we happily serve, and we’ll always remember who’s in the driver’s seat on the way to a better world for all. What Makes a Honda, is Who makes a Honda

Honda has a clear vision for the future, and it’s a joyful one. We are looking for individuals with the skills, courage, persistence, and dreams that will help us reach our future-focused goals. At our core is innovation. Honda is constantly innovating and developing solutions to drive our business with record success. We strive to be a company that serves as a source of “power” that supports people around the world who are trying to do things based on their own initiative and that helps people expand their own potential. To this end, Honda strives to realize “the joy and freedom of mobility” by developing new technologies and an innovative approach to achieve a “zero environmental footprint.”

We are looking for qualified individuals with diverse backgrounds, experiences, continuous improvement values, and a strong work ethic to join our team.

If your goals and values align with Honda’s, we want you to join our team to Bring the Future!

Job Purpose

American Honda Motor is looking for an experienced manager to join our Business Intelligence team. As a Business Intelligence Manager, you will partner with multi-functional teams to design, develop, and deliver comprehensive data and reporting solutions that allow business teams to make informed decisions. You and your team will provide data processing, analyses, dashboards, insights, and recommendations to improve our digital products, e-commerce, and customer marketing strategies.

Key Accountabilities


 * Develop a scalable business intelligence function and infrastructure for multiple business units at American Honda Motors
 * Manage and execute a technical roadmap that builds our analytics and reporting databases
 * Partner with data engineering teams to create ETL requirements that transform and load data from internal or external sources. Develop and manage data models and pipelines
 * Deploy and manage the adaptation of new BI tools and services
 * Guide business teams on data sources and dashboards. Ensure consistency in data use across teams. Identify manual and inefficient recurring processes in data analytics and implement automated solutions
 * Manage and prioritize analytic work queue, including problem formulation, data gathering, and requirements specification, processing, analysis, and presentations. Build automation and analysis pipelines to provide insights at scale
 * Work with business and analytics leaders to create key indicator dashboards that measure the performance of digital products, marketing, and customer experience
 * Partner with product, marketing, and other business teams to define data reporting requirements and deliver capable BI resources and solutions
 * Analyze and curate large data sets using data preparation applications and SQL
 * Build and maintain reports, dashboards, and presentations that provide insights intuitively to support business decisions
 * Provide analysis, insights, and recommendations to improve customer acquisition, engagement, and retention on Honda products and services
 * Support A/B testing to identify opportunities in product user experience
 * Manage and provide all ad-hoc analytics
 * Recruit and manage a team of business intelligence analysts
 * Drive decision-making on resource allocation and talent development
   
   

Qualifications, Experience, And Skills


 * Bachelor's degree in Computer Science or equivalent practical experience in business intelligence, data engineering, or analytics role
 * 10+ years of industry experience in managing complex and unstructured data sets, developing analytic and reporting data warehouse, data marts, and data pipelines
 * 8+ years of experience using SQL and/or Python to manipulate data and provide data analytics
 * 8+ years of experience in managing analytics and reporting data tables that support large or multiple business units
 * 8+ years of experience developing dashboards and visualizations with PowerBI, Tableau, or other reporting applications
 * 5+ years of experience as a people manager
 * Strong problem-solving skills – using data in identifying and solving problems, managing stakeholder issues, creating efficient analytic solutions, and presenting results and recommendations to influence decisions
 * Ability to define data infrastructure roadmap and manage multiple projects simultaneously
 * Experience developing data integrations with different data sources and systems
 * Strong knowledge of relational database concepts
 * Experts in data analytics methods and statistics
 * Demonstrates clear communication and presentation skills (oral and written)
 * Work independently in a dynamic environment
   
   

What differentiates Honda and make us an employer of choice?

Total Rewards


 * Competitive Base Salary (pay will be based on several variables that include, but not limited to geographic location, work experience, etc.)
 * Regional Bonus (when applicable)
 * Manager Lease Car Program (No Cost - Car, Maintenance, and Insurance included)
 * Industry-leading Benefit Plans (Medical, Dental, Vision, Rx)
 * Paid time off, including vacation, holidays, shutdown
 * Company Paid Short-Term and Long-Term Disability
 * 401K Plan with company match + additional contribution
 * Relocation assistance (if eligible)
   
   

Career Growth


 * Advancement Opportunities
 * Career Mobility
 * Education Reimbursement for Continued Learning
 * Training and Development Programs
   
   

Additional Offerings


 * Lifestyle Account
 * Childcare Reimbursement Account
 * Elder Care Support
 * Tuition Assistance & Student Loan Repayment
 * Wellbeing Program
 * Community Service and Engagement Programs
 * Product Programs
   
   

Honda is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, creed, religion, national origin, sex, sexual orientation, gender identity and expression, age, disability, veteran status, or any other protected factor. American Honda Motor is looking for an experienced manager to join our Business Intelligence team. As a Business Intelligence Manager, you will partner with multi-functional teams to design, develop, and deliver comprehensive data and reporting solutions that allow business teams to make informed decisions. You and your team will provide data processing, analyses, dashboards, insights, and recommendations to improve our digital products, e-commerce, and customer marketing strategies.


 * Competitive Base Salary (pay will be based on several variables that include, but are not limited to, geographic location, work experience, etc.)
 * Regional Bonus (when applicable)
 * Manager Lease Car Program (No Cost - Car, Maintenance, and Insurance included)
 * Industry-leading Benefit Plans (Medical, Dental, Vision, Rx)
 * Paid time off, including vacation, holidays, and shutdown
 * Company Paid Short-Term and Long-Term Disability
 * 401K Plan with company match + additional contribution
 * Relocation assistance (if eligible)","48 applicants","Full-time","Mid-Senior level","Information Technology","Motor Vehicle Manufacturing","","","","4097","https://american-honda-motor-co-i.contactrh.com/jobs/12312/43767282/en_US","EXTERNAL",""
"Data Analyst","Santa Monica, CA","22 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-analyst-at-the-walt-disney-company-4324665752?trk=public_jobs_topcard-title","The Walt Disney Company","https://www.linkedin.com/company/the-walt-disney-company?trk=public_jobs_topcard-org-name","About Direct To Consumer

Join Disney’s Content Security Fraud and Paid Sharing Analytics team as a Data Analyst. You will be a key player in enhancing the security features of Disney’s streaming services, including Disney+, Hulu, and ESPN+. This role involves serving product, engineering, and business strategy partners through comprehensive data analysis and insight generation. You will collaborate closely with data engineering to tackle data challenges and advance our content security practices and products.

What You'll Do


 * Convert ambiguous stakeholder queries from Product, Engineering, Business Strategy, Marketing, etc., into structured data requirements and analyses.
 * Provide actionable, data-driven recommendations to stakeholders through detailed analysis.
 * Utilize SQL and scripting languages to analyze both structured and unstructured data.
 * Collaborate with data engineers to ensure the accuracy and quality of data required for analysis.
 * Present insights effectively using data visualization tools or oral presentations.
 * Design and execute A/B testing to evaluate content security features and enhancements.
   
   

Key Qualifications


 * Exceptional curiosity and analytical skills, focusing on insights that drive business outcomes.
 * 3+ years of experience as an data analyst, with advanced proficiency in SQL and Basic proficiency in Python
 * Skilled in data visualization tools such as Tableau, Looker or MicroStrategy.
 * Experienced in A/B testing methodologies for digital products.
 * Strong ability to manage end-to-end analytics projects, from initial requirements to impactful results.
 * Excellent at building relationships with teammates, business partners, and technical colleagues.
 * Highly motivated and capable of working independently.
   
   

Required Education


 * A Bachelor’s degree in Engineering, Computer Science, Statistics, Economics, Mathematics, Finance, or a related field
   
   

Nice To Haves


 * Background in streaming media or subscription-based products.
 * Experience with analytics for application-based products.
 * Familiarity with the tech Industry.
 * A Master's degree in Engineering, Computer Science, Statistics, Economics, Mathematics, Finance, or a related field
   
   

Additional Information

#DISNEYTECH

#DisneyAnalytics

The hiring range for this position in Santa Monica, CA is $97,500 to $130,700 per year, and in New York City, NY is $102,100 to $136,900 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","Over 200 applicants","Full-time","Entry level","Information Technology","Entertainment Providers","$97,500.00/yr - $136,900.00/yr","","","1292","https://www.linkedin.com/jobs/view/data-analyst-at-the-walt-disney-company-4324665752?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Analyst","Houston, TX","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/data-analyst-at-exxonmobil-4337073004?trk=public_jobs_topcard-title","ExxonMobil","https://www.linkedin.com/company/exxonmobil?trk=public_jobs_topcard-org-name","About Us
At ExxonMobil, our vision is to lead in energy innovations that advance modern living and a net-zero future. As one of the world’s largest publicly traded energy and chemical companies, we are powered by a unique and diverse workforce fueled by the pride in what we do and what we stand for.

The success of our Upstream, Product Solutions and Low Carbon Solutions businesses is the result of the talent, curiosity and drive of our people. They bring solutions every day to optimize our strategy in energy, chemicals, lubricants and lower-emissions technologies.

We invite you to bring your ideas to ExxonMobil to help create sustainable solutions that improve quality of life and meet society’s evolving needs. Learn more about our What and our Why and how we can work together.

About Houston
ExxonMobil's state-of-the-art campus north of Houston serves as home to its Upstream, Product Solutions and Low Carbon Solutions businesses and their associated service groups. The facility opened in 2014 and accommodates more than 10,000 employees and visitors.

By bringing many global functional groups together, the campus provides employees with the tools and capabilities needed today, and in the future, to achieve business objectives and accelerate the discovery of new resources, technologies and products. It was designed to foster improved collaboration, creativity and innovation and enhance the company’s ability to attract, develop and retain the top talent in the industry.

The campus is located in Spring, Texas, on 385 wooded acres immediately to the west of Interstate Highway 45 (I-45), at the intersection of I-45 and the Hardy Toll Road, approximately 25 miles from the cultural vibrancy of downtown Houston.

The campus was constructed to the highest standards of energy efficiency and environmental stewardship. Its design incorporates extensive research into best practices in building and workplace design through extensive benchmarking of the world’s top academic, research, and corporate facilities.

About
Learn more about what we do in Houston here.
What role you will play in our team


 * A Data Analyst will leverage data engineering and BI development techniques to pipeline, automate, analyze, and visualize data
 * This role reports to the Continuous Improvement team and supports strategic decision-making for safety, production, and cost optimization by applying data-driven insights
 * This job will be located in Houston, TX
   
   

What You Will Do

 * Develop automated reports, conduct analyses, and provide visibility into KPIs and performance drivers and trends help create final displays of the results, often for formal presentations
 * Build and manage data pipelines integrating structured and unstructured data sources
 * Design, develop, and institute automated workflows utilizing various technologies (SQL, Python, Databricks, Alteryx, Spotfire, MS Power Platform and more) to minimize human error, standardize data, and apply data management best practices with a focus on data integrity and governance
 * Develop ETL processes and maintain application integrations across multiple systems and data sources
 * Coordinate with Field and Engineering to perform analysis on drivers impacting LOE, Capital, and Production
 * Develop, maintain, and distribute recurring reports for Permian Operations timely and accurately
 * Assist in compiling data for regulatory, financial, and accounting reporting
 * Maintain up-to-date and accurate data analysis and tool documentation for reference purposes
 * Evaluate current processes around data entry, data QC, report distribution and provide recommendations and solutions on optimizing existing processes
 * Identify redundancies, automation opportunities, process inefficiencies and provide solutions
 * Communicate, collaborate, and report with multiple departments – field operations, IT, accounting, data support groups, etc
 * Develop, maintain, distribute, and provide training on standardized tools for analyzing LOE, Capital, Production, and SSHE events/observations
 * Stay updated on advancements in data automation, analysis, AI, machine learning, and digital oilfield technologies
 * Mentor engineers/analysts within the team on data engineering and BI development techniques
   
   

About You

 * Bachelor's degree required in Data/Computer Science, Engineering, Mathematics or related field
 * Education should include mathematical and computer training
 * 5+ years experience in a technical role
 * Advanced level of data handling skills to include data integration and creating reports
 * Proficient working with relational databases and generating complex data visualizations
 * Can modify established workflows and evaluate and assess errors as they arise
 * Can interpret, understand, and explain workflows and data processes
 * Performs complex analytics, generates insightful dashboards and or can write code to automate basic redundant workflows/processes
 * Works under limited supervision
 * Works with technical staff and professionals
 * Experience with data visualization including Spotfire and PowerBI applications is required
 * Experience with ETL processes and Workflow automation (Ex: Databricks, Alteryx) is required
 * Advanced proficiency in MS Office suite
   
   

Preferred Qualifications/ Experience

 * Understanding of programming languages such as Python, R, Matlab or similar is highly preferred
 * Subject Matter Expert within select functions applicable to Data Analyst role
   
   

Your Benefits
An ExxonMobil career is one designed to last. Our commitment to you runs deep: our employees grow personally and professionally, with benefits built on our core categories of health, security, finance, and life.

We offer you:


 * Pension Plan: Enrollment is automatic and at no cost to you. The basic benefit is a monthly annuity to be paid to you in retirement for the rest of your life.
 * Savings Plan: You can contribute between 6% and 20% of your pay and are encouraged to enroll right away. If you contribute at least 6% to your savings plan, the Company will contribute a 7% match
 * Comprehensive medical, dental, and vision plans.
 * Culture of Health: Programs and resources to support your wellbeing.
 * Employee Health Advisory Program: Provides confidential professional counseling for you and your family, including tools and resources promoting mental health and resiliency at no additional cost to you.
 * Disability Plan: Income replacement for when you cannot work due to illness or injury occurring on or off the job. Enrollment is automatic and at no cost to you.
   
   

More information on our Company’s benefits can be found at www.exxonmobilfamily.com

Please note benefits may be changed from time to time without notice, subject to applicable law.

Stay connected with us

Learn more at our website

Follow us on LinkedIN and Instagram

Like us on Facebook

Subscribe our channel at YouTube

Employer equal opportunity

ExxonMobil is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, sexual orientation, gender identity, national origin, citizenship status, protected veteran status, genetic information, or physical or mental disability.

Nothing herein is intended to override the corporate separateness of local entities. Working relationships discussed herein do not necessarily represent a reporting connection, but may reflect a functional guidance, stewardship, or service relationship.

Exxon Mobil Corporation has numerous affiliates, many with names that include ExxonMobil, Exxon, Esso and Mobil. For convenience and simplicity, those terms and terms like corporation, company, our, we and its are sometimes used as abbreviated references to specific affiliates or affiliate groups. Abbreviated references describing global or regional operational organizations and global or regional business lines are also sometimes used for convenience and simplicity. Similarly, ExxonMobil has business relationships with thousands of customers, suppliers, governments, and others. For convenience and simplicity, words like venture, joint venture, partnership, co-venturer, and partner are used to indicate business relationships involving common activities and interests, and those words may not indicate precise legal relationships.

Job Id: 82322","Over 200 applicants","Full-time","Entry level","Information Technology","Oil and Gas","","","","1689","https://www.linkedin.com/jobs/view/data-analyst-at-exxonmobil-4337073004?trk=public_jobs_topcard-title","EASY_APPLY",""
"Decision Scientist- Retail Media","Chicago, IL","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/decision-scientist-retail-media-at-safeway-4336817167?trk=public_jobs_topcard-title","Safeway","https://www.linkedin.com/company/safeway?trk=public_jobs_topcard-org-name","Prior to applying it is required that you inform your manager of your desire to apply for a new position.

Why choose us?

Are you ready to take the next step in your career? Join us for an exciting opportunity at Albertsons Companies, where innovation and customer service go hand-in-hand!

At Albertsons Companies, we are looking for someone who’s not just seeking a job, but someone who wants to make an impact. In this role, you’ll have the opportunity to lead, innovate, and contribute to the growth of a company that values great service and lasting customer relationships. This position offers the chance to work in a fast-paced, dynamic environment that’s constantly evolving.

Main Responsibilities

Albertson’s Companies is looking for a Decision Scientist to join our Marketing Science Research team to drive complex, high priority analytics projects that are critical to understanding and adding value to our business. The Marketing Science Research team will work directly with Data Science, Engineering, and our Senior Leadership to help answer questions that influence the direction of the business in both short & long term via data-driven insights and targeted recommendations. In this role, your focus will be designing and executing analysis around our most pressing problems to drive causal understanding of campaign performance.

You have extensive, hands-on SQL & Python knowledge that allows you to parse through large & noisy datasets to validate assumptions and uncover new paths forward. You have a passion for debunking false correlations and understand how to control for the correct variables to develop causal understanding without bias. You have strong stakeholder management skills and aren’t afraid of working with ambiguity; the success as a team depends on identifying the most valuable problems and extracting the right requirements from stakeholders across the business (Strategy, Leadership, Engineering, Innovation) while finding creative solutions to legacy problems. You will report to the Head of Marketing Science Research and act as our lead analyst responsible for causal analysis & test design to answer our business’s most pressing questions.


 * Work with our Engineering and Data Science teams to develop our incrementality testing & methodologies (Bayesian Structural Time Series, Synthetic Approaches, matched market, etc.) for in-store media.
 * Bridge Business, Engineering, and Data Science teams to translate requirements for our Retail Media business into in-store capabilities necessary for robust measurement that will be meaningful to our CPG partners.
 * Help build the story to shift the Retail Media Network Industry toward Incremental Performance Metrics by distinguishing and comparing these success metrics vs. traditional metrics like ROAS.
   
   

The position is in office and based in Pleasanton, CA -Boise, ID- or Itasca, IL.

We Are Looking For Candidates Who Possess The Following


 * A bachelor’s degree in Math, Statistics, Engineering, or an equivalent STEM degree strongly preferred.
 * 5+ years of direct experience in Data Analyst/Science roles.
 * 2+ years’ experience within Advertising/Media Data strongly preferred.
 * Expert SQL skills and robust working knowledge of Data Warehousing required.
 * Strong Python experience required.
 * Demonstrated experience working with & optimizing large, complex data sets.
 * Demonstrated experience surfacing meaningful insights and integrating strategic recommendations that directly influence business trajectory.
 * Skill with data visualization (PowerBI, ggplot, plotly, etc.) & storytelling skills to help translate complex insights to stakeholders with varying levels of data literacy.
 * Strategic bent and ability to drive, build, and optimize analyses and light-weight data products without strict guidance.
   
   

We Also Provide a Variety Of Benefits Including


 * Competitive wages paid weekly
 * Associate discounts
 * Health and financial well-being benefits for eligible associates (Medical, Dental, 401k and more!)
 * Time off (vacation, holidays, sick pay). For eligibility requirements please visit myACI Benefits
 * Leaders invested in your training, career growth and development
 * An inclusive work environment with talented colleagues who reflect the communities we serve
   
   

Our Values – Click below to view video: ACI Values

The salary range is $95,400 to $123,900 annually. Starting salary will vary based on criteria such as location, experience, and qualifications. There may be flexibility for exceptional candidates.

Benefits may include, medical, dental, vision, disability and life insurance, sick pay, PTO/Vacation pay/Flexible Time Off, paid holidays (8-9 days annually) bereavement pay and retirement benefits (such as 401(k) eligibility). Associates in this position are also eligible for a quarterly bonus.

A copy of the full job description can be made available to you.

","132 applicants","Full-time","Entry level","Engineering and Information Technology","Retail","$95,400.00/yr - $123,900.00/yr","Anna Lee","https://www.linkedin.com/in/anna-lee-2a16762","3498","https://www.linkedin.com/jobs/view/decision-scientist-retail-media-at-safeway-4336817167?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer / Analytics Consultant","Tucker, GA","1 week ago","2025-11-25","https://www.linkedin.com/jobs/view/data-engineer-analytics-consultant-at-mckee-nix-and-associates-inc-4324376600?trk=public_jobs_topcard-title","MCKEE NIX AND ASSOCIATES, INC","https://www.linkedin.com/company/mckee-nix-and-associates-inc?trk=public_jobs_topcard-org-name","As a Data Engineer / Analytics Consultant at McKee-Nix & Associates, you will be responsible for building and maintaining data infrastructure, pipelines, and analytics solutions that support business operations, sales strategy, and decision-making. You will work closely with cross-functional teams—such as sales, operations, and leadership—to translate data into insights that improve efficiency, forecasting, and growth across the company’s plumbing and mechanical distribution business.

Key Responsibilities

Develop, maintain, and optimize data pipelines (ETL / ELT) to integrate data from disparate systems (e.g., ERP, CRM, inventory, sales).

Build and maintain data warehouses or data lakes for efficient storage and retrieval of structured and semi-structured data.

Model data to support business reporting, analytics, and predictive insights (forecasting sales, inventory demand, etc.).

Implement data transformation processes, standardize data definitions, and enforce data quality and validation rules.

Create dashboards, reports, and visualizations for business stakeholders (sales leadership, operations, finance) to surface key metrics and trends.

Collaborate with sales and operations teams to identify analytics needs, develop business intelligence solutions, and support data-driven decision-making.

Monitor data pipeline performance, troubleshoot issues, and ensure reliability and scalability.

Establish data governance practices, including documentation, lineage tracking, and data security standards.

Train internal teams on data tools, dashboards, and analytics best practices.

Stay current with industry trends, data tools, and best practices, and recommend improvements to architecture and data processes.



Requirements

Bachelor’s degree in Computer Science, Data Science, Information Systems, or a related field (or equivalent experience).

3+ years of experience in data engineering, analytics, or a related role.

Proficiency in SQL for data modeling and querying.

Experience with data pipeline tools and frameworks (e.g., Python, Apache Airflow, or similar).

Experience working with data storage technologies (data warehouses, lakes, cloud storage).

Familiarity with BI / reporting tools (e.g., Power BI, Tableau, or similar).

Strong problem-solving and analytical thinking skills, with the ability to interpret business needs into technical data requirements.

Excellent communication skills, capable of bridging technical and non-technical stakeholders.

Experience with data governance, documentation, and metadata management.



Benefits

Competitive base salary plus performance-based incentives

Health, dental, and vision insurance

401(k) retirement plan with company matching

Generous paid time off: vacation, sick leave, and company holidays

Flexible work arrangements (hybrid or on-site, depending on business needs)

Professional development support: training, certification reimbursement, and analytics conferences

Travel reimbursement for any on-site business visits or engagements

Opportunities for career advancement into senior analytics, data architecture, or leadership roles

Wellness support: mental health resources, wellness stipend or gym benefit

Paid parental / family leave


","48 applicants","Full-time","Mid-Senior level","Manufacturing","Wholesale","","","","15689100","https://mckeenix.zohorecruit.com/jobs/Careers/839044000000545013/Data-Engineer-Analytics-Consultant?source=LinkedIn-Basic&embedsource=LinkedIn%2BLimited%2BListings","EXTERNAL",""
"Vice President of Applications","Arlington, VA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/vice-president-of-applications-at-richard-wayne-roberts-4347529303?trk=public_jobs_topcard-title","Richard, Wayne & Roberts","https://www.linkedin.com/company/richard-wayne-&-roberts?trk=public_jobs_topcard-org-name","Vice President, Software Engineering & Enterprise Analytics




Location: On-site in Arlington VA

A large-scale, multi-site energy organization is seeking a Vice President of Software Engineering & Enterprise Analytics to define and execute the company’s technical vision across software development, enterprise data platforms, advanced analytics, and artificial intelligence. Reporting to the CIO, this executive will drive innovation, build scalable digital ecosystems, and elevate engineering and analytics maturity across the enterprise.




This leader will guide teams responsible for software engineering, data engineering, data science, enterprise analytics, and AI/ML solution development. The role requires a blend of strategic foresight, organizational leadership, deep technical fluency, and the ability to translate business needs into high-impact digital capabilities.




Key Responsibilities

Strategic Technology Leadership

 * Build and deliver a unified roadmap for enterprise software, data platforms, analytics, and AI/ML solutions.
 * Establish engineering and analytics standards, governance models, and technology-wide architecture principles.
 * Lead modernization initiatives including cloud transformation, platform consolidation, legacy refactoring, and enterprise AI enablement.
 * Present KPIs, value realization, and strategic impact to executive stakeholders.

Software Engineering Excellence

 * Oversee design, development, deployment, and lifecycle management of custom applications and enterprise digital platforms.
 * Champion engineering best practices including Agile delivery, CI/CD, DevSecOps, test automation, and code quality.
 * Approve enterprise architecture decisions and major systems designs.
 * Lead platform evaluations, vendor management, and integration strategy.

Enterprise Analytics, Data, and AI

 * Direct enterprise data strategy including data engineering, governance, lineage, quality, and metadata management.
 * Oversee enterprise analytics services—BI, dashboards, KPI frameworks, predictive analytics, and decision-support tools.
 * Lead development and deployment of AI/ML solutions using enterprise-grade platforms such as: Azure Machine Learning, AWS SageMaker, Google Vertex AI; Databricks, Snowflake Snowpark, H2O.ai, DataRobot, NVIDIA AI frameworks; Kubeflow, MLflow, Airflow, or other model lifecycle orchestration systems
 * Drive adoption of AI for operational efficiency, anomaly detection, reliability optimization, forecasting, automation, and intelligent decision systems.
 * Promote responsible AI practices, model governance, and scalability across business units.

Cross-Functional Partnership

 * Partner with leaders across operations, commercial, finance, supply chain, and plant/field functions to identify high-value digital opportunities.
 * Convert business challenges into integrated technology roadmaps and strategic programs.
 * Act as a trusted advisor to senior leadership on software, data, analytics, and AI strategy.

Organizational Leadership

 * Build, mentor, and retain high-performing software engineering, analytics, data science, and data engineering teams.
 * Oversee budgets, staffing, capacity planning, and vendor/partner ecosystem management.
 * Shape an innovative, inclusive, performance-oriented culture.
 * Establish professional development pathways and succession planning.

Additional Responsibilities

 * Ensure compliance with corporate policies, cybersecurity standards, and regulatory requirements.
 * Maintain awareness of emerging technologies in software engineering, cloud ecosystems, industrial automation, and enterprise AI.
 * Participate in steering committees and cross-functional leadership forums.
 * Support special projects and technology initiatives as needed.




Qualifications

 * Bachelor’s degree in Computer Science, Data Science, Engineering, or a related field; master’s preferred.
 * 10+ years of progressive leadership across software engineering, enterprise data, analytics, AI/ML, or platform engineering.
 * At least 2 years in an executive or senior leadership role overseeing multi-disciplinary technical teams.
 * Proven success deploying enterprise-scale platforms integrating application development, data engineering, and advanced analytics/AI.
 * Deep expertise in:
 * Application architecture and distributed systems
 * Enterprise AI/ML platforms (SageMaker, Vertex AI, Azure ML, Databricks, H2O.ai, etc.)
 * Data warehousing/lakehouse technologies
 * BI and visualization platforms
 * Strong executive communication skills and the ability to influence senior leadership.
 * Business acumen and the ability to tie technology strategy directly to measurable outcomes.
 * Commitment to building diverse, equitable, and inclusive teams.

","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Oil and Gas","","Brianna F.","https://www.linkedin.com/in/briannafajohn","15842","https://www.linkedin.com/jobs/view/vice-president-of-applications-at-richard-wayne-roberts-4347529303?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr Analyst, Data Engineer (SQL | Python | Databricks)","Columbus, OH","2 weeks ago","2025-11-18","https://www.linkedin.com/jobs/view/sr-analyst-data-engineer-sql-python-databricks-at-nationwide-4341165168?trk=public_jobs_topcard-title","Nationwide","https://www.linkedin.com/company/nationwide?trk=public_jobs_topcard-org-name","If you’re passionate about innovation and love working in an environment where you can constantly improve and adopt new technologies to drive business results, then Nationwide’s Information Technology team could be the place for you! At Nationwide®, “on your side” goes beyond just words. Our customers are at the center of everything we do and we’re looking for associates who are passionate about delivering extraordinary care.

This role does not qualify for employer-sponsored work authorization. Nationwide does not participate in the Stem OPT Extension program.

This role will be filled in a hybrid capacity, with collaboration taking place in either our Columbus OH, Des Moines IA, or the Scottsdale AZ office 2 days per week.

Join the team behind Gizmo, the core data platform supporting the Property & Casualty (P&C) business. As a Senior Analyst, Data Engineer, you’ll be responsible for building and maintaining data pipelines that drive operational reporting. You’ll work with tools like Databricks, Python, and SQL to deliver clean, structured data that meets the needs of analysts and business stakeholders. Your focus will be on optimizing workflows for performance and scalability, ensuring data quality across multiple sources, and contributing to automation and process improvements.

This role offers the chance to work with a modern tech stack and make a direct impact on business decision-making and operational efficiency. While Databricks, Python, and SQL are essential, experience with Git, CI/CD tools, and data modeling is a plus. You’ll be part of a collaborative team committed to delivering trusted data solutions and continuous improvement.

Job Description Summary

Nationwide’s industry leading workforce is passionate about creating data solutions that are secure, reliable and efficient in support of our mission to provide extraordinary care. Nationwide embraces an agile work environment and collaborative culture through the understanding of business processes, relationship entities and requirements using data analysis, quality, visualization, governance, engineering, robotic process automation, and machine learning to produce targeted data solutions. If you have the drive and desire to be part of a future forward data enabled culture, we want to hear from you.

As a Data Engineer you’ll be responsible for acquiring, curating, and publishing data for analytical or operational uses. Data should be in a ready-to-use form that creates a single version of the truth across all data consumers, including business users, data scientists, and Technology. Ready-to-use data can be for both real time and batch data processes and may include unstructured data. Successful data engineers have the skills typically required for the full lifecycle software engineering development from translating requirements into design, development, testing, deployment, and production maintenance tasks. You’ll have the opportunity to work with various technologies from big data, relational and SQL databases, unstructured data technology, and programming languages.

Job Description

Key Responsibilities:


 * Provides technical consultation on data product projects by analyzing end to end data product requirements and existing business processes to assist in the design, development and implementation of data products.
 * Translates business data stories into a technical story breakdown structure and work estimate so value and fit for a schedule or sprint is determined.
 * Applies secure software and systems engineering practices throughout the delivery lifecycle to ensure our data and technology solutions are protected from threats and vulnerabilities.
 * Develops and maintains scaleable data pipelines for both streaming and batch requirements.
 * Assists in building out new API integrations to support continuing increases in data volume and complexity.
 * Practices code management and integration with engineering Git principle and practice repositories.
   
   

May Perform Other Responsibilities As Assigned.

Reporting Relationships: Reports to Manager/Director Data Leader.

Typical Skills And Experiences

Education: Undergraduate studies in computer science, management information systems, business, statistics, math, a related field or comparable experience and education strongly preferred. Graduate studies in business, statistics, math, computer science or a related field are a plus.

License/Certification/Designation: Certifications are not required but encouraged.

Experience: One to three years of relevant experience with data quality rules, data management organization/standards or practices. Experience with query languages, statistical software and data wrangling and provisioning tools. Experience analyzing trends and patterns in structured and unstructured data to support business problem solving. Insurance/financial services industry knowledge a plus.

Knowledge, Abilities and Skills: Data application and practices knowledge. Skilled with modern programming and scripting languages (e.g., SQL, R, Python, Spark, UNIX Shell scripting, Perl, or Ruby). Good oral and written communication skills.

Other criteria, including leadership skills, competencies and experiences may take precedence.

Staffing exceptions to the above must be approved by the hiring manager’s leader and HR Business Partner.

Values: Regularly and consistently demonstrates the Nationwide Values.

Job Conditions

Overtime Eligibility: Exempt (Not Eligible)

Working Conditions: Normal office environment.

ADA: The above statements cover what are generally believed to be principal and essential functions of this job. Specific circumstances may allow or require some people assigned to the job to perform a somewhat different combination of duties.

Benefits

We have an array of benefits to fit your needs, including: medical/dental/vision, life insurance, short and long term disability coverage, paid time off with newly hired associates receiving a minimum of 18 days paid time off each full calendar year pro-rated quarterly based on hire date, nine paid holidays, 8 hours of Lifetime paid time off, 8 hours of Unity Day paid time off, 401(k) with company match, company-paid pension plan, business casual attire, and more. To learn more about the benefits we offer, click here.

Nationwide is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive culture where everyone feels challenged, appreciated, respected and engaged. Nationwide prohibits discrimination and harassment and affords equal employment opportunities to employees and applicants without regard to any characteristic (or classification) protected by applicable law.

Smoke-Free Iowa Statement: Nationwide Mutual Insurance Company, its affiliates and subsidiaries comply with the Iowa Smokefree Air Act. Smoking is prohibited in all enclosed areas on or around company premises as well as company issued vehicles. The company offers designated smoking areas in which smoking is permitted at each individual location. The Act prohibits retaliation for reporting complaints or violations. For more information on the Iowa Smokefree Air Act, individuals may contact the Smokefree Air Act Helpline at 888-944-2247.

Note To Employment Agencies

We value the partnerships we have built with our preferred vendors. Nationwide does not accept unsolicited resumes from employment agencies. All resumes submitted by employment agencies directly to any Nationwide employee or hiring manager in any form without a signed Nationwide Client Services Agreement on file and search engagement for that position will be deemed unsolicited in nature. No fee will be paid in the event the candidate is subsequently hired as a result of the referral or through other means.

","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Insurance","","","","2340","https://careers.nationwide.com/sr-analyst-data-engineer-sql-python-databricks/job/17529933568B51EBBA0EFC1E1356193D?src=LinkedIn","EXTERNAL",""
"Decision Scientist- Retail Media","Boise, ID","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/decision-scientist-retail-media-at-safeway-4337026136?trk=public_jobs_topcard-title","Safeway","https://www.linkedin.com/company/safeway?trk=public_jobs_topcard-org-name","Prior to applying it is required that you inform your manager of your desire to apply for a new position.

Why choose us?

Are you ready to take the next step in your career? Join us for an exciting opportunity at Albertsons Companies, where innovation and customer service go hand-in-hand!

At Albertsons Companies, we are looking for someone who’s not just seeking a job, but someone who wants to make an impact. In this role, you’ll have the opportunity to lead, innovate, and contribute to the growth of a company that values great service and lasting customer relationships. This position offers the chance to work in a fast-paced, dynamic environment that’s constantly evolving.

Main Responsibilities

Albertson’s Companies is looking for a Decision Scientist to join our Marketing Science Research team to drive complex, high priority analytics projects that are critical to understanding and adding value to our business. The Marketing Science Research team will work directly with Data Science, Engineering, and our Senior Leadership to help answer questions that influence the direction of the business in both short & long term via data-driven insights and targeted recommendations. In this role, your focus will be designing and executing analysis around our most pressing problems to drive causal understanding of campaign performance.

You have extensive, hands-on SQL & Python knowledge that allows you to parse through large & noisy datasets to validate assumptions and uncover new paths forward. You have a passion for debunking false correlations and understand how to control for the correct variables to develop causal understanding without bias. You have strong stakeholder management skills and aren’t afraid of working with ambiguity; the success as a team depends on identifying the most valuable problems and extracting the right requirements from stakeholders across the business (Strategy, Leadership, Engineering, Innovation) while finding creative solutions to legacy problems. You will report to the Head of Marketing Science Research and act as our lead analyst responsible for causal analysis & test design to answer our business’s most pressing questions.


 * Work with our Engineering and Data Science teams to develop our incrementality testing & methodologies (Bayesian Structural Time Series, Synthetic Approaches, matched market, etc.) for in-store media.
 * Bridge Business, Engineering, and Data Science teams to translate requirements for our Retail Media business into in-store capabilities necessary for robust measurement that will be meaningful to our CPG partners.
 * Help build the story to shift the Retail Media Network Industry toward Incremental Performance Metrics by distinguishing and comparing these success metrics vs. traditional metrics like ROAS.
   
   

The position is in office and based in Pleasanton, CA -Boise, ID- or Itasca, IL.

We Are Looking For Candidates Who Possess The Following


 * A bachelor’s degree in Math, Statistics, Engineering, or an equivalent STEM degree strongly preferred.
 * 5+ years of direct experience in Data Analyst/Science roles.
 * 2+ years’ experience within Advertising/Media Data strongly preferred.
 * Expert SQL skills and robust working knowledge of Data Warehousing required.
 * Strong Python experience required.
 * Demonstrated experience working with & optimizing large, complex data sets.
 * Demonstrated experience surfacing meaningful insights and integrating strategic recommendations that directly influence business trajectory.
 * Skill with data visualization (PowerBI, ggplot, plotly, etc.) & storytelling skills to help translate complex insights to stakeholders with varying levels of data literacy.
 * Strategic bent and ability to drive, build, and optimize analyses and light-weight data products without strict guidance.
   
   

We Also Provide a Variety Of Benefits Including


 * Competitive wages paid weekly
 * Associate discounts
 * Health and financial well-being benefits for eligible associates (Medical, Dental, 401k and more!)
 * Time off (vacation, holidays, sick pay). For eligibility requirements please visit myACI Benefits
 * Leaders invested in your training, career growth and development
 * An inclusive work environment with talented colleagues who reflect the communities we serve
   
   

Our Values – Click below to view video: ACI Values

The salary range is $95,400 to $123,900 annually. Starting salary will vary based on criteria such as location, experience, and qualifications. There may be flexibility for exceptional candidates.

Benefits may include, medical, dental, vision, disability and life insurance, sick pay, PTO/Vacation pay/Flexible Time Off, paid holidays (8-9 days annually) bereavement pay and retirement benefits (such as 401(k) eligibility). Associates in this position are also eligible for a quarterly bonus.

A copy of the full job description can be made available to you.

","69 applicants","Full-time","Entry level","Engineering and Information Technology","Retail","$95,400.00/yr - $123,900.00/yr","Anna Lee","https://www.linkedin.com/in/anna-lee-2a16762","3498","https://www.linkedin.com/jobs/view/decision-scientist-retail-media-at-safeway-4337026136?trk=public_jobs_topcard-title","EASY_APPLY",""
"Financial Data Analyst","Austin, TX","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/financial-data-analyst-at-austin-capital-bank-4338377127?trk=public_jobs_topcard-title","Austin Capital Bank","https://www.linkedin.com/company/austin-capital-bank?trk=public_jobs_topcard-org-name","Full-Time | Austin Capital Bank | Austin, TX

Company Overview

Austin Capital Bank is a fast-growing, tech-forward community bank based in Austin, Texas. We’re a nationwide leader in responsible financial innovation—combining the stability of a 500 million dollar regulated bank with the agility of a fintech. Our mission is to deliver simple, reliable, and customer-friendly financial products that improve the financial well-being of people across the country. Our products have touched over a million customers in all 50 states.

We’ve been recognized on the Inc. 5000 list of fastest-growing companies multiple years in a row—and we’re just getting started. Our team members are approachable, attentive, and trusted problem-solvers who take pride in doing right by our customers and each other.

Why You’ll Love Working Here


 * A team that feels like a team – Supportive coworkers, approachable leaders, and a culture that values listening, learning, collaboration…and good snacks
 * It feels great to contribute to a company that’s winning and growing – our financials say it all – we’re nicely profitable and gaining market share.
 * Opportunities to grow – Career development, tuition assistance, and room to explore roles across the bank.
 * 100% Employer-paid medical, dental, & vision insurance – Full coverage for employee-only plans, with affordable family options.
 * Wellness program – Extra funds from us to help cover your out-of-pocket medical expenses.
 * Generous paid time off – Start with 16 days per year that grows with tenure.
 * Paid holidays – 11+ per year, so you can truly unplug.
 * 401(k) with 4% employer match – Invest in your future with our support.
   
   

Our Core Values

At Austin Capital Bank, every team member embodies our values. We work, hire, promote, and lead by them:


 * Wicked Smart – Intellectually and emotionally self-aware.
 * Take Initiative – A bias to action, movement forward.
 * No Big Egos – Self-confidence with humility.
 * Honesty – Respectful and direct forthright communication.
 * Curiosity – Innovation doesn’t come from drawing within the lines.
   
   

If you’re someone who rolls up their sleeves, leads with integrity, and believes that kindness and high performance can coexist, you’ll fit right in.

About The Role

Austin Capital Bank (ACB) is hiring a Financial Data Analyst to align our financial forecasting and reporting with Data Analytics organization. You will own the data structures, models, and analyses that power financial planning and forecasting, partner closely with Finance during monthly/quarterly close, and deliver high-quality insights to business and product leaders. The ideal candidate combines strong finance acumen (budgeting/forecasting/variance analysis) with hands-on data skills (SQL, cloud data warehouses, and modern analytics tools).

What You’ll Do

Finance Planning, Forecasting & Reporting


 * Build and maintain driver-based financial models to support annual operating plans and rolling forecasts (revenue, COGS, Opex, headcount, capex)
 * Perform monthly variance analysis (Actuals vs. Budget/Forecast) and partner with Finance and the data team to explain movements, uncover drivers, and recommend corrective actions
 * Create scenario/sensitivity analyses (best/base/worst cases) for revenue, unit economics, and margin outcomes; quantify risks and opportunities
 * Support month-end and quarter-end close with reconciliations, accruals, and cohort/deferral schedules; ensure alignment between finance reports and source data
 * Develop standardized KPI packages and executive dashboards (e.g., revenue, contribution margin, CAC/LTV, churn/retention, cohort profitability, cash runway), refreshing on a predictable cadence
   
   

Data Analytics


 * Write or generate high-quality SQL to extract, join, and transform data from our cloud data warehouse; curate reliable, documented datasets for Finance and Accounting
 * Collaborate with analytics engineering (e.g., dbt) to productionize finance models and ensure version control, testing, and lineage
 * Build automated data quality checks (reconciliation rules, threshold monitors) and partner with Finance to resolve exceptions
 * Optimize query performance and data partitioning for timely reporting across month-end close and weekly forecast cycles
 * Partner with fraud and product teams to incorporate key drivers (pricing, interchange, charge-offs, fraud losses, partner fees) into finance datasets
   
   

Stakeholder Enablement & Communication


 * Translate complex data findings into concise narratives, visuals, and clear recommendations for Finance and the Executive Team
 * Establish SLAs for recurring deliverables (close packages, board metrics, forecast refreshes) and communicate deviations proactively
 * Document assumptions, definitions, and metric logic; drive alignment on a single source of truth for financial KPIs
   
   

Required

What You Bring


 * 3–6 years in FP&A, financial analysis, or data analytics supporting finance within fintech, banking, SaaS, or similarly data-rich domains
 * Intermediate SQL with demonstrated experience querying large datasets in a cloud data warehouse (e.g., Snowflake, BigQuery, Redshift)
 * Strong proficiency in Excel/Sheets (index/match/xlookup, nested logic, pivoting, scenario/sensitivity modeling)
 * Solid understanding of financial statements (P&L, balance sheet, cash flow), GAAP concepts (revenue recognition, accruals, deferrals), and variance analysis
 * Experience building driver-based forecast models and operational KPI dashboards for executive audiences
 * Clear, concise communication skills; ability to translate technical details into business insights
   
   

Preferred


 * Experience with dbt and modular analytics modeling; familiarity with CI/testing and documentation practices
 * Python (pandas, numpy) or R for analysis, reconciliation, or statistical analysis
 * Familiarity with BI/analytics tools (ThoughtSpot, Looker, Tableau, Power BI) including data modeling and governance
 * Exposure to banking/fintech economics: interchange, ACH, BIN sponsorship, fraud losses, charge-offs, loss provisioning, and cohort/retention analysis
 * Experience designing metric definitions and data contracts that align Finance with Product, Risk, and Operations
 * Hands-on use of AI prompts/agents for data tasks, with evidence of rigorous validation and controls
   
   

Please only submit an application if you are currently based in Austin Texas.

Powered by JazzHR

AoO08Nio5b","122 applicants","Full-time","Mid-Senior level","Information Technology","Internet Publishing","","","","33260301","https://www.linkedin.com/jobs/view/financial-data-analyst-at-austin-capital-bank-4338377127?trk=public_jobs_topcard-title","EASY_APPLY",""
"Regional Entitlements Manager","Charlotte, NC","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/regional-entitlements-manager-at-circle-k-4324337394?trk=public_jobs_topcard-title","Circle K","https://ca.linkedin.com/company/circle-k?trk=public_jobs_topcard-org-name","Job Description Summary

The primary role of the Regional Entitlements Manager is to accurately manage and track the entitlements phase (including but not limited to annexation, rezonings, horizontal and vertical permitting) of Circle K’s project pipeline. This role manages Circle K vendors who are responsible for meeting the deadlines to obtain permits (site development permits, erosion control, stormwater quantity/quality, building permits, health permits, utility approvals, etc.) to deliver construction projects on time.

Essential Duties

The position includes, but is not limited to, the following essential job duties, responsibilities, and requirements:


 * Responsible for managing and monitoring project due diligence, lease contingencies, purchase & sale agreement requirements, and permitting processes and procedures that impact Circle K’s project pipeline
 * Responsible for delivering projects on time to the construction field team by ensuring all lease contingencies, and permitting approvals have been properly satisfied
 * Maintain accurate records of all permit applications, approvals, and denials, and provide regular reports to management on the status of permitting activities
 * Oversees External Project Managers and collaborates closely with members of the Circle K field teams
 * Accurately manages project pipeline utilizing our internal tools, spreadsheets and data base on a rolling 5-year basis
 * Lead, schedule, and manage project meetings and calls
 * Ability to assess the impact of regulatory requirements on the budget & schedule of Circle K pipeline projects
 * Work with the team to determine reporting needs related to project management
 * Identify process inefficiencies and implement improvements. Lead related trainings on a national level
 * Participate in quarterly accountability meetings and annual pipeline planning meetings
 * Perform additional tasks as assigned
   
   

Job Requirements


 * Bachelor’s degree preferred, or equivalent combination of education, training and experience
 * Strong communication skills required
 * Self-directed and self-motivated problem solver, comfortable working independently and in cross-functional teams.
 * Highly organized with the ability to manage multiple projects, meet tight deadlines, and continually prioritize and re-prioritize tasks as new projects are assigned.
 * Must possess strong analytical skills and strong attention to detail.
   
   

Physical Requirements

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Complete physical activity inventory of the position includes:


 * Sit for long periods of time.
 * Operate computer keyboard and mouse for data entry.
 * View computer monitor
 * Hear and speak via telephone.
 * Reach forward and/or overhead
 * Occasionally lift up to 20 pounds
   
   

Preferred Qualifications


 * 5+ years of relevant work experience with Real Estate, Land Use Planning, and Construction
 * A four-year degree in Land/Urban Planning, Landscape Architecture, Civil Engineering, Construction Management or a related field
 * Ability to read and interpret site civil plans and architectural building elevations
 * 2+ years of experience establishing and managing project schedules using industry standard software such as Smartsheets, Microsoft Project, Procore, etc.
 * Advanced Microsoft Excel proficiency, and ability to become proficient with additional softwares and applications.
   
   

Work Environment

The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Working conditions inventory of the position includes:


 * The noise level in the work environment is usually moderate at a normal range.
 * The lighting will include natural light from the outside as well as fluorescent lighting throughout the work areas.
 * Work with minimum direction and periodic supervision.
   
   

Job Description Acknowledgment

This Job Description indicates the general nature and level of work to be performed in this position and it is not intended to contain or be interpreted as a comprehensive inventory of all the duties, responsibilities, functions and qualifications required of the position. The incumbent may be asked to perform other duties and will be evaluated, in part, on performance of the tasks listed in this job description. As with all positions, the responsibilities and duties of this position may change. The Company reserves the right to revise this Job Description at any time with or without notice. This Job Description does not constitute a contract for employment and either the incumbent or the Company may terminate employment at any time, for any reason, with or without notice.

Circle K is an Equal Opportunity Employer. The Company complies with the Americans with Disabilities Act (the ADA) and all state and local disability laws. Applicants with disabilities may be entitled to a reasonable accommodation under the terms of the ADA and certain state or local laws as long as it does not impose an undue hardship on the Company. Please inform the Company’s Human Resources Representative if you need assistance completing any forms or to otherwise participate in the application process.

#onsite

Circle K is an Equal Opportunity Employer.

The Company complies with the Americans with Disabilities Act (the ADA) and all state and local disability laws. Applicants with disabilities may be entitled to a reasonable accommodation under the terms of the ADA and certain state or local laws as long as it does not impose an undue hardship on the Company. Please inform the Company’s Human Resources Representative if you need assistance completing any forms or to otherwise participate in the application process.

Click below to review information about our company's use of the federal E-Verify program to check work eligibility:

In English

In Spanish

","Be among the first 25 applicants","Full-time","Mid-Senior level","Sales and Business Development","Retail","","Whitney Lin, MBA","https://www.linkedin.com/in/whitney-wall","12446","https://www.linkedin.com/jobs/view/regional-entitlements-manager-at-circle-k-4324337394?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data & Analytics Engineer","New York, NY","1 week ago","2025-11-22","https://www.linkedin.com/jobs/view/data-analytics-engineer-at-tandem-4338389676?trk=public_jobs_topcard-title","Tandem","https://www.linkedin.com/company/withtandem?trk=public_jobs_topcard-org-name","Why you should join us

Tandem is a generational opportunity to rethink how we bring new therapies to market, and our path to doing so is significantly de-risked – we have:


 * Exponential organic growth: We have product-market fit and are growing rapidly through word-of-mouth. Tandem supports thousands of patients every day, is doubling doctor users every quarter, and is working with the largest biopharma companies in the world.
 * An AI-first business model: Our approach is distinctly enabled by AI, but our business will get stronger (not commoditized) as foundation models improve. We are building durability through two-sided network effects that will compound over time.
 * Top tier investors: With the traction to support conviction in our model, we raised significant funding from investors (Thrive Capital and General Catalyst) to build an exceptional team of engineers and operators.
   
   

Our number one priority is scaling to market demand. We are looking for individuals who are high horsepower, high throughput, and hyper resourceful to help us increase capacity and grow. We move fast and need to move faster.

All full-time roles are in person in New York. You can learn more about working with us in the last section of this page.

About The Role

As a Data & Analytics Engineer at Tandem, you’ll build the data foundation that powers how we operate, measure, and grow. You’ll design and maintain our core data models, pipelines, and reporting infrastructure — ensuring the right people have access to clean, trustworthy, decision-grade data at the speed we need to move. This is a cross-functional, impact-heavy role where you’ll work closely with product, ops, growth, and leadership to build the systems that enable better, faster decisions across the company.

You’ll also help define our data & analytics engineering practices: how we structure metrics, review code, manage pipelines, and build for scale. Your work will directly support everything from product usage visibility to operational performance to life sciences client reporting.

This is a demanding role, with a high level of autonomy and responsibility. You will be expected to ""act like an owner"" and commit yourself to Tandem's success. If you are low-ego, hungry to learn, and excited about intense, impactful work that drives both company growth and accelerated career progression, we want to hear from you.

If you join, you will:


 * Build and maintain the core data models that serve as the foundation for internal analytics and client-facing insights
 * Design and operate the data pipelines that transform raw sources into clean, analytics-ready tables
 * Create dashboards and reporting tools that drive performance visibility and decision-making across product, ops, and GTM
 * Define and enforce metric consistency across teams — including core business KPIs and product usage definitions
 * Help improve and scale our analytics stack (we use GCP BigQuery and Dataform, Fivetran, Postgres, and dashboarding tools)
 * Collaborate with stakeholders across teams to understand data needs and translate them into reliable systems
 * Contribute to internal data culture through documentation, education, and code quality standards
   
   

We’re looking for you if you have:


 * 3–6 years of experience in data engineering, analytics engineering, or a technical data analyst role with production ownership
 * Expert-level SQL and comfort working in a code-first environment (versioning, testing, documentation)
 * Experience designing data models that balance usability, performance, and long-term maintainability
 * Familiarity with the modern data stack — dbt, Fivetran, Airflow, GCP/AWS/Snowflake, Metabase (or equivalents)
 * Strong written and verbal communication that allows you to be an effective participant in both internal debates and external relationships
 * Track record of moving quickly, finding shortcuts, and going to unreasonable lengths to deliver on goals
 * High NPS with your former teammates
   
   

This is a list of ideal qualifications for this position. If you don't meet every single one of them, you should still consider applying! We’re excited to work with people from underrepresented backgrounds, and we encourage people from all backgrounds to apply.

Working with us

Tandem is based in New York, with our full team working out of a beautiful and spacious office in SoHo.

We run as a high-trust environment with high autonomy, which requires that everyone is fully competent and operates in line with our principles:


 * Commit to audacity. ""Whether you think you can, or you think you can't – you're right.”
 * Do the math. Be rigorous, assume nothing.
 * Find the shortest path. Use hacks, favors, and backdoors. Only take a longer road on purpose.
 * Spit it out. Be direct, invite critique, avoid equivocation – we want right answers.
 * Be demanding and supportive. Expect excellence from everyone and offer help to achieve it.
 * Do what it takes to be number 1. We work hard to make sure we win.
   
   

We provide competitive compensation with meaningful equity (for full-time employees). Everyone who joins early will be a major contributor to our success, and we reflect this through ownership and pay.

We also provide rich benefits to ensure you can focus on creating impact (for full-time employees):


 * Fully covered medical, vision, and dental insurance.
 * Memberships for One Medical, Talkspace, Teladoc, and Kindbody.
 * Unlimited paid time off (PTO) and 16 weeks of parental leave.
 * 401K plan setup, FSA option, commuter benefits, and DashPass.
 * Lunch at the office every day and Dinner at the office after 7 pm.
   
   

Our salary ranges are based on paying competitively for our company’s size and industry, and are one part of the total compensation package that also includes equity, benefits, and other opportunities at Tandem (for full-time employees). Individual pay decisions are ultimately based on a number of factors, including qualifications for the role, experience level, skillset, geography, and balancing internal equity.

Tandem is an equal opportunity employer and does not discriminate on the basis of race, gender, sexual orientation, gender identity/expression, national origin, disability, age, genetic information, veteran status, marital status, pregnancy or related condition, or any other basis protected by law.

Compensation Range: $150K - $200K

","139 applicants","Full-time","Entry level","Information Technology","Technology, Information and Internet","$150,000.00/yr - $200,000.00/yr","","","93670294","https://jobs.ashbyhq.com/tandem/5a8640ce-8a3e-40bf-afd1-f0b63a0a2ef3/application?utm_source=6qaMboprve","EXTERNAL",""
"Data Analyst","Sunnyvale, CA","14 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-analyst-at-avance-consulting-4324386362?trk=public_jobs_topcard-title","Avance Consulting","https://uk.linkedin.com/company/avance-services?trk=public_jobs_topcard-org-name","Job Title : Data Analyst with Pyspark & AB Testing

Location : Sunnyvale, CA ( Onsite )

Job Type : Fulltime







Required Qualifications

 * At least 4 years of experience in Information Technology
 * Proven years of applied experience in exploratory data analysis, devising, deploying and servicing statistical models
 * Strong hands-on experience with data mining and data visualization, Tableau, A/B Testing, SQL for developing and creating data pipelines to source and transform Data
 * Strong experience using Python, Advanced SQL and PySpar

Preferred Qualifications

 * Advanced degree with Master’s or above in area of quantitative discipline such as Statistics, Applied Math, Operations Research, Computer Science, Engineering or Physics or a related field
 * Marketing domain background (Web analytics, click stream data analysis, and other KPI’s on marketing campaigns
 * Knowledge of Machine Learning techniques","Over 200 applicants","Full-time","Mid-Senior level","Analyst","Oil and Gas","","Pavankalyan Kalva","https://www.linkedin.com/in/pavankalyan-kalva","613812","http://vancy-8X030853@apply.wisestep-inc.com","EXTERNAL",""
"AI Researcher","Irvine, CA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/ai-researcher-at-western-digital-4347620457?trk=public_jobs_topcard-title","Western Digital","https://www.linkedin.com/company/western-digital?trk=public_jobs_topcard-org-name","At Western Digital, our vision is to power global innovation and push the boundaries of technology to make what you thought was once impossible, possible.



At our core, Western Digital is a company of problem solvers. People achieve extraordinary things given the right technology. For decades, we’ve been doing just that—our technology helped people put a man on the moon and capture the first-ever picture of a black hole.



We offer an expansive portfolio of technologies, HDDs, and platforms for business, creative professionals, and consumers alike under our Western Digital®, WD®, WD_BLACK™, and SanDisk® Professional brands.



We are a key partner to some of the largest and highest-growth organizations in the world. From enabling systems to make cities safer and more connected, to powering the data centers behind many of the world’s biggest companies and hyperscale cloud providers, to meeting the massive and ever-growing data storage needs of the AI era, Western Digital is fueling a brighter, smarter future.



Today’s exceptional challenges require your unique skills. Together, we can build the future of data storage.





Job Description



Western Digital creates technologies that power the world’s data infrastructure. From advanced storage solutions to intelligent data systems, we enable customers, businesses, and partners to unlock the full potential of their data. Across our Sales and Marketing organization, we continue to innovate, streamline operations, and accelerate growth through modern analytics and AI-driven automation.



We are seeking an AI Researcher who will evaluate how artificial intelligence can improve processes, reduce operational costs, generate additional revenue opportunities, and enhance productivity across the Sales and Marketing organization. This is a research-focused role, not a developer position. The AI Researcher will analyze current workflows, tools, and data usage patterns, identify opportunities for AI-driven impact, and advise internal engineering and development teams on which solutions should be prioritized for implementation.



The ideal candidate blends strategic thinking, technical understanding, and business acumen. They will research new AI techniques, assess feasibility, map processes, calculate ROI, and propose clear, actionable recommendations that enable developers and systems teams to build the highest-value solutions.



ESSENTIAL DUTIES AND RESPONSIBILITIES



 * Conduct research on AI and machine learning capabilities that can support Sales and Marketing goals such as cost reduction, lead generation, funnel optimization, and workflow automation
   
   

 * Analyze current organizational processes and identify high-ROI opportunities for AI intervention
   
   

 * Evaluate and score potential automation or optimization projects based on feasibility, cost, impact, and data readiness
   
   

 * Partner closely with developers, analysts, and system owners to translate research findings into actionable system enhancements
   
   

 * Create research briefs, business cases, and recommendation documents for leadership
   
   

 * Propose frameworks for automated lead scoring, customer segmentation, predictive insights, content generation workflows, and marketing efficiency improvements
   
   

 * Evaluate vendor AI tools, platforms, and integrations; compare build vs buy recommendations
   
   

 * Develop a roadmap for AI adoption within Sales and Marketing, aligning with business priorities and budget constraints
   
   

 * Stay current on industry trends, LLM advancements, AI-driven marketing technologies, and competitive benchmarks
   
   

 * Conduct ethical and risk assessments for any proposed AI solution, ensuring alignment with security and compliance standards
   
   

What Success Looks Like



 * Identifying high-value opportunities that result in meaningful cost savings or efficiency gains
   
   

 * Providing clear, actionable, and prioritized recommendations to developers
   
   

 * Delivering research that accelerates WD’s AI adoption and supports organizational decision-making
   
   

 * Creating a scalable and repeatable evaluation framework for future AI initiatives
   
   
   
   

Qualifications



REQUIRED



 * Bachelor’s degree in Data Science, Computer Science, Applied Math, Business Analytics, or related field
   
   

 * 5+ years of experience in AI research, marketing analytics, sales operations research, or similar roles
   
   

SKILLS



 * Strong analytical and quantitative skills, including the ability to model savings, revenue lift, and efficiency gains

 * Familiarity with AI technologies including LLMs, GenAI platforms, embeddings, RAG systems, and marketing automation tools
   
   

 * Comfortable evaluating AI workflows, APIs, and vendor features to assess feasibility
   
   

 * Excellent understanding of Sales and Marketing processes including funnel analytics, lead generation, audience segmentation, and campaign optimization
   
   

 * Strong documentation and communication abilities; able to translate research insights for non-technical stakeholders
   
   

 * Ability to partner cross-functionally with product managers, developers, and business leaders
   
   

PREFERRED



 * Experience working in a Sales, Marketing, or E-Commerce environment
   
   

 * Exposure to Adobe Marketing ecosystem (Analytics, Target, Marketo), Salesforce, or similar platforms
   
   

 * Prior involvement in cost-optimization programs or operational efficiency projects
   
   

 * Experience developing business cases or ROI analyses for technical investments
   
   

 * Understanding of data governance, AI ethics, and responsible AI practices
   
   
   
   

Additional Information



Western Digital is committed to providing equal opportunities to all applicants and employees and will not discriminate against any applicant or employee based on their race, color, ancestry, religion (including religious dress and grooming standards), sex (including pregnancy, childbirth or related medical conditions, breastfeeding or related medical conditions), gender (including a person’s gender identity, gender expression, and gender-related appearance and behavior, whether or not stereotypically associated with the person’s assigned sex at birth), age, national origin, sexual orientation, medical condition, marital status (including domestic partnership status), physical disability, mental disability, medical condition, genetic information, protected medical and family care leave, Civil Air Patrol status, military and veteran status, or other legally protected characteristics. We also prohibit harassment of any individual on any of the characteristics listed above. Our non-discrimination policy applies to all aspects of employment. We comply with the laws and regulations set forth in the ""Know Your Rights: Workplace Discrimination is Illegal” poster. Our pay transparency policy is available here.



Western Digital thrives on the power and potential of diversity. As a global company, we believe the most effective way to embrace the diversity of our customers and communities is to mirror it from within. We believe the fusion of various perspectives results in the best outcomes for our employees, our company, our customers, and the world around us. We are committed to an inclusive environment where every individual can thrive through a sense of belonging, respect and contribution.



Western Digital is committed to offering opportunities to applicants with disabilities and ensuring all candidates can successfully navigate our careers website and our hiring process. Please contact us at jobs.accommodations@wdc.com to advise us of your accommodation request. In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying.



Based on our experience, we anticipate that the application deadline will be 2/25/2026 (3 months from posting), although we reserve the right to close the application process sooner if we hire an applicant for this position before the application deadline. If we are not able to hire someone from this role before the application deadline, we will update this posting with a new anticipated application deadline.



Compensation & Benefits Details



 * An employee’s pay position within the salary range may be based on several factors including but not limited to (1) relevant education; qualifications; certifications; and experience; (2) skills, ability, knowledge of the job; (3) performance, contribution and results; (4) geographic location; (5) shift; (6) internal and external equity; and (7) business and organizational needs.
 * The salary range is what we believe to be the range of possible compensation for this role at the time of this posting. We may ultimately pay more or less than the posted range and this range is only applicable for jobs to be performed in California, Colorado, New York or remote jobs that can be performed in California, Colorado and New York. This range may be modified in the future.
 * If your position is non-exempt, you are eligible for overtime pay pursuant to company policy and applicable laws. You may also be eligible for shift differential pay, depending on the shift to which you are assigned.

 * You will be eligible to be considered for bonuses under either Western Digital’s Short Term Incentive Plan (“STI Plan”) or the Sales Incentive Plan (“SIP”) which provides incentive awards based on Company and individual performance, depending on your role and your performance. You may be eligible to participate in our annual Long-Term Incentive (LTI) program, which consists of restricted stock units (RSUs) or cash equivalents, pursuant to the terms of the LTI plan. Please note that not all roles are eligible to participate in the LTI program, and not all roles are eligible for equity under the LTI plan. RSU awards are also available to eligible new hires, subject to Western Digital’s Standard Terms and Conditions for Restricted Stock Unit Awards.
   
   

 * We offer a comprehensive package of benefits including paid vacation time; paid sick leave; medical/dental/vision insurance; life, accident and disability insurance; tax-advantaged flexible spending and health savings accounts; employee assistance program; other voluntary benefit programs such as supplemental life and AD&D, legal plan, pet insurance, critical illness, accident and hospital indemnity; tuition reimbursement; transit; the Applause Program; employee stock purchase plan; and the Western Digital Savings 401(k) Plan.
 * Note: No amount of pay is considered to be wages or compensation until such amount is earned, vested, and determinable. The amount and availability of any bonus, commission, benefits, or any other form of compensation and benefits that are allocable to a particular employee remains in the Company's sole discretion unless and until paid and may be modified at the Company’s sole discretion, consistent with the law.

Notice To Candidates: Please be aware that Western Digital and its subsidiaries will never request payment as a condition for applying for a position or receiving an offer of employment. Should you encounter any such requests, please report it immediately to Western Digital Ethics Helpline or email compliance@wdc.com.

","25 applicants","Full-time","Mid-Senior level","Marketing","Computer Hardware Manufacturing, Computers and Electronics Manufacturing, and Semiconductor Manufacturing","","","","4593","https://www.linkedin.com/jobs/view/ai-researcher-at-western-digital-4347620457?trk=public_jobs_topcard-title","EASY_APPLY",""
"Analytics Engineer","San Mateo, CA","2 weeks ago","2025-11-12","https://www.linkedin.com/jobs/view/analytics-engineer-at-verkada-4335810007?trk=public_jobs_topcard-title","Verkada","https://www.linkedin.com/company/verkada?trk=public_jobs_topcard-org-name","Who We Are

Verkada is transforming how organizations protect their people and places with an integrated, AI-powered platform. A leader in cloud physical security, Verkada helps organizations strengthen safety and efficiency through one connected software platform that includes solutions for video security, access control, air quality sensors, alarms, intercoms, and visitor management.

Over 30,000 organizations worldwide, including more than 100 companies in the Fortune 500, trust Verkada as their physical security layer for easier management, intelligent control, and scalable deployments. Founded in 2016, Verkada has expanded rapidly with 15 offices and 2,200+ full-time employees.

About The Role

Verkada’s Growth Ops team is looking for a talented individual to play an integral role in leveraging our data and technology to help our marketing team run better, faster, and smarter. You will have the opportunity to play a vital role in both creating and driving world-class insights that will drive the next phase of growth here at Verkada.

Successful Marketing Analytics leaders at Verkada are fluent in SQL and data modeling, understand the principles of effective data visualization, and know how to contextualize their work within the business in order to drive growth. This role reports to our Sr. Manager, Analytics Engineering. We are committed to a thriving in-office culture. This role requires that you be on-site at our office in San Mateo, CA 5 days a week.

What You'll Do


 * Own the full analytics workflow, from transforming raw data in dbt to building dashboards in Looker and presenting findings that influence strategy.
 * Collaborate with stakeholders to design metrics that align with company objectives and inform decision-making.
 * Build and maintain scalable, well-documented data models in dbt and Looker/LookML that power reporting and analysis across the org.
 * Help shape data governance and foster data literacy, empowering stakeholders to self-serve with trustworthy and accurate data.
 * Deliver high-impact, data-driven insights and recommendations; collaborate with leadership to influence key decisions and optimize the growth funnel
   
   

What You Bring


 * 3–5 years of experience in data analytics or data science.
 * Advanced SQL proficiency and experience working with modern databases (BigQuery, Snowflake, Redshift)
 * Experience building dashboards with data visualization tools (Looker, Tableau, Power BI).
 * Demonstrated track record of success in a high-growth, self-directed business environment.
 * Strong analytical mindset; enjoys solving complex and ambiguous problems.
 * Excellent verbal and written communication skills, with ability to translate complex data into clear business narratives.
 * Must be willing and able to commute 5 days in office.
   
   

Nice to Have


 * Direct relevant experience in Marketing Analytics or a similar function (Growth Analytics, Data Science, Product Analytics, etc.)
 * Experience with data modeling, ETL/ELT, and data warehousing.
 * Experience with dbt
 * Experience with Looker/LookML
 * Proficiency with Python, R, and statistical analysis.
 * Familiarity with business systems: Salesforce, Marketo, Outreach, or similar.
   
   

Employee Benefits

Verkada is committed to fostering a workplace environment that prioritizes the holistic health and wellbeing of our employees and their families by offering comprehensive wellness perks, benefits, and resources. Our benefits and perks programs include, but are not limited to:


 * Healthcare programs that can be tailored to meet the personal health and financial well-being needs - Premiums are 100% covered for the employee under at least one plan and 80% for family premiums under all plans Nationwide medical, vision and dental coverage
 * Health Saving Account (HSA) with annual employer contributions and Flexible Spending Account (FSA) with tax saving options
 * Expanded mental health support
 * Paid parental leave policy & fertility benefits
 * Time off to relax and recharge through our paid holidays, firmwide extended holidays, flexible PTO and personal sick time
 * Professional development stipend
 * Fertility Stipend
 * Wellness/fitness benefits
 * Healthy lunches provided daily
 * Commuter benefits
   
   

Additional Information


 * You must be independently authorized to work in the U.S. We are unable to sponsor or take over sponsorship of an employment visa for this role, at this time.
   
   

Annual Pay Range

At Verkada, we want to attract and retain the best employees, and compensate them in a way that appropriately and fairly values their individual contribution to the company. With that in mind, we carefully consider a number of factors to determine the appropriate starting pay for an employee, including their primary work location and an assessment of a candidate's skills and experience, as well as market demands and internal parity. A Verkada employee may be eligible for additional forms of compensation, depending on their role, including sales incentives, discretionary bonuses, and/or equity in the company in the form of restricted stock units (RSUs)

Below is the annual on-target earnings (OTE) range for full-time employees for this position, comprised of base compensation and commissions (if applicable).

Estimated Annual Pay Range

$130,000—$180,000 USD

Verkada Is An Equal Opportunity Employer

As an equal opportunity employer, Verkada is committed to providing employment opportunities to all individuals. All applicants for positions at Verkada will be treated without regard to race, color, ethnicity, religion, sex, gender, gender identity and expression, sexual orientation, national origin, disability, age, marital status, veteran status, pregnancy, or any other basis prohibited by applicable law.

Your application will be handled in accordance with our Candidate Privacy Policy.","138 applicants","Full-time","Entry level","Information Technology","Software Development","$130,000.00/yr - $180,000.00/yr","","","12699415","https://www.linkedin.com/jobs/view/analytics-engineer-at-verkada-4335810007?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr. Manager Data Engineering & Analytics","New York, NY","3 weeks ago","2025-11-05","https://www.linkedin.com/jobs/view/sr-manager-data-engineering-analytics-at-upclear-4334179391?trk=public_jobs_topcard-title","UpClear","https://www.linkedin.com/company/upclear?trk=public_jobs_topcard-org-name","ABOUT UPCLEAR

UpClear delivers a SaaS revenue management platform that is used by some of the most recognizable consumer goods brands in the world. Our system supports Trade Promotion Management, Trade Promotion Optimization, Integrated Business Planning and Revenue Management. We serve more than 80 brands in over 30 countries. Our growth is substantial and consistent; we have been on the Inc 5000 list of fastest growing private companies for eight years in a row. UpClear's global headquarters is in New York City and we have satellite offices in London, Paris, and Singapore.


POSITION OVERVIEW

We are hiring a Sr. Manager Data Engineering & Analytics to define our data strategy and build a high-performing data practice. You'll design and operate scalable data platforms, establish governance and quality standards, and partner with business and product leaders to turn data into decisions. This role blends leadership and hands-on execution—you'll mentor engineers while shaping architecture, optimizing pipelines, and driving reliable, accessible data across the company. 


RESPONSIBILITIES 

 * Define and implement the data strategy, architecture, and roadmap aligned with company objectives. 

 * Establish best practices for data management, quality, and governance across the organization. 

 * Partner with business, product, and engineering leaders to translate data into actionable insights and scalable systems. 

 * Build, lead, and mentor a multidisciplinary data team (data engineering, analytics). 

 * Design, develop, and maintain scalable data architectures and pipelines (including data warehouse, ETL/ELT, and data models). 

 * Oversee data visualization and reporting infrastructure to ensure reliable, consistent insights across teams. 

 * Bridge data engineering and analytics functions, ensuring alignment between raw data pipelines and business intelligence outputs. 

 * Oversee integration of disparate data sources into unified and reliable data platforms. 

 * Ensure high performance, availability, and accuracy of data systems across environments and regions. 

 * Remain hands-on with key technologies (SQL, cloud data tools) as needed to accelerate implementation. 

 * Evaluate and introduce new technologies and practices that enhance data quality, governance, and observability. 

 * Implement robust data governance frameworks, policies, and compliance standards. 

 * Establish and monitor data quality KPIs and SLAs. 

 * Support operational and executive reporting initiatives with clean, well-modeled data. 
   
   

Requirements


 * Bachelor's or Master's Degree in Computer Science, Data Engineering, or a related field. 

 * 8+ years of experience in data engineering, with 3+ years in a leadership or management role. 

 * Proven experience building and scaling data teams and platforms from early stage to maturity. 

 * Experience managing both data engineers and analysts, or working across both functions. 

 * Strong understanding of modern data stack technologies (e.g., dbt, Snowflake, Azure Data Factory, Databricks, Airflow). 

 * Expertise in SQL and at least one programming language (Python, C#, etc.). 

 * Experience with data governance, lineage, and metadata management tools. 

 * Strong understanding of analytics workflows and BI tools (Tableau, Power BI) 

 * The ability to translate technical data models into business value. 

 * Hands-on mindset{{:}} comfortable contributing technically while shaping the strategic direction. 
   
   

Benefits



WHY UPCLEAR ?

 * Be part of a growing global SaaS company, with offices in NYC, London, Paris, Singapore
 * Work on latest Cloud technology and build architecture for fast-growing Tech
 * Weekly happy hours, good office culture, global cross team collaboration, direct access to executive leadership for guidance.
   

UpClear employees have access to a range of competitive benefits, including

 * Various Health Care Plans you can choose from to best fits your needs (Medical, Dental & Vision)
 * Retirement Plan with company match (401k, IRA)
 * Generous Paid Time Off package that grows with seniority (Vacation, Sick, and Public Holidays)
 * Paid Maternity leave
 * Paid Parental bonding leave
 * One month paid sabbatical after five continuous years of work at UpClear
 * Hybrid work model
 * Competitive Salary ($150K - $200K)

The salary range listed is a good faith determination of potential base compensation that may be offered to a successful applicant for this position at the time of this job advertisement and may be modified in the future. When determining a team member's base salary several factors may be considered as applicable including, but not limited to, relevant education, qualifications, certifications, experience, skills, seniority.","Be among the first 25 applicants","Full-time","Mid-Senior level","Information Technology","Technology, Information and Internet","$150,000.00/yr - $200,000.00/yr","","","466640","https://www.linkedin.com/jobs/view/sr-manager-data-engineering-analytics-at-upclear-4334179391?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr. Data Engineer","Phoenix, AZ","1 month ago","2025-10-30","https://www.linkedin.com/jobs/view/sr-data-engineer-at-phoenix-suns-4338694474?trk=public_jobs_topcard-title","Phoenix Suns","https://www.linkedin.com/company/phoenix-suns?trk=public_jobs_topcard-org-name","Player 15 Group Headquarters

Phoenix, AZ

Job Summary

Player 15 Group – the sports & entertainment company behind the Phoenix Suns (NBA), Phoenix Mercury (WNBA), Valley Suns (G League), and Mortgage Matchup Center — is redefining the industry standard. Headquartered in downtown Phoenix and engaging fans across the world, Player 15 Group is driven by possibility, innovation, and the desire to create memorable moments for our fans and community.

Our culture is anchored in purpose-driven leadership and fueled by individuals who bring passion, creativity, and vision to everything they do. We challenge convention, amplify voices, and create experiences that resonate well beyond the final buzzer. This is where talent meets purpose and bold ideas become reality.

We are seeking an experienced and motivated Sr. Data Engineer to join our team. In this high-impact role, you will be responsible for advancing the data infrastructure while playing a critical role in shaping the department’s long-term data strategy.

What You Will Do


 * Architect, develop, and maintain data pipelines, leveraging Redshift to integrate and transform data across Ticketing, Marketing, and CRM platforms.
 * Design and maintain data models that power reporting, segmentation, forecasting, pricing, etc.
 * Build and support Segment CDP as the core customer data source, focusing on identity resolution and data activation across marketing and sales channels.
 * Apply well-established and modern hybrid data warehousing methodologies (e.g., Kimball, Inmon, dimensional modeling, star/snowflake schemas) to design scalable, consistent, and business-aligned data structures.
 * Establish a consistent approach to data quality, governance, and documentation across the warehouse - integrating anomaly and integrity checks, clear lineage, and well-defined business logic for all models and transformations.
 * Partner with cross-functional stakeholders (Business Intelligence, Marketing, Ticketing, Partnerships, Finance, etc.) to understand business needs and translate them into data engineering solutions.
 * Contribute to long-term architecture decisions, ensuring that our data ecosystem evolves thoughtfully to support organizational growth.
 * Continuously identify opportunities to improve our data infrastructure and practices.
 * Ensure all pipelines and models align with data privacy and security regulations (for example, CCPA and GDPR) and collaborate with IT leadership to meet cybersecurity standards.
   
   

What We Need From Our Sr. Data Engineer


 * Proven track record in data engineering with expertise in Redshift (or other cloud data warehouses such as Snowflake, Azure, etc.).
 * Hands-on expertise with SQL, Python, and ETL/ELT tools.
 * Experience with Customer Data Platforms (Segment, StellarAlgo, KORE Helix, Agilitek Fan Data Platform, etc.) including implementation, integration, and downstream activation.
 * Expertise with modern data stack tools (DBT, Airflow, AWS services, etc.) and best practices for data orchestration.
 * Experience architecting and optimizing data pipelines for business intelligence tools (Tableau, Power BI, Looker), ensuring scalable and trusted data flows from DWA into reporting layers and extracts.
 * Proficiency with version control (Git/GitHub) and collaborative development practices.
 * Experience optimizing cloud data infrastructure for both cost and performance.
 * Familiarity with AI/ML pipelines and API/microservices integration to enable predictive analytics and fan 360 initiatives.
 * Experience optimizing on-premise virtual machine usage and shaping the strategy for migrating workloads to cloud infrastructure.
 * Previous experience defining success metrics such as pipeline uptime, data freshness, and activation ROI.
   
   

Experience/ Education Requirements


 * Bachelor’s degree in Computer Science, Information Systems, Engineering, or related field (or equivalent practical experience).
 * 5+ years of data engineering experience with a strong focus on cloud data warehouses.
 * Proven ability to design, build, and maintain scalable pipelines and models that support enterprise analytics and BI.
 * Awareness of data privacy, security, and compliance considerations in warehouse and pipeline design.
 * Previous experience within Sports ecosystem is preferred.
   
   

What You Can Expect

The work environment characteristics described here are representative of those that must be met by Sr. Data Engineer to optimally perform the essential functions of this role. Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions.

Ability to transit throughout the arena for long periods of time.This position works mainly indoors, removed from extreme weather; exposure to weather is S-Sedentary Work – Exerting up to 10 pounds of force occasionally.Must be able to carry on a conversation both on the phone and in-person.Ability to Read, Write & Speak in EnglishWide range of full-time benefit options including
 * Medical, Dental and Vision coverages
 * Life and Disability options
 * Vacation, sick and holiday leave programs

Perks:
 * Discounts at Fanatics Team Shop
 * Tickets available for Phoenix Suns and Phoenix Mercury games

Visit our Culture page to learn more about our culture and work environment
Player 15 Group is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.

Please note this job description is not crafted to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.

For questions about this career opportunity, please contact the People & Culture Recruiting team at recruiting@suns.com","Be among the first 25 applicants","Full-time","Mid-Senior level","Information Technology","Spectator Sports","","","","19732","https://www.linkedin.com/jobs/view/sr-data-engineer-at-phoenix-suns-4338694474?trk=public_jobs_topcard-title","EASY_APPLY",""
"Databricks Data Analyst","Atlanta, GA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/databricks-data-analyst-at-capgemini-4339030137?trk=public_jobs_topcard-title","Capgemini","https://fr.linkedin.com/company/capgemini?trk=public_jobs_topcard-org-name","Choosing Capgemini means choosing a company where you will be empowered to shape your career in the way you’d like, where you’ll be supported and inspired by a collaborative community of colleagues around the world, and where you’ll be able to reimagine what’s possible. Join us and help the world’s leading organizations unlock the value of technology and build a more sustainable, more inclusive world.

Job Location: Atlanta, GA/ Chicago, IL

Works in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.1. Applies scientific methods to analyse and solve software engineering problems.2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.

Job Responsibilities

Perform data analysis, interpret large datasets using Databricks and SQL-based queries.

Use Python for data cleaning, transformation, and advanced analytics.

Work with business and IT stakeholders to define requirements for data pipelines, ETL based on the business needs

Collaborate with data engineers and business teams to ensure data accuracy and availability.

Experience in data models, reports, and dashboards for business stakeholders.

Ensure compliance with data governance and security standards.

Support data engineering teams and business for testing (UT, SIT UAT)

Required Skills

5-10 years of experience in data analysis or related roles.

Strong in Databricks for data processing and analytics.

Advanced knowledge of SQL and Python for querying and data manipulation.

Understanding of data visualization tools (Power BI, Tableau, or similar).

Understanding of data modeling and relational database concepts.

Life at Capgemini

Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:

Flexible work

Healthcare including dental, vision, mental health, and well-being programs

Financial well-being programs such as 401(k) and Employee Share Ownership Plan

Paid time off and paid holidays

Paid parental leave

Family building benefits like adoption assistance, surrogacy, and cryopreservation

Social well-being benefits like subsidized back-up child/elder care and tutoring

Mentoring, coaching and learning programs

Employee Resource Groups nd Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.

Capgemini is committed to providing reasonable accommodations du

Disaster Relief

The base compensation range for this role in the posted location is: $80420 to $106050

Capgemini provides compensation range information in accordance with applicable national, state, provincial, and local pay transparency laws. The base compensation range listed for this position reflects the minimum and maximum target compensation Capgemini, in good faith, believes it may pay for the role at the time of this posting. This range may be subject to change as permitted by law.

The actual compensation offered to any candidate may fall outside of the posted range and will be determined based on multiple factors legally permitted in the applicable jurisdiction.

These may include, but are not limited to: Geographic location, Education and qualifications, Certifications and licenses, Relevant experience and skills, Seniority and performance, Market and business consideration, Internal pay equity.

It is not typical for candidates to be hired at or near the top of the posted compensation range.

In addition to base salary, this role may be eligible for additional compensation such as variable incentives, bonuses, or commissions, depending on the position and applicable laws.

Capgemini offers a comprehensive, non-negotiable benefits package to all regular, full-time employees. In the U.S. and Canada, available benefits are determined by local policy and eligibility and may include:


 * Paid time off based on employee grade (A-F), defined by policy: Vacation: 12-25 days, depending on grade, Company paid holidays, Personal Days, Sick Leave
 * Medical, dental, and vision coverage (or provincial healthcare coordination in Canada)
 * Retirement savings plans (e.g., 401(k) in the U.S., RRSP in Canada)
 * Life and disability insurance
 * Employee assistance programs
 * Other benefits as provided by local policy and eligibility
   
   

Important Notice: Compensation (including bonuses, commissions, or other forms of incentive pay) is not considered earned, vested, or payable until it becomes due under the terms of applicable plans or agreements and is subject to Capgemini’s discretion, consistent with applicable laws. The Company reserves the right to amend or withdraw compensation programs at any time, within the limits of applicable legislation.

Disclaimers

Capgemini is an Equal Opportunity Employer encouraging inclusion in the workplace. Capgemini also participates in the Partnership Accreditation in Indigenous Relations (PAIR) program which supports meaningful engagement with Indigenous communities across Canada by promoting fairness, accessibility, inclusion and respect. We value the rich cultural heritage and contributions of Indigenous Peoples and actively work to create a welcoming and respectful environment. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.

This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodation does not pose an undue hardship. Capgemini is committed to providing reasonable accommodation during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.

Please be aware that Capgemini may capture your image (video or screenshot) during the interview process and that image may be used for verification, including during the hiring and onboarding process.

Click the following link for more information on your rights as an Applicant in the United States. http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law

Capgemini is a global business and technology transformation partner, helping organizations to accelerate their dual transition to a digital and sustainable world, while creating tangible impact for enterprises and society. It is a responsible and diverse group of 340,000 team members in more than 50 countries. With its strong over 55-year heritage, Capgemini is trusted by its clients to unlock the value of technology to address the entire breadth of their business needs. It delivers end-to-end services and solutions leveraging strengths from strategy and design to engineering, all fueled by its market leading capabilities in AI, generative AI, cloud and data, combined with its deep industry expertise and partner ecosystem.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","IT Services and IT Consulting","$80,420.00/yr - $106,050.00/yr","","","157240","https://careers.capgemini.com/job/Atlanta%2C-GA-Databricks-Data-Analyst-GA-30301/1270772301/?feedId=388933&utm_source=LinkedInJobPostings","EXTERNAL",""
"Sr. Data Engineer","Palo Alto, CA","2 weeks ago","2025-11-17","https://www.linkedin.com/jobs/view/sr-data-engineer-at-oppo-4336724163?trk=public_jobs_topcard-title","OPPO","https://cn.linkedin.com/company/oppo?trk=public_jobs_topcard-org-name","OPPO US Research Center is looking for a highly motivated Data Engineer. In this role, you will be responsible for designing and implementing robust data warehouse architectures, enabling data-driven decision-making through scalable systems that support real-time and batch processing. If you're passionate about building high-quality data pipelines and delivering actionable insights to drive business performance, we want to hear from you.

Key Responsibilities:


 * Design and develop data warehouse architecture and implement best practices in data governance and data asset access control
 * Build and maintain a comprehensive data system by deeply understanding business processes and providing both real-time data services and actionable data reports to support business operations
 * Research and implement technologies for both real-time and batch data processing in the big data domain, promoting their adoption in various business use cases
 * Collaborate closely with cross-functional teams to translate business needs into technical solutions, ensuring data reliability, quality, and timeliness
   
   

Requirements

Key Responsibilities:


 * 5 years of hands-on experience in data warehouse or big data development, with solid expertise in building both real-time and offline data pipelines
 * Extensive experience with Internet data, including user growth and conversion data, and strong A/B testing and data analysis capabilities
 * Proficiency in big data tools and frameworks such as Spark, Flink, Clickhouse and at least one of SQL dialects for big data
 * Strong understanding of data modeling concepts, especially dimensional modeling and data warehousing theory
 * Strong business understanding with the ability to quickly grasp the logic behind complex data systems
 * Excellent communication and collaboration skills, with a proactive attitude towards problem-solving
   
   

Preferred:


 * Extensive data engineering experience combined with strong business acumen in the Advertisement domain and app distribution domain
 * Multilingual capabilities or cross-cultural communication experience in European markets is a plus
   
   

Benefits

OPPO is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

The US base salary range for this full-time position is $100,000-$300,000 + bonus + long term incentives benefits. Our salary ranges are determined by role, level, and location.","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","$100,000.00/yr - $300,000.00/yr","","","2852649","https://www.linkedin.com/jobs/view/sr-data-engineer-at-oppo-4336724163?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Irvine, CA","6 days ago","2025-11-26","https://www.linkedin.com/jobs/view/data-engineer-at-hyundai-capital-america-4338944850?trk=public_jobs_topcard-title","Hyundai Capital America","https://www.linkedin.com/company/hyundai-capital-america?trk=public_jobs_topcard-org-name","Who We Are

Through our service brands Hyundai Motor Finance, Genesis Finance, and Kia Finance, Hyundai Capital America offers a wide range of financial products tailored to meet the needs of Hyundai, Genesis, and Kia customers and dealerships. We provide vehicle financing, leasing, subscription, and insurance solutions to over 2 million consumers and businesses. Embodying our commitment to grow, innovate, and diversify, we strive to reimagine the customer and dealer experience and launch innovative new products that broaden our market reach. We believe that success comes from within and are proud to support our team members through skill development and career advancement. Hyundai Capital America is an Equal Opportunity Employer committed to creating a diverse and inclusive culture for our workforce. We are a values-driven company dedicated to supporting both internal and external communities through volunteering, philanthropy, and the empowerment of our Employee Resource Groups. Together, we strive to be the leader in financing freedom of movement.

We Take Care of Our People

Along with competitive pay, as an employee of HCA, you are eligible for the following benefits:


 * Medical, Dental and Vision plans that include no-cost and low-cost plan options
 * Immediate 401(k) matching and vesting
 * Vehicle purchase and lease discounts plus monthly vehicle allowances
 * Paid Volunteer Time Off with company donation to a charity of your choice
 * Tuition reimbursement
   
   

What To Expect

The Data Engineer is responsible for designing and developing data pipelines and information assets utilizing modern technology approaches to ensure alignment with reference architecture, data requirements, time frames are iterative delivery of data pipeline artifacts.

What You Will Do


 * Solutions Delivery – Analysis, Design, and Development
 * Create and maintain optimal data pipeline architecture.
 * Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS big-data technologies.
 * Build data pipelines, ELT optimization, data mappings, and ETL progress design to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
 * Responsible for ensuring that the technical output of the Data Engineering team conforms to best practices and standards .
 * Draft technical design and specifications, and data lineage.
 * Participate on other related assessments such as Data Analysis, Root Cause Analysis, Impact Analysis, As-Is solution assessment and ToBe solution recommendation, etc.
 * Test and Maintenance
 * Implement improvements to application performance for potential bottlenecks.
 * Update process documentation to keep system library up to date.
 * Validate system developed according to requirement by testing.
 * Solutions Delivery Management
 * Follow processes and practices to enable the delivery of data engineering artifacts.
 * Execute plans to drive higher solution efficiency and delivery velocity of Data Services solution.
   
   

What You Will Bring


 * Minimum 5-7 years’ progressive experience in data analytics, computer systems engineering, or software engineering.
 * Proven experience with Data Integration tools such as Informatica, AWS Glue, AWS Redshift, AWS S3, and languages such as Stored Procedures, Python, Spark, etc.
 * Auto-finance experience and specifically Cassiopeia product experience required.
 * SQL and Oracle knowledge required.
 * Bachelor’s degree required.
 * Advanced degree preferred.
 * Experience in building and optimizing relational and structured data pipelines, architectures and data sets.
 * Strong analytic skills to work with unstructured datasets.
 * Has in-depth functional expertise and broad business knowledge of data domains.
 * Ability to find solutions on data requirements and issues.
 * Ability to conduct code reviews to ensure that the technical output conforms to best practices and standards.
 * Ability to communicate and influence Business and IT in terms of understanding the data. requirements, respective data solutions, and technical decisions.
 * Strong collaboration and motivation skills.
 * Strong communication skills (verbal and written).
   
   

Work Environment

Employees in this class are subject to extended periods of sitting, standing, and walking, vision to monitor and moderate noise levels. Work is performed in an at home and office environment.

The posted salary range for this job takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; geographic location, and other business and organizational needs. Successful candidates may be hired anywhere in the salary range based on these factors. It is uncommon to hire candidates at or near the top of the range.

California Privacy Notice

This notice only applies to our applicants who reside in the State of California.

The latest version of our Privacy Policy can be found here. This Privacy Policy provides you with notice, at or before the point of collection, about the categories of personal information to be collected from you, the purposes for which your personal information is collected or used, and whether that information is sold or shared, so that you can exercise meaningful control over our use of your personal information. We are providing this notice to comply with the California Consumer Privacy Act of 2018, as amended as amended by the California Privacy Rights Act of 2020 (“CCPA”).

If you have any questions about CCPA regarding California residents or HCA team members, please contact the Privacy Team at Privacy2@hcs.com.

Primary Location

United States-California-Irvine

Work Locations

Headquarters 1

Job

Enterprise Data Strategy

Job Type

Regular

Overtime Status

Exempt

Schedule

Full-time

Minimum Salary: $

92,500.00

Maximum Salary: $

143,500.00

Job Posting

Nov 25, 2025","Over 200 applicants","Full-time","Entry level","Information Technology","Financial Services","$92,500.00/yr - $143,500.00/yr","","","726805","https://careerglobalhc.taleo.net/careersection/hca/jobdetail.ftl?job=250000MG&src=LinkedIn","EXTERNAL",""
"Analytics Engineer II","Los Angeles, CA","1 week ago","2025-11-24","https://www.linkedin.com/jobs/view/analytics-engineer-ii-at-stubhub-4333762331?trk=public_jobs_topcard-title","StubHub","https://www.linkedin.com/company/stubhub?trk=public_jobs_topcard-org-name","StubHub is on a mission to redefine the live event experience on a global scale. Whether someone is looking to attend their first event or their hundredth, we’re here to delight them all the way from the moment they start looking for a ticket until they step through the gate. The same goes for our sellers. From fans selling a single ticket to the promoters of a worldwide stadium tour, we want StubHub to be the safest, most convenient way to offer a ticket to the millions of fans who browse our platform around the world.

We are seeking talented Analytics Engineer from mid to senior levels to join StubHub’s Data Engineering & Analytics organization. In this role you will be responsible for scaling both analytic products (data assets, dashboards, tools/services) and analytic frameworks (decision frameworks, metrics, analytical models). You will be a “force multiplier” who significantly improves and speeds up StubHub’s ability to make great data-informed decisions.

Location: Hybrid (3 days in office/2 days remote) – New York, NY or Santa Monica, CA

About The Team

The Analytics Engineering team exists to enable robust data-informed decision making that steers our business growth goals, through the creation of high-quality data products and scaled insights. Analytics Engineering helps solve the scale problems and common data access patterns encountered by analysts, data scientists, and other business data consumers. All data modules and tools owned by AE are then leveraged not only by members of that business domain, but also data consumers from across the company. We are looking for the right person who can operate and translate across all parts of the business.

What You'll Do


 * Manage cross-functional analytical data models, metric frameworks and implementations, and self-serve dashboards/tools
 * Specialize in one or more business domains, building deep expertise and anticipating the needs of that business vertical
 * Collaborate cross functionally with business and product teams while simultaneously ""speaking the language” of engineering teams, oftentimes acting as proxy for one or the other
   
   

What You've Done


 * 3-5 years of relevant analytics engineering, data engineering, or business intelligence experience in a fast paced, high growth environment
 * Proficiency with transforming and analyzing large scale data with modern cloud computing platforms (e.g. SparkSQL, BigQuery, Snowflake, Databricks)
 * High proficiency with SQL and experience with one or more programming languages (e.g. Python, Java) and markup/configuration languages (e.g. YAML)
 * Proficiency in building data models and pipelines using orchestration software (e.g. Airflow, dbt)
 * Experience building reports/dashboards with business intelligence (BI) tools, such as Tableau and Looker
 * Exposure to both batch data processing and real-time streaming technologies
 * Familiarity with data cataloging and metadata management tools
 * Passionate about working with non-technical stakeholders to understand, anticipate, and deliver on their data needs
   
   

What We Offer


 * Accelerated Growth Environment: An environment designed for swift skill and knowledge enhancement, where you have the autonomy to lead experiments and tests on a massive scale.
 * Top Tier Compensation Package: Competitive base, equity, and upside that tracks with your impact.
 * Flexible Time Off: Embrace a healthy work-life balance with unlimited Flex Time Off, providing you the flexibility to manage your schedule and recharge as needed.
 * Comprehensive Benefits Package: Prioritize your well-being with a comprehensive benefits package, featuring 401k, and premium Health, Vision, and Dental Insurance options.
   
   

The anticipated gross base pay range is below for this role. Actual compensation will vary depending on factors such as a candidate’s qualifications, skills, experience, and competencies. Base annual salary is one component of StubHub’s total compensation and competitive benefits package, which includes equity, 401(k), paid time off, paid parental leave, and comprehensive health benefits.

Salary Range

$150,000—$200,000 USD

About Us

StubHub is the world’s leading marketplace to buy and sell tickets to any live event, anywhere. Through StubHub in North America and viagogo, our international platform, we service customers in 195 countries in 33 languages and 49 available currencies. With more than 300 million tickets available annually on our platform to events around the world -- from sports to music, comedy to dance, festivals to theater -- StubHub offers the safest, most convenient way to buy or sell tickets to the most memorable live experiences. Come join our team for a front-row seat to the action.

For California Residents: California Job Applicant Privacy Notice found here

We are an equal opportunity employer and value diversity on our team. We do not discriminate on the basis of race, color, religion, sex, national origin, gender, sexual orientation, age, disability, veteran status, or any other legally protected status.","Over 200 applicants","Full-time","Entry level","Information Technology","Software Development","$150,000.00/yr - $200,000.00/yr","","","10061","https://job-boards.eu.greenhouse.io/stubhubinc/jobs/4704159101?gh_src=47e65a22teu","EXTERNAL",""
"Financial Data Analyst","Alpharetta, GA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/financial-data-analyst-at-genpact-4347369809?trk=public_jobs_topcard-title","Genpact","https://www.linkedin.com/company/genpact?trk=public_jobs_topcard-org-name","Ready to build the future with AI?

At Genpact, we don’t just keep up with technology—we set the pace. AI and digital innovation are redefining industries, and we’re leading the charge. Genpact’s AI Gigafactory, our industry-first accelerator, is an example of how we’re scaling advanced technology solutions to help global enterprises work smarter, grow faster, and transform at scale. From large-scale models to agentic AI, our breakthrough solutions tackle companies’ most complex challenges.




If you thrive in a fast-moving, innovation-driven environment, love building and deploying cutting-edge AI solutions, and want to push the boundaries of what’s possible, this is your moment.




Genpact (NYSE: G) is an advanced technology services and solutions company that delivers lasting value for leading enterprises globally. Through our deep business knowledge, operational excellence, and cutting-edge solutions – we help companies across industries get ahead and stay ahead. Powered by curiosity, courage, and innovation, our teams implement data, technology, and AI to create tomorrow, today. Get to know us at genpact.com and on LinkedIn, X, YouTube, and Facebook.




Inviting applications for the role of Financial Data Analyst at Alpharetta , GA .




Role : Financial Data Analyst

Location : Alpharetta , GA 30005 / 3 days from Office

Hiring Type: Fulltime with Genpact + Benefits




Responsibilities

 * Define and execute the product roadmap for AI tooling and data integration initiatives, driving products from concept to launch in a fast-paced, Agile environment.
 * Translate business needs and product strategy into detailed requirements and user stories.
 * Collaborate with engineering, data, and AI/ML teams to design and implement data connectors that enable seamless access to internal and external financial datasets.
 * Partner with data engineering teams to ensure reliable data ingestion, transformation, and availability for analytics and AI models.
 * Evaluate and work to onboard new data sources, ensuring accuracy, consistency, and completeness of fundamental and financial data.
 * Continuously assess opportunities to enhance data coverage, connectivity, and usability within AI and analytics platforms.
 * Monitor and analyze product performance post-launch to drive ongoing optimization and inform future investments.
 * Facilitate alignment across stakeholders, including engineering, research, analytics, and business partners, ensuring clear communication and prioritization.




Minimum qualifications

 * Bachelor’s degree in Computer Science, Finance, or related discipline. MBA/Master’s Degree desired.
 * 5+ years of experience in a similar role
 * Strong understanding of fundamental and financial datasets, including company financials, market data, and research data.
 * Proven experience in data integration, particularly using APIs, data connectors, or ETL frameworks to enable AI or analytics use cases.
 * Familiarity with AI/ML data pipelines, model lifecycle, and related tooling.
 * Experience working with cross-functional teams in an Agile environment.
 * Strong analytical, problem-solving, and communication skills with the ability to translate complex concepts into actionable insights.
 * Prior experience in financial services, investment banking, or research domains.
 * Excellent organizational and stakeholder management abilities with a track record of delivering data-driven products.




Preferred qualifications

 * Deep understanding of Python, SQL, or similar scripting languages
 * Knowledge of cloud data platforms (AWS, GCP, or Azure) and modern data architectures (data lakes, warehouses, streaming)
 * Familiarity with AI/ML platforms
 * Understanding of data governance, metadata management, and data security best practices in financial environments.
 * Experience with API standards (REST, GraphQL) and data integration frameworks.
 * Demonstrated ability to partner with engineering and data science teams to operationalize AI initiatives.




Why join Genpact?

• Lead AI-first transformation – Build and scale AI solutions that redefine industries

• Make an impact – Drive change for global enterprises and solve business challenges that matter

• Accelerate your career—Gain hands-on experience, world-class training, mentorship, and AI certifications to advance your skills

• Grow with the best – Learn from top engineers, data scientists, and AI experts in a dynamic, fast-moving workplace

• Committed to ethical AI – Work in an environment where governance, transparency, and security are at the core of everything webuild

• Thrive in a values-driven culture – Our courage, curiosity, and incisiveness - built on a foundation of integrity and inclusion - allow your ideas to fuel progress

Come join the 140,000+ coders, tech shapers, and growth makers at Genpact and take your career in the only direction that matters: Up.

Let’s build tomorrow together.




Genpact is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. Genpact is committed to creating a dynamic work environment that values respect and integrity, customer focus, and innovation.




Furthermore, please do note that Genpact does not charge fees to process job applications and applicants are not required to pay to participate in our hiring process in any other way. Examples of such scams include purchasing a 'starter kit,' paying to apply, or purchasing equipment or training.

","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Business Consulting and Services, IT Services and IT Consulting, and Software Development","$70,000.00/yr - $80,000.00/yr","","","210064","https://www.linkedin.com/jobs/view/financial-data-analyst-at-genpact-4347369809?trk=public_jobs_topcard-title","EASY_APPLY",""
"Machine Learning Engineer","Cambridge, MA","1 week ago","2025-11-24","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-ikigai-4338786218?trk=public_jobs_topcard-title","Ikigai","https://www.linkedin.com/company/ikigailabs?trk=public_jobs_topcard-org-name","Company Description

The Ikigai platform unlocks the power of generative AI for tabular data. We enable business users to connect disparate data, leverage no-code AI/ML, and build enterprise-wide AI apps in just a few clicks. Ikigai is built on top of its three proprietary foundation blocks developed from years of MIT research - aiMatch, for data reconciliation, aiCast, for prediction, and aiPlan, for scenario planning and optimization. Our platform enables eXpert-in-The-Loop (XiTL) for model reinforcement learning and refinement, at scale.

With a combination of enterprise expertise and deep research in the field of AI, Ikigai Labs helps scale enterprises with AI by solving data engineering and modeling problems for business users and data scientists alike. Our unique ability to unlock value in tabular and time series data through AI-powered data harmonization, forecasting, dynamic learning and planning, is our Ikigai, our purpose in the world of AI.

As an AI/ML Engineer at Ikigai Labs, you will be part of a high-performing team responsible for optimizing and deploying ML solutions to maximize performance and scalability. We seek a dynamic and passionate engineer with strong software fundamentals and a keen interest in collaborative problem-solving.

Key Responsibilities:


 * ML Optimization and Deployment: Develop and deploy machine learning models for optimal performance and scalability
 * Productivity Tools Development: Build tools and services to enhance the ML platform, utilizing technologies like Kubernetes, Helm, and EKS
 * Model Architecture: Apply a strong understanding of deep learning architectures (CNNs, RNNs, etc.) to solve complex problems
 * Research Adaptation: Stay abreast of recent ML and deep learning literature and adapt findings to real-world applications
 * Collaborative Development: Work with cross-functional teams to integrate AI and ML solutions that drive business value
 * Data Handling: Manage large datasets and build ML pipelines for data processing and training
 * ETL/ELT Processes: Design and develop scalable data integration processes
 * Predictive Modeling Platform: Develop an on-demand predictive modeling platform using gRPC
 * Cloud and Containerization: Utilize Kubernetes for managing Docker containers and various cloud services (AWS, Azure) to solve cloud-native challenges
 * Stakeholder Management: Provide occasional support to our customer success team
   
   

Technologies We Use:


 * Languages: Python3, C++, Rust, SQL
 * Frameworks: PyTorch, TensorFlow, Docker
 * Databases: Postgres, Elasticsearch, DynamoDB, RDS
 * Cloud: Kubernetes, Helm, EKS, Terraform, AWS
 * Data Engineering: Apache Arrow, Dremio, Ray
 * Miscellaneous: Git, Jupyterhub, Apache Superset, Plotly Dash
   
   

Qualifications:


 * Bachelor’s degree in Computer Science, Math, Engineering, or related field (Master's preferred) with 0-5+ years of experience (depending on the level)
 * Strong understanding of data structures, data modeling, algorithms, and software architecture
 * Proficient in probability, statistics, and algorithm development
 * Hands-on experience with ML and deep learning libraries (Scikit Learn, Keras, TensorFlow, PyTorch, Theano, DyLib)
 * (Bonus) Experience with big data and distributed computing (Hadoop, MapReduce, Spark, Storm)
 * Proficiency in Python, AWS services, and ETL/ELT pipelines
 * Understanding of key software design principles, design patterns, and testing best practices
 * Experience with Kubernetes and/or EKS is a plus
 * Ability to learn quickly in a fast-paced, agile environment
 * Excellent organizational, time management, and communication skills
 * Willingness to engage in pair programming, share knowledge, and provide and receive constructive feedback
 * Strong problem-solving skills and the ability to take initiative
   
   

Location Requirement: Candidates must reside in or near Cambridge, MA or San Mateo, CA. This role is not open to other locations at this time.

Equal Opportunity Employment:

Ikigai Labs is committed to equal employment opportunity and non-discrimination for all employees and qualified applicants. We value diversity and are dedicated to fostering an inclusive environment for all employees, regardless of race, color, sex, gender identity or expression, age, religion, national origin, ancestry, citizenship, disability, military or veteran status, genetic information, sexual orientation, marital status, or any other characteristic protected under applicable law.

If you are passionate about machine learning and eager to make an impact, we would love to hear from you. Apply today to join the Ikigai Labs team and help us build the future of AI.

Powered by JazzHR

PIleYeWvCd","Over 200 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Internet Publishing","","","","72750890","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-ikigai-4338786218?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Hanscom AFB, MA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/data-engineer-at-raft-4347590954?trk=public_jobs_topcard-title","Raft","https://www.linkedin.com/company/raft-tech?trk=public_jobs_topcard-org-name","This is a U.S. based position. All of the programs we support require U.S. citizenship to be eligible for employment. All work must be conducted within the continental U.S.

Who we are:

Raft (https://TeamRaft.com) is a customer-obsessed non-traditional small business with a purposeful focus on Distributed Data Systems, Platforms at Scale, and Complex Application Development, with headquarters in McLean, VA. Our range of clients includes innovative federal and public agencies leveraging design thinking, cutting-edge tech stack, and cloud-native ecosystem. We build digital solutions that impact the lives of millions of Americans.

We’re looking for an experienced Data Engineer to support our customers and join our passionate team of high-impact problem solvers.

About the role:

Data Engineers on our Distributed Systems team are focused on building data platforms that make it easy for different types of user personas to access data from a central control plane. This includes building backend services, connecting OSS projects in a repeatable and performant way, and extending feature sets. Experience involving data engineering and all things data. Utilizing new tools like DuckDB, Apache Pinot, Apache Superset, and others. As the Staff Data Engineer you will be working closely with Technical SMEs on the government stakeholders to build, configure, and deploy the next generation of data platform for mission-critical needs.

Required Qualifications:


 * Subject Matter Expertise on a backend language like Java, Go, Python
 * Hands-on experience with Kafka and Delta Lake in real-world applications.
 * Must have educational background in STEM such as Computer Science, Electrical Engineering and Mathematics
 * Up-to-date knowledge of industry trends in Data Engineering, Data Streaming, and Data Search, actively engaging with the community.
 * Proven expertise in working with DoD datasets, with a deep understanding of data transformation techniques.
 * Ability to break down complex requirements into smaller, actionable tasks, demonstrating feasibility through proof-of-concepts (POCs).
 * Experience with Kubernetes, along with a strong background in CI/CD pipelines and Platform as a Service (PaaS) environments.
   
   

Highly preferred:


 * Hands-on experience with Trino and/or DuckDB, as well as Flink or another Stream Processing Engine.
 * Experience in building quick POCs and evaluating the operational pros and cons of Custom Off-The-Shelf (COTS) products versus their Open Source Software (OSS) alternatives.
   
   

Clearance Requirements:


 * Active Secret security clearance
 * Must be able to maintain and obtain a Top Secret clearance
   
   

Work Type:


 * Onsite at Hanscom AFB
 * May require up to 15% travel
   
   

Salary Range:


 * $140,000 - $180,000
 * The determination of compensation is predicated upon a candidate's comprehensive experience, demonstrated skill, and proven abilities
   
   

What we will offer you:


 * Highly competitive salary
 * Fully covered healthcare, dental, and vision coverage
 * 401(k) and company match
 * Take as you need PTO + 11 paid holidays
 * Education & training benefits
 * And More!
   
   

Our Vision Statement:

We bridge the gap between humans and data through radical transparency and our obsession with the mission.

Our Customer Obsession:

We will approach every deliverable like it's a product. We will adopt a customer-obsessed mentality. As we grow, and our footprint becomes larger, teams and employees will treat each other not only as teammates but customers. We must live the customer-obsessed mindset, always. This will help us scale and it will translate to the interactions that our Rafters have with their clients and other product teams that they integrate with. Our culture will enable our success and set us apart from other companies.

How do we get there?

Public-sector modernization is critical for us to live in a better world. We, at Raft, want to innovate and solve complex problems. And, if we are successful, our generation and the ones that follow us will live in a delightful, efficient, and accessible world where out-of-box thinking, and collaboration is a norm.

Raft’s core philosophy is Ubuntu: I Am, Because We are. We support our “nadi” by elevating the other Rafters. We work as a hyper collaborative team where each team member brings a unique perspective, adding value that did not exist before. People make Raft special. We celebrate each other and our cognitive and cultural diversity. We are devoted to our practice of innovation and collaboration.

We’re an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.","Be among the first 25 applicants","Full-time","Entry level","Information Technology","Software Development","$140,000.00/yr - $180,000.00/yr","","","64607633","https://www.linkedin.com/jobs/view/data-engineer-at-raft-4347590954?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer – Corporate Technology Data Engineering & Analytics","New York, NY","21 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-engineer-%E2%80%93-corporate-technology-data-engineering-analytics-at-massmutual-4340343599?trk=public_jobs_topcard-title","MassMutual","https://www.linkedin.com/company/massmutual-financial-group?trk=public_jobs_topcard-org-name","The Opportunity

Join our dynamic team as a Data Engineer – Corporate Technology Data Engineering & Analytics, where you'll play a pivotal role in driving the execution of our data and technology strategy. This role is crucial in driving digital transformation and operational efficiency across Investment Management. As part of this role, you will engage in building data solutions including streaming and batch pipelines, data marts & data warehouse. You will be responsible for establishing robust data collection and processing pipelines to fulfill Investment Management business requirements.

The Team

You’ll be an integral part of our esteemed Corporate Technology Team, focused on Data Engineering & Analytics. Our team operates on a global scale, driving innovation and excellence across diverse areas of expertise. As a Data Engineer, you'll play a critical role in high impact Corporate Technology Investment Initiatives, ensuring alignment with organizational objectives and driving impactful outcomes. This is an opportunity to collaborate closely with Corporate Technology Data and Analytics team and Investment management business stakeholders. Our team thrives on collaboration, innovation, and a shared commitment to excellence. Together, we're shaping the future of technology within our organization and making a lasting impact on a global scale. Join us and be part of a dynamic team where your contributions will be valued and your potential unleashed.

The Impact


 * Design, build, and measure complex ELT jobs to process disparate data sources and form a high integrity, high quality, clean data asset.
 * Executes and provides feedback for data modeling policies, procedure, processes, and standards.
 * Assists with capturing and documenting system flow and other pertinent technical information about data, database design, and systems.
 * Develop comprehensive data quality standards and implement effective tools to ensure data accuracy and reliability.
 * Collaborate with various Investment Management departments to gain a better understanding of new data patterns.
 * Collaborate with Data Analysts, Data Architects, and BI developers to ensure design and development of scalable data solutions aligning with business goals.
 * Translate high-level business requirements into detailed technical specs.
   
   

The Minimum Qualifications


 * Bachelor’s degree in Computer Science, Engineering, Information Systems or related technical field.
 * 8+ years of experience with data analytics, data modeling, and database design.
 * 5+ years experience with ELT methodologies and tools.
 * 5+ years experience in designing, developing, tuning and troubleshooting SQL.
 * 3+ years of coding and scripting (Python, Java, Scala) and design experience.
 * 2+ years of experience with Spark framework.
   
   

The Ideal Qualifications


 * Knowledge of Informatica Power center and Informatica IDMC.
 * Knowledge of distributed, column- orientated technology to create high-performant database technologies like - Vertica, Snowflake.
 * Strong data analysis skills for extracting insights from financial data
 * Proficiency in reporting tools (e.g., Power BI, Tableau).
 * Domain knowledge of Investment Management operations including Security Masters, Securities Trade and Recon Operations, Reference data management, Pricing.
 * Familiarity with regulatory requirements and compliance standards in the investment management industry.
 * Experience with IBOR’s such as Blackrock Alladin, CRD, Eagle STAR (ABOR), Eagle Pace, and Eagle DataMart.
 * Familiarity with investment data platforms such as GoldenSource, FINBOURNE, NeoXam, RIMES, and JPM Fusion.
 * Strong analytical and problem-solving abilities.
 * Exceptional communication and interpersonal skills.
 * Ability to influence and motivate teams without direct authority.
 * Excellent time management and organizational skills, with the ability to prioritize multiple initiatives.
   
   

MassMutual is an equal employment opportunity employer. We welcome all persons to apply.

If you need an accommodation to complete the application process, please contact us and share the specifics of the assistance you need.

California residents: For detailed information about your rights under the California Consumer Privacy Act (CCPA), please visit our California Consumer Privacy Act Disclosures page.

","75 applicants","Full-time","Entry level","Information Technology","Data Infrastructure and Analytics","","","","3631","https://www.linkedin.com/jobs/view/data-engineer-%E2%80%93-corporate-technology-data-engineering-analytics-at-massmutual-4340343599?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr. Data Engineer","Orange, CA","9 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/sr-data-engineer-at-alignment-health-4348233491?trk=public_jobs_topcard-title","Alignment Health","https://www.linkedin.com/company/alignment-health?trk=public_jobs_topcard-org-name","Alignment Health is breaking the mold in conventional health care, committed to serving seniors and those who need it most: the chronically ill and frail. It takes an entire team of passionate and caring people, united in our mission to put the senior first. We have built a team of talented and experienced people who are passionate about transforming the lives of the seniors we serve. In this fast-growing company, you will find ample room for growth and innovation alongside the Alignment Health community. Working at Alignment Health provides an opportunity to do work that really matters, not only changing lives but saving them. Together.

Alignment Healthcare is a data and technology driven healthcare company focused on partnering with health systems, health plans and provider groups to provide care delivery that is preventive, convenient, coordinated, and that results in improved clinical outcomes for seniors.

We are experiencing rapid growth (backed by top private equity firms), our Data Services and BI team is looking for the best and brightest Sr. Data Engineer. Data drives the way we make decisions. We love our customers and understanding them better makes it possible to provide the best clinical outcome and care experience.

We are currently seeking a Sr. Data Engineer for Data & Business Intelligence team. This position will play a key role in design and development of cloud-based BI and Analytics services using Microsoft BI Platform, Microsoft Azure cloud services.

General Duties/Responsibilities (May Include But Are Not Limited To)


 * Translate business requirements into specifications that will be used to implement the required reports and dashboards.
 * Work with business units to gather requirements, development and delivery of business intelligence & reporting services and lead end to end Data delivery.
 * Develops and implements business intelligence & analytics to support organizational initiatives.
 * Build rich and dynamic dashboards using out-of-box features, customizations, and visualizations.
 * Design and publish custom dashboards for business functions, stakeholders, and corporate users around the company.
 * Design, model, develop & optimize stored procedures to meet data management and data reporting objectives.
 * Design and model data flows and ETL procedures ensuring data quality and integrity.
 * Troubleshoot and resolve issues with the processes used and the content produced by the BI platform.
 * Provide ongoing maintenance support through troubleshooting, report modifications and
   
   

optimization.

Supervisory Responsibilities

N/A

Minimum Requirements

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions.

Minimum Experience


 * 5+ years of professional experience in Data Engineering / ETL development & Reporting services.
 * 5+ years of experience with BI/Reporting software products (MSBI) and knowledge of Healthcare Industry standards and requirements.
 * 5+ years of database experience with MS SQL Server.
 * Write efficient Azure SQL queries and stored procedures for high-performance data processing.
 * 5+ years of experience in healthcare industry with proven understanding of data terminology.
 * Healthcare Experience and Clear understanding & working knowledge of HIPAA protocols.
 * Extensive hands-on experience with Microsoft’s Power-BI/SSRS/Azure Data Factory (ADF)and other cloud-based BI and Reporting services.
 * Extensive experience in Advance Analytics tools like -Azure ML, CRAN R Library, Azure Functions, Azure Cognitive Services. o Extensive hands-on experience with Big Data platforms (Databricks, Spark, Hadoop, Python or similar) to process and transform large datasets is a plus. o Experience with Azure, AWS or GCP is a plus.
 * Experience with DevOps pipelines and CI/CD.
   
   

Education/Licensure


 * BS in Computer Science, IT or equivalent and/or equivalent experience. o Microsoft Azure Certification is a plus.
   
   

Other


 * Demonstrated ability to build partnerships and maintain cohesive relationships.
 * Demonstrated ability planning, organizing, and executing multiple complex analytics projects.
 * Ability to effectively present information and respond to questions from groups of managers and customers.
 * Excellent human relations and verbal/written communication skills.
 * Clear understanding & working knowledge of HIPAA protocols.
   
   

Work Environment


 * The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions.
   
   

Essential Physical Functions

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

While performing the duties of this job, the employee is regularly required to talk or hear. The employee regularly is required to stand, walk, sit, use hand to finger, handle or feel objects, tools, or controls; and reach with hands and arms. The employee frequently lifts and/or moves up to 10 pounds. Specific vision abilities required by this job include close vision and the ability to adjust focus.

Alignment Healthcare, LLC is proud to practice Equal Employment Opportunity and Affirmative Action. We are looking for diversity in qualified candidates for employment: Minority/Female/Disable/Protected Veteran.

If you require any reasonable accommodation under the Americans with Disabilities Act (ADA) in completing the online application, interviewing, completing any pre-employment testing or otherwise participating in the employee selection process, please contact careers@ahcusa.com.

Pay Range: $130,332.00 - $195,498.00

Pay range may be based on a number of factors including market location, education, responsibilities, experience, etc.

Alignment Health is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, age, protected veteran status, gender identity, or sexual orientation.


 * DISCLAIMER: Please beware of recruitment phishing scams affecting Alignment Health and other employers where individuals receive fraudulent employment-related offers in exchange for money or other sensitive personal information. Please be advised that Alignment Health and its subsidiaries will never ask you for a credit card, send you a check, or ask you for any type of payment as part of consideration for employment with our company. If you feel that you have been the victim of a scam such as this, please report the incident to the Federal Trade Commission at https://reportfraud.ftc.gov/#/. If you would like to verify the legitimacy of an email sent by or on behalf of Alignment Health’s talent acquisition team, please email careers@ahcusa.com.","48 applicants","Full-time","Mid-Senior level","Information Technology","Hospitals and Health Care","$130,332.00/yr - $195,498.00/yr","","","3278075","https://www.linkedin.com/jobs/view/sr-data-engineer-at-alignment-health-4348233491?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","New York, NY","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/data-engineer-at-rokt-4337139576?trk=public_jobs_topcard-title","Rokt","https://www.linkedin.com/company/rokt?trk=public_jobs_topcard-org-name","We are Rokt, a hyper-growth ecommerce leader. Rokt is the global leader in ecommerce, unlocking real-time relevance in the moment that matters most. Rokt's AI Brain and ecommerce Network powers billions of transactions connecting hundreds of millions of customers, and is trusted to do this by the world's leading companies.

We are a team of builders helping smart businesses find innovative ways to meet customer needs and generate incremental revenue. Leading companies drive 10-50% of additional revenue—and often all their profits—from the extra products or services they sell. This economic edge unleashes a world of possibilities for growth and innovation.

The Rokt engineering team builds best-in-class ecommerce technology that provides personalized and relevant experiences for customers globally and empowers marketers with sophisticated, AI-driven tooling to understand consumers better. Our bespoke platform handles millions of transactions per day. It considers billions of data points which give engineers the opportunity to build technology at scale, collaborate across teams, and gain exposure to a wide range of technology.

At Rokt, we practice transparency in career paths and compensation. At Rokt, we believe in transparency, which is why we have a well-defined career ladder with transparent compensation and clear career paths based on competency and ability. Rokt'stars constantly strive to raise the bar, pushing the envelope of what is possible.

We are looking for an Data Engineer.

A fixed annual salary of $170,000 - $210,000, an employee equity plan grant, and world-class benefits.

Equity grants are issued in good faith, subject to company policies, board approval, and individual eligibility.

About The Role

Join Rokt as a Data Engineer on the Metrics team, you will architect the semantic and data layers that define how Rokt measures success. You'll transform raw product and GTM event streams into trusted, governed, analytics-ready models; codify business logic into reusable metric definitions; and build proactive monitoring to keep our ""single source of truth"" healthy and reliable at scale. You'll serve as metric steward for one or more business domains, owning the semantic layer and data models end-to-end

You'll partner closely with engineers, product managers, data scientists, and GTM stakeholders across Rokt's Research & Development organization to enable self-serve insights and consistent decision-making.

What You'll Do


 * Model data for trust & reuse: Build modular, tested transformations (e.g. in Spark/Python) that convert raw logs into canonical datasets and marts powering experimentation, product analytics, and executive reporting.
 * Own the metrics layer: Design and maintain a governed catalog of metrics and dimensions (e.g.Datahub) with clear definitions, lineage, and versioning.
 * Operate reliable pipelines: Orchestrate and harden batch/stream pipelines (e.g., Airflow/Kafka/Spark) with SLAs, backfills, and cost-aware performance tuning.
 * Proactive data quality: Implement unit/integration tests, anomaly detection, and monitoring (e.g Great Expectations/Monte Carlo/Bigeye) to catch metric drift and upstream integration issues before they reach users.
 * Integration health visibility: Build dashboards/alerts for client conversion data health and integration metrics (e.g., EMQ, AQS), and drive root-cause analysis and remediation with partner teams.
 * Enable self-serve analytics: Create intuitive dashboards and templates (e.g., Tableau) that expose the metric layer and unlock analysis for engineering, PM, and GTM users.
 * Define logging standards: Partner with product/engineering to instrument event schemas and logging guidelines that improve downstream observability and data quality.
 * Document & govern: Establish style guides, playbooks, and change-management processes for metric and model evolution (including deprecation and backfills).
 * Raise the bar: Lead code reviews, mentor peers, and contribute to platform roadmaps across Rokt Research.
   
   

Requirements

Who You Are


 * 3-6+ years in data engineering / data warehousing roles building production-grade data models and metrics at scale.
 * Expert SQL (Trino preferred) and solid Python for analytics engineering and data tooling.
 * Experience with Spark (PySpark or Spark SQL) for large-scale data processing, optimization, and distributed computation.
 * Hands-on orchestration experience (e.g., Airflow, Dagster) and comfort operating pipelines end-to-end (monitoring, backfills, SLAs, cost/perf tuning). Manage Kubernetes based data workflows.
 * Cloud experience with AWS
 * Proficiency in at least one cloud warehouse (Clickhouse, Snowflake, BigQuery, or Redshift) or datalake technologies (i.e Apache Iceberg, Apache Hudi, DeltaLake) and comfort with large-scale partitioning, clustering, and performance patterns.
 * Track record owning data quality and data reliability for critical metrics; you've implemented tests, lineage, and observability that prevented or rapidly mitigated incidents.
 * Ability to partner with engineers, PMs, and GTM teams to translate ambiguous business questions into robust metric definitions and data products.
 * Experience building/maintaining a semantic metrics layer (dbt metrics, LookML, MetricFlow, or Transform) and/or reverse ETL to operational tools.
 * Exposure to streaming patterns (Kafka/Flink/Spark Structured Streaming) and metric computation.
 * Familiarity with experimentation frameworks (A/B testing, guardrail metrics) and causal inference basics.
 * Domain experience in ecommerce / adtech / performance marketing.
 * Infra-as-code (e.g., Terraform), containerization (Docker/Kubernetes), or platform engineering exposure.
   
   

Benefits

Why Join Rokt


 * Build the Future of AI in Ecommerce: Be at the forefront of AI-driven transformation in a company that's pioneering how brands engage customers in the ""moment that matters"" during online transactions.
 * Hyper-Growth = Fast Progression: Rokt is a rapidly growing tech leader, which means huge opportunities for your career advancement, learning, and taking on bigger responsibilities quickly.
 * Culture of Builders: Work with a smart, humble, and bold team that shares a ""builder"" DNA - we love to innovate, take risks, and turn ambitious ideas into tangible results. We win as a team and learn from every experiment.
 * Ownership & Impact: Every Rokt'star (employee) has a voice and real equity in the company. You'll have autonomy to make decisions, drive projects, and see the direct impact of your work on millions of users.
 * World-Class Benefits & Support: Join a people-first culture with transparent career paths, continuous development (LevelUp training, mentorship), and great perks (equity grants, catered lunches, global offices, and more) that empower you to do your best work.
   
   

About The Benefits

We leverage best-in-class technology and market-leading innovation in AI and ML, with all of that being underlined by building and maintaining a fantastic and inclusive culture where people can be their authentic selves, and offering a great list of perks and benefits to go with it:


 * Become a shareholder. Every Rokt'star gets equity in the company
 * Enjoy catered lunch every day and healthy snacks in the office. Plus join the gym on us!
 * Extra leave (bonus annual leave, sabbatical leave etc.)
 * Access generous retirement plans like a 4% dollar-for-dollar 401K matching plan and get fully funded premium health insurance!
 * Dog-friendly office
 * Work with the greatest talent in town
 * See the world! We have offices in New York, Seattle, Sydney, Tokyo and London
   
   

We believe we're better together. We love spending time together and are in the office most days (teams are in the office minimum 4 days per week).

We at Rokt choose to create a company that is as diverse and inclusive as the world we live in by attracting, growing & keeping the best talent. Equal employment opportunities are available to all applicants without regard to race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

If this sounds like a role you'd enjoy, apply here, and you'll hear from our recruiting team.

Note: The first stage of the recruitment process for this role is to complete a 15-minute online aptitude test as well as an employee personality profile assessment, which will be sent out to your application email. Successful candidates will be contacted to discuss the next steps.","37 applicants","Full-time","Entry level","Engineering","Advertising Services, Technology, Information and Internet, and Software Development","$170,000.00/yr - $210,000.00/yr","","","1977526","https://www.linkedin.com/jobs/view/data-engineer-at-rokt-4337139576?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist","Los Angeles, CA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/data-scientist-at-softermii-4347650179?trk=public_jobs_topcard-title","Softermii","https://www.linkedin.com/company/softermii?trk=public_jobs_topcard-org-name","Research and Development Office

Data Scientist

Remote

About The Company

Softermii (https://www.softermii.com/) is an outsourcing/outstaffing company with more than 11 years of experience in web and mobile application development with a team of more than 120 specialists from 6 countries.

We have withstood multiple challenges, such as COVID-19 pandemic and war aggression against Ukraine, we have secured sustainable development processes, saved all our projects and jobs. Even more – we’re constantly growing.

Every day, we add a new project to our portfolio in the following areas of expertise:


 * Healthcare
 * Real estate
 * Livestream E-commerce
 * Fintech (Wealth Tech, Capital Trading)
 * Real Time Communications (RTC)
   
   

In addition, we develop 2 of our own solutions that help our customers get faster applications for video or audio calls (https://www.softermii.com/solutions/vidrtc) or an application for real estate with 3D visualization

(https://www.softermii.com/solutions/apartmii)

Company Mission

Softermii: Succeed Without (L) imitations

We will turn any idea into a valuable product.

Our Plans As a Company

We want to move from a regular outsourcing business to an ecosystem of outsourcing, education and product development companies.

Over the years, we have arrived at a highly personalized working model with transparent workflows. This model allows us to create software products that meet our clients’ goals with precision.

Softermii is currently looking for a Data Scientist

Project: The project is a platform that helps companies manage their work more easily.

It is designed so that business owners and employees can focus on growing the company rather than dealing with routine tasks.

The Service Allows You To


 * quickly resolve customer requests and issues (helpdesk / support),
 * accurately track working hours — both billable and non-billable,
 * automate invoicing,
 * effectively manage projects and their profitability.
   
   

Type of cooperation: full-time

️Your Responsibilities On The Project Will Be


 * Build and maintain ML models for ticket classification, routing, and support automation.
 * Develop intelligent systems for knowledge retrieval, response generation, and predictive analytics.
 * Automate data workflows and create reliable, scalable ML pipelines from data preprocessing to deployment.
 * Monitor model performance, detect drift, and ensure ongoing accuracy and stability of AI systems.
 * Partner with Product, Support, and Engineering teams to integrate ML solutions into helpdesk workflows.
 * Own AI/ML projects end-to-end: from defining the problem to production deployment and iteration.
 * Share knowledge, conduct code reviews, and promote best practices across the team.
   
   

You can be part of the following team: AI Consultant, CTO (you will work with CTO the most).

Tools we use: Jira, Confluence, Git, Figma

Technical Requirements


 * 4+ years of experience in Data Science or ML, with a track record of delivering production models.
 * Experience with LLMs and prompt engineering, text classification, and machine learning fundamentals.
 * Advanced programming skills in Python (pandas, numpy, scikit-learn, CatBoost/XGBoost), writing clean and maintainable code.
 * Excellent SQL skills, confident with relational databases and query optimization.
 * Experience deploying, monitoring, and maintaining ML models in production environments.
 * Strong problem-solving mindset, able to translate business requirements into ML solutions.
 * Clear communicator who can explain complex models and systems to both technical and non-technical stakeholders.
 * Experience with APIs;
 * English level (written & verbal) - Upper-intermediate.
   
   

Will Be a Pluss If You Have


 * Experience building RAG systems or knowledge retrieval applications.
 * Familiarity with LangChain or similar LLM orchestration frameworks.
 * Background in helpdesk, support operations, or MSP domain.
 * Experience with vector databases (ChromaDB, Pinecone, Weaviate, pgvector).
 * MLOps practices and tools (model versioning, CI/CD for ML).
 * Experience with cloud platforms (Azure preferred).
 * ETL/orchestration frameworks (Airflow, Prefect).
 * Sentiment analysis and text mining applications.
   
   

‍Who will you have the opportunity to meet during the hiring process (stages):

Call, HR, Tech interview, Final interview with the client.

What We Can Offer You


 * We have stable and highly-functioning processes – everyone has their own role and clear responsibilities, so decisions are made quickly and without unnecessary approvals.
 * You will have enough independence to make decisions that can affect not only the project but also the work of the company.
 * We are a team of like-minded experts who create interesting products during working hours, and enjoy spending free time together.
 * Do you like learning something new in your profession or want to improve your English? If you join us in a full-time role, we’ll be happy to cover 50% of the cost of our internal English courses, as well as external professional courses, webinars, conferences.
 * Do you want an individual development plan? We will form one especially for you + you can count on mentoring from our seniors and leaders.
 * Do you have a friend who is currently looking for new job opportunities? Recommend them to us and get a bonus.
 * And what if you want to relax? If you join us full-time, we provide 21 paid vacation days. We also have 11 paid days off for Public Holidays.
 * What if you're feeling bad? For the full-time collaboration, you can take 5 paid sick leave days per year.
 * Do you want to volunteer? We will add you to a chat, where we can get a bulletproof vest, buy a pickup truck or send children's drawings to the front.
 * And we have the most empathetic HRs (who also volunteers!). So we are ready to support your well-being in various ways.
   
   

A Little More Information That You May Find Useful


 * our adaptation period lasts 3 months, this period of time is enough for us to understand each other better;
 * there is a performance review after each year of our collaboration where we use a skills map to track your growth;
 * we really have no boundaries in the truest sense of the word – we have a flexible working day.
   
   

We are looking for like-minded professionals who believe in making the world a better place by building technology that’s meant to last and scale.

Join Softermii and help us take software to the next level of awesome.

Of course, we have a referral bonus system. So if you have a friend who likes our job opening, you can give us their telegram contact, and we in turn will thank you with a bonus if we start working with them!","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","IT Services and IT Consulting","","","","10416761","https://www.linkedin.com/jobs/view/data-scientist-at-softermii-4347650179?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer – Corporate Technology Data Engineering & Analytics","Hartford, CT","21 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-engineer-%E2%80%93-corporate-technology-data-engineering-analytics-at-massmutual-4340163903?trk=public_jobs_topcard-title","MassMutual","https://www.linkedin.com/company/massmutual-financial-group?trk=public_jobs_topcard-org-name","The Opportunity

Join our dynamic team as a Data Engineer – Corporate Technology Data Engineering & Analytics, where you'll play a pivotal role in driving the execution of our data and technology strategy. This role is crucial in driving digital transformation and operational efficiency across Investment Management. As part of this role, you will engage in building data solutions including streaming and batch pipelines, data marts & data warehouse. You will be responsible for establishing robust data collection and processing pipelines to fulfill Investment Management business requirements.

The Team

You’ll be an integral part of our esteemed Corporate Technology Team, focused on Data Engineering & Analytics. Our team operates on a global scale, driving innovation and excellence across diverse areas of expertise. As a Data Engineer, you'll play a critical role in high impact Corporate Technology Investment Initiatives, ensuring alignment with organizational objectives and driving impactful outcomes. This is an opportunity to collaborate closely with Corporate Technology Data and Analytics team and Investment management business stakeholders. Our team thrives on collaboration, innovation, and a shared commitment to excellence. Together, we're shaping the future of technology within our organization and making a lasting impact on a global scale. Join us and be part of a dynamic team where your contributions will be valued and your potential unleashed.

The Impact


 * Design, build, and measure complex ELT jobs to process disparate data sources and form a high integrity, high quality, clean data asset.
 * Executes and provides feedback for data modeling policies, procedure, processes, and standards.
 * Assists with capturing and documenting system flow and other pertinent technical information about data, database design, and systems.
 * Develop comprehensive data quality standards and implement effective tools to ensure data accuracy and reliability.
 * Collaborate with various Investment Management departments to gain a better understanding of new data patterns.
 * Collaborate with Data Analysts, Data Architects, and BI developers to ensure design and development of scalable data solutions aligning with business goals.
 * Translate high-level business requirements into detailed technical specs.
   
   

The Minimum Qualifications


 * Bachelor’s degree in Computer Science, Engineering, Information Systems or related technical field.
 * 8+ years of experience with data analytics, data modeling, and database design.
 * 5+ years experience with ELT methodologies and tools.
 * 5+ years experience in designing, developing, tuning and troubleshooting SQL.
 * 3+ years of coding and scripting (Python, Java, Scala) and design experience.
 * 2+ years of experience with Spark framework.
   
   

The Ideal Qualifications


 * Knowledge of Informatica Power center and Informatica IDMC.
 * Knowledge of distributed, column- orientated technology to create high-performant database technologies like - Vertica, Snowflake.
 * Strong data analysis skills for extracting insights from financial data
 * Proficiency in reporting tools (e.g., Power BI, Tableau).
 * Domain knowledge of Investment Management operations including Security Masters, Securities Trade and Recon Operations, Reference data management, Pricing.
 * Familiarity with regulatory requirements and compliance standards in the investment management industry.
 * Experience with IBOR’s such as Blackrock Alladin, CRD, Eagle STAR (ABOR), Eagle Pace, and Eagle DataMart.
 * Familiarity with investment data platforms such as GoldenSource, FINBOURNE, NeoXam, RIMES, and JPM Fusion.
 * Strong analytical and problem-solving abilities.
 * Exceptional communication and interpersonal skills.
 * Ability to influence and motivate teams without direct authority.
 * Excellent time management and organizational skills, with the ability to prioritize multiple initiatives.
   
   

MassMutual is an equal employment opportunity employer. We welcome all persons to apply.

If you need an accommodation to complete the application process, please contact us and share the specifics of the assistance you need.

California residents: For detailed information about your rights under the California Consumer Privacy Act (CCPA), please visit our California Consumer Privacy Act Disclosures page.

","37 applicants","Full-time","Entry level","Information Technology","Data Infrastructure and Analytics","","","","3631","https://massmutual.easyapply-ats.com/us/linkedin/692d0d96ebc5da86b53da8a6?sa_f=692e2c0068f043330648584a","EXTERNAL",""
"Data Scientist","Orange, CA","1 week ago","2025-11-25","https://www.linkedin.com/jobs/view/data-scientist-at-alignment-health-4347336736?trk=public_jobs_topcard-title","Alignment Health","https://www.linkedin.com/company/alignment-health?trk=public_jobs_topcard-org-name","Alignment Health is breaking the mold in conventional health care, committed to serving seniors and those who need it most: the chronically ill and frail. It takes an entire team of passionate and caring people, united in our mission to put the senior first. We have built a team of talented and experienced people who are passionate about transforming the lives of the seniors we serve. In this fast-growing company, you will find ample room for growth and innovation alongside the Alignment Health community. Working at Alignment Health provides an opportunity to do work that really matters, not only changing lives but saving them. Together.

Alignment Healthcare is a data and technology driven healthcare company focused partnering with health systems, health plans and provider groups to provide care delivery that is preventive, convenient, coordinated, and that results in improved clinical outcomes for seniors.

We are seeking a mission-driven Data Scientist to join our growing team and support risk adjustment strategy within our Medicare Advantage line of business. This role focuses on enhancing risk score accuracy, CMS audit preparedness (RADV), and building AI-powered tools that improve clinical documentation review and integrity.

You’ll play a key role in advancing AVA, our proprietary clinical intelligence platform, by developing next-generation models that support autonomous chart review and NLP/GenAI-driven documentation analytics. This is a unique opportunity to work at the intersection of healthcare, compliance, and machine learning—transforming how we ensure both quality and regulatory alignment.

Job Duties/Responsibilities

Collaborate with key business leaders to understand their business problems and come up with analytical solutions. Applying coding skills and knowledge data structures to develop projects in partnership with other scientists and engineers in the team Build customer segmentation models to better understand our customers and tailor the clinical outcome and healthcare care experience for them. Build and fine-tune models for both LLMs and OCR-based document understanding, enabling accurate extraction from scanned or low-quality medical charts. Develop scalable model pipelines that integrate NLP, computer vision, and unstructured data, leveraging cloud-based infrastructure (Azure) and containerized environments. Collaborate with engineering teams to version, test, and deploy models using Git, CI/CD pipelines, and virtual machine (VM) environments. Design algorithms to predict audit risk and detect documentation anomalies across cohorts and markets. Partner with Coding, Compliance, CDI, Clinical, and Legal teams to ensure data outputs are aligned with CMS guidance. Help standardize definitions, documentation logic, and reporting workflows to scale enterprise-wide AI-readiness. Help analytical support for CMS Star Ratings strategy, including:


 * Audit sampling methodology validation
 * Chart review error pattern identification
 * Root cause analysis on deletion rates and extrapolation exposure
   
   

Supervisory Responsibilities: N/A

Minimum Requirements

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Minimum Experience


 * 2+ years of relevant experience in predictive modeling and analysis
   
   

Education/Licensure


 * Required: PhD in Computer Science, Engineering, Mathematics, Statistics, or related field, or equivalent experience
   
   

Other


 * Excellent communication, analytical and collaborative problem-solving skills
 * Experience in building end to end data science solutions and applying machine learning methods to real world problems with measurable outcomes.
 * Deep understanding and experience with various machine learning algorithms, including deep neural networks, natural language processing and LLMs.
 * Solid data structures & algorithms background.
 * Strong programming skills in one of the following: Python, Java, R, Scala or C++
 * Demonstrated proficiency in SQL and relational databases.
 * Experience with data visualization and presentation, turning complex analysis into insight.
 * Experience in setting experimental analytics frameworks or strategies for complex scenarios.
 * Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development, and evaluation data sets, etc.
 * Experience with manipulating and analyzing complex, high-volume, high-dimensionality and unstructured data from varying sources
   
   

Preferred Qualifications


 * Healthcare experience
 * Experience in Big Data processing technologies: Databricks
 * Experience in Azure, AWS or other cloud ecosystems.
 * Experience in NoSQL databases.
 * Published work in academic conferences or industry circles.
 * Demonstrable track record dealing well with ambiguity, prioritizing needs, and delivering results in an agile, dynamic startup environment
 * Knowledge of CMS Risk Adjustment Data Validation (RADV) audits
   
   

Work Environment


 * The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
   
   

Essential Physical Functions

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.


 * While performing the duties of this job, the employee is regularly required to talk or hear. The employee regularly is required to stand, walk, sit, use hand to finger, handle or feel objects, tools, or controls; and reach with hands and arms.
 * The employee frequently lifts and/or moves up to 10 pounds. Specific vision abilities required by this job include close vision and the ability to adjust focus.
   
   

Alignment Healthcare, LLC is proud to practice Equal Employment Opportunity and Affirmative Action. We are looking for diversity in qualified candidates for employment: Minority/Female/Disable/Protected Veteran.

If you require any reasonable accommodation under the Americans with Disabilities Act (ADA) in completing the online application, interviewing, completing any pre-employment testing or otherwise participating in the employee selection process, please contact careers@ahcusa.com.

Pay Range: $149,882.00 - $224,823.00

Pay range may be based on a number of factors including market location, education, responsibilities, experience, etc.

Alignment Health is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, age, protected veteran status, gender identity, or sexual orientation.


 * DISCLAIMER: Please beware of recruitment phishing scams affecting Alignment Health and other employers where individuals receive fraudulent employment-related offers in exchange for money or other sensitive personal information. Please be advised that Alignment Health and its subsidiaries will never ask you for a credit card, send you a check, or ask you for any type of payment as part of consideration for employment with our company. If you feel that you have been the victim of a scam such as this, please report the incident to the Federal Trade Commission at https://reportfraud.ftc.gov/#/. If you would like to verify the legitimacy of an email sent by or on behalf of Alignment Health’s talent acquisition team, please email careers@ahcusa.com.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Hospitals and Health Care","$149,882.00/yr - $224,823.00/yr","","","3278075","https://www.linkedin.com/jobs/view/data-scientist-at-alignment-health-4347336736?trk=public_jobs_topcard-title","EASY_APPLY",""
"Lead Analytics Engineer","New York, NY","1 week ago","2025-11-22","https://www.linkedin.com/jobs/view/lead-analytics-engineer-at-clear-4333358567?trk=public_jobs_topcard-title","CLEAR","https://www.linkedin.com/company/clear-by-alclear-llc?trk=public_jobs_topcard-org-name","Have you ever had that green-light feeling? When you hit every green light and the day just feels like magic. CLEAR's mission is to create frictionless experiences where every day has that feeling. With more than 30+ million passionate members and hundreds of partners around the world, CLEAR’s identity platform is transforming the way people live, work, and travel. Whether it’s at the airport, stadium, or right on your phone, CLEAR connects you to the things that make you, you - unlocking easier, more secure, and more seamless experiences - making them all feel like magic.

As CLEAR continues to scale, we’re deepening our investment in the data ecosystem that powers our decision-making. We’re looking for a Lead Analytics Engineer to own the presentation layer of our data stack. This is a hands-on, senior individual contributor role for someone who blends exquisite data modeling craft, deep familiarity with tools like dbt and Looker, a knowledge of the state of the art, and a passion for designing data structures that enable intuitive self-service. 

You’ll define the semantic and analytical layers that drive clarity across the business, transforming complex data into clear, trusted metrics and models that everyone at CLEAR can rely on.

What You'll Do:

 * Own and evolve the presentation and semantic layers: design, build, and optimize data models that serve as the foundation for Analytics at CLEAR. Develop metrics that drive a consistent, opinionated view of business performance across Finance, Product, Marketing, and Operations teams.
 * Partner with data engineering teams to define the transformation logic (via dbt or similar frameworks) that connects raw data to consumable business views, optimize pipelines to improve query performance, and ensure models align with best practices.
 * Own a roadmap for enabling AI-powered analytics driving improved data documentation and a path for exposing our semantic layer to AI models. 
 * Improve self-service rates by building intuitive data structures, reusable views, and clear metric definitions that empower teams to answer their own questions.
 * Mentor analysts and analytics engineers, guiding them in data modeling best practices, BI design, and stakeholder engagement.

What You Bring:

 * 7+ years of experience working in analytics engineering, BI engineering, or data engineering roles within a modern cloud data warehouse environment. Today we use Snowflake, dbt, Dagster, and Looker.
 * Expert-level SQL: you can structure models for clarity, reuse, and performance at scale. 
 * Deep experience with BI tools including semantic layer design, metric standardization, and the enablement of AI-driven analytics.
 * Strong understanding of dimensional modeling and data warehousing principles. You are always thinking about performance and scalability.
 * Demonstrated ability to balance technical rigor with business impact designing models that are as intuitive for stakeholders as they are efficient under the hood.
 * Track record of driving BI and self-service, creating environments where data users can confidently explore and analyze on their own.
 * Strong communication and influence skills, able to partner effectively across technical and business domains to align on data strategy and definitions.
 * Proactive ownership and curiosity, always seeking opportunities to simplify, standardize, and scale how data is modeled and delivered.

Why You’ll Love This Role:
 * High-impact: You’ll build the analytics foundations that will guide decision-making across CLEAR.
 * Craft and influence: This role blends technical ownership with the opportunity to shape how data is understood company-wide.
 * Mission-driven culture: You’ll help build experiences that make life simpler and more secure for millions.
 * Autonomy: You’ll own and lead initiatives end-to-end, mentor others, and establish best practices that scale with the company.
 * Culture that moves: We are a team that values curiosity, iteration, direct feedback, and risk taking.
 * Great benefits & growth: Competitive compensation, liquid equity, catered lunches, and good vibes.

How You'll be Rewarded:

At CLEAR, we help YOU move forward - because when you’re at your best, we’re at our best. You’ll work with talented team members motivated by our mission of making experiences safer and easier. Our offices are bright and energetic with an open concept and plenty of conference rooms and casual co-working spaces. We also offer catered lunches every day and have fully stocked kitchens. Outside of the office, we invest in your well-being and learning & development with stipends and reimbursement programs. 

We offer holistic total rewards, including comprehensive healthcare plans, family-building benefits (fertility and adoption/surrogacy support), flexible time off, annual wellness stipend, free OneMedical memberships for you and your dependents, a CLEAR Plus membership, and a 401(k) retirement plan with employer match. The base salary range for this role is $165,000-$200,000, depending on levels of skills and experience.

The base salary range represents the low and high end of CLEAR’s salary range for this position. Salaries will vary depending on various factors which include, but are not limited to location, education, skills, experience and performance. The range listed is just one component of CLEAR’s total compensation package for employees and other rewards may include annual bonuses, commission, Restricted Stock Units.

CLEAR provides reasonable accommodation to qualified individuals with disabilities or protected needs. Please let us know if you require a reasonable accommodation to apply for a job or perform your job. Examples of reasonable accommodation include, but are not limited to, time off, extra breaks, making a change to the application process or work procedures, policy exceptions, providing documents in an alternative format, live captioning or using a sign language interpreter, or using specialized equipment.



 ","33 applicants","Full-time","Mid-Senior level","Information Technology","Consumer Services","$165,000.00/yr - $200,000.00/yr","","","961661","https://www.linkedin.com/jobs/view/lead-analytics-engineer-at-clear-4333358567?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer – Corporate Technology Data Engineering & Analytics","Springfield, MA","21 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-engineer-%E2%80%93-corporate-technology-data-engineering-analytics-at-massmutual-4340373535?trk=public_jobs_topcard-title","MassMutual","https://www.linkedin.com/company/massmutual-financial-group?trk=public_jobs_topcard-org-name","The Opportunity

Join our dynamic team as a Data Engineer – Corporate Technology Data Engineering & Analytics, where you'll play a pivotal role in driving the execution of our data and technology strategy. This role is crucial in driving digital transformation and operational efficiency across Investment Management. As part of this role, you will engage in building data solutions including streaming and batch pipelines, data marts & data warehouse. You will be responsible for establishing robust data collection and processing pipelines to fulfill Investment Management business requirements.

The Team

You’ll be an integral part of our esteemed Corporate Technology Team, focused on Data Engineering & Analytics. Our team operates on a global scale, driving innovation and excellence across diverse areas of expertise. As a Data Engineer, you'll play a critical role in high impact Corporate Technology Investment Initiatives, ensuring alignment with organizational objectives and driving impactful outcomes. This is an opportunity to collaborate closely with Corporate Technology Data and Analytics team and Investment management business stakeholders. Our team thrives on collaboration, innovation, and a shared commitment to excellence. Together, we're shaping the future of technology within our organization and making a lasting impact on a global scale. Join us and be part of a dynamic team where your contributions will be valued and your potential unleashed.

The Impact


 * Design, build, and measure complex ELT jobs to process disparate data sources and form a high integrity, high quality, clean data asset.
 * Executes and provides feedback for data modeling policies, procedure, processes, and standards.
 * Assists with capturing and documenting system flow and other pertinent technical information about data, database design, and systems.
 * Develop comprehensive data quality standards and implement effective tools to ensure data accuracy and reliability.
 * Collaborate with various Investment Management departments to gain a better understanding of new data patterns.
 * Collaborate with Data Analysts, Data Architects, and BI developers to ensure design and development of scalable data solutions aligning with business goals.
 * Translate high-level business requirements into detailed technical specs.
   
   

The Minimum Qualifications


 * Bachelor’s degree in Computer Science, Engineering, Information Systems or related technical field.
 * 8+ years of experience with data analytics, data modeling, and database design.
 * 5+ years experience with ELT methodologies and tools.
 * 5+ years experience in designing, developing, tuning and troubleshooting SQL.
 * 3+ years of coding and scripting (Python, Java, Scala) and design experience.
 * 2+ years of experience with Spark framework.
   
   

The Ideal Qualifications


 * Knowledge of Informatica Power center and Informatica IDMC.
 * Knowledge of distributed, column- orientated technology to create high-performant database technologies like - Vertica, Snowflake.
 * Strong data analysis skills for extracting insights from financial data
 * Proficiency in reporting tools (e.g., Power BI, Tableau).
 * Domain knowledge of Investment Management operations including Security Masters, Securities Trade and Recon Operations, Reference data management, Pricing.
 * Familiarity with regulatory requirements and compliance standards in the investment management industry.
 * Experience with IBOR’s such as Blackrock Alladin, CRD, Eagle STAR (ABOR), Eagle Pace, and Eagle DataMart.
 * Familiarity with investment data platforms such as GoldenSource, FINBOURNE, NeoXam, RIMES, and JPM Fusion.
 * Strong analytical and problem-solving abilities.
 * Exceptional communication and interpersonal skills.
 * Ability to influence and motivate teams without direct authority.
 * Excellent time management and organizational skills, with the ability to prioritize multiple initiatives.
   
   

MassMutual is an equal employment opportunity employer. We welcome all persons to apply.

If you need an accommodation to complete the application process, please contact us and share the specifics of the assistance you need.

California residents: For detailed information about your rights under the California Consumer Privacy Act (CCPA), please visit our California Consumer Privacy Act Disclosures page.

","56 applicants","Full-time","Entry level","Information Technology","Data Infrastructure and Analytics","","","","3631","https://massmutual.easyapply-ats.com/us/linkedin/692d0d94ebc5da86b53da8a2?sa_f=692e2c0068f043330648584a","EXTERNAL",""
"Data Scientist, Financial Engineering","San Francisco, CA","1 day ago","2025-11-30","https://www.linkedin.com/jobs/view/data-scientist-financial-engineering-at-openai-4313803491?trk=public_jobs_topcard-title","OpenAI","https://www.linkedin.com/company/openai?trk=public_jobs_topcard-org-name","About The Team

OpenAI’s Financial Engineering (FinEng) team powers how revenue flows through our products—pricing & packaging, checkout, payments, subscriptions, and the financial infrastructure behind them. We partner with Product, Engineering, Risk, Finance, and Go-to-Market to make paying for OpenAI products seamless, reliable, and efficient worldwide.

About The Role

As a Data Scientist on FinEng, you’ll own the analytics and experimentation that improve our checkout and payments, subscriptions, and pricing & monetization systems. You’ll define the metrics that matter, build the source-of-truth data assets, and design experiments that increase conversion, reduce churn and payment failures, and expand global payment method coverage. Your work will directly influence revenue, customer experience, and how we scale internationally.

This role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.

In this role, you will


 * Own checkout & payments analytics and experimentation across methods and locales (e.g., bank transfers, emerging rails), improving conversion while monitoring risk and latency.
 * Build and run the experimentation program for in-house checkout—define success metrics and guardrails, execute staged rollouts, and use offline incrementality when online tests aren’t feasible.
 * Create operational visibility and source-of-truth data with FinEng Data Engineering—land team-level metrics, SLAs, and self-serve dashboards that drive proactive action.
 * Lead subscription, retention, and monetization analytics—ship launch-readiness for new subscription features, reduce involuntary churn (e.g., targeted retrials/nudges), and develop elasticity/FX frameworks toward pricing optimality.
   
   

You might thrive in this role if you have


 * 5+ years in a quantitative role (data science, product analytics, or experimentation) in high-growth or fintech environments
 * Fluency in SQL and Python, with a track record designing and interpreting A/B tests and quasi-experiments
 * Experience building product metrics from scratch and operationalizing them for decision-making
 * Excellent communication skills with PMs, engineers, risk/finance partners, and executives
 * Strategic instincts beyond significance tests—clear thinking about tradeoffs (conversion vs. risk vs. cost vs. user experience)
   
   

You could be an especially great fit if you have


 * Payments, checkout, or subscription analytics experience (PSPs, bank rails, disputes/refunds, risk, e-commerce)
 * Background in offline incrementality methods, uplift modeling, CUPED/causal inference, or counterfactual evaluation
 * Experience with internationalization/local payments, FX, and pricing & packaging strategy
 * Comfort building operational analytics (alerting, SLIs/SLOs) and partnering closely with data engineering
   
   

About OpenAI

OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.

We are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.

For additional information, please see OpenAI’s Affirmative Action and Equal Employment Opportunity Policy Statement.

Background checks for applicants will be administered in accordance with applicable law, and qualified applicants with arrest or conviction records will be considered for employment consistent with those laws, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act, for US-based candidates. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.

To notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.

We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.

OpenAI Global Applicant Privacy Policy

At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.

Compensation Range: $255K - $405K","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Research Services","$255,000.00/yr - $405,000.00/yr","","","11130470","https://jobs.ashbyhq.com/openai/898a87fb-4cb8-450e-9840-ee5dc710a57d/application","EXTERNAL",""
"Data Engineer","Lehi, UT","5 days ago","2025-11-27","https://www.linkedin.com/jobs/view/data-engineer-at-adobe-4337845270?trk=public_jobs_topcard-title","Adobe","https://www.linkedin.com/company/adobe?trk=public_jobs_topcard-org-name","Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

Are you ready to have fun with data? As a Data Engineer focused on cloud spend optimization at Adobe, you’ll play a key role in transforming massive amounts of cloud usage data into actionable insights. You’ll combine strong data engineering fundamentals with analytical curiosity—helping surface patterns, trends, and opportunities to drive more efficient cloud operations across Adobe’s platforms and products.

This role sits at the intersection of data engineering, analytics, and AI innovation. You’ll build and maintain data pipelines that power our cost insights, partner with analysts and data scientists to interpret results, and experiment with emerging approaches—including AI Agent development—to automate data analysis and accelerate decision-making.

Key Responsibilities


 * Design, build, and maintain scalable and reliable data pipelines for cloud spend and utilization analytics.
 * Develop data models and transformations that make complex cloud usage data accessible and useful.
 * Analyze large datasets to identify trends, anomalies, and optimization opportunities.
 * Partner with data scientists and product engineers to translate findings into business and technical actions.
 * Contribute to the development of data-driven tools, including early experimentation with AI Agents for insight generation and automation.
 * Ensure data quality, integrity, and performance across all stages of the pipeline.
 * Document workflows, participate in code reviews, and continuously improve data processes.
   
   

Qualifications


 * BS in Computer Science, Engineering, or a related field with 4+ years of experience in data engineering or data science.
 * Strong proficiency in SQL and Python for data wrangling, automation, and analysis.
 * Experience with AWS, DBT, and Airflow (or similar modern data stack tools).
 * Solid understanding of data modeling, warehousing concepts, and ETL/ELT pipeline design.
 * Comfortable with exploratory data analysis and visualization using tools like Pandas, Matplotlib, or Jupyter.
 * Curiosity about AI Agent development and how generative AI can transform analytics workflows.
 * Analytical mindset with strong attention to detail and problem-solving skills.
 * Strong communication skills and a collaborative, growth-oriented attitude.
   
   

Our compensation reflects the cost of labor across several  U.S. geographic markets, and we pay differently based on those defined markets. The U.S. pay range for this position is $113,400 -- $206,300 annually. Pay within this range varies by work location and may also depend on job-related knowledge, skills, and experience. Your recruiter can share more about the specific salary range for the job location during the hiring process.

At Adobe, for sales roles starting salaries are expressed as total target compensation (TTC = base + commission), and short-term incentives are in the form of sales commission plans. Non-sales roles starting salaries are expressed as base salary and short-term incentives are in the form of the Annual Incentive Plan (AIP).

In addition, certain roles may be eligible for long-term incentives in the form of a new hire equity award.

State-Specific Notices:

California:

Fair Chance Ordinances

Adobe will consider qualified applicants with arrest or conviction records for employment in accordance with state and local laws and “fair chance” ordinances.

Colorado:

Application Window Notice

If this role is open to hiring in Colorado (as listed on the job posting), the application window will remain open until at least the date and time stated above in Pacific Time, in compliance with Colorado pay transparency regulations. If this role does not have Colorado listed as a hiring location, no specific application window applies, and the posting may close at any time based on hiring needs.

Massachusetts:

Massachusetts Legal Notice

It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.

Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.

Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.","Over 200 applicants","Full-time","Entry level","Information Technology","Advertising Services, IT Services and IT Consulting, and Software Development","$113,400.00/yr - $206,300.00/yr","","","1480","https://careers.adobe.com/us/en/job/ADOBUSR161781EXTERNALENUS/Data-Engineer?utm_source=linkedin&utm_medium=phenom-feeds&source=LinkedIn","EXTERNAL",""
"Analytics Engineer","Austin, TX","1 day ago","2025-11-30","https://www.linkedin.com/jobs/view/analytics-engineer-at-base-power-company-4339828652?trk=public_jobs_topcard-title","Base Power Company","https://www.linkedin.com/company/basepowercompany?trk=public_jobs_topcard-org-name","About Base

Base is America’s next-generation power company. We’re rebuilding the foundation of modern civilization–electricity–by deploying a vast network of distributed batteries that is transforming today’s fragile, centralized grid into a resilient and abundant system. We are engineers, operators, and creatives solving some of the most complex, interdisciplinary challenges of our time.

About The Role

As an Analytics Engineer at Base, you will sit at the intersection of data, engineering, and business decisions. You will be responsible for transforming raw data into trusted models and insights that drive product, deployments, business operations, supply chain, go-to-market, manufacturing, hardware design, and more. You'll enable decision-making at scale, directly impacting our ability to grow in both new and existing markets.

Note: This is not a Data Analyst position.

What You'll Do


 * Develop deep understanding of the domains of the business (e.g., Deployments, Business Operations, Supply Chain, Manufacturing) and build the data models that describe how they work.
 * Collaborate deeply with both technical and non-technical stakeholders, gathering requirements and implementing models that are secure, reliable, timely, and extensible.
 * Design and maintain pipelines that transform raw data into analytics-ready structures.
 * Develop internal tools and applications (dashboards, metrics layers, data apps, etc.) that empower real-time decision-making.
 * Drive data quality standards across the stack, implementing monitoring, observability, and documentation practices that scale.
 * Proactively seek out opportunities where analytics can solve business or operational challenges and deliver end-to-end solutions.
 * Serve as a trusted partner to leadership, helping them run their organizations more effectively with data.
   
   

What You'll Bring


 * 5+ years of experience in a software or data focused role - Analytics Engineer, Data Engineer, or Software Engineer
 * Demonstrated experience with autonomy and process ownership
 * Experience with data stack tools: dbt, Data Warehouses (BigQuery, Snowflake, Redshift), BI Tools (Looker/Tableau), Orchestration (Airflow, Temporal, etc)
 * Expert with SQL and experienced with Python or other programming languages (Golang, Javascript, etc)
 * Ability to build world-class data models in a fast, start-up environment
 * Demonstrated aptitude for strategic partnerships and communication with both technical and non-technical Stakeholders
   
   

Who We Are

Base is a company for people who want to win and who want their work to matter. We think from first principles, move with urgency, and treat the mission like our own.

We talk about what isn’t working before we talk about what is because every problem is an opportunity to fix something, improve the system, and compound progress. We cut through complexity, stay close to the work, and let results speak for themselves.

Our Values


 * First Principles Thinking: Question assumptions. Principles > rules.
 * Operate at Base Pace: Focus on what matters, act quickly, and learn by doing.
 * Give & Get Feedback: Be direct, be humble, and maintain a growth mindset.
 * Everyone’s an Owner: Follow through on commitments and own results.
 * Strong Opinions, Loosely Held: Drive clarity and make calls with imperfect information.
 * Committed to the Mission: Rebuilding the grid is a big challenge. We work hard because we care deeply about the impact we’re creating. We work in-person. It’s not a 9-to-5. We are all-in.
 * Fun & Optimism Coexist with Grit: Collaboration and celebration coincide with the intensity of building real things.
   
   

Do the best work of your life at Base.","80 applicants","Full-time","Entry level","Information Technology","Energy Technology","","","","96134922","https://jobs.ashbyhq.com/base-power/5a0c2397-aa62-4b25-998d-e06de50f8387?source=LinkedIn","EXTERNAL",""
"Senior Data Analytics / Business Analyst","Boston, MA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/senior-data-analytics-business-analyst-at-nift-4338808930?trk=public_jobs_topcard-title","Nift","https://www.linkedin.com/company/nift-networks?trk=public_jobs_topcard-org-name","Nift is disrupting performance marketing, delivering millions of new customers to brands every month. We are actively looking for a Senior Data Analytics / Business Analyst. This person will report to our Data Science Manager and work closely with our Data Science and Engineering teams to create solutions for accelerated business performance.

As a Senior Data Analytics / Business Analyst, you'll work closely with the heads of all functional areas at Nift to drive revenue growth and improve the consumer experience. This is a critical position for Nift as you will identify and prioritize opportunities that directly impact revenue, applying your expertise in Data Analytics with a proactive, growth-oriented mindset. We're looking for someone who can deeply understand customer behavior through data and research, and who has the execution focus to iteratively test, measure, take action, and resolve issues.

Our Mission:

Nift's mission is to reshape how people discover and try new brands by introducing them to new products and services through thoughtful ""thank-you"" gifts. Our customer-first approach ensures businesses acquire new customers efficiently while making customers feel valued and rewarded.

We are a data-driven, cash-flow-positive company that has experienced 731% growth over the last three years. Now, we're scaling to become one of the largest sources for new customer acquisition worldwide. Backed by investors who supported Fitbit, Warby Parker, and Twitter, we are poised for exponential growth and ready to demonstrate impact on a global scale. Read more about our growth here.

What you will do:


 * Define and track key performance indicators for the Nift platform/product
 * Conduct root cause analysis, statistical analysis & reasoning of trends, feature extraction & regression modeling
 * Formulate and implement action plans to drive and accelerate revenue growth
 * Design / run A/B & multivariate experiments
 * Design, build, and automate dashboards & reporting
 * Collaborate with data science, engineering and UX on the end-to-end process of design, test implementation, and analysis
 * Document, communicate findings, develop & implement action plans to resolve any / all issues discovered
 * Use advanced data modeling and analysis techniques to discover/improve performance deficiencies
 * Design, build, and implement processes to fix & optimize them
 * Ensure the accuracy of data on all projects and deliverables
 * Examine, interpret and report results of analytical initiatives to all relevant stakeholders on our leadership, sales, and product teams
 * Oversee the data/report requests process: tracking requests submitted, prioritizing the requests, approving the results, etc.
   
   

What you need:


 * 5+ years of experience working in a commercial production environment
 * Bachelor's degree in an analytical field such as economics, mathematics, statistics, or computer science (an advanced degree in a quantitative field is preferred)
 * MBA or MA in Applied Economics (Preferred)
 * Experience dealing with large consumer data sets
 * Experience in applying logistic regression modeling, to business problems
 * Excellent statistical analysis, root cause analysis & identification
 * Proven experience with defining, implementing, and analyzing A/B and multivariate experiments
 * Strong proficiency with SQL
 * Strong urgency and reliability in delivering on time, with excellent written and verbal communication skills
   
   

What you get:


 * Competitive compensation, flexible remote work
 * Unlimited Responsible PTO
 * Great opportunity to join a growing, cash-flow-positive company while having a direct impact on Nift's revenue, growth, scale, and future success","154 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Marketing Services","","","","10562109","https://grnh.se/0fc002es7us","EXTERNAL",""
"Software Engineer - Data Platform","Los Angeles, CA","1 week ago","2025-11-18","https://www.linkedin.com/jobs/view/software-engineer-data-platform-at-hadrian-4311331444?trk=public_jobs_topcard-title","Hadrian","https://www.linkedin.com/company/hadrianautomation?trk=public_jobs_topcard-org-name","Hadrian — Manufacturing the Future

Hadrian is building autonomous factories that help aerospace and defense companies manufacture rockets, satellites, jets, and ships up to 10x faster and up to 2x cheaper. By combining advanced software, robotics, and full-stack manufacturing, we are reinventing how America produces its most critical parts.

We recently raised $260 million dollar Series C to accelerate this mission. We are excited to be launching a new Factory in Mesa, Arizona, a 270,000 square foot facility that will create 350 new jobs immediately. We are opening a new headquarters to support thousands of future hires, launching Hadrian Maritime to serve naval production, and introducing a Factory-as-a-Service model that delivers complete systems instead of individual parts.

Hadrian works with startups, Tier 1 and Tier 2 suppliers, and major defense contractors across space, shipbuilding, and aviation to scale production, reduce costs, and accelerate delivery on mission-critical programs. We are backed by leading investors including Lux Capital, Founders Fund, and Andreessen Horowitz. Our fast-growing team is united by a shared mission to reindustrialize American manufacturing for the 21st century and beyond!

The Role

As a foundational software engineer on our data platform engineering team, you will lead the charge on a variety of projects writing software to aggregate, store, and make sense of data.

Examples of possible work include everything from building data warehousing for ERP and machine data, building software agents to get data off of machines, and building certified data sets to enable operations and business intelligence use of data.

You will be challenged to think creatively and solve complex data integration problems. You will work cross functionally with production experts, software engineers, and machining specialists to develop novel solutions working toward fully automated factories.

What You'll Do


 * Scope, architect, implement, and deploy critical applications that will drive revenue and make a positive impact in the world.
 * Build and manage a robust data warehouse and write software to coordinate and deploy data pipelines.
 * Conceptualize and own the data architecture for multiple large-scale projects.
 * Create and contribute to data frameworks that span on-premises and cloud infrastructure improve the efficacy of logging machine data, while working with data infrastructure to triage issues and resolve.
 * Solve our most challenging machine data integration problems, utilizing optimal ETL patterns, frameworks, query techniques, sourcing from structured and unstructured data sources.
 * Collaborate with machine engineers, product managers, and data scientists to understand data needs, representing key data insights visually in a meaningful way.
 * Get to build alongside an incredible team of software engineers, mechanical engineers, operators, and the best machinists/CAM programmers in the world.
   
   

What We're Looking For


 * Have extensive experience shipping modern, data-centric applications (our data systems use Argo-Workflows, Dagster, Superset, Aurora, RDS, S3, and back-ends are Go and Python, with gRPC/Avro and Kafka as our messaging platform).
 * Have experience with IaC and GitOps tooling (We use Terraform extensively and have centralized on Kubernetes/Argo/Helm).
 * Extremely well versed with data querying techniques across NoSQL and SQL platforms.
 * Have a Bachelor's degree in Computer Science and/or equivalent experience.
 * Solid understanding in building data architecture and pipelines.
 * Are self-motivated and eager to get hands-on and tackle challenges independently while working collaboratively toward identified objectives.
 * Work with a platform mentality -- driven to find the right architecture and plan up front and solve problems with the long term in mind.
 * Take responsibility and ownership finding solutions no matter what.
 * Deploy your broad experience and big picture view to fix undreamed of problems with innovative solutions.
 * Feel passionate about making things move in the real world with software.
 * Are excited to work in a fast-paced environment with high-stakes and quick iteration cycles.
 * Are a highly effective communicator when speaking or writing, especially when presenting technical information.
   
   

Compensation

For this role, the target salary range is $120,000 - $200,000 (actual range may vary based on experience).

This is the lowest to highest salary we reasonably and in good faith believe we would pay for this role at the time of this posting. We may ultimately pay more or less than the posted range, and the range may be modified in the future. An employee's pay position within the salary range will be based on several factors, including, but not limited to, relevant education, qualifications, certifications, experience, skills, geographic location, performance, and business or organizational needs.

Benefits


 * 100% coverage of medical, dental, vision, and life insurance plans for employees
 * 401k
 * Relocation stipend if you’re moving from outside of LA
 * Flexible vacation policy
   
   

ITAR Requirements

To conform to U.S. Government space technology export regulations, including the International Traffic in Arms Regulations (ITAR) you must be a U.S. citizen, lawful permanent resident of the U.S., protected individual as defined by 8 U.S.C. 1324b(a)(3), or eligible to obtain the required authorizations from the U.S. Department of State. Learn more about the ITAR here.

Hadrian Is An Equal Opportunity Employer

It is the Company’s policy to provide equal employment opportunity for all applicants and employees. The Company does not unlawfully discriminate on the basis of race inclusive of traits historically associated with race (including, but not limited to, hair texture and protective hairstyles, such as braids, locks and twists), color, religion, sex (including pregnancy, childbirth, or related medical conditions), gender identity, gender expression, transgender status, national origin (including, in California, possession of a drivers license), ancestry, citizenship, age, physical or mental disability, height or weight, medical condition, family care status, military or veteran status, marital status, domestic partner status, sexual orientation, genetic information, exercise of reproductive rights, any other basis protected by local, state, or federal laws, or any combination of the above characteristics. When necessary, the Company also makes reasonable accommodations for disabled candidates and employees, including for candidates or employees who are disabled by pregnancy, childbirth, or related medical conditions.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Defense and Space Manufacturing","$120,000.00/yr - $200,000.00/yr","","","71668100","https://jobs.ashbyhq.com/hadrian-automation/c7953b1a-6672-49b1-9364-79ecb8db638c?source=LinkedIn","EXTERNAL",""
"Senior Data Engineer","New York, NY","2 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/senior-data-engineer-at-fusemachines-4335586626?trk=public_jobs_topcard-title","Fusemachines","https://www.linkedin.com/company/fusemachines?trk=public_jobs_topcard-org-name","About Fusemachines

Fusemachines is a 10+ year old AI company, dedicated to delivering state-of-the-art AI products and solutions to a diverse range of industries. Founded by Sameer Maskey, Ph.D., an Adjunct Associate Professor at Columbia University, our company is on a steadfast mission to democratize AI and harness the power of global AI talent from underserved communities. With a robust presence in four countries and a dedicated team of over 400 full-time employees, we are committed to fostering AI transformation journeys for businesses worldwide. At Fusemachines, we not only bridge the gap between AI advancement and its global impact but also strive to deliver the most advanced technology solutions to the world.

Senior Data Engineer

Are you an experienced Data Engineering professional with a passion for building scalable, reliable, and high-performance data systems? Do you have hands-on experience designing and optimizing end-to-end real-time and batch pipelines, and developing cloud-native data architectures using modern technologies such as AWS, GCP, Azure, Databricks, and Snowflake?

We are building a dynamic pipeline of pre-qualified talent to fill critical data engineering roles as our business continues to scale.

By providing your information, you are included in our priority pipeline of highly qualified candidates across various specialized Data Engineering opportunities within Fusemachines. This curated list ensures you will be among the very first to receive consideration for future full-time opportunities, giving you a significant advantage and leading to a much shorter evaluation and interview process when a critical role opens.

Fusemachines is an Equal Opportunities Employer, committed to diversity and inclusion. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or any other characteristic protected by applicable federal, state, or local laws.

Important: Immigration Sponsorship Policy

Fusemachines is unable to proceed with candidates who require any form of work authorization or immigration support from the company. This restriction applies to all types of support, including:


 * Direct Company Sponsorship: Such as H-1B, J-1, or TN visas
 * Employer of Record: Listing Fusemachines as the immigration employer on any government documentation
 * Written Documentation: Providing letters or other support for any work authorization (e.g., OPT, STEM OPT, CPT)
   
   

Powered by JazzHR

RdEDRGP9Ti","30 applicants","Full-time","Mid-Senior level","Information Technology","Internet Publishing","","","","2920773","https://www.linkedin.com/jobs/view/senior-data-engineer-at-fusemachines-4335586626?trk=public_jobs_topcard-title","EASY_APPLY",""
"Software Engineer II-Data Platform","San Antonio, Texas Metropolitan Area","8 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/software-engineer-ii-data-platform-at-h-e-b-4325372138?trk=public_jobs_topcard-title","H-E-B","https://www.linkedin.com/company/heb?trk=public_jobs_topcard-org-name","Responsibilities

Since H-E-B Digital Technology's inception, we've been investing heavily in our customers' digital experience, reinventing how they find inspiration from food, make food decisions, and ultimately get food into their homes. This is an exciting time to join H-E-B Digital-we're using the best available technologies to deliver modern, engaging, reliable, and scalable experiences to meet the needs of our growing audience.

As a Software Engineer II, you'll deliver complex code solutions. You'll contribute to overall system design, architecture, security, scalability, reliability, application performance, and provide end-to-end support.

Once you're eligible, you'll become an Owner in the company, so we're looking for commitment, hard work, and focus on quality and Customer service. 'Partner-owned' means our most important resources--People--drive the innovation, growth, and success that make H-E-B The Greatest Omnichannel Retailing Company.

Do you have a:

HEART FOR PEOPLE... willing to provide support to junior developers?

HEAD FOR BUSINESS... skills to effectively deliver code solutions and features?

PASSION FOR RESULTS... drive to produce quality results with little direct supervision?

Education & Experience


 * Bachelor’s degree in Computer Science, Information Systems, or equivalent practical experience
 * 2+ years of hands-on experience in software engineering, DevOps, or data engineering roles
 * Proven track record of supporting and maintaining production-grade systems with a strong sense of ownership
 * Experience participating in on-call rotations for mission-critical applications
   
   

Technical Skills


 * Programming Languages: Proficient in Python (automation, data processing) and SQL
 * DevOps & Tooling: Hands-on experience with Terraform (IaC), Ansible (configuration management), Git, CI/CD platforms (GitLab, Jenkins), and Linux system administration
 * Cloud Platforms: Familiar with AWS services including EC2, RDS, S3, ALB, Lambda, and Glue; exposure to equivalent services in Azure or GCP
 * Data & Visualization: Skilled in data visualization tools such as Tableau, Looker, and Power BI; strong understanding of data warehousing and modeling concepts
 * ETL & Pipelines: Working knowledge of ETL processes and data pipeline architecture
   
   

Software Engineering Expertise


 * Strong debugging and troubleshooting skills across infrastructure, services, and data workflows
 * Solid understanding of distributed systems, performance optimization, and service reliability engineering
 * Experience with Agile methodologies and iterative development practices
   
   

Platform & Architecture


 * Experience designing and managing cloud infrastructure (AWS/GCP), including VPC networking and security best practices
 * Proficient in deploying repeatable infrastructure using Terraform
 * Skilled in automating system provisioning and configuration with Ansible
 * Familiar with orchestrating data pipelines and integrating cloud storage/data lake solutions (e.g., S3, Glue, Athena)
   
   

Specialized Engineering Contributions


 * Infrastructure Automation: Designed and maintained infrastructure-as-code for multi-node Tableau clusters and supporting AWS services
 * Data Engineering: Built pipelines to extract data from Tableau’s Postgres repository, transform to Parquet format, and integrate with Glue for downstream analytics
 * Operational Reliability: Managed blue-green deployments, system upgrades, failovers, and implemented monitoring/alerting for performance and availability
 * Scripting & Tooling: Developed Python-based tools for system management, query automation, and batch processing
   
   

Do you have what it takes to be an H-E-B Software Engineer II?


 * High degree of personal accountability to self and team for continued growth
 * Ability to operate independently while owning your effect on the organization.
 * Resilient and optimistic when faced with the unexpected
 * Can manage most ambiguity within scope of daily work
   
   

and is willing to learn how to proactively disambiguate requirements.


 * Team player - Actively learning the team's domain by asking questions, sharing knowledge with their teammates, and contributing to their team's documentation. Collaborates well with team and partners outside the team (Product Management, Design, QA, etc.)
 * Committed to adding value by supporting the team, contributing your perspective, and committing to the right amount of work.
 * Growth Mindset - Ability to fail-forward, ask questions, apply coaching, and show a genuine desire to learn, grow, and teach. Serves as a model for more junior engineers and consistently demonstrates team, organization, and company values in daily work.
 * Self-starter - Proactive in seeking out help when unclear about priority and dependencies; take initiative to learn the team, the work, and the business.
 * Impact - Understands area of work and shares knowledge with others. Generously shares opinions, feelings, constructive feedback, and gives credit where it is due.
 * Connect - Learning to facilitate conversations to make sure all viewpoints are represented, and that bias is understood. Listens to opposing perspectives and works toward the best solution for all.
   
   

Can you...


 * Travel by car or plane with overnight stays
 * Work extended hours; sit for extended periods
 * Work rotating and on-call schedules, as needed
   
   

11-2024","56 applicants","Full-time","Entry level","Engineering and Information Technology","Retail","","","","164159","https://careers.heb.com/jobs/160490/Software+Engineer+II-Data+Platform?lang=en-US&mode=apply&iis=LinkedIn","EXTERNAL",""
"Data Engineer","Hayward, CA","1 week ago","2025-11-24","https://www.linkedin.com/jobs/view/data-engineer-at-veev-by-lennar-4338924647?trk=public_jobs_topcard-title","Veev, By Lennar","https://www.linkedin.com/company/veevbylennar?trk=public_jobs_topcard-org-name","About Veev

Veev is leading the transformation of the construction industry with an innovative approach to modular home construction. Veev’s prefabricated closed-panel systems allow homes to be assembled efficiently on-site while delivering a more sustainable and higher-quality final product than traditional construction. As a new subsidiary of Lennar, Veev leverages the strength and scale of its parent company while maintaining the speed and disruptive approach of its roots as a Silicon Valley-based startup. Veev has developed a vertically integrated approach that involves multidisciplinary collaboration across real estate, design, development, engineering, manufacturing, and construction.

This role is critical to Veev's mission of transforming the construction industry with modern, sustainable, and efficient construction techniques. As a Data Engineer, you will directly enable efficiency, scalability, and data-driven decision-making by designing, building, and maintaining reliable data pipelines and centralized reporting systems. Your work will provide the trusted data foundation that empowers Veev to scale operations, improve sustainability, and drive industry-wide change through actionable insights and advanced forecasting.

The Role

As a Data Engineer at Veev, you will play a critical role in enabling the company’s Business and Operational Dashboard initiative by designing, building, and maintaining the data infrastructure that powers organizational insights. You will ensure data pipelines are reliable, scalable, and secure—serving as the backbone for decision-making across executive leadership, operations, finance, and technology teams.

Working closely with the Program Manager, Business Analyst, and IT/IS teams, you will own the technical execution that ensures clean, automated, and efficient data flows from multiple systems (ERP, BI, operational platforms) into a centralized, trusted database.

Responsibilities


 * Design, develop, and maintain robust ETL/ELT pipelines to integrate data from ERP, CRM, manufacturing, and operational systems. Build and optimize databases and data warehouses (e.g., Snowflake, SQL, or similar) to support enterprise reporting and advanced analytics.
 * Enable centralized reporting by structuring core datasets for use in executive dashboards, QBR reports, and board-level presentations. Ensure data quality and governance by implementing monitoring, validation, and alerting systems for data integrity.
 * Partner with BI developers and analysts to deliver clean, structured datasets for dashboards and reporting tools (e.g., Tableau, Power BI, Superset).
 * Automate workflows and data ingestion processes to ensure real-time or near-real-time data availability.
 * Collaborate with IT/IS teams to define schemas, APIs, and integration approaches for new and existing systems.
 * Leverage machine learning and AI models to forecast business scenarios, predict operational trends, and support advanced planning use cases.
 * Troubleshoot data-related issues and optimize the performance of queries and pipelines.
 * Support security and compliance standards, ensuring proper handling of sensitive and financial data.
 * Continuously improve the scalability and resilience of Veev’s data infrastructure to match business growth.
   
   

Must-Have Skills And Competencies


 * Bachelor’s degree in Computer Science, Engineering, Information Systems, or a related field.
 * 4+ years of experience in data engineering, ETL/ELT development, or database management.
 * Proven expertise in SQL, Python, or similar languages for building and maintaining data pipelines.
 * Strong knowledge of data modeling, warehousing, and governance frameworks to support reliable reporting and analytics.
 * Experience integrating data from multiple systems such as ERP, CRM, or operational platforms.
 * Ability to work cross-functionally with IT/IS, BI, and business stakeholders to deliver scalable solutions.
 * Strong problem-solving skills with attention to detail and performance optimization.
 * Excellent communication skills to translate technical complexity into a business context.
   
   

Nice-to-Have Skills And Competencies


 * Experience with Python, Spark, or other data processing frameworks.
 * Knowledge of ERP integrations (e.g., NetSuite, SAP, Oracle).
 * Familiarity with CI/CD pipelines and DevOps practices for data systems. Exposure to data governance, MDM (master data management), or data cataloging.
 * Experience supporting digital transformation or large-scale enterprise reporting projects.
   
   

Compensation

Offers are based on a combination of experience, skills, and location. Pursuant to state and local pay disclosure requirements, the pay range for this role is $120k - $150k annually for Hayward, CA.

Core Benefits

Veev offers a comprehensive benefits package designed to support the well-being and growth of its employees, including:


 * Paid vacations, sick, and holidays
 * Health benefits, including medical, dental, and vision insurance
 * 401(k) with matching contributions
   
   

Additional Perks


 * Pre-tax Commuter Account
 * Subsidized EV charging and commuter shuttles (some HQ locations)
 * Growth & Development Opportunities
   
   

Ready to Take the Next Step?

Be part of a mission-driven team that’s transforming construction for the future. Apply today and help us build better, smarter, and more sustainable homes.

Our Commitment to Inclusion

At Veev, we’re dedicated to fostering a diverse and inclusive environment where everyone can thrive. We strive to create a space where all employees can be their authentic selves, feel a sense of community, and do great work together. We actively seek to build a community where diverse perspectives are welcomed, and every employee feels empowered to be their authentic selves. We encourage applications from all backgrounds.","Over 200 applicants","Full-time","Entry level","Information Technology","Residential Building Construction","$120,000.00/yr - $150,000.00/yr","","","18594945","https://www.linkedin.com/jobs/view/data-engineer-at-veev-by-lennar-4338924647?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist","San Francisco, CA","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/data-scientist-at-opendoor-4334231889?trk=public_jobs_topcard-title","Opendoor","https://www.linkedin.com/company/opendoor-com?trk=public_jobs_topcard-org-name","Data Scientist, Pricing

Location: In office 4 days a week; San Francisco CA or Seattle WA.

Opendoor is transforming one of the largest, most complex markets in the world — residential real estate — using data at massive scale. Every pricing signal we generate directly impacts how we value homes, how we manage risk, and how efficiently capital moves through our marketplace. The work is highly leveraged: the quality of our pricing decisions influences conversion, margins, customer trust, and the company’s financial performance.

We are looking for mid to senior level Data Scientists. In this role, you will be a core driver of how Opendoor prices real estate at scale. You’ll operate at the intersection of economics, machine learning, experimentation, and product strategy — tackling ambiguity, shaping the pricing roadmap, and building models/analyses that materially move the business. Your insights will influence how we evaluate millions of dollars of housing inventory — and directly shape outcomes for our customers, our balance sheet, and the health of our marketplace.

What You’ll Do



 * Build and maintain pricing metrics, dashboards, and frameworks.
 * Run experiments and causal analyses to measure impact and drive decisions.
 * Develop predictive + statistical models that improve pricing accuracy.
 * Partner closely with Product, Engineering, and Operations teams to influence roadmap and model deployment.
 * Deliver insights and narratives that inform executive strategy.
   
   
   

Skills & Qualifications



 * Deep statistical reasoning: hypothesis design, experimental design, causal inference, and ability to distinguish signal vs noise.
 * Proven end-to-end ML ownership: data acquisition, feature engineering, model development, validation, deployment, and ongoing monitoring.
 * Strong SQL + Python proficiency; comfortable working with production data pipelines and modern ML tooling (e.g., Spark, Airflow, Ray, SageMaker, Vertex, etc.).
 * Demonstrated ability to translate complex analytical findings into clear business recommendations and influence cross-functional decision-making.
 * Experience working with ill-defined problems and driving clarity on problem definition, success metrics, and realistic tradeoffs.
 * High data-quality bar: disciplined approach to validation, bias analysis, and making decisions rooted in evidence vs intuition.
 * Effective communicator — able to tell the story behind the model to both highly technical and non-technical audiences.
   
   
   

Base salary range for this role varies. Generally, the base salary range is $170,400 – $213,000 annually + RSUs + bonus + ESPP + additional employee benefits (medical/dental/vision, life insurance, unlimited PTO, 401K).

JR 9200

About us…. Powering life’s progress, one move at a time

Since 2014, we’ve been reinventing life’s most important transaction with a new, simple way to buy and sell a home. The traditional real estate process is broken, and our mission is clear: build a digital, end-to-end experience that makes buying and selling a home simple and certain.

We’re a team of problem solvers, innovators, and operators building the largest, most trusted platform for residential real estate. Whether it’s starting a family, taking a new job, or making a life change, we help people move forward with confidence.

This work isn’t easy, and it’s not for everyone. But if you want to be part of a team that’s tilting the world in favor of people who want to sell, buy, or own a home then you’ll find purpose here.

Opendoor Values Openness

We believe that being open about who we are and what we do allows us to be better. Individuals seeking employment at Opendoor are considered without regard to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, sexual orientation, gender identity or other protected status under all applicable laws, regulations, and ordinances. We collect, use, and disclose applicant personal information as described in our personnel privacy policies. To learn more, you can find the policy details for California residents here and for Canada residents here.

We are committed to assisting members of the military community in utilizing their skills at Opendoor. U.S. candidates are able to review your military job classification at MyNextMove.org and apply for positions that align with your expertise.

At Opendoor, we are committed to providing reasonable accommodations throughout our recruitment processes for candidates with disabilities, pregnancy, religious beliefs, or other reasons protected by applicable laws. If you require assistance or a reasonable accommodation, please contact us at TAops-accomodations@opendoor.com.

","Over 200 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Real Estate","$170,400.00/yr - $213,000.00/yr","","","9398436","https://www.opendoor.com/careers/open-positions?gh_jid=4615429006&gh_src=79614ad86us","EXTERNAL",""
"Data Scientist","Houston, TX","2 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/data-scientist-at-exxonmobil-4335408333?trk=public_jobs_topcard-title","ExxonMobil","https://www.linkedin.com/company/exxonmobil?trk=public_jobs_topcard-org-name","About Us
At ExxonMobil, our vision is to lead in energy innovations that advance modern living and a net-zero future. As one of the world’s largest publicly traded energy and chemical companies, we are powered by a unique and diverse workforce fueled by the pride in what we do and what we stand for.

The success of our Upstream, Product Solutions and Low Carbon Solutions businesses is the result of the talent, curiosity and drive of our people. They bring solutions every day to optimize our strategy in energy, chemicals, lubricants and lower-emissions technologies.

We invite you to bring your ideas to ExxonMobil to help create sustainable solutions that improve quality of life and meet society’s evolving needs. Learn more about our What and our Why and how we can work together.

What You Will Do
We are hiring multiple Data Scientists to lead the design, development, and deployment of advanced AI/ML solutions across diverse domains, including:


 * Generative AI & NLP (LLMs, agentic workflows)
 * Time Series Forecasting & Anomaly Detection
 * Optimization & Prescriptive Analytics
 * Commercial Analytics (pricing, marketing, supply chain)
 * Subsurface & Wells (physics-informed ML, production optimization)
 * Computer Vision & Document Intelligence
   
   

You will work end-to-end—from problem framing and experimentation through production and sustainment—partnering with engineers and business stakeholders to deliver scalable, reliable, and impactful solutions.

What Role Will You Play In The Team

 * Lead end-to-end delivery of AI/ML solutions: scoping, modeling, evaluation, deployment, and monitoring.
 * Collaborate with cross-functional teams to translate business problems into mathematical frameworks.
 * Build solutions in one or more domains listed above, applying best practices for data quality, explainability, and governance.
 * Develop GenAI applications (chatbots, copilots, multi-agent workflows) and/or time series, optimization, or commercial analytics models.
 * Ensure production readiness through MLOps practices (CI/CD, MLflow, monitoring, cost optimization).
 * Mentor peers and contribute to internal AI capability building.
   
   

About You
Desired Skills

 * 5+ years of direct experience delivering production AI/ML solutions.
 * Expertise in one or more of the following: NLP/GenAI, time series, optimization, commercial analytics, subsurface/wells, computer vision.
 * Strong foundations in statistics, probability, and algorithm design.
 * Proficiency in Python and ML frameworks (PyTorch, TensorFlow, scikit-learn) experience with Databricks/Spark.
 * Familiarity with GenAI frameworks (LangChain, Promptflow) and/or optimization libraries.
 * Experience with MLOps, model governance, and explainable AI techniques (e.g., SHAP, LIME).
 * Excellent communication and collaboration skills.
   
   

Preferred Knowledge/Skills

 * Cloud platforms (Azure ML, Azure OpenAI, Databricks).
 * Commercial domain experience (pricing, forecasting, supply chain) or energy/subsurface expertise.
 * Knowledge graphs, hybrid search/RAG, and semantic technologies.
 * Agile development and software engineering best practices.
   
   

Educational Background Recommended

 * Master’s or PhD in Data Science, Computer Science, Engineering, Applied Math, or related field.
   
   

Your Benefits
An ExxonMobil career is one designed to last. Our commitment to you runs deep: our employees grow personally and professionally, with benefits built on our core categories of health, security, finance, and life.
We offer you:

 * Pension Plan: Enrollment is automatic and at no cost to you. The basic benefit is a monthly annuity to be paid to you in retirement for the rest of your life.
 * Savings Plan: You can contribute between 6% and 20% of your pay and are encouraged to enroll right away. If you contribute at least 6% to your savings plan, the Company will contribute a 7% match.
 * Workplace Flexibility: We have several programs such as “Flex your Day”, providing ad-hoc flexibility around when and where you work, as well as longer-term programs such as leaves of absence and part-time work.
 * Comprehensive medical, dental, and vision plans.
 * Culture of Health: Programs and resources to support your wellbeing.
 * Employee Health Advisory Program: Provides confidential professional counseling for you and your family, including tools and resources promoting mental health and resiliency at no additional cost to you.
 * Disability Plan: Income replacement for when you cannot work due to illness or injury occurring on or off the job. Enrollment is automatic and at no cost to you.
   
   

More information on our Company’s benefits can be found at www.exxonmobilfamily.com.

Please note benefits may be changed from time to time without notice, subject to applicable law.

Stay connected with us

Learn more at our website

Follow us on LinkedIN and Instagram

Like us on Facebook

Subscribe our channel at YouTube

Employee equal opportunity

ExxonMobil is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, sexual orientation, gender identity, national origin, citizenship status, protected veteran status, genetic information, or physical or mental disability.
Nothing herein is intended to override the corporate separateness of local entities. Working relationships discussed herein do not necessarily represent a reporting connection, but may reflect a functional guidance, stewardship, or service relationship.

Exxon Mobil Corporation has numerous affiliates, many with names that include ExxonMobil, Exxon, Esso and Mobil. For convenience and simplicity, those terms and terms like corporation, company, our, we and its are sometimes used as abbreviated references to specific affiliates or affiliate groups. Abbreviated references describing global or regional operational organizations and global or regional business lines are also sometimes used for convenience and simplicity. Similarly, ExxonMobil has business relationships with thousands of customers, suppliers, governments, and others. For convenience and simplicity, words like venture, joint venture, partnership, co-venturer, and partner are used to indicate business relationships involving common activities and interests, and those words may not indicate precise legal relationships.

Job ID: 82223
","Over 200 applicants","Full-time","Entry level","Engineering","Oil and Gas","","","","1689","https://www.linkedin.com/jobs/view/data-scientist-at-exxonmobil-4335408333?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","San Francisco, CA","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/data-engineer-at-rokt-4337069474?trk=public_jobs_topcard-title","Rokt","https://www.linkedin.com/company/rokt?trk=public_jobs_topcard-org-name","We are Rokt, a hyper-growth ecommerce leader. Rokt is the global leader in ecommerce, unlocking real-time relevance in the moment that matters most. Rokt's AI Brain and ecommerce Network powers billions of transactions connecting hundreds of millions of customers, and is trusted to do this by the world's leading companies.

We are a team of builders helping smart businesses find innovative ways to meet customer needs and generate incremental revenue. Leading companies drive 10-50% of additional revenue—and often all their profits—from the extra products or services they sell. This economic edge unleashes a world of possibilities for growth and innovation.

The Rokt engineering team builds best-in-class ecommerce technology that provides personalized and relevant experiences for customers globally and empowers marketers with sophisticated, AI-driven tooling to understand consumers better. Our bespoke platform handles millions of transactions per day. It considers billions of data points which give engineers the opportunity to build technology at scale, collaborate across teams, and gain exposure to a wide range of technology.

At Rokt, we practice transparency in career paths and compensation. At Rokt, we believe in transparency, which is why we have a well-defined career ladder with transparent compensation and clear career paths based on competency and ability. Rokt'stars constantly strive to raise the bar, pushing the envelope of what is possible.

We are looking for an Data Engineer.

A fixed annual salary of $170,000 - $210,000, an employee equity plan grant, and world-class benefits.

Equity grants are issued in good faith, subject to company policies, board approval, and individual eligibility.

About The Role

Join Rokt as a Data Engineer on the Metrics team, you will architect the semantic and data layers that define how Rokt measures success. You'll transform raw product and GTM event streams into trusted, governed, analytics-ready models; codify business logic into reusable metric definitions; and build proactive monitoring to keep our ""single source of truth"" healthy and reliable at scale. You'll serve as metric steward for one or more business domains, owning the semantic layer and data models end-to-end

You'll partner closely with engineers, product managers, data scientists, and GTM stakeholders across Rokt's Research & Development organization to enable self-serve insights and consistent decision-making.

What You'll Do


 * Model data for trust & reuse: Build modular, tested transformations (e.g. in Spark/Python) that convert raw logs into canonical datasets and marts powering experimentation, product analytics, and executive reporting.
 * Own the metrics layer: Design and maintain a governed catalog of metrics and dimensions (e.g.Datahub) with clear definitions, lineage, and versioning.
 * Operate reliable pipelines: Orchestrate and harden batch/stream pipelines (e.g., Airflow/Kafka/Spark) with SLAs, backfills, and cost-aware performance tuning.
 * Proactive data quality: Implement unit/integration tests, anomaly detection, and monitoring (e.g Great Expectations/Monte Carlo/Bigeye) to catch metric drift and upstream integration issues before they reach users.
 * Integration health visibility: Build dashboards/alerts for client conversion data health and integration metrics (e.g., EMQ, AQS), and drive root-cause analysis and remediation with partner teams.
 * Enable self-serve analytics: Create intuitive dashboards and templates (e.g., Tableau) that expose the metric layer and unlock analysis for engineering, PM, and GTM users.
 * Define logging standards: Partner with product/engineering to instrument event schemas and logging guidelines that improve downstream observability and data quality.
 * Document & govern: Establish style guides, playbooks, and change-management processes for metric and model evolution (including deprecation and backfills).
 * Raise the bar: Lead code reviews, mentor peers, and contribute to platform roadmaps across Rokt Research.
   
   

Requirements

Who You Are


 * 3-6+ years in data engineering / data warehousing roles building production-grade data models and metrics at scale.
 * Expert SQL (Trino preferred) and solid Python for analytics engineering and data tooling.
 * Experience with Spark (PySpark or Spark SQL) for large-scale data processing, optimization, and distributed computation.
 * Hands-on orchestration experience (e.g., Airflow, Dagster) and comfort operating pipelines end-to-end (monitoring, backfills, SLAs, cost/perf tuning). Manage Kubernetes based data workflows.
 * Cloud experience with AWS
 * Proficiency in at least one cloud warehouse (Clickhouse, Snowflake, BigQuery, or Redshift) or datalake technologies (i.e Apache Iceberg, Apache Hudi, DeltaLake) and comfort with large-scale partitioning, clustering, and performance patterns.
 * Track record owning data quality and data reliability for critical metrics; you've implemented tests, lineage, and observability that prevented or rapidly mitigated incidents.
 * Ability to partner with engineers, PMs, and GTM teams to translate ambiguous business questions into robust metric definitions and data products.
 * Experience building/maintaining a semantic metrics layer (dbt metrics, LookML, MetricFlow, or Transform) and/or reverse ETL to operational tools.
 * Exposure to streaming patterns (Kafka/Flink/Spark Structured Streaming) and metric computation.
 * Familiarity with experimentation frameworks (A/B testing, guardrail metrics) and causal inference basics.
 * Domain experience in ecommerce / adtech / performance marketing.
 * Infra-as-code (e.g., Terraform), containerization (Docker/Kubernetes), or platform engineering exposure.
   
   

Benefits

Why Join Rokt


 * Build the Future of AI in Ecommerce: Be at the forefront of AI-driven transformation in a company that's pioneering how brands engage customers in the ""moment that matters"" during online transactions.
 * Hyper-Growth = Fast Progression: Rokt is a rapidly growing tech leader, which means huge opportunities for your career advancement, learning, and taking on bigger responsibilities quickly.
 * Culture of Builders: Work with a smart, humble, and bold team that shares a ""builder"" DNA - we love to innovate, take risks, and turn ambitious ideas into tangible results. We win as a team and learn from every experiment.
 * Ownership & Impact: Every Rokt'star (employee) has a voice and real equity in the company. You'll have autonomy to make decisions, drive projects, and see the direct impact of your work on millions of users.
 * World-Class Benefits & Support: Join a people-first culture with transparent career paths, continuous development (LevelUp training, mentorship), and great perks (equity grants, catered lunches, global offices, and more) that empower you to do your best work.
   
   

About The Benefits

We leverage best-in-class technology and market-leading innovation in AI and ML, with all of that being underlined by building and maintaining a fantastic and inclusive culture where people can be their authentic selves, and offering a great list of perks and benefits to go with it:


 * Become a shareholder. Every Rokt'star gets equity in the company
 * Enjoy catered lunch every day and healthy snacks in the office. Plus join the gym on us!
 * Extra leave (bonus annual leave, sabbatical leave etc.)
 * Access generous retirement plans like a 4% dollar-for-dollar 401K matching plan and get fully funded premium health insurance!
 * Dog-friendly office
 * Work with the greatest talent in town
 * See the world! We have offices in New York, Seattle, Sydney, Tokyo and London
   
   

We believe we're better together. We love spending time together and are in the office most days (teams are in the office minimum 4 days per week).

We at Rokt choose to create a company that is as diverse and inclusive as the world we live in by attracting, growing & keeping the best talent. Equal employment opportunities are available to all applicants without regard to race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

If this sounds like a role you'd enjoy, apply here, and you'll hear from our recruiting team.

Note: The first stage of the recruitment process for this role is to complete a 15-minute online aptitude test as well as an employee personality profile assessment, which will be sent out to your application email. Successful candidates will be contacted to discuss the next steps.","76 applicants","Full-time","Entry level","Engineering","Advertising Services, Technology, Information and Internet, and Software Development","$170,000.00/yr - $210,000.00/yr","","","1977526","https://www.linkedin.com/jobs/view/data-engineer-at-rokt-4337069474?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Columbus, OH","8 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-engineer-at-rogue-fitness-4340158728?trk=public_jobs_topcard-title","Rogue Fitness","https://www.linkedin.com/company/rogue-fitness?trk=public_jobs_topcard-org-name","Overview

Job Description:

As a Data Engineer, you will be the central architect for backend development ETL projects, responsible for ensuring a reliable, optimized data pipeline. You will also collaborate closely with our Directors and Managers to ensure they have access to the reports and data that are critical for their diverse needs. This requires understanding many aspects of the business and the systems that drive them, including: ecommerce, manufacturing, and fulfillment.

This role offers a unique opportunity to engage in meaningful projects, and solve critical challenges. You will drive initiatives that empower departments with data, automated manual reporting, and enable our adoption of AI in innovative ways. While you will gain exposure to transformative AI projects, your primary focus will be on developing a robust data lake that facilitates reporting and analysis.

The Data Engineer is a fully onsite role in Columbus, Ohio. Remote work is not available. Applicants must be authorized to work in the United States for any employer.
Responsibilities



 * Maintain efficient data pipelines, addressing data challenges such as inconsistency, quality issues, and complex transformation
 * Ingest internal and external data into the bronze layer
 * Collaborate with the team to understand pipeline structure and mechanize ad hoc data streams
 * Transform raw data into clean and optimized usable building blocks in the silver layer
 * Work with departments to understand business needs and prepare and format data for reporting purposes in the gold layer
 * Utilize GCP services such as Cloud Scheduler and Cloud Functions
 * Develop comprehensive testing strategies to ensure data integrity and pipeline functionality using Python notebooks. Collaborate closely with the Data Manager to design and execute data reporting pipelines
 * Lead technical project development with a high degree of autonomy, owning key tech improvements such as writing Python SDKs and researching efficient methods of data transformation
   
   

Qualifications



 * 2-5 years of relevant data engineering experience
 * Bachelor’s degree in Computer Science or a related field
 * Proficiency in Python and its data-related libraries (Pandas, NumPy, SciPy)
 * 2 years of experience designing and optimizing complex SQL pipelines in GCP
 * Experience as a lead developer defining project requirements
 * Experience working with diverse databases, including e-commerce
 * Experience ingesting data from diverse APIs
 * Experience with version control using Git
 * Excellent communication skills and problem-solving abilities
 * Demonstrated ability to work independently and collaboratively
 * High attention to detail, particularly with data security best practices
 * Experience working with infrastructure as code tools such as Terraform
 * Experience developing SDKs for data ingestion workflows
   
   
   

By applying to Rogue, regardless of the platform you choose to use, you are agreeing to Rogue's preferred methods of communication (i.e. text message). Submitting an application, through whatever online forum is ultimately used, constitutes a knowing and voluntary agreement to send and receive text messages during the recruitment process.","93 applicants","Full-time","Entry level","Information Technology","Retail","","","","1781202","https://roguefitness.wd1.myworkdayjobs.com/RogueFitness_External_Careers/job/Columbus-Ohio/Data-Engineer_R-102388/apply?mode=job&iis=SOURCE&iisn=LinkedIn","EXTERNAL",""
"Sr. Data Engineer","Glen Allen, VA","13 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/sr-data-engineer-at-richmond-national-4340156853?trk=public_jobs_topcard-title","Richmond National","https://www.linkedin.com/company/richmond-national?trk=public_jobs_topcard-org-name","Senior Data Engineer

We are seeking a highly skilled and experienced Senior Data Engineer to join Richmond National Insurance Company. As a Senior Data Engineer, you will work closely with the Lead Data Engineer and Director of Data to design, develop, and maintain our cloud data infrastructure by ensuring the availability, reliability, and scalability of our data systems. You will collaborate with cross-functional teams, including data engineers, business analysts, and software engineers, to develop innovative data solutions that enable data-driven decision-making across the organization.

Responsibilities


 * Data Infrastructure Management: Design, build, and maintain a robust and scalable cloud data infrastructure, including data pipelines, databases, and data lakes, to support the organization's data needs.
 * Team Leadership: Lead and mentor a team of data engineers and data analysts, providing technical guidance, support, and fostering a culture of collaboration and innovation.
 * Data Architecture: Define and implement the data architecture strategy, ensuring data models, schemas, and integration patterns align with business requirements and industry best practices.
 * ETL Development: Develop and optimize Extract, Transform, Load (ETL) processes to extract data from various sources, transform it into a consistent format, and load it into the data ecosystem.
 * Data Quality and Governance: Establish data quality standards, implement data governance processes, and perform regular data quality checks to ensure the accuracy, consistency, and reliability of data.
 * Performance Optimization: Identify and implement performance tuning strategies to enhance the efficiency and speed of data processing and analysis.
 * Data Security: Collaborate with the data and IT leadership team to implement data privacy and security measures, ensuring compliance with regulations and standards.
 * Collaboration and Communication: Collaborate with cross-functional teams to understand the data needs and deliver data solutions that support their requirements.
 * Continuous Improvement: Stay up to date with industry trends, emerging technologies, and best practices in data engineering, and proactively introduce new tools and techniques to improve data engineering processes and efficiency.
 * Documentation and Documentation: Maintain comprehensive documentation of data pipelines, workflows, and data structures, ensuring clear documentation for both technical and non-technical stakeholders.
   
   

Qualifications


 * Proven experience (5+ years) as a Data Engineer, preferably in the insurance or financial industry or a similar domain.
 * Strong expertise in data modeling, ETL development, and data integration techniques.
 * Proficiency in programming languages such as Python, Java, or Scala, and experience with SQL and database technologies.
 * Solid understanding of distributed computing principles and big data technologies such as Hadoop, Spark, or Hive.
 * Experience with cloud-based data platforms and services, such as AWS, Azure, or Google Cloud Platform.
 * Familiarity with data visualization tools and techniques.
 * Excellent problem-solving skills and a strong attention to detail.
 * Effective communication and collaboration skills to work with cross-functional teams and stakeholders.
   
   

Join our team as the Senior Data Engineer and play a crucial role in shaping and optimizing our data infrastructure to support Richmond National's data-driven initiatives. Apply your expertise to drive innovation and enable better decision-making processes through advanced data engineering techniques.

Benefits Overview


 * Medical, Dental, and Vision insurance plans. FSA/HSA plans available.
 * Basic Life/AD&D/Short Term/Long Term Disability coverage.
 * 401(k) - Company match of up to 6%
 * Flexible PTO plan, 11 paid company-wide holidays, plus your birthday off.
 * Recognized as a Top Workplace by Richmond Times-Dispatch
   
   

Equal Employment Opportunity (EEO)

Richmond National is an equal employment opportunity employer, the Company’s employment decisions and practices are not and will not be unlawfully influenced or affected by race, color, creed, age, religion, national origin, sex, disability, genetic information, veteran status, uniformed services, sexual orientation (including transgender status, gender identity or expression), gender, traits historically associated with race, such as hairstyle, pregnancy, childbirth, or related medical conditions or on any other characteristic protected by applicable federal, state, or local law. This policy of equal employment opportunity applies to all policies and procedures relating to recruitment and hiring, compensation, benefits, and all other terms and conditions of employment.","84 applicants","Full-time","Mid-Senior level","Information Technology","Insurance","","","","76546939","https://www.linkedin.com/jobs/view/sr-data-engineer-at-richmond-national-4340156853?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Analyst, Payments Reconciliation","San Francisco, CA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/data-analyst-payments-reconciliation-at-rippling-4338738935?trk=public_jobs_topcard-title","Rippling","https://www.linkedin.com/company/rippling?trk=public_jobs_topcard-org-name","About Rippling

Rippling gives businesses one place to run HR, IT, and Finance. It brings together all of the workforce systems that are normally scattered across a company, like payroll, expenses, benefits, and computers. For the first time ever, you can manage and automate every part of the employee lifecycle in a single system.

Take onboarding, for example. With Rippling, you can hire a new employee anywhere in the world and set up their payroll, corporate card, computer, benefits, and even third-party apps like Slack and Microsoft 365—all within 90 seconds.

Based in San Francisco, CA, Rippling has raised $1.4B+ from the world’s top investors—including Kleiner Perkins, Founders Fund, Sequoia, Greenoaks, and Bedrock—and was named one of America's best startup employers by Forbes.

We prioritize candidate safety. Please be aware that all official communication will only be sent from @Rippling.com addresses.

About The Role

Join our growing Payments Data & Analytics team as an experienced Data Analyst. This is an opportunity to be embedded in the engine room of our customer funds analytics —playing a critical role in reconciling customer data, improving data quality, and making our payments reconciliation platform bulletproof and more scalable. You’ll work closely with Engineering, Product, and Finance teams to ensure customers have clean, actionable data at their fingertips.

Your role will involve analyzing complex data sets, managing analytical projects, and collaborating with various teams to deliver complete and accurate analytics to ensure compliance with regulators and external parties.

You should have strong critical thinking skills, and the ability to frame and break down complex problems. You thrive under ambiguity and can operate cross functionally in a fast paced environment. You are able to operate across the data stack, and support all elements from data engineering to delivering strategic recommendations.

What You Will Do


 * Build internal tooling and processes to reconcile financial and transactional data from multiple sources to enable accurate, repeatable customer funds reporting
 * Collaborate with key stakeholders (Accounting, Compliance, Engineering, etc.) to understand business requirements and develop solutions to automate reporting and reconciliation, including internal tool development and/or implementation of third party tools.
 * Maintain strong internal controls to protect against payment errors or compliance breaches.
 * Support audits, month-end reconciliation, system implementations and special projects.
 * Leverage data analysis and AI-powered tools to identify process gaps, detect anomalies, and drive automation opportunities.
 * Improve the fidelity and performance of our DBT pipelines and help evolve our broader data architecture
   
   

What You Will Need


 * A minimum of 3 years of experience in Business Intelligence/Data Analytics within a Finance, Accounting, or Compliance function
 * Excellent verbal communication and presentation ability. You are able to frame problems, and communicate to all levels of an organization
 * Proven track record of working cross functionally and communicating findings to executive leadership
 * Experience partnering with Finance/Accounting organizations in performing detailed and data intensive reconciliations with disparate datasets.
 * Experience reconciling financial or transactional data (ideally in an e-commerce or payments environment)
 * Experience with data warehousing and reporting technologies like DBT, Snowflake, Tableau, etc.
 * Expert in SQL
 * Familiarity with business intelligence best practices and tooling
 * Familiarity with data transformation best practices and tooling (e.g. dbt projects, incremental tables, etc.)
 * Experience with data visualization tools and delivering self service reporting
   
   

Additional Information

Rippling is an equal opportunity employer. We are committed to building a diverse and inclusive workforce and do not discriminate based on race, religion, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, veteran or military status, or any other legally protected characteristics, Rippling is committed to providing reasonable accommodations for candidates with disabilities who need assistance during the hiring process. To request a reasonable accommodation, please email accomodations@rippling.com

Rippling highly values having employees working in-office to foster a collaborative work environment and company culture. For office-based employees (employees who live within a defined radius of a Rippling office), Rippling considers working in the office, at least three days a week under current policy, to be an essential function of the employee's role.

This role will receive a competitive salary + benefits + equity. The salary for US-based employees will be aligned with one of the ranges below based on location; see which tier applies to your location here.

A variety of factors are considered when determining someone’s compensation–including a candidate’s professional background, experience, and location. Final offer amounts may vary from the amounts listed below.

The pay range for this role is:

90,000 - 157,500 USD per year(US Tier 1)","Over 200 applicants","Full-time","Entry level","Information Technology","Software Development","$90,000.00/yr - $157,500.00/yr","","","17988315","https://www.linkedin.com/jobs/view/data-analyst-payments-reconciliation-at-rippling-4338738935?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Data Analyst","San Mateo, CA","2 weeks ago","2025-11-13","https://www.linkedin.com/jobs/view/senior-data-analyst-at-verkada-4335875317?trk=public_jobs_topcard-title","Verkada","https://www.linkedin.com/company/verkada?trk=public_jobs_topcard-org-name","Who We Are

Verkada is transforming how organizations protect their people and places with an integrated, AI-powered platform. A leader in cloud physical security, Verkada helps organizations strengthen safety and efficiency through one connected software platform that includes solutions for video security, access control, air quality sensors, alarms, intercoms, and visitor management.

Over 30,000 organizations worldwide, including more than 100 companies in the Fortune 500, trust Verkada as their physical security layer for easier management, intelligent control, and scalable deployments. Founded in 2016, Verkada has expanded rapidly with 15 offices and 2,200+ full-time employees.

About The Role

Verkada’s Growth Ops team is looking for a talented individual to play an integral role in leveraging our data and technology to help our marketing team run better, faster, and smarter. You will have the opportunity to play a vital role in both creating and driving world-class insights that will drive the next phase of growth here at Verkada.

Successful Marketing Analytics leaders at Verkada are fluent in SQL and data modeling, understand the principles of effective data visualization, and know how to contextualize their work within the business in order to drive growth. This role reports to our Sr. Manager, Analytics Engineering. We are committed to a thriving in-office culture. This role requires that you be on-site at our office in San Mateo, CA 5 days a week.

What You'll Do


 * Own the full analytics workflow, from transforming raw data in dbt to building dashboards in Looker and presenting findings that influence strategy.
 * Collaborate with stakeholders to design metrics that align with company objectives and inform decision-making.
 * Build and maintain scalable, well-documented data models in dbt and Looker/LookML that power reporting and analysis across the org.
 * Help shape data governance and foster data literacy, empowering stakeholders to self-serve with trustworthy and accurate data.
 * Deliver high-impact, data-driven insights and recommendations; collaborate with leadership to influence key decisions and optimize the growth funnel
   
   

What You Bring


 * 3–5 years of experience in data analytics or data science.
 * Advanced SQL proficiency and experience working with modern databases (BigQuery, Snowflake, Redshift)
 * Experience building dashboards with data visualization tools (Looker, Tableau, Power BI).
 * Demonstrated track record of success in a high-growth, self-directed business environment.
 * Strong analytical mindset; enjoys solving complex and ambiguous problems.
 * Excellent verbal and written communication skills, with ability to translate complex data into clear business narratives.
 * Must be willing and able to commute 5 days in office.
   
   

Nice to Have


 * Direct relevant experience in Marketing Analytics or a similar function (Growth Analytics, Data Science, Product Analytics, etc.)
 * Experience with data modeling, ETL/ELT, and data warehousing.
 * Experience with dbt
 * Experience with Looker/LookML
 * Proficiency with Python, R, and statistical analysis.
 * Familiarity with business systems: Salesforce, Marketo, Outreach, or similar.
   
   

Employee Benefits

Verkada is committed to fostering a workplace environment that prioritizes the holistic health and wellbeing of our employees and their families by offering comprehensive wellness perks, benefits, and resources. Our benefits and perks programs include, but are not limited to:


 * Healthcare programs that can be tailored to meet the personal health and financial well-being needs - Premiums are 100% covered for the employee under at least one plan and 80% for family premiums under all plans Nationwide medical, vision and dental coverage
 * Health Saving Account (HSA) with annual employer contributions and Flexible Spending Account (FSA) with tax saving options
 * Expanded mental health support
 * Paid parental leave policy & fertility benefits
 * Time off to relax and recharge through our paid holidays, firmwide extended holidays, flexible PTO and personal sick time
 * Professional development stipend
 * Fertility Stipend
 * Wellness/fitness benefits
 * Healthy lunches provided daily
 * Commuter benefits
   
   

Additional Information


 * You must be independently authorized to work in the U.S. We are unable to sponsor or take over sponsorship of an employment visa for this role, at this time.
   
   

Annual Pay Range

At Verkada, we want to attract and retain the best employees, and compensate them in a way that appropriately and fairly values their individual contribution to the company. With that in mind, we carefully consider a number of factors to determine the appropriate starting pay for an employee, including their primary work location and an assessment of a candidate's skills and experience, as well as market demands and internal parity. A Verkada employee may be eligible for additional forms of compensation, depending on their role, including sales incentives, discretionary bonuses, and/or equity in the company in the form of restricted stock units (RSUs)

Below is the annual on-target earnings (OTE) range for full-time employees for this position, comprised of base compensation and commissions (if applicable).

Estimated Annual Pay Range

$130,000—$180,000 USD

Verkada Is An Equal Opportunity Employer

As an equal opportunity employer, Verkada is committed to providing employment opportunities to all individuals. All applicants for positions at Verkada will be treated without regard to race, color, ethnicity, religion, sex, gender, gender identity and expression, sexual orientation, national origin, disability, age, marital status, veteran status, pregnancy, or any other basis prohibited by applicable law.

Your application will be handled in accordance with our Candidate Privacy Policy.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Software Development","$130,000.00/yr - $180,000.00/yr","","","12699415","https://www.linkedin.com/jobs/view/senior-data-analyst-at-verkada-4335875317?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","New York, NY","3 weeks ago","2025-11-07","https://www.linkedin.com/jobs/view/data-engineer-at-atlantic-group-4334688435?trk=public_jobs_topcard-title","Atlantic Group","https://www.linkedin.com/company/the-atlantic-group?trk=public_jobs_topcard-org-name","Our client, a real estate and asset-based lender, is looking to hire a full-time Analytics Engineer to work onsite out of their Midtown Manhattan location.




This is a dynamic team focusing on optimizing the firm's asset management operations and business intelligence (BI) capabilities. This role combines technical data engineering expertise with analytical science skills to drive data-informed decision-making across their portfolio.




This is a broad/generalist focused role with a heavy focus on Data Engineering first and foremost (although there may be some data science oriented projects as well).




Responsibilities:

 * Build automated reporting systems and interactive dashboards for portfolio monitoring, including custom analyses for executive leadership, asset management, and origination
 * Implement machine learning (AI) models for asset valuation, market analysis, and investment opportunity screening
 * Build and optimize Snowflake databases and queries to support real-time business intelligence needs
 * Design and implement quality assurance processes for data extraction, transformation, and analysis workflows
 * Design and maintain scalable data pipelines in Nexla and Python to integrate property management systems, financial databases, and market data feeds into Snowflake DW
 * Create predictive models to identify asset performance trends, risks, and opportunities across the real estate portfolio, with a focus on occupancy rates and NOI metrics
 * Design and optimize ETL processes to ensure data quality/consistency, with robust monitoring and alert systems




Qualifications:

 * Bachelor's or Master's Degree in Computer Science, Data Science, or related field
 * 3-7 years of experience; additional experience may be considered in lieu of degree
 * Strong Python programming with proficiency in Python requests libraries (pandas, numpy, scikit-learn)
 * Experience building and optimizing ETL pipelines using modern data platforms (they use Nexla) and working with Snowflake or similar cloud data warehouses
 * Proficiency in data preprocessing, cleaning, and transformation techniques for both structured and unstructured data sources
 * Advanced SQL expertise, ideally with Snowflake, including optimization/security best practices




Nice To Haves (Not Required):

 * ML frameworks (TensorFlow, PyTorch)
 * Experience with supervised and unsupervised learning algorithms, model evaluation metrics, and ML deployment in production environments
 * Experience with large language models (LLMs), prompt engineering, and NLP frameworks (e.g., Hugging Face Transformers) for document processing and information extraction
 * Develop and implement OCR/NLP models to extract, validate, and classify key information from loan agreements, property reports, and other financial documents




ID: 44163","Over 200 applicants","Full-time","Mid-Senior level","Information Technology and Engineering","Financial Services, Investment Management, and Capital Markets","","","","1215629","https://www.linkedin.com/jobs/view/data-engineer-at-atlantic-group-4334688435?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)"
"Data Engineer II","Livingston, NJ","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/data-engineer-ii-at-coreweave-4347329568?trk=public_jobs_topcard-title","CoreWeave","https://www.linkedin.com/company/coreweave?trk=public_jobs_topcard-org-name","CoreWeave is The Essential Cloud for AI™. Built for pioneers by pioneers, CoreWeave delivers a platform of technology, tools, and teams that enables innovators to build and scale AI with confidence. Trusted by leading AI labs, startups, and global enterprises, CoreWeave combines superior infrastructure performance with deep technical expertise to accelerate breakthroughs and turn compute into capability. Founded in 2017, CoreWeave became a publicly traded company (Nasdaq: CRWV) in March 2025. Learn more at www.coreweave.com.

What You’ll Do

The Data Engineering team builds foundational datasets and analytics services that enable BI and data science across CoreWeave. We aim to democratize insights and foster a culture where data-driven decision-making thrives at every level of the organization.

About The Role

We’re seeking a skilled Data Engineer to develop foundational data models that empower our Business Intelligence engineers, analysts, and data scientists to efficiently work with and gain insights from our data. You’ll create and maintain star and snowflake schemas within our lakehouse environment, generate key datasets and metrics essential to tracking business health, and optimize the flow and storage of data to support analytical workloads across the organization.

Who You Are


 * Hands-on experience applying Kimball modeling principles to large datasets
 * Expertise with analytical table/file formats such as Iceberg, Hudi, Parquet, Avro, and ORC
 * Proven experience optimizing MPP databases (StarRocks, Snowflake, BigQuery, Redshift)
 * 3–5+ years of programming experience in Python, Java, or Scala in a professional setting
 * Advanced SQL skills, with the ability to write, optimize, and debug complex queries
 * Hands-on experience with Airflow for batch orchestration and distributed computing frameworks like Spark or Flink
 * Experience managing systems deployed on Kubernetes is highly desirable, but not required
   
   

Preferred


 * Experience designing and optimizing large-scale data pipelines
 * Strong understanding of data lakehouse architectures and analytics workflows
   
   

Wondering if you’re a good fit?

We Believe In Investing In Our People And Value Candidates Who Bring Their Own Diverse Experiences To Our Teams – Even If You Aren’t a 100% Skill Or Experience Match. Here Are a Few Qualities We’ve Found Compatible With Our Team


 * You love designing and optimizing data models for analytics
 * You’re curious about building efficient, scalable data pipelines
 * You’re an expert in turning complex data into actionable business insights
   
   

Why CoreWeave?

About

At CoreWeave, we work hard, have fun, and move fast! We’re in an exciting stage of hyper-growth that you won’t want to miss. We’re not afraid of a little chaos, and we’re constantly learning. Our team cares deeply about how we build our product and how we work together, which is represented through our core values:


 * Be Curious at Your Core
 * Act Like an Owner
 * Empower Employees
 * Deliver Best-in-Class Client Experiences
 * Achieve More Together
   
   

We support and encourage an entrepreneurial outlook and independent thinking. We foster an environment that encourages collaboration and provides the opportunity to develop innovative solutions to complex problems. As we get set for takeoff, growth opportunities within the organization are constantly expanding. You will be surrounded by some of the best talent in the industry, who will want to learn from you, too. Come join us!

The base salary range for this role is $109,000 to $160,000. The starting salary will be determined based on job-related knowledge, skills, experience, and market location. We strive for both market alignment and internal equity when determining compensation. In addition to base salary, our total rewards package includes a discretionary bonus, equity awards, and a comprehensive benefits program (all based on eligibility).

What We Offer

The range we’ve posted represents the typical compensation range for this role. To determine actual compensation, we review the market rate for each candidate which can include a variety of factors. These include qualifications, experience, interview performance, and location.

In addition to a competitive salary, we offer a variety of benefits to support your needs, including:


 * Medical, dental, and vision insurance - 100% paid for by CoreWeave
 * Company-paid Life Insurance
 * Voluntary supplemental life insurance
 * Short and long-term disability insurance
 * Flexible Spending Account
 * Health Savings Account
 * Tuition Reimbursement
 * Ability to Participate in Employee Stock Purchase Program (ESPP)
 * Mental Wellness Benefits through Spring Health
 * Family-Forming support provided by Carrot
 * Paid Parental Leave
 * Flexible, full-service childcare support with Kinside
 * 401(k) with a generous employer match
 * Flexible PTO
 * Catered lunch each day in our office and data center locations
 * A casual work environment
 * A work culture focused on innovative disruption
   
   

Our Workplace

While we prioritize a hybrid work environment, remote work may be considered for candidates located more than 30 miles from an office, based on role requirements for specialized skill sets. New hires will be invited to attend onboarding at one of our hubs within their first month. Teams also gather quarterly to support collaboration

California Consumer Privacy Act - California applicants only

CoreWeave is an equal opportunity employer, committed to fostering an inclusive and supportive workplace. All qualified applicants and candidates will receive consideration for employment without regard to race, color, religion, sex, disability, age, sexual orientation, gender identity, national origin, veteran status, or genetic information.

As part of this commitment and consistent with the Americans with Disabilities Act (ADA), CoreWeave will ensure that qualified applicants and candidates with disabilities are provided reasonable accommodations for the hiring process, unless such accommodation would cause an undue hardship. If reasonable accommodation is needed, please contact: careers@coreweave.com.

Export Control Compliance

This position requires access to export controlled information. To conform to U.S. Government export regulations applicable to that information, applicant must either be (A) a U.S. person, defined as a (i) U.S. citizen or national, (ii) U.S. lawful permanent resident (green card holder), (iii) refugee under 8 U.S.C.


 * 1157, or (iv) asylee under 8 U.S.C.
 * 1158, (B) eligible to access the export controlled information without a required export authorization, or (C) eligible and reasonably likely to obtain the required export authorization from the applicable U.S. government agency. CoreWeave may, for legitimate business reasons, decline to pursue any export licensing process.","Over 200 applicants","Full-time","Entry level","Information Technology","Technology, Information and Internet","$109,000.00/yr - $160,000.00/yr","","","36121341","https://coreweave.com/careers/job?4615931006&board=coreweave&gh_jid=4615931006","EXTERNAL",""
"Category Manager, Data Center Equipment","Bellevue, WA","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/category-manager-data-center-equipment-at-crusoe-4336848138?trk=public_jobs_topcard-title","Crusoe","https://www.linkedin.com/company/crusoe?trk=public_jobs_topcard-org-name","Crusoe's mission is to accelerate the abundance of energy and intelligence. We’re crafting the engine that powers a world where people can create ambitiously with AI — without sacrificing scale, speed, or sustainability.

Be a part of the AI revolution with sustainable technology at Crusoe. Here, you'll drive meaningful innovation, make a tangible impact, and join a team that’s setting the pace for responsible, transformative cloud infrastructure.

About the Role:

Crusoe's mission to power the future of computing depends on a world-class supply chain for our data center infrastructure. The equipment we deploy—from networking and servers to storage and racks—is the backbone of our AI Cloud. We are looking for a highly technical and strategic Category Manager, Data Center Equipment to own the commercial strategy for these critical hardware categories.

You will be responsible for the entire product lifecycle, building deep supplier partnerships with key OEMs and collaborating closely with engineering and sales to ensure we have a competitive, scalable, and cost-effective hardware platform. This is a crucial role that sits at the intersection of technology, finance, and supply chain, directly impacting Crusoe's ability to innovate and scale at speed.

This role will be required to be in office 5 days/week in our Seattle, WA office.

What You'll Be Working On:


 * Develop Category Strategies: Create and execute sourcing plans for all data center equipment (e.g., networking, servers, storage, racks, and cables).
 * Manage the Product Lifecycle: Oversee the entire process from initial sourcing and selection through to end-of-life planning.
 * Conduct Market Analysis: Identify key industry trends, monitor the competitive landscape, and uncover new technology opportunities.
 * Lead Supplier Negotiations: Negotiate with suppliers to secure favorable pricing, supply agreements, and service level agreements (SLAs).
 * Drive Cross-Functional Alignment: Collaborate with sales, engineering, and logistics teams to ensure product availability and support.
 * Oversee the Supplier Portfolio: Manage supplier performance through regular reviews and lead the qualification process for new vendors.
 * Implement Pricing Strategies: Develop and oversee product pricing strategies to maximize profitability and market share.
   
   
   

What You'll Bring to the Team:


 * Educational Foundation: Bachelor's degree in Supply Chain Management, Business, or a related field.
 * Data Center Sourcing Experience: 5+ years in category management or strategic sourcing, with a specific focus on data center hardware.
 * Technical Acumen: Deep understanding of the markets and technologies for networking, server, and storage equipment.
 * Proven Track Record: A history of developing and executing hardware category strategies that deliver cost savings, mitigate supply risk, and support rapid scaling.
 * Expert Negotiator: Strong skills in negotiating complex contracts, pricing, and supply agreements with major OEMs.
 * Stakeholder Partnership: Exceptional ability to partner with and influence technical (Engineering) and commercial (Sales) stakeholders.
 * Analytical Mindset: Excellent problem-solving abilities, with experience in market analysis and developing pricing strategies.
   
   
   

Benefits:


 * Industry competitive pay
 * Restricted Stock Units in a fast growing, well-funded technology company
 * Health insurance package options that include HDHP and PPO, vision, and dental for you and your dependents
 * Employer contributions to HSA accounts
 * Paid Parental Leave
 * Paid life insurance, short-term and long-term disability
 * Teladoc
 * 401(k) with a 100% match up to 4% of salary
 * Generous paid time off and holiday schedule
 * Cell phone reimbursement
 * Tuition reimbursement
 * Subscription to the Calm app
 * MetLife Legal
 * Company paid commuter benefit; $300/month
   
   
   

Compensation Range

Compensation will be paid in the range of up to: $132,000-160,000/year + Bonus.

Restricted Stock Units are included in all offers. Compensation to be determined by the applicants knowledge, education, and abilities, as well as internal equity and alignment with market data.

Crusoe is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, disability, genetic information, pregnancy, citizenship, marital status, sex/gender, sexual preference/ orientation, gender identity, age, veteran status, national origin, or any other status protected by law or regulation.","Be among the first 25 applicants","Full-time","Mid-Senior level","Marketing and Sales","Technology, Information and Internet","$132,000.00/yr - $160,000.00/yr","","","19150725","https://jobs.ashbyhq.com/Crusoe/bf39a75d-e697-4277-b9cd-fbed5d3ca212","EXTERNAL",""
"Software Developer, Data Engineering","Nashville, TN","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/software-developer-data-engineering-at-healthstream-4294686037?trk=public_jobs_topcard-title","HealthStream","https://www.linkedin.com/company/healthstream?trk=public_jobs_topcard-org-name","Description

Company Overview

HealthStream is the leader in healthcare workforce solutions. We help organizations work better by helping their people work smarter.

HealthStream provides the leading learning, clinical development, credentialing, and scheduling applications delivered on healthcare’s #1 platform. We streamline everyday tasks while improving performance, engagement, and safety – fostering a workplace where people flourish, and care thrives.

Why Join Us

At HealthStream, you’ll have the opportunity to make a meaningful impact on the future of healthcare by collaborating with a team of talented professionals dedicated to innovation and excellence. We offer competitive compensation, comprehensive benefits, and a supportive work environment where creativity and collaboration thrive.

Our shared vision is to enhance the quality of healthcare by empowering the people who deliver care – a commitment we have upheld for over 30 years through providing innovative solutions and driving constant growth. Join us in revolutionizing the healthcare industry and shaping the future of patient care. As a HealthStreamer, you will be at the forefront of healthcare technology innovation, making a recurring impact on the industry.

We’re proud of our values-forward culture that offers our people:


 * Mission-oriented work
 * Diverse and inclusive culture
 * Competitive Compensation & Bonuses
 * Comprehensive Insurance Plans
 * Mental and Physical Health Support
 * Work-from-home flexibility
 * Fitness Center Reimbursements
 * Streaming Good time off for volunteering
 * Wellness workshops
 * Buddy Program for new HealthStreamers
 * Collaborative work environment
 * Career growth opportunities
 * Continuous learning opportunities
 * Inspiring workspaces to collaborate and connect with other HealthStreamers
 * Free employee parking at our Resource Centers in Nashville and San Diego
   
   

At HealthStream, our thriving culture encourages collaboration and values contributions, allowing our team members to continuously solve big problems and grow. We offer flexibility and paid time off to support work-life integration for all employees, including a hybrid work environment and Streaming Good volunteer day. For team members in commutable distance, HealthStream has Resource Centers in Nashville, TN and San Diego, CA. Our resource centers provide an inspiring workspace to collaborate and recharge as well as company-sponsored onsite social events for development, connection, and celebration.

We are committed to driving innovation in healthcare and ensuring that patients receive competent care from qualified professionals. As a HealthStream team member, you will help bring this vision to life. If you want to work for a company committed to its values and vision, HealthStream is the place for you!

HealthStream is an equal opportunity employer. HealthStream prohibits employment practices that discriminate against individual employees or groups of employees on the basis of age, color, disability, national origin, race, religion, sex, sexual orientation, pregnancy, veteran or military status, genetic information or any other category deemed protected by state and/or federal law.

Position Information

Position Overview

Work under guidance and supervision of Director, Data Engineering. The primary responsibilities of this position are to participate in design, development and support of data extraction from various sources, data ingestion into HealthStream’s Data Lake and data transformation of data within HealthStream’s Data Lake. Including and not limited to building tools, creation of complex queries and programs, analyzing database performance and making recommendations for improvements, testing and evaluating new data related tools.

Key Responsibilities

You will be responsible for adhering to all HealthStream security policies, procedures, and assigned training.


 * Design and develop new and tune existing SQL queries as needed
 * Design, develop and implement automated solutions to extract data from different sources within Healthstream
 * Design, develop and implement automated solutions to ingest data into HealthStream’s data Lake
 * Design, develop and implement automated solutions to transform data within HealthStream’s data Lake
 * Participate in the on-call rotation to troubleshoot and resolve data issues
 * Investigate and resolve data issues as needed.
 * Evaluate and implement new data related technologies.
 * Must be methodical and able to establish priorities
   
   

Qualifications

Requirements


 * Prefer a bachelor’s degree in Computer Science, Information Systems, Engineering or related field.
 * Three or more years’ experience in data warehousing and ETL tools / frameworks.
 * Three or more years working experience with programming languages (e.g. Python, Java, SQL), data modeling and database Management systems.
 * Two or more years’ experience working in big data technologies such as Kafka, Spark, Hive.
 * At least one year of experience with developing data processes using AWS or Azure.
   
   

Qualifications


 * Proficient using GIT Version using CLI.
 * Proficient in DBT using Jinga Templates
 * Proficient in understanding Data Pipelines using SQL statements.
 * Proficient in SDLC methodologies such as Agile and Kanban.
 * Proficient in using tools like Visual Studio Code, Azure DevOps, github and database query tools like Dbeaver, Aginity.
 * Strong coding skills in scripting languages such as Python or SPARQL
 * Solid understanding of data governance principles and best practices for maintaining data quality and integrity.
 * Strong collaboration and communication skills for working with cross-functional teams.
 * Excellent problem-solving skills with the ability to troubleshoot and resolve complex technical issues.
 * Experience developing and supporting mission critical applications that function 24 hours a day, 7 days a week
 * High motivation and commitment to quality and customer service
 * Must be able to work in a strong team-oriented environment
 * Ability to handle high volumes of work without error
 * Mentor to, learn from, and backup other team members as necessary
 * Treats customers with respect-commitment to service
 * Promotes the mission and vision-performance excellence
 * Responds to work demands
 * Maintains confidentiality
 * Excellent written and oral communication skills
 * Works collaboratively with others-teamwork
 * Helps others accomplish objectives-teamwork
 * Demonstrates a friendly approach
 * Accurately and effectively communicates
 * Responds to customer needs-commitment to service
   
   

Compensation


 * Compensation: The salary range for this position is $78,629-105,000. Salary will be determined on the candidate’s level of experience and qualifications. Compensation will be commensurate with skills, relevant experience, and performance in similar roles.
   
   

Benefits

HealthStream offers a comprehensive benefits package to eligible employees, including:


 * Medical, Dental and Vision insurance
 * Paid Time Off
 * Parental Leave
 * 401k and Roth
 * Flexible Spending Account
 * Health Savings Account
 * Life Insurance
 * Short- and Long-Term Disability
 * Medical Bridge Insurance
 * Critical Illness Insurance
 * Accident Insurance
 * Identity Protection
 * Legal Protection
 * Pet Insurance
 * Employee Assistance Program
 * Fitness Reimbursement
   
   

Are you passionate about enhancing healthcare outcomes and empowering healthcare professionals? Join the HealthStream team and become a HealthStreamer! Together, we can make a difference in the world of healthcare.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","$78,629.00/yr - $105,000.00/yr","","","14967","https://www.linkedin.com/jobs/view/software-developer-data-engineering-at-healthstream-4294686037?trk=public_jobs_topcard-title","EASY_APPLY",""
"Software Engineer- Data","Bellevue, WA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/software-engineer-data-at-statsig-4187110723?trk=public_jobs_topcard-title","Statsig","https://www.linkedin.com/company/statsig?trk=public_jobs_topcard-org-name","About Statsig

Statsig is on a mission to fundamentally change how software is built, tested, and shipped. Thousands of companies use Statsig to deploy features safely, run experiments that drive understanding of their customers and business, and analyze user trends to inform their next investment areas. This isn't just about building a better A/B testing tool; this is about catalyzing positive change in how builders build, ultimately resulting in better products and happier customers!

Who You Are

Statsig is seeking a talented and motivated individual to join our Data team as a Software Engineer-Data Platforms. As a Software Engineer-Data Platforms, your primary responsibility will be to ensure our data pipelines and computations are accurate, reliable, efficient, and fast. As an analytics company, data engineering is core to our success. Data is our life blood and our competitive advantage. The data team is roughly 8-10 individuals, and you'll be closely working with other data platform engineers, data scientists, and other software engineering teams.

Product we’re building

The product we offer is based on the growth infrastructure powering big tech companies like Meta, Amazon, Uber, Netflix, and LinkedIn. This growth engine allowed Facebook grow to more than 3 billion users (Why we started Statsig, https://blog.statsig.com/why-we-started-statsig-45cd80079e7d). Product teams at successful tech companies use the tools and infrastructure on a daily basis which enables them to stay in the Build > Measure > Learn > Build loop. This unlocks rapid software development, quick user feedback, and the ability to iterate rapidly with advanced analytics. At Statsig, we’re bringing that power to every product team. We specialize in delivering feature release management, experimentation, and advanced analytics.

Currently, Statsig's data infrastructure handles >100B daily events, thousands of experiments, across hundreds of customers, and billions of users (unique user_ids).

Ideal Experience


 * Proficient in Python, with expertise in SQL. Prior experience in Java, Node.js, Rust, and React are considered a bonus.
 * Familiar with big data technologies like BigQuery and Spark, or a strong background in distributed data processing, data modeling, and software engineering of data services.
 * Advanced knowledge and hands-on experience working with data architectures and modern cloud technologies.
 * Comfort in working in fast, high-growth environments. The ideal candidate is comfortable with multi-tasking, ambiguous projects, and has a strong bias for action.
   
   

Requirements


 * Authorized to work in the US.
 * Able to work full-time, in-person out of our Bellevue office during normal business hours.
 * 4+ years of hands-on software engineering experience with emphasis on data platforms.
   
   

This is a full-time, in-office role from Bellevue, WA. Candidates are expected to be able to work full-time from our Bellevue office.

Please note that this job description is subject to change and may not include all responsibilities or qualifications required for the role of Software Engineer-Data Platforms at Statsig.

EEOC

Statsig is an equal opportunity employer and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, or disability status.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","","","","19048773","https://jobs.ashbyhq.com/statsig/24ea4c8e-4c60-496f-ba98-5fffd7a8fe8b","EXTERNAL",""
"Data Scientist - Specialist","Atlanta, GA","2 weeks ago","2025-11-18","https://www.linkedin.com/jobs/view/data-scientist-specialist-at-equifax-4323180477?trk=public_jobs_topcard-title","Equifax","https://www.linkedin.com/company/equifax?trk=public_jobs_topcard-org-name","What You’ll Do


 * Be an integral part of the Data Science Lab team that works closely with internal clients in all phases of prototype development and deployment
 * Utilize subject matter expertise of data structures, analytics, algorithms/models, and strong computer science fundamentals to lead data preparation, analytics, and development of deployable solutions across multiple projects
 * Collect, analyze and interpret large data assets to define and build multiple innovative solution components leveraging business and technical expertise. Lead the analytical strategy on critical technical capabilities
 * Contribute to evaluation of new data sources, provide recommendations on value of data sources, and design code to improve the productivity of Equifax, enhance and update code where needed.
 * Perform as lead technical data scientist for multiple technical and business domains, collaborating with other teams to develop predictive models, risk assessments, fraud detection, recommendation engines, etc. encouraging enhanced solutions and asking questions
 * Able to analyze and prepare complex and new data sources and incorporate them into analytical solutions.
 * Research innovative data solutions (in distributed cloud computing constrained and unconstrained optimization) to solve real market problems
 * SQL Mastery & Optimization: Design, write, and optimize highly complex SQL queries for data extraction, transformation, and analysis, often dealing with massive datasets.
 * Design, develop, and implement advanced NLP and LLM solutions, including text classification, summarization, and NER (Name Entity Recognition), powered by state-of-the-art embedding models like Gemini and BERT.
 * Utilize subject matter expertise of data structures, analytics, algorithms/models, and strong computer science fundamentals to lead data preparation, analytics, and development of deployable solutions across multiple projects
 * Collect, analyze and interpret large data assets to define and build multiple innovative solution components leveraging business and technical expertise. Lead the analytical strategy on critical technical capabilities
 * Contribute to evaluation of new data sources, provide recommendations on value of data sources, and design code to improve the productivity of Equifax, enhance and update code where needed.
 * Perform as lead technical data scientist for multiple technical and business domains, collaborating with other teams to develop predictive models, risk assessments, fraud detection, recommendation engines, etc. encouraging enhanced solutions and asking questions
 * Remain current on new developments in AI/Machine Learning, distributed algorithms, Big Data, Predictive Analytics, and Cloud Technology
 * Communicate results to senior management and external stakeholders, able to communicate the strategic impact of the work
 * Evaluate the technical work of experienced data scientists guiding them on deliverable quality and accuracy
 * Serve as SME consultant for COE / Business Unit / Regions, share best practices globally
   
   

What Experience You Need


 * Master’s degree in Mathematics, Statistics, Data Science, Physics, Computer Science, Operations Research, Engineering or related quantitative field strongly preferred.
 * Theoretical and practical understanding of algorithm time and space complexity, and a proven ability to apply this knowledge to develop efficient and scalable data science solutions
 * 7-10 years of experience in a related role, with experience demonstrating leadership capabilities
 * Proven track record of designing and developing predictive models in real-world applications
 * 5+ years experience applying predictive analytics and modeling to solve business problems
 * 5+ years of experience with Python, Tensorflow, SQL (strong skills and scripting experience), and Spark with advanced experience in data manipulation libraries (e.g., Pandas, Dask, Spark DataFrames)
 * Experience with model performance evaluation and predictive model optimization for accuracy and efficiency
   
   

What Could Set You Apart


 * 1+ years Experience managing teams of at least two employees
 * Experience with large-scale data processing in distributed environments
 * Strong communication skills of analytical results to technical and non-technical audiences alike
 * Experience working on big data platforms (e.g., Google Cloud, AWS, Snowflake, Hadoop) a plus
 * Extensive experience with NLP (Natural Language Processing), LLMs (Large Language Models) and/or Generative AI
 * Agile development including Scrum
 * Ph.D. degree in mathematics, statistics, computer science, or related quantitative field","85 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Financial Services","","","","3695","https://www.linkedin.com/jobs/view/data-scientist-specialist-at-equifax-4323180477?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineering","Raleigh, NC","1 week ago","2025-11-23","https://www.linkedin.com/jobs/view/data-engineering-at-captrust-4227299873?trk=public_jobs_topcard-title","CAPTRUST","https://www.linkedin.com/company/captrust?trk=public_jobs_topcard-org-name","WHO are we looking for?

CAPTRUST is seeking a Data Engineer to design, build, and maintain a scalable, high-quality data infrastructure enabling scalable analytics, self-service reporting, and AI-powered solutions across the firm. This role is ideal for an experienced professional with a passion for developing innovative data products, pipelines, and solutions. The Engineer will collaborate with stakeholders across departments to design scalable data solutions, enhance data quality, and optimize data-driven processes to support business objectives.

Responsibilities


 * Design, build, and maintain scalable data products in Microsoft Fabric, including data pipelines, lakehouses, warehouses, and semantic models
 * Support AI/ML workflows by delivering metadata-enriched, well-documented data products for feature engineering, integrating with machine learning pipelines, and enabling model monitoring
 * Ensure data quality and consistency through profiling, validation rules, and integration of data quality standards into development workflows
 * Optimize existing ETL processes for performance, reliability, and cost effectiveness
 * Implement automated workflows and orchestration logic to ensure timely, repeatable, and cost-effective data delivery across the organization
 * Integrate metadata management practices, supporting discovery, lineage, and cataloging
 * Collaborate with data analysts, citizen developers, and key stakeholders to design data models and data products, championing data best practices and influencing CAPTRUST’s data culture
   
   

Qualifications

Minimum Qualifications:


 * Bachelor’s degree in data analytics, computer science, information systems, or a related field (or equivalent work experience)
 * 8 years of experience in data engineering, data science, or analytics role
 * Advanced proficiency in SQL, Python, with hands-on experience with data modeling, ETL processes, and data pipeline development
 * Experience with Microsoft Fabric or similar platforms, including dataflows, lakehouses, warehouses, and pipelines
 * Understanding of metadata and governance frameworks to support secure, discoverable, and documented data assets
 * Ability to manage multiple projects, prioritize tasks, and meet deadlines in a fast-paced environment
 * Strong business acumen and problem-solving skills, with the ability to connect data products to business outcomes
   
   

Desired Qualifications/Skills


 * Strong problem-solving skills and attention to detail
 * Excellent communication skills, with the ability to translate complex data insights into business-friendly recommendations
 * Experience working with CRM systems (e.g., Microsoft Dynamics)
 * Familiarity with semantic modeling for Power BI and other business intelligence tools
 * Ability to work independently and proactively, while also being a strong team player
 * Demonstrated ability to drive process improvements and enhance data-driven decision-making within an organization
 * High standard of professionalism, integrity, and accountability
   
   

WHAT can you expect from your career at CAPTRUST?

Our colleagues, like our clients, tend to stay with CAPTRUST for years. There’s a reason for it; it’s a great culture in which to work and grow. We all work together, each of us motivating those around us with our commitment to high standards. At CAPTRUST, expect a fully stocked break room, fun employee events, and a quality team surrounding you with opportunities for personal growth.

Our Employee Benefits Package shows how much we value our team. Some benefits include:


 * Employee ownership opportunities
 * Brick Bonus success sharing program
 * Comprehensive health coverage + Personify Health wellness platform
 * 401(k) program with a 5% employer match + financial planning for colleagues
   
   

WHERE will you be working?

4208 Six Forks Rd #1700 | Raleigh, NC 27609

Due to the nature of the role, this is not a remote or work from home position.

HOW do we build a world class organization one brick at a time?

We make it a priority to hire those who have a commitment to service, a real interest in other people, and a passion to continuously improve. Simply put: the difference at CAPTRUST is the quality of our people and depth of our bench. If you are ready to make your mark, we want to talk to you.

Are you the next brick?

To get it done the CAPTRUST Way, an individual should exhibit the following characteristics:


 * Ability to build successful, collaborative, and trusting relationships
 * Instinctive aptitude for consistently creating accurate, concise, respectful, and easy-to-understand verbal and written communications conveying complex information
 * A strong sense of urgency about getting work done and solving problems to achieve results that benefit our clients and colleagues, even when faced with challenges
 * Inherent desire to give back to our communities and enrich the lives of those around us
 * An other-centered mindset
 * Integrity through maintaining objectivity
   
   

EEO/Diversity Statement

At CAPTRUST, we are committed to building and maintaining a diverse workforce and inclusive work environment where ALL colleagues feel authentically seen, respected, and supported.

CAPTRUST is committed to providing employment opportunities without regard to race, color, age, sex, sexual orientation, familial status, religious creed, national origin, ancestry, medical condition, marital status and registered domestic partner status, citizenship status, military and veteran status, disability, protected medical condition, genetic information, or any other status protected by law. CAPTRUST makes all employment decisions without regard to these protected statuses and does not tolerate harassment or discrimination. #mid-senior

This position will remain open until filled.

","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Investment Management, Financial Services, and Investment Banking","","","","73799","https://www.linkedin.com/jobs/view/data-engineering-at-captrust-4227299873?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI/ML Engineer- Supply Chain","Miramar, FL","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/ai-ml-engineer-supply-chain-at-women-of-the-vine-spirits-4339001610?trk=public_jobs_topcard-title","Women of the Vine & Spirits","https://www.linkedin.com/company/women-of-the-vine?trk=public_jobs_topcard-org-name","Company

Southern Glazer's Wine & Spirits

Location

Miramar, FL

Other

Other

Apply

What You Need To Know

Shape a remarkable future with us. Build a career working for an industry leader that truly invests in their people - and equips them with leading technology, continuous learning, and the ability to bring their best selves to work. As the premier wine and spirits distributor, Southern Glazer's isn't just one of Forbes' Top Private Companies; it's a family-owned business with deep roots dating back to 1933.

The reputation of Southern Glazer's is well-established, and it's no surprise that we are regularly recognized for our culture. Southern Glazer's has been recognized by Newsweek as one of America's Greatest Workplaces for Inclusion and Diversity, as well as for Women and Parents and Families. These accolades speak volumes about our commitment to creating a supportive and inclusive culture of belonging for all employees.

As a full-time employee, you can choose from a wide-ranging menu of our Top Shelf Benefits, including comprehensive medical and prescription drug coverage, dental and vision plans, tax-saving Flexible Spending Accounts, disability coverage, life insurance plans, and a 401(k) plan. We also offer tuition assistance, a wellness program, parental leave, vacation accrual, paid sick leave, and more.

By joining Southern Glazer's, you would be part of a team that values excellence, innovation, and community. This is more than just a job - it's an opportunity to build the future of beverage distribution and grow with a company that truly cares about its people.

Overview

The AI/ML Engineer is responsible for designing, building, and deploying machine learning models and AI systems to transform data into actionable insights. The AI/ML Engineer ensures that models developed by data scientists are scalable and seamlessly integrated into production environments, where they are monitored for data and infrastructure drift. Collaboration with Data Scientists, Software Developers, Engineers, and Domain Architects is essential for the AI/ML Engineer to gather requirements and integrate AI solutions into existing systems, creating a cohesive technological ecosystem.

Primary Responsibilities


 * Design and develop LLM-powered chatbots and agents that integrate with business systems and workflows.
 * Fine-tune or prompt-engineer foundation models (e.g., OpenAI, Anthropic, Databricks MosaicML) for enterprise use cases.
 * Build retrieval-augmented generation (RAG) pipelines and vector databases for domain-specific knowledge integration.
 * Develop data ingestion and orchestration pipelines using Databricks, Python, or Spark for model input/output.
 * Implement evaluation frameworks for chatbot quality, hallucination detection, and model performance tracking.
 * Collaborate with backend and data engineering teams to deploy AI models as APIs or microservices in production.
 * Ensure security, compliance, and ethical AI standards across all deployments.
 * Experiment with multi-agent workflows and contextual memory for autonomous task execution.
 * Contribute to the organization's AI engineering playbook, ensuring scalable and reusable design patterns.
   
   

Additional Primary Responsibilities


 * Deploy machine learning models into production environments and ensure models are scalable and able to handle real-time data processing.
 * Monitor model performance and accuracy over time and update modes with new data when available and as requirements change.
 * Debug and troubleshoot issues with model performance and/or deployment.
 * Ensure AI models adhere to ethical guidelines and regulatory standards and address issues related to bias, fairness and transparency in AI systems.
 * Develop and optimize algorithms to enable machines to perform tasks aligned with business objectives.
 * Handle data preprocessing and feature engineering.
   
   

Minimum Qualifications


 * Bachelor's or Master's in Computer Science, Data Science, Engineering, or related field.
 * 3+ years of experience in AI/ML engineering, with proven experience in LLM or chatbot development.
 * Strong proficiency in Python (LangChain, or similar frameworks).
 * Experience with Databricks, Azure ML, AWS SageMaker, or equivalent platforms.
 * Hands-on experience with OpenAI API, Anthropic Claude, Hugging Face Transformers, or MosaicML.
 * Familiarity with vector databases.
 * Solid understanding of prompt engineering, RAG, model fine-tuning, and evaluation metrics.
 * Proficiency in SQL and data pipeline development.
 * Strong understanding of MLOps, CI/CD pipelines, and API deployment practices.
 * Excellent communication and collaboration skills with cross-functional teams.
 * Experience building enterprise-grade AI assistants or autonomous agent frameworks.
 * Familiarity with multi-agent orchestration and tools integration (e.g., MCP, LangGraph, CrewAI).
 * Exposure to supply chain, planning, or analytics use cases.
   
   

Physical Demands


 * Physical demands include a considerable amount of time sitting and typing/keyboarding, using a computer (e.g., keyboard, mouse, and monitor), or adding machine
 * Physical demands with activity or condition may include walking, bending, reaching, standing, squatting, and stooping
 * May require occasional lifting/lowering, pushing, carrying, or pulling up to 20lbs
   
   

EEO Statement

Southern Glazer's Wine and Spirits, an Affirmative Action/EEO employer, prohibits discrimination and harassment of any type and provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. SGWS complies with all federal, state and local laws concerning consideration of a qualified applicant's arrest and/or criminal conviction records. Southern Glazer's Wine and Spirits provides competitive compensation based on estimated performance level consistent with the past relevant experience, knowledge, skills, abilities and education of employees. Unless otherwise expressly stated, any pay ranges posted here are estimates from outside of Southern Glazer's Wine and Spirits and do not reflect Southern Glazer's pay bands or ranges.

If you have any questions or concerns about whether this posting complies/adheres with local pay transparency requirements, please contact the SGWS talent acquisition team at NationalTA@sgws.com

\

Apply","109 applicants","Full-time","Entry level","Engineering and Information Technology","Food and Beverage Services","","","","2768518","https://jobs.womenofthevine.com/jobs/67d66670-1e1c-480e-828f-0f0bd17c2903","EXTERNAL",""
"Software Engineer II, Data Engineering & Infrastructure","San Francisco, CA","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/software-engineer-ii-data-engineering-infrastructure-at-aurora-4301602184?trk=public_jobs_topcard-title","Aurora","https://www.linkedin.com/company/auroradriver?trk=public_jobs_topcard-org-name","Who We Are

Aurora’s mission is to deliver the benefits of self-driving technology safely, quickly, and broadly.

The Aurora Driver will create a new era in mobility and logistics, one that will bring a safer, more efficient, and more accessible future to everyone.

At Aurora, you will tackle massively complex problems alongside other passionate, intelligent individuals, growing as an expert while expanding your knowledge. For the latest news from Aurora, visit aurora.tech or follow us on LinkedIn.

Aurora hires talented people with diverse backgrounds who are ready to help build a transportation ecosystem that will make our roads safer, get crucial goods where they need to go, and make mobility more efficient and accessible for all. We are seeking a talented and experienced Software Engineer to join our data engineering and infrastructure team. In this role, you will be a key contributor to the design, development, and maintenance of our data platform, building the scalable and reliable systems that enable our organization to leverage data for insights and product innovation. You will work on the core data lake and data warehouse ecosystem infrastructure, data pipelines, and tools that process data at massive scale, ensuring it is accessible, high-quality, and secure.

In this role, you will


 * Design, build, and maintain robust and scalable data pipelines and ETL/ELT processes to ingest, transform, and load data from various sources into our data warehouse.
 * Develop and manage data infrastructure components using AWS cloud services and infrastructure-as-code tools like Terraform.
 * Collaborate with data scientists, analysts, autonomy engineering teams and product teams to understand their data needs and build solutions that meet their requirements.
 * Optimize data processing systems for performance, reliability, and cost-efficiency.
 * Implement monitoring, alerting, and logging for data pipelines and infrastructure to ensure operational stability.
 * Champion best practices in data governance, data quality, and security.
   
   

Required Qualifications


 * Bachelor’s degree in Computer Science, Engineering, or a related field, or equivalent practical experience.
 * 3+ years of professional experience in software engineering, with a focus on data-related projects.
 * Proficiency in at least one programming language commonly used for data engineering (e.g., Python, Go or C++).
 * Solid experience with big data processing frameworks like Apache Spark, Flink, Kinesis Data Stream, or similar technologies.
 * Hands-on experience with cloud platforms (AWS, GCP, or Azure) and their data services (e.g., S3, Redshift, BigQuery, Glue).
 * Strong knowledge of SQL and experience working with relational and NoSQL databases.
 * Intermediate knowledge of data analytics infrastructure, including data transformation tools such as DBT and visualization frameworks and tools
 * Experience with building and managing data pipelines using an orchestrator like Apache Airflow.
 * Able to systematically approach open-ended questions to identify pragmatic data solutions that scale
 * Able to work effectively in a highly cross-functional, fast-moving and high-stakes environment
 * Proven ability to communicate technical, data-driven solutions to both technical and non-technical audiences across stakeholders
   
   

Desirable Qualifications


 * Experience with data warehousing solutions like Snowflake or data lake architectures.
 * Familiarity with modern data stack tools and practices.
 * A passion for building elegant, scalable, and maintainable systems.
 * Experience using Amazon Web Services (AWS) tools
   
   

The base salary wage range for this position is $139,000 - $223,000 per year. Aurora’s pay ranges are determined by role, level, and location. Within the range, the successful candidate’s starting base pay will be determined based on factors including job-related skills, experience, qualifications, relevant education or training, and market conditions. These ranges may be modified in the future. The successful candidate will also be eligible for an annual bonus, equity compensation, and benefits.

#Entry-Level

Working at Aurora

At Aurora, we bring together extraordinarily talented and experienced people united by the strength of our values. We operate with integrity, set outrageous goals, and build a culture where we win together — all without any jerks. Our Careers page provides insight into what it is like to work at Aurora, and you can find all the latest updates in our Newsroom.

Commitment to inclusion

Aurora considers candidates without regard to their race, color, religion, national origin, age, sex, gender, gender identity, gender expression, sexual orientation, marital status, pregnancy status, parent or caregiver status, ancestry, political affiliation, veteran and/or military status, physical or mental disability, or any other status protected by federal or state law. Aurora considers qualified applicants with criminal histories, consistent with applicable federal, state, and local law. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at careersiteaccommodations@aurora.tech.

For California applicants, information collected and processed as part of your application and any job applications you choose to submit is subject to Aurora’s California Employment Privacy Policy.

","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","$139,000.00/yr - $223,000.00/yr","","","17973173","https://aurora.tech/jobs/8172103002?gh_src=b6049de52us","EXTERNAL",""
"Data Engineer II","Sunnyvale, CA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/data-engineer-ii-at-coreweave-4347418841?trk=public_jobs_topcard-title","CoreWeave","https://www.linkedin.com/company/coreweave?trk=public_jobs_topcard-org-name","CoreWeave is The Essential Cloud for AI™. Built for pioneers by pioneers, CoreWeave delivers a platform of technology, tools, and teams that enables innovators to build and scale AI with confidence. Trusted by leading AI labs, startups, and global enterprises, CoreWeave combines superior infrastructure performance with deep technical expertise to accelerate breakthroughs and turn compute into capability. Founded in 2017, CoreWeave became a publicly traded company (Nasdaq: CRWV) in March 2025. Learn more at www.coreweave.com.

What You’ll Do

The Data Engineering team builds foundational datasets and analytics services that enable BI and data science across CoreWeave. We aim to democratize insights and foster a culture where data-driven decision-making thrives at every level of the organization.

About The Role

We’re seeking a skilled Data Engineer to develop foundational data models that empower our Business Intelligence engineers, analysts, and data scientists to efficiently work with and gain insights from our data. You’ll create and maintain star and snowflake schemas within our lakehouse environment, generate key datasets and metrics essential to tracking business health, and optimize the flow and storage of data to support analytical workloads across the organization.

Who You Are


 * Hands-on experience applying Kimball modeling principles to large datasets
 * Expertise with analytical table/file formats such as Iceberg, Hudi, Parquet, Avro, and ORC
 * Proven experience optimizing MPP databases (StarRocks, Snowflake, BigQuery, Redshift)
 * 3–5+ years of programming experience in Python, Java, or Scala in a professional setting
 * Advanced SQL skills, with the ability to write, optimize, and debug complex queries
 * Hands-on experience with Airflow for batch orchestration and distributed computing frameworks like Spark or Flink
 * Experience managing systems deployed on Kubernetes is highly desirable, but not required
   
   

Preferred


 * Experience designing and optimizing large-scale data pipelines
 * Strong understanding of data lakehouse architectures and analytics workflows
   
   

Wondering if you’re a good fit?

We Believe In Investing In Our People And Value Candidates Who Bring Their Own Diverse Experiences To Our Teams – Even If You Aren’t a 100% Skill Or Experience Match. Here Are a Few Qualities We’ve Found Compatible With Our Team


 * You love designing and optimizing data models for analytics
 * You’re curious about building efficient, scalable data pipelines
 * You’re an expert in turning complex data into actionable business insights
   
   

Why CoreWeave?

About

At CoreWeave, we work hard, have fun, and move fast! We’re in an exciting stage of hyper-growth that you won’t want to miss. We’re not afraid of a little chaos, and we’re constantly learning. Our team cares deeply about how we build our product and how we work together, which is represented through our core values:


 * Be Curious at Your Core
 * Act Like an Owner
 * Empower Employees
 * Deliver Best-in-Class Client Experiences
 * Achieve More Together
   
   

We support and encourage an entrepreneurial outlook and independent thinking. We foster an environment that encourages collaboration and provides the opportunity to develop innovative solutions to complex problems. As we get set for takeoff, growth opportunities within the organization are constantly expanding. You will be surrounded by some of the best talent in the industry, who will want to learn from you, too. Come join us!

The base salary range for this role is $109,000 to $160,000. The starting salary will be determined based on job-related knowledge, skills, experience, and market location. We strive for both market alignment and internal equity when determining compensation. In addition to base salary, our total rewards package includes a discretionary bonus, equity awards, and a comprehensive benefits program (all based on eligibility).

What We Offer

The range we’ve posted represents the typical compensation range for this role. To determine actual compensation, we review the market rate for each candidate which can include a variety of factors. These include qualifications, experience, interview performance, and location.

In addition to a competitive salary, we offer a variety of benefits to support your needs, including:


 * Medical, dental, and vision insurance - 100% paid for by CoreWeave
 * Company-paid Life Insurance
 * Voluntary supplemental life insurance
 * Short and long-term disability insurance
 * Flexible Spending Account
 * Health Savings Account
 * Tuition Reimbursement
 * Ability to Participate in Employee Stock Purchase Program (ESPP)
 * Mental Wellness Benefits through Spring Health
 * Family-Forming support provided by Carrot
 * Paid Parental Leave
 * Flexible, full-service childcare support with Kinside
 * 401(k) with a generous employer match
 * Flexible PTO
 * Catered lunch each day in our office and data center locations
 * A casual work environment
 * A work culture focused on innovative disruption
   
   

Our Workplace

While we prioritize a hybrid work environment, remote work may be considered for candidates located more than 30 miles from an office, based on role requirements for specialized skill sets. New hires will be invited to attend onboarding at one of our hubs within their first month. Teams also gather quarterly to support collaboration

California Consumer Privacy Act - California applicants only

CoreWeave is an equal opportunity employer, committed to fostering an inclusive and supportive workplace. All qualified applicants and candidates will receive consideration for employment without regard to race, color, religion, sex, disability, age, sexual orientation, gender identity, national origin, veteran status, or genetic information.

As part of this commitment and consistent with the Americans with Disabilities Act (ADA), CoreWeave will ensure that qualified applicants and candidates with disabilities are provided reasonable accommodations for the hiring process, unless such accommodation would cause an undue hardship. If reasonable accommodation is needed, please contact: careers@coreweave.com.

Export Control Compliance

This position requires access to export controlled information. To conform to U.S. Government export regulations applicable to that information, applicant must either be (A) a U.S. person, defined as a (i) U.S. citizen or national, (ii) U.S. lawful permanent resident (green card holder), (iii) refugee under 8 U.S.C.


 * 1157, or (iv) asylee under 8 U.S.C.
 * 1158, (B) eligible to access the export controlled information without a required export authorization, or (C) eligible and reasonably likely to obtain the required export authorization from the applicable U.S. government agency. CoreWeave may, for legitimate business reasons, decline to pursue any export licensing process.","Over 200 applicants","Full-time","Entry level","Information Technology","Technology, Information and Internet","$109,000.00/yr - $160,000.00/yr","","","36121341","https://coreweave.com/careers/job?4615931006&board=coreweave&gh_jid=4615931006","EXTERNAL",""
"Manager, Data and AI Strategy","Houston, TX","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/manager-data-and-ai-strategy-at-conocophillips-4324347438?trk=public_jobs_topcard-title","ConocoPhillips","https://www.linkedin.com/company/conocophillips?trk=public_jobs_topcard-org-name"," * World’s largest independent upstream oil and gas business
 * SPIRIT values - Safety People Integrity Responsibility Innovation Teamwork
 * Operations in 13 countries
   
   

Welcome to ConocoPhillips, where innovation and excellence create a platform for opportunity and growth. Come realize your full potential here.

Who We Are

We are one of the world’s largest independent exploration and production companies, based on proved reserves and production of liquids and natural gas. With operations and activities in 13 countries, we explore for, develop, and produce crude oil and natural gas globally. We are challenged with an important job to safely find and deliver energy to the world. Our employees are critical to our success, and with them we power civilization.

We’re grounded by our SPIRIT Values – safety, people, integrity, responsibility, innovation, and teamwork. These values position us to deliver strong performance in a dynamic business – but not at all costs. We believe it’s not just what we do – it’s how we do it – that sets us apart.

Fostering an Inclusive Work Environment

To deliver superior performance, we create an environment that respects the contributions and differences of every individual. Wherever possible, we use these differences to drive competitive business advantage, personal growth and, ultimately, create business success.

Job Summary

As Manager, Data & AI Strategy, you will play a pivotal role in shaping the future of digital innovation at ConocoPhillips. Reporting to the Manager of Digital and AI Capabilities, you will lead a team responsible for defining and executing enterprise-wide data and AI strategies that drive measurable business outcomes. This role is about more than technology—it’s about enabling smarter decisions, fostering a data-driven culture, and ensuring the ethical use of AI across our global operations. If you are passionate about leveraging data and AI to transform the energy industry and thrive in a collaborative, forward-thinking environment, this is your opportunity to make an impact.

Position Overview

Your responsibilities may include:


 * Define and own the enterprise-wide Data and AI Strategy, ensuring alignment with ConocoPhillips’ business objectives
 * Lead a cross-functional team to implement AI and data governance, Responsible AI practices, and strategic initiatives
 * Champion data-driven decision-making and promote data ownership and marketplace concepts across the organization
 * Collaborate with business units and functional teams to integrate AI and data solutions into core processes
 * Build strategic partnerships to enhance AI capabilities and accelerate innovation
 * Mentor and develop the Data & AI Strategy team, fostering a culture of accountability, urgency, and innovation
 * Establish and track digital maturity metrics to measure progress against internal and industry benchmarks
 * Monitor and report on the performance of data and AI initiatives, identifying opportunities for growth and efficiency
 * Represent ConocoPhillips in industry forums to maintain leadership in digital and AI innovation
 * Lead digital campaigns and showcases to demonstrate emerging technologies and capabilities
   
   

Success Profile (Leadership Competencies):


 * Strategic Influence: Ability to shape enterprise-wide strategies and gain alignment from senior leaders
 * Innovation Leadership: Drives adoption of emerging technologies and fosters a culture of continuous improvement
 * Collaboration: Builds strong partnerships across technical, functional, and business teams
 * Change Agility: Navigates complexity and leads transformation with confidence and clarity
   
   

Basic/Required:


 * Legally authorized to work in the United States
 * Bachelor’s degree or higher in Data Science, Computer Science, Engineering, or related field or foreign equivalent
 * 10 or more years of experience in data and analytics, with a proven track record delivering AI/ML solutions and data products
 * Willing and able (with or without reasonable accommodations) to travel 10% of the time on a yearly basis
   
   

Preferred:


 * Advanced degree in Data Science, Computer Science, Engineering, or related field, or foreign equivalent
 * Experience leading cross-functional teams and delivering solutions at scale
 * Expertise in data science, AI/ML, cloud data platforms, and modern analytics stacks
 * Experience implementing Responsible AI programs
 * Experience developing and implementing AI or data strategies in large-scale organizations
 * Operational experience within upstream oil and gas
 * Knowledge of managing structured and unstructured data, including text, graphics, and video
 * Strong understanding of upstream oil and gas operations
 * Demonstrated ability to develop and execute data and AI strategies that drive business transformation
 * Strategic planning and program management skills
 * Strong executive presence and ability to influence senior stakeholders
 * Exceptional communication and leadership skills
 * Familiarity with IT security standards for oil and gas data and enterprise information
 * Proven ability to partner with AI and data vendors, including early-stage companies
   
   

Apply By:

Dec 15, 2025

Sponsorship:

ConocoPhillips’ sponsorship for employment authorization in the U.S. is NOT available for this position.

EEO:

In the US, ConocoPhillips is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, national origin, age, disability, veteran status, gender identity or expression, genetic information, or any other legally protected status.","127 applicants","Full-time","Mid-Senior level","Information Technology","Oil and Gas","","","","3600","https://conocophillips.wd1.myworkdayjobs.com/External/job/Houston-TX/Manager\u002d\u002dData-and-AI-Strategy_REQ-005265?source=LinkedIn","EXTERNAL",""
"Analytics Engineer","San Francisco, CA","2 days ago","2025-11-30","https://www.linkedin.com/jobs/view/analytics-engineer-at-cognition%2B-4339448569?trk=public_jobs_topcard-title","Cognition+","https://ca.linkedin.com/company/gocognition?trk=public_jobs_topcard-org-name","We are an applied AI lab building end-to-end software agents.

We’re the makers of Devin, the first AI software engineer. Cognition is building collaborative AI teammates that enable engineers to focus on more interesting problems and empower engineering teams to strive for more ambitious goals.

Our team is small and talent-dense. Among our founding team, we have world-class competitive programmers, former founders, and leaders from companies at the cutting edge of AI including , Scale AI, Cursor, Waymo, Tesla, Lunchclub, Modal, Google DeepMind, and Nuro.

Building Devin is just the first step—our hardest challenges still lie ahead. If you’re excited to solve some of the world’s biggest problems and build AI that can reason on real-world tasks, apply to join us.

About The Role

We’re hiring a technical Analytics Engineer to own our full data stack – from database architecture and pipelines to integrations and reporting. You’ll design and maintain the systems that keep our data reliable, accessible, and actionable across the company with a particular focus on product and GTM reporting.

In this role you will:


 * Design and manage database architecture and data models
 * Build and maintain ETL/ELT pipelines and orchestration workflows
 * Create and manage new data integrations across internal and external systems
 * Own business reporting: datasets, dashboards, metrics, and self-serve analytics
 * Ensure data quality, observability, governance, and documentation
   
   

Requirements for the role:


 * 4+ years in a data engineering, data science, or full-stack data role
 * Expert SQL and strong Python (or R)
 * Experience with data modeling, warehouse architecture, and BI-oriented schema design
 * Hands-on experience with ETL/ELT tools (dbt, Airflow, Dagster, etc.)
 * Experience building or maintaining BI reporting (Metabase a plus)
 * Strong knowledge of statistics and experimentation
 * Based in SF or NYC
   
   ","129 applicants","Full-time","Entry level","Information Technology","Software Development","","","","42703","https://www.linkedin.com/jobs/view/analytics-engineer-at-cognition%2B-4339448569?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer II","New York, NY","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/data-engineer-ii-at-coreweave-4347478651?trk=public_jobs_topcard-title","CoreWeave","https://www.linkedin.com/company/coreweave?trk=public_jobs_topcard-org-name","CoreWeave is The Essential Cloud for AI™. Built for pioneers by pioneers, CoreWeave delivers a platform of technology, tools, and teams that enables innovators to build and scale AI with confidence. Trusted by leading AI labs, startups, and global enterprises, CoreWeave combines superior infrastructure performance with deep technical expertise to accelerate breakthroughs and turn compute into capability. Founded in 2017, CoreWeave became a publicly traded company (Nasdaq: CRWV) in March 2025. Learn more at www.coreweave.com.

What You’ll Do

The Data Engineering team builds foundational datasets and analytics services that enable BI and data science across CoreWeave. We aim to democratize insights and foster a culture where data-driven decision-making thrives at every level of the organization.

About The Role

We’re seeking a skilled Data Engineer to develop foundational data models that empower our Business Intelligence engineers, analysts, and data scientists to efficiently work with and gain insights from our data. You’ll create and maintain star and snowflake schemas within our lakehouse environment, generate key datasets and metrics essential to tracking business health, and optimize the flow and storage of data to support analytical workloads across the organization.

Who You Are


 * Hands-on experience applying Kimball modeling principles to large datasets
 * Expertise with analytical table/file formats such as Iceberg, Hudi, Parquet, Avro, and ORC
 * Proven experience optimizing MPP databases (StarRocks, Snowflake, BigQuery, Redshift)
 * 3–5+ years of programming experience in Python, Java, or Scala in a professional setting
 * Advanced SQL skills, with the ability to write, optimize, and debug complex queries
 * Hands-on experience with Airflow for batch orchestration and distributed computing frameworks like Spark or Flink
 * Experience managing systems deployed on Kubernetes is highly desirable, but not required
   
   

Preferred


 * Experience designing and optimizing large-scale data pipelines
 * Strong understanding of data lakehouse architectures and analytics workflows
   
   

Wondering if you’re a good fit?

We Believe In Investing In Our People And Value Candidates Who Bring Their Own Diverse Experiences To Our Teams – Even If You Aren’t a 100% Skill Or Experience Match. Here Are a Few Qualities We’ve Found Compatible With Our Team


 * You love designing and optimizing data models for analytics
 * You’re curious about building efficient, scalable data pipelines
 * You’re an expert in turning complex data into actionable business insights
   
   

Why CoreWeave?

About

At CoreWeave, we work hard, have fun, and move fast! We’re in an exciting stage of hyper-growth that you won’t want to miss. We’re not afraid of a little chaos, and we’re constantly learning. Our team cares deeply about how we build our product and how we work together, which is represented through our core values:


 * Be Curious at Your Core
 * Act Like an Owner
 * Empower Employees
 * Deliver Best-in-Class Client Experiences
 * Achieve More Together
   
   

We support and encourage an entrepreneurial outlook and independent thinking. We foster an environment that encourages collaboration and provides the opportunity to develop innovative solutions to complex problems. As we get set for takeoff, growth opportunities within the organization are constantly expanding. You will be surrounded by some of the best talent in the industry, who will want to learn from you, too. Come join us!

The base salary range for this role is $109,000 to $160,000. The starting salary will be determined based on job-related knowledge, skills, experience, and market location. We strive for both market alignment and internal equity when determining compensation. In addition to base salary, our total rewards package includes a discretionary bonus, equity awards, and a comprehensive benefits program (all based on eligibility).

What We Offer

The range we’ve posted represents the typical compensation range for this role. To determine actual compensation, we review the market rate for each candidate which can include a variety of factors. These include qualifications, experience, interview performance, and location.

In addition to a competitive salary, we offer a variety of benefits to support your needs, including:


 * Medical, dental, and vision insurance - 100% paid for by CoreWeave
 * Company-paid Life Insurance
 * Voluntary supplemental life insurance
 * Short and long-term disability insurance
 * Flexible Spending Account
 * Health Savings Account
 * Tuition Reimbursement
 * Ability to Participate in Employee Stock Purchase Program (ESPP)
 * Mental Wellness Benefits through Spring Health
 * Family-Forming support provided by Carrot
 * Paid Parental Leave
 * Flexible, full-service childcare support with Kinside
 * 401(k) with a generous employer match
 * Flexible PTO
 * Catered lunch each day in our office and data center locations
 * A casual work environment
 * A work culture focused on innovative disruption
   
   

Our Workplace

While we prioritize a hybrid work environment, remote work may be considered for candidates located more than 30 miles from an office, based on role requirements for specialized skill sets. New hires will be invited to attend onboarding at one of our hubs within their first month. Teams also gather quarterly to support collaboration

California Consumer Privacy Act - California applicants only

CoreWeave is an equal opportunity employer, committed to fostering an inclusive and supportive workplace. All qualified applicants and candidates will receive consideration for employment without regard to race, color, religion, sex, disability, age, sexual orientation, gender identity, national origin, veteran status, or genetic information.

As part of this commitment and consistent with the Americans with Disabilities Act (ADA), CoreWeave will ensure that qualified applicants and candidates with disabilities are provided reasonable accommodations for the hiring process, unless such accommodation would cause an undue hardship. If reasonable accommodation is needed, please contact: careers@coreweave.com.

Export Control Compliance

This position requires access to export controlled information. To conform to U.S. Government export regulations applicable to that information, applicant must either be (A) a U.S. person, defined as a (i) U.S. citizen or national, (ii) U.S. lawful permanent resident (green card holder), (iii) refugee under 8 U.S.C.


 * 1157, or (iv) asylee under 8 U.S.C.
 * 1158, (B) eligible to access the export controlled information without a required export authorization, or (C) eligible and reasonably likely to obtain the required export authorization from the applicable U.S. government agency. CoreWeave may, for legitimate business reasons, decline to pursue any export licensing process.","Over 200 applicants","Full-time","Entry level","Information Technology","Technology, Information and Internet","$109,000.00/yr - $160,000.00/yr","","","36121341","https://www.linkedin.com/jobs/view/data-engineer-ii-at-coreweave-4347478651?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer, E-Commerce","Seattle, WA","2 days ago","2025-11-29","https://www.linkedin.com/jobs/view/data-engineer-e-commerce-at-tiktok-4325102783?trk=public_jobs_topcard-title","TikTok","https://www.linkedin.com/company/tiktok?trk=public_jobs_topcard-org-name","Responsibilities
As a data engineer in the Data Platform E-Commerce team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.

This position can be based out of our Mountain View or Seattle office.

Responsibilities - What You'll Do
• Design and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis);
• Design and implement reliable, scalable, robust and extensible big data systems that support core products and business;
• Establish solid design and best engineering practice for engineers as well as non-technical people.

Qualifications
Minimum qualifications:
• BS or MS degree in Computer Science or related technical field or equivalent practical experience;
• Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.);
• Experience with performing data analysis, data ingestion and data integration;
• Experience with ETL(Extraction, Transformation & Loading) and architecting data systems;
• Experience with schema design, data modeling and SQL queries;
• Passionate and self-motivated about technologies in the Big Data area.

About TikTok
TikTok is the leading destination for short-form mobile video. At TikTok, our mission is to inspire creativity and bring joy. TikTok's global headquarters are in Los Angeles and Singapore, and we also have offices in New York City, London, Dublin, Paris, Berlin, Dubai, Jakarta, Seoul, and Tokyo.


Why Join Us
Inspiring creativity is at the core of TikTok's mission. Our innovative product is built to help people authentically express themselves, discover and connect – and our global, diverse teams make that possible. Together, we create value for our communities, inspire creativity and bring joy - a mission we work towards every day.
We strive to do great things with great people. We lead with curiosity, humility, and a desire to make impact in a rapidly growing tech company. Every challenge is an opportunity to learn and innovate as one team. We're resilient and embrace challenges as they come. By constantly iterating and fostering an ""Always Day 1"" mindset, we achieve meaningful breakthroughs for ourselves, our company, and our users. When we create and grow together, the possibilities are limitless. Join us.

Diversity & Inclusion
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.


TikTok Accommodation
TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://tinyurl.com/RA-request


Job Information
【For Pay Transparency】Compensation Description (Annually)
The base salary range for this position in the selected city is $177688 - $341734 annually.
Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.
Benefits may vary depending on the nature of employment and the country work location. Employees have day one access to medical, dental, and vision insurance, a 401(k) savings plan with company match, paid parental leave, short-term and long-term disability coverage, life insurance, wellbeing benefits, among others. Employees also receive 10 paid holidays per year, 10 paid sick days per year and 17 days of Paid Personal Time (prorated upon hire with increasing accruals by tenure).
The Company reserves the right to modify or change these benefits programs at any time, with or without notice.
For Los Angeles County (unincorporated) Candidates:
Qualified applicants with arrest or conviction records will be considered for employment in accordance with all federal, state, and local laws including the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act. Our company believes that criminal history may have a direct, adverse and negative relationship on the following job duties, potentially resulting in the withdrawal of the conditional offer of employment:
1. Interacting and occasionally having unsupervised contact with internal/external clients and/or colleagues;
2. Appropriately handling and managing confidential information including proprietary and trade secret information and access to information technology systems; and
3. Exercising sound judgment.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Software Development","$177,688.00/yr - $341,734.00/yr","","","33246798","https://www.linkedin.com/jobs/view/data-engineer-e-commerce-at-tiktok-4325102783?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Houston, TX","14 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-engineer-at-richard-wayne-roberts-4340785580?trk=public_jobs_topcard-title","Richard, Wayne & Roberts","https://www.linkedin.com/company/richard-wayne-&-roberts?trk=public_jobs_topcard-org-name","Python Data Engineer — Houston, TX (Onsite Only)




A global energy and commodities organization is seeking an experienced Python Data Engineer to expand and optimize data assets that support high-impact analytics. This role works closely with traders, analysts, researchers, and data scientists to translate business needs into scalable technical solutions. The position is fully onsite due to the collaborative, fast-paced nature of the work.




MUST come from an Oil & Gas organization, prefer commodity trading firm.

CANNOT do C2C.




Key Responsibilities

 * Build modular, reusable Python components to connect external data sources with internal tools and databases.
 * Partner with business stakeholders to define data ingestion and access requirements.
 * Translate business requirements into well-designed technical deliverables.
 * Maintain and enhance the central Python codebase following established standards.
 * Contribute to internal developer tools and ETL frameworks, helping standardize and consolidate core functionality.
 * Collaborate with global engineering teams and participate in internal Python community initiatives.




Qualifications

 * 7+ years of professional Python development experience.
 * Strong background in data engineering and pipeline development.
 * Experience with web scraping tools (Requests, BeautifulSoup, Selenium).
 * Hands-on Oracle/PL SQL development, including stored procedures.
 * Strong grasp of object-oriented design, design patterns, and service-oriented architectures.
 * Experience with Agile/Scrum, code reviews, version control, and issue tracking.
 * Familiarity with scientific computing libraries (Pandas, NumPy).
 * Excellent communication skills.
 * Industry experience in energy or commodities preferred.
 * Exposure to containerization (Docker, Kubernetes) is a plus.

","124 applicants","Full-time","Mid-Senior level","Information Technology","Oil and Gas","","Brianna F.","https://www.linkedin.com/in/briannafajohn","15842","https://www.linkedin.com/jobs/view/data-engineer-at-richard-wayne-roberts-4340785580?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)"
"Data Engineer Analyst","Herndon, VA","1 month ago","2025-10-29","https://www.linkedin.com/jobs/view/data-engineer-analyst-at-bespoke-technologies-inc-4331355883?trk=public_jobs_topcard-title","Bespoke Technologies, Inc.","https://www.linkedin.com/company/bespoketechinc?trk=public_jobs_topcard-org-name","BT-154 – Data Engineer Analyst

Skill Level: Senior

Location: Chantilly/Herndon


 * MUST HAVE A TS/SCI CLEARANCE TO APPLY. Those without an active security clearance will not be considered.**
   
   

Role Description

As a Data Engineer at the Senior Analyst level, you will be a key contributor to the team responsible for building and maintaining the data pipelines for a Data Platform. This is a hands-on role where you will support the development, deployment, and operation of critical data infrastructure. You will work closely with senior engineers, applying your technical skills to execute tasks, troubleshoot issues, and learn the foundations of enterprise-scale data engineering.

Responsibilities


 * Assist in the development and maintenance of ETL/ELT data pipelines using established patterns and tools.
 * Utilize reusable pipeline templates and Infrastructure-as-Code (IaC) scripts to deploy data flows consistently and efficiently.
 * Support the O&M of existing pipelines by monitoring performance, troubleshooting failures, and responding to alerts.
 * Execute data quality checks and assist in the implementation of data validation rules
 * Work with senior team members to test and deploy new pipeline features and optimizations.
 * Contribute to the creation and maintenance of technical documentation for data pipelines and processes.
   
   

Required Qualifications


 * 2+ years of experience in a data-focused role (e.g., data engineering, backend development, database administration).
 * Experience with Python and SQL for data manipulation and scripting.
 * Familiarity with data engineering concepts, including ETL processes and data warehousing.
 * Exposure to cloud environments (e.g., AWS, Azure) and data platforms like Databricks or Snowflake.
 * Basic understanding of Agile/Scrum methodologies.
 * A strong desire to learn and grow in the data engineering field.
 * Active Top Secret/SCI security clearance.
   
   

Preferred Qualifications


 * Direct experience with data platforms.
 * Experience with Spark/PySpark.
 * Familiarity with Infrastructure-as-Code tools like Terraform.
 * Exposure to data orchestration tools (e.g., Airflow) or CI/CD pipelines.","84 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","","","","71291624","https://www.linkedin.com/jobs/view/data-engineer-analyst-at-bespoke-technologies-inc-4331355883?trk=public_jobs_topcard-title","EASY_APPLY",""
"Machine Learning Engineer - Advertising","New York, NY","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/machine-learning-engineer-advertising-at-spotify-4337180295?trk=public_jobs_topcard-title","Spotify","https://se.linkedin.com/company/spotify?trk=public_jobs_topcard-org-name","Our mission on the Advertising Product & Technology team is to build a next generation advertising platform that aligns with our unique value proposition for audio and video. We work to scale the user experience for hundreds of millions of fans and hundreds of thousands of advertisers. This scale brings unique challenges as well as tremendous opportunities for our artists and creators.

We are seeking a Machine Learning Engineer II with expertise in machine learning model development, AI engineering, online experimentation techniques, and large-scale engineering systems. This role will lead strategic initiatives and projects within CareML.

The CareML squad focuses on enabling review for podcast content and ads with respect to brand safety and suitability. By leveraging data and experimentation, we aim to categorize topics existing on both content and ads in various taxonomies that are used to drive large-scale ad serving systems for all of Spotify. We operate on the cutting edge of both machine learning and AI engineering, employing both in-house first party models developed through traditional machine learning and third-party foundation models leveraged from different providers.

We are looking for someone who is motivated by user and business problems as much as they are by technical problems, and who enjoys ambiguity, brainstorming, experimentation, and iteration. You will work in close collaboration with key stakeholders across engineering, product, business, and leadership teams to build the most impactful solutions for our Spotify listeners and business.

What You'll Do


 * Design and implement machine learning systems to categories ad and podcast content
 * Research and apply best practices for driving automation with respect to human review processes
 * Partner with multiple teams to shape and enhance shared systems and pipelines
 * Come up with creative ways to apply AI tools to develop innovative solutions
 * Collaborate with and backend engineers, data scientists, and product managers to establish baselines, inform product decisions, and develop new technologies
   
   

Who You Are


 * You have professional experience in applied machine learning
 * You are proficient in programming languages such as Python, Java, or Scala
 * You have experience with operating in a cloud-native infrastructure
 * You have worked with LLMs to deliver solutions through AI engineering
 * As a plus, you may have experience with adtech, categorization systems, and evaluation tools / data curation techniques
   
   

Where You'll Be


 * We offer you the flexibility to work where you work best! For this role, you can be within the Americas region as long as we have a work location.
 * This team operates within the Eastern time zone for collaboration.
   
   

The United States base range for this position is $138,250.00 - $197,500.00, plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays, paid sick leave. This range encompasses multiple levels. Leveling is determined during the interview process. Placement in a level depends on relevant work history and interview performance. These ranges may be modified in the future.

Spotify is an equal opportunity employer. You are welcome at Spotify for who you are, no matter where you come from, what you look like, or what’s playing in your headphones. Our platform is for everyone, and so is our workplace. The more voices we have represented and amplified in our business, the more we will all thrive, contribute, and be forward-thinking! So bring us your personal experience, your perspectives, and your background. It’s in our differences that we will find the power to keep revolutionizing the way the world listens.

At Spotify, we are passionate about inclusivity and making sure our entire recruitment process is accessible to everyone. We have ways to request reasonable accommodations during the interview process and help assist in what you need. If you need accommodations at any stage of the application or interview process, please let us know - we’re here to support you in any way we can.

Spotify transformed music listening forever when we launched in 2008. Our mission is to unlock the potential of human creativity by giving a million creative artists the opportunity to live off their art and billions of fans the chance to enjoy and be passionate about these creators. Everything we do is driven by our love for music and podcasting. Today, we are the world’s most popular audio streaming subscription service.","Over 200 applicants","Full-time","Entry level","Engineering","Musicians","$138,250.00/yr - $197,500.00/yr","","","207470","https://www.linkedin.com/jobs/view/machine-learning-engineer-advertising-at-spotify-4337180295?trk=public_jobs_topcard-title","EASY_APPLY",""
"Quantitative Data Engineer","Boston, MA","21 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/quantitative-data-engineer-at-massmutual-4340383650?trk=public_jobs_topcard-title","MassMutual","https://www.linkedin.com/company/massmutual-financial-group?trk=public_jobs_topcard-org-name","Quantitative Research & Development Team

Full-Time

Springfield, MA or Boston, MA

The Opportunity

As a Quantitative Data Engineer you will work in a fast paced, innovative, and collaborative environment on exciting technology directives. A Quantitative Data Engineer embodies a unique combination of technical, business and people skills. Both emotional intelligence and the ability to solve complex problems and communicate effectively are key to success. Ideally, you have a strong background in Fixed Income data as well as workflow orchestration and CI/CD pipelines. Additionally, it is preferred that you have robust experience in cloud platforms and system architecture.

The Team

As aQuantitative Data Engineer, you will join the Quantitative Investment Platforms team, part of MassMutual’s Investment Management QRD organization. The Quantitative development team is comprised of highly skilled, financial industry savvy professionals who render collaborative and portfolio risk solutions to our portfolio managers. Team members demonstrate high levels of competence in the areas of resilience, accountability, agility, and are focused on continuous improvement and development. The team culture is collaborative, cross-functional, and fosters high performance results with an emphasis on encouraging a healthy work/life balance.

The Impact

Our ideal Quantitative Data Engineeris passionate about data and deploying solutions and workflow automations.


 * You enjoy building data projects from the ground up and are equally comfortable working with business partners to understand requirements as you are developing and delivering robust solutions that meet the highest standards. 
 * Learning new technologies and working in the cloud excite you. 
 * You are team-oriented and a strong communicator.
 * Design, build and maintain complex ELT jobs that deliver business value
 * Translate high-level business requirements into technical specs
 * Ingest data from disparate sources into the various data stores
 * Cleanse and enrich data and apply adequate data quality controls
 * Provide insight and direction to guide the future development of MassMutual’s data platform
 * Develop re-usable tools to help streamline the delivery of new projects
 * Collaborate closely with other developers and provide mentorship
 * Evaluate and recommend tools, technologies, processes and reference architectures 
 * Deploy reusable workflow & orchestration
 * Work in an Agile development environment, attending daily stand-up meetings and delivering incremental improvements
   
   

The Minimum Qualifications


 * A Bachelor’s degree in Math, Engineering, Computer Science, or related field.
 * 5+ Years of experience in the IT and/or finance industry
 * 5+ years ofunderstanding of ELT methodologies and tools via Python
 * 5+ years of experience with GIT and code review/deployment & scheduling part of
 * 5+ years of experience in relational databases (SQLServer/PostgreSQL) and NOSQL databases (Mongo)
   
   

The Ideal Qualifications


 * Master’s degree in Math, Computer Science, Engineering or a related field
 * 7+ Years of experience in the IT and/or finance industry
 * Python: Extensive hands on experience developing with Python and advanced data processing using Python libraries & AWS services.
 * Cloud: Experience working in a cloud environment and basic administration (e.g.AWS)
 * Extensive experience in modeling and tuning relational databases (SQL Server/PostgreSQL) and NOSQL databases (Mongo)
 * Troubleshooting: Experience with troubleshooting and root cause analysis to determine and remediate potential issues
 * Workflow: Good knowledge of orchestration and scheduling tools
 * Reporting: Experience with data reporting (e.g. Micro strategy, Tableau, Looker) or via python libraries
 * Entrepreneurial mindset with the ability to work in a rapid and iterative development environment
 * Experience delivering mobile apps and app store ecosystems
 * Extremely organized, detail-oriented individual who is capable of self-managing and multi-tasking in a fast-paced, demanding environment
 * Excellent written and verbal communication skills, including the ability to effectively present complex information clearly and appropriately handle sensitive information
 * A Data-driven mindset and the ability to use quantitative tools and analyze unstructured feedback to inform the development of solutions
 * The ability to adapt to changing business priorities and a strong work ethic
 * Curiosity regarding emerging digital and technology trends can translate into excellent customer experiences
 * Proven ability to collaborate cross-functionally and influence outcomes
 * Communication: Excellent communication, problem solving and organizational and analytical skills
 * Experience in Agile/SCRUM-specifically in Story/Acceptance criteria development
   
   

What to Expect as Part of MassMutual and the Team


 * Regular meetings with the IM QRD and ETX teams
 * Focused one-on-one meetings with your manager
 * Networking opportunities including access to Asian, Hispanic/Latinx, African American, women, LGBTQIA+, veteran and disability-focused Business Resource Groups
 * Access to learning content on Degreed and other informational platforms
 * Your ethics and integrity will be valued by a company with a strong and stable ethical business with industry leading pay and benefits
   
   

MassMutual is an equal employment opportunity employer. We welcome all persons to apply.

If you need an accommodation to complete the application process, please contact us and share the specifics of the assistance you need.

California residents: For detailed information about your rights under the California Consumer Privacy Act (CCPA), please visit our California Consumer Privacy Act Disclosures page.

","75 applicants","Full-time","Entry level","Information Technology","Financial Services","","","","3631","https://www.linkedin.com/jobs/view/quantitative-data-engineer-at-massmutual-4340383650?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer II","Washington, DC","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/data-engineer-ii-at-coreweave-4347349556?trk=public_jobs_topcard-title","CoreWeave","https://www.linkedin.com/company/coreweave?trk=public_jobs_topcard-org-name","CoreWeave is The Essential Cloud for AI™. Built for pioneers by pioneers, CoreWeave delivers a platform of technology, tools, and teams that enables innovators to build and scale AI with confidence. Trusted by leading AI labs, startups, and global enterprises, CoreWeave combines superior infrastructure performance with deep technical expertise to accelerate breakthroughs and turn compute into capability. Founded in 2017, CoreWeave became a publicly traded company (Nasdaq: CRWV) in March 2025. Learn more at www.coreweave.com.

What You’ll Do

The Data Engineering team builds foundational datasets and analytics services that enable BI and data science across CoreWeave. We aim to democratize insights and foster a culture where data-driven decision-making thrives at every level of the organization.

About The Role

We’re seeking a skilled Data Engineer to develop foundational data models that empower our Business Intelligence engineers, analysts, and data scientists to efficiently work with and gain insights from our data. You’ll create and maintain star and snowflake schemas within our lakehouse environment, generate key datasets and metrics essential to tracking business health, and optimize the flow and storage of data to support analytical workloads across the organization.

Who You Are


 * Hands-on experience applying Kimball modeling principles to large datasets
 * Expertise with analytical table/file formats such as Iceberg, Hudi, Parquet, Avro, and ORC
 * Proven experience optimizing MPP databases (StarRocks, Snowflake, BigQuery, Redshift)
 * 3–5+ years of programming experience in Python, Java, or Scala in a professional setting
 * Advanced SQL skills, with the ability to write, optimize, and debug complex queries
 * Hands-on experience with Airflow for batch orchestration and distributed computing frameworks like Spark or Flink
 * Experience managing systems deployed on Kubernetes is highly desirable, but not required
   
   

Preferred


 * Experience designing and optimizing large-scale data pipelines
 * Strong understanding of data lakehouse architectures and analytics workflows
   
   

Wondering if you’re a good fit?

We Believe In Investing In Our People And Value Candidates Who Bring Their Own Diverse Experiences To Our Teams – Even If You Aren’t a 100% Skill Or Experience Match. Here Are a Few Qualities We’ve Found Compatible With Our Team


 * You love designing and optimizing data models for analytics
 * You’re curious about building efficient, scalable data pipelines
 * You’re an expert in turning complex data into actionable business insights
   
   

Why CoreWeave?

About

At CoreWeave, we work hard, have fun, and move fast! We’re in an exciting stage of hyper-growth that you won’t want to miss. We’re not afraid of a little chaos, and we’re constantly learning. Our team cares deeply about how we build our product and how we work together, which is represented through our core values:


 * Be Curious at Your Core
 * Act Like an Owner
 * Empower Employees
 * Deliver Best-in-Class Client Experiences
 * Achieve More Together
   
   

We support and encourage an entrepreneurial outlook and independent thinking. We foster an environment that encourages collaboration and provides the opportunity to develop innovative solutions to complex problems. As we get set for takeoff, growth opportunities within the organization are constantly expanding. You will be surrounded by some of the best talent in the industry, who will want to learn from you, too. Come join us!

The base salary range for this role is $109,000 to $160,000. The starting salary will be determined based on job-related knowledge, skills, experience, and market location. We strive for both market alignment and internal equity when determining compensation. In addition to base salary, our total rewards package includes a discretionary bonus, equity awards, and a comprehensive benefits program (all based on eligibility).

What We Offer

The range we’ve posted represents the typical compensation range for this role. To determine actual compensation, we review the market rate for each candidate which can include a variety of factors. These include qualifications, experience, interview performance, and location.

In addition to a competitive salary, we offer a variety of benefits to support your needs, including:


 * Medical, dental, and vision insurance - 100% paid for by CoreWeave
 * Company-paid Life Insurance
 * Voluntary supplemental life insurance
 * Short and long-term disability insurance
 * Flexible Spending Account
 * Health Savings Account
 * Tuition Reimbursement
 * Ability to Participate in Employee Stock Purchase Program (ESPP)
 * Mental Wellness Benefits through Spring Health
 * Family-Forming support provided by Carrot
 * Paid Parental Leave
 * Flexible, full-service childcare support with Kinside
 * 401(k) with a generous employer match
 * Flexible PTO
 * Catered lunch each day in our office and data center locations
 * A casual work environment
 * A work culture focused on innovative disruption
   
   

Our Workplace

While we prioritize a hybrid work environment, remote work may be considered for candidates located more than 30 miles from an office, based on role requirements for specialized skill sets. New hires will be invited to attend onboarding at one of our hubs within their first month. Teams also gather quarterly to support collaboration

California Consumer Privacy Act - California applicants only

CoreWeave is an equal opportunity employer, committed to fostering an inclusive and supportive workplace. All qualified applicants and candidates will receive consideration for employment without regard to race, color, religion, sex, disability, age, sexual orientation, gender identity, national origin, veteran status, or genetic information.

As part of this commitment and consistent with the Americans with Disabilities Act (ADA), CoreWeave will ensure that qualified applicants and candidates with disabilities are provided reasonable accommodations for the hiring process, unless such accommodation would cause an undue hardship. If reasonable accommodation is needed, please contact: careers@coreweave.com.

Export Control Compliance

This position requires access to export controlled information. To conform to U.S. Government export regulations applicable to that information, applicant must either be (A) a U.S. person, defined as a (i) U.S. citizen or national, (ii) U.S. lawful permanent resident (green card holder), (iii) refugee under 8 U.S.C.


 * 1157, or (iv) asylee under 8 U.S.C.
 * 1158, (B) eligible to access the export controlled information without a required export authorization, or (C) eligible and reasonably likely to obtain the required export authorization from the applicable U.S. government agency. CoreWeave may, for legitimate business reasons, decline to pursue any export licensing process.","Over 200 applicants","Full-time","Entry level","Information Technology","Technology, Information and Internet","$109,000.00/yr - $160,000.00/yr","","","36121341","https://www.linkedin.com/jobs/view/data-engineer-ii-at-coreweave-4347349556?trk=public_jobs_topcard-title","EASY_APPLY",""
"Operations Data Advisor","Midland, TX","4 days ago","2025-11-27","https://www.linkedin.com/jobs/view/operations-data-advisor-at-diamondback-energy-4315608394?trk=public_jobs_topcard-title","Diamondback Energy","https://www.linkedin.com/company/diamondbackenergy?trk=public_jobs_topcard-org-name","CURRENT EMPLOYEES - Please apply using ""Jobs Hub"" in Workday. This career site is for external applicants only.

The Data Advisor will support upstream operations by developing and maintaining high-impact reporting solutions. This role requires a deep understanding of oil & gas operations and strong technical skills in data visualization and analysis. The ideal candidate will be a proactive problem solver who can translate operational data into actionable insights for Operations teams.

Job Duties And Responsibilities


 * Develop and maintain advanced Spotfire dashboards and SQL-based reports to support upstream operations
 * Use Python for data manipulation, automation, and custom analytics where needed
 * Collaborate with the operations teams to understand reporting needs and deliver timely, accurate insights
 * Work with data from systems such as ProCount, WellView, SiteView, Actenum, Ignition, and XSPOC
 * Ensure data accuracy, consistency, and usability across reporting platforms
 * Support ad-hoc analysis and reporting requests from field and office teams
 * Document reporting processes and data sources to ensure transparency and repeatability
 * Identify opportunities to improve reporting workflows and automate repetitive tasks
   
   

Required Qualifications


 * Bachelor’s degree in Engineering, Computer Science, Data Analytics, or related field – or equivalent professional experience
 * At least seven (7+) years of experience in data reporting or analytics roles within upstream oil & gas
 * Expert-level proficiency in Spotfire and SQL
 * Strong working knowledge of Python for data analysis and scripting
 * Familiarity with upstream operations workflows and terminology
 * Experience working with IFS, Peloton and SCADA Systems
 * Experience building operational dashboards for field and executive audiences
   
   

Work Authorization

Diamondback Energy is not currently sponsoring employment visas for this position.

Diamondback is an Equal Employment Opportunity Employer. Diamondback provides equal employment opportunities to all qualified applicants without regard to race, sex, sexual orientation, gender identity, national origin, color, age, religion, veteran or disability status, genetic information, pregnancy, or any other status protected by law. Diamondback participates in E-Verify. Learn more about E-Verify.","59 applicants","Full-time","Mid-Senior level","Project Management and Information Technology","Oil and Gas","","","","135579","https://diamondbackenergy.wd12.myworkdayjobs.com/DBE/job/Midland-TX/Operations-Data-Advisor_R100437-1?source=LinkedIn","EXTERNAL",""
"Data Analyst","All, MO","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/data-analyst-at-city-of-new-york-4347694717?trk=public_jobs_topcard-title","City of New York","https://www.linkedin.com/company/city-of-new-york?trk=public_jobs_topcard-org-name","The Department of Sustainable Delivery (DSD) is a new division within the NYC Department of Transportation (DOT), launched in 2025 to respond to the rapid growth of app-based delivery and the widespread use of micromobility devices on city streets. As these vehicles become more common for both personal and commercial use, DSD is responsible for ensuring they are used safely, legally, and in ways that support the City’s broader transportation and climate goals. DSD employs a multifaceted approach combining data analytics, policy, enforcement, education, and industry oversight to reduce crashes and conflicts on city streets. Its mission is to bring structure, clarity, and safety to the city’s evolving micromobility landscape, ensuring these vehicles are integrated responsibly into the urban environment.

DOT seeks a Data Analyst to support DSD in designing and executing data-driven research, and in building and maintaining the data infrastructure that supports research, policy, and operational decision-making.

In addition to processing and analyzing diverse datasets related to transportation and delivery, this position will design, implement, and optimize data pipelines; develop and maintain data ingestion, validation, and transformation processes; and integrate new data sources into DOT’s data ecosystem.

Under the direction and supervision of the Executive Director for Sustainable Delivery Policy, the Data Analyst will:


 * Provide analytical support for research projects, legislation, studies, and reports.
 * Create data visualizations and dashboards to communicate findings to internal and external stakeholders.
 * Design, build, and maintain scalable data pipelines for large and complex datasets, ensuring high data quality, integrity, and availability.
 * Coordinate solutions for ingesting and processing third-party data feeds, including establishing data validation and quality-control processes.
 * Collaborate with IT and analytics teams to design and optimize cloud-based infrastructure for storage, processing, and analytics (e.g., Microsoft Azure, Snowflake)
 * Work with Power BI, Python, SQL, and/or other tools to transform raw data into usable formats for dashboards, reports, and analysis.
 * Document data flows, business logic, and technical processes to support data governance and reproducibility.
 * Support DSD and the Analytics, Performance, and Management unit with analytical requests, system integrations, and the development of internal data standards.
   
   

IT AUTOMATION AND MONITORING E - 95712

Minimum Qualifications


 * A baccalaureate degree in computer science, engineering or a related field from an accredited college and four years of satisfactory full-time experience related to IT automation engineering, monitoring engineering, management of infrastructure; or
 * Eight years of satisfactory full-time experience related to IT automation engineering, monitoring engineering, management of infrastructure;
 * Education and/or experience which is equivalent to ""1"" or ""2"" above.
   
   

Preferred Skills


 * Demonstrated ability to synthesize data findings into clear, actionable insights for policy development, program design, or performance evaluation. - Strong programming skills in Python (experience with libraries such as Pandas, Polars, or Django) and SQL (Snowflake, SQL Server, Oracle). - Experience with cloud services such as Microsoft Azure (Data Factory, DevOps) or similar platforms. - Ability to design, implement, and optimize data pipelines for large, complex datasets. - Experience with business intelligence tools (e.g., Microsoft Power BI, Tableau) for dashboard development and KPI reporting. - Strong MS Excel skillset. - Familiarity with geospatial data and mapping tools (e.g., QGIS, ArcGIS). - Strong communication skills (oral and written) and the ability to collaborate across technical and non-technical teams.
   
   

Public Service Loan Forgiveness

As a prospective employee of the City of New York, you may be eligible for federal loan forgiveness programs and state repayment assistance programs. For more information, please visit the U.S. Department of Education’s website at https://studentaid.gov/pslf/.

Residency Requirement

New York City Residency is not required for this position

Additional Information

The City of New York is an inclusive equal opportunity employer committed to recruiting and retaining a diverse workforce and providing a work environment that is free from discrimination and harassment based upon any legally protected status or protected characteristic, including but not limited to an individual's sex, race, color, ethnicity, national origin, age, religion, disability, sexual orientation, veteran status, gender identity, or pregnancy.

, $75,000.00 – $140,000.00","Over 200 applicants","Full-time","Entry level","Information Technology","Government Administration","","","","2904","https://www.linkedin.com/jobs/view/data-analyst-at-city-of-new-york-4347694717?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Dearborn, MI","6 days ago","2025-11-26","https://www.linkedin.com/jobs/view/data-engineer-at-stefanini-north-america-and-apac-4339104222?trk=public_jobs_topcard-title","Stefanini North America and APAC","https://br.linkedin.com/company/stefanini-na-apac?trk=public_jobs_topcard-org-name","Details:

Job Description

Stefanini Group is hiring!

Stefanini is looking for a Senior Data Engineer Dearborn, MI (Onsite)

For quick apply, please reach out Fardeen Ali at 248-582-6473/fardeen.ali2@stefanini.com

You are responsible for designing, building, and maintaining data solutions including data infrastructure, pipelines, etc. for collecting, storing, processing and analyzing large volumes of data efficiently and accurately.

Responsibilities


 * Collaborate with business and technology stakeholders to understand current and future data requirements
 * Design, build and maintain reliable, efficient and scalable data infrastructure for data collection, storage, transformation, and analysis
 * Plan, design, build and maintain scalable data solutions including data pipelines, data models, and applications for efficient and reliable data workflow
 * Design, implement and maintain existing and future data platforms like data warehouses, data lakes, data lakehouse etc. for structured and unstructured data
 * Design and develop analytical tools, algorithms, and programs to support data engineering activities like writing scripts and automating tasks
 * Ensure optimum performance and identify improvement opportunities
   
   

Job Requirements

Details:

Experience Required


 * 5+ years of experience in Data Engineering
 * Experience with GCP (Google Cloud Platform)
 * Strong experience with Python
 * Expertise with SQL
   
   

Experience Preferred


 * 5+ years of experience in the automotive industry, particularly in auto remarketing and sales
 * Master's degree in a relevant field (e.g., Computer Science, Data Science, Engineering)
 * Proven ability to thrive in dynamic environments, managing multiple priorities and delivering high-impact results even with limited information
 * Exceptional problem-solving skills, a proactive and strategic mindset, and a passion for technical excellence and innovation in data engineering
 * Demonstrated commitment to continuous learning and professional development
 * Familiarity with machine learning libraries, such as TensorFlow, PyTorch, or Scikit-learn
 * Experience with MLOps tools and platforms
   
   

Education Required:


 * Bachelor's Degree
 * Listed salary ranges may vary based on experience, qualifications, and local market. Also, some positions may include bonuses or other incentives***
   
   

Stefanini takes pride in hiring top talent and developing relationships with our future employees. Our talent acquisition teams will never make an offer of employment without having a phone conversation with you. Those face-to-face conversations will involve a description of the job for which you have applied. We also speak with you about the process, including interviews and job offers.

About Stefanini Group

The Stefanini Group is a global provider of offshore, onshore and near shore outsourcing, IT digital consulting, systems integration, application, and strategic staffing services to Fortune 1000 enterprises around the world. Our presence is in countries like the Americas, Europe, Africa, and Asia, and more than four hundred clients across a broad spectrum of markets, including financial services, manufacturing, telecommunications, chemical services, technology, public sector, and utilities. Stefanini is a CMM level 5, IT consulting company with a global presence. We are a CMM Level 5 company.

","188 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","","Lokesh Kumar Sharma","https://www.linkedin.com/in/lokeshk-s","1279359","https://www.linkedin.com/jobs/view/data-engineer-at-stefanini-north-america-and-apac-4339104222?trk=public_jobs_topcard-title","EASY_APPLY",""
"Software Engineer, Infrastructure - Analytics","San Francisco, CA","3 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/software-engineer-infrastructure-analytics-at-openai-4339922607?trk=public_jobs_topcard-title","OpenAI","https://www.linkedin.com/company/openai?trk=public_jobs_topcard-org-name","About The Team

The Scaling team designs, builds, and operates critical infrastructure that enables research at OpenAI.

Our mission is simple: accelerate the progress of research towards AGI. We do this by building core systems that researchers rely on - ranging from low-level infrastructure components to research-facing custom applications. These systems must scale with the increasing complexity and size of our workloads, while remaining reliable and easy to use.

About The Role

As we grow, we’re looking for a pragmatic and versatile software engineer who thrives in fast-moving environments and enjoys building systems that empower others.

This is a generalist software engineering role with an emphasis on distributed systems, data processing infrastructure, and operational excellence. You’ll develop and operate foundational backend services that power key OpenAI’s research workflows - both by creating new infrastructure and by building on existing systems. The use cases will span across observability, analytics, performance engineering, and other domains, all with the goal of solving meaningful and impactful problems to research.

This role is based in San Francisco, CA or open to being remote within the US. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.

In This Role, You Will


 * Design, build, and operate scalable backend systems that support various ML research workflows, including observability and analytics.
 * Develop reliable infrastructure that supports both streaming and batch data processing at scale.
 * Creating internal-facing tools and applications as needed.
 * Debug and improve performance of services running on Kubernetes, including operational tooling and observability.
 * Collaborate with engineers and researchers to deliver reliable systems that meet real-world needs in production.
 * Help improve system reliability by participating in the on-call rotation and responding to critical incidents.
   
   

You Might Thrive In This Role If You Have


 * Strong proficiency in Python/Rust and backend software development, ideally in large codebases.
 * Experience with distributed systems and scalable data processing infrastructure, including technologies like Kafka, Spark, Trino/Presto, Iceberg.
 * Hands-on experience operating services in Kubernetes, with familiarity in tools like Terraform and Helm.
 * Comfort working across the stack - from low-level infrastructure components to application logic - and making trade-offs to move quickly.
 * A focus on building systems that are both technically sound and easy for others to use.
 * Curiosity and adaptability in fast-changing environments, especially in high-growth orgs.
   
   

About OpenAI

OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.

We are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.

For additional information, please see OpenAI’s Affirmative Action and Equal Employment Opportunity Policy Statement.

Background checks for applicants will be administered in accordance with applicable law, and qualified applicants with arrest or conviction records will be considered for employment consistent with those laws, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act, for US-based candidates. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.

To notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.

We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.

OpenAI Global Applicant Privacy Policy

At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.

Compensation Range: $310K - $460K","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Research Services","$310,000.00/yr - $460,000.00/yr","","","11130470","https://jobs.ashbyhq.com/openai/d169ecba-8366-485b-bc53-11a01d408b2d/application","EXTERNAL",""
"Data Engineer","Ridgefield, CT","3 weeks ago","2025-11-06","https://www.linkedin.com/jobs/view/data-engineer-at-veracity-software-inc-4337789540?trk=public_jobs_topcard-title","Veracity Software Inc","https://www.linkedin.com/company/veracitysoftwareinc?trk=public_jobs_topcard-org-name","Location: Ridgefield, Connecticut, United States

Work Arrangement: Flexible work-from-home days (onsite 2-3x per week)

Openings: 2

Step into the future with our Enterprise Data, AI & Platforms (EDP) team! At our company, we harness Data & AI to transform healthcare, positively impacting the lives of millions of patients and animals. As part of the EDP team, you will contribute to building a strong data-driven culture, drive key data transformation initiatives, and shape the future of decision-making across our global organization.

We are seeking a highly skilled and experienced Data Engineer to design, build, and maintain scalable data infrastructure on a cloud platform. You will be responsible for data pipelines, ETL processes, and overall data architecture strategy, ensuring data availability, quality, and integrity for business stakeholders and analytics teams.

Key Responsibilities:


 * Design, develop, and maintain scalable data pipelines and ETL/ELT processes.
 * Collaborate with data architects, modelers, IT, and business stakeholders to define and evolve cloud-based data architecture.
 * Optimize data storage solutions (e.g., S3, Snowflake, Redshift), ensuring data integrity, security, and accessibility.
 * Implement data quality, validation processes, and monitoring frameworks.
 * Maintain documentation for data workflows, architecture, and pipeline processes.
 * Troubleshoot and optimize data pipeline performance.
 * Engage with clients and stakeholders to analyze requirements and recommend data solutions.
 * Stay current with emerging technologies and industry trends in cloud and data engineering.
   
   

Requirements:

Data Engineer:


 * Associate degree in Computer Science/MIS (4+ years experience) or Bachelor's (2+ years) or Master's (1+ year) in related field.
 * Hands-on experience with AWS services (Glue, Lambda, Athena, Step Functions, Lake Formation).
 * Proficiency in Python and SQL.
 * Familiarity with DevOps/CI/CD principles and project lifecycle methodologies.
 * Moderate knowledge of cloud platforms (AWS, Azure, GCP) and data integration concepts.
   
   

Senior Data Engineer:


 * Associate degree (8+ years experience) or Bachelor's (4+ years) or Master's (2+ years) in relevant field.
 * Expert-level experience in cloud platforms, preferably AWS.
 * Advanced SQL skills, data modeling, and data warehousing concepts (Kimball, star/snowflake schemas).
 * Experience with big data frameworks (Spark, Hadoop, Flink) and relational/NoSQL databases.
 * Hands-on experience with ETL/ELT tools (Airflow, dbt, AWS Glue).
 * Knowledge of DevOps/CI/CD for data solutions.
   
   

Desired Skills & Abilities:


 * 4+ years of progressive data engineering experience with cloud-based data platforms.
 * Understanding of data governance, data quality, and metadata management.
 * Familiarity with Snowflake and dbt (data build tool).
 * Strong problem-solving skills in pipeline troubleshooting and optimization.
 * AWS Solutions Architect certification is a plus.
   
   

Technical Skills (Required):


 * AWS services: Glue, Lambda, Athena, Step Functions, Lake Formation
 * Programming Languages: Python, SQL","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","11137552","https://www.linkedin.com/jobs/view/data-engineer-at-veracity-software-inc-4337789540?trk=public_jobs_topcard-title","EASY_APPLY",""
"Business Development Manager","Phoenix, AZ","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/business-development-manager-at-round-peg-solutions-rps-4338940949?trk=public_jobs_topcard-title","Round-Peg Solutions (RPS)","https://uk.linkedin.com/company/round-peg-solutions-rps-?trk=public_jobs_topcard-org-name","We are seeking a talented Program Manager or Technical Sales individual to join a team of passionate engineers/ program managers turned Sales in targeting niche engineering teams within aerospace.




Job Summary of the Business Development Manager:




As a Business Development Manager, you will lead strategic growth efforts by identifying and securing new opportunities with niche high-value customers in aerospace, defense, and industrial markets. You’ll build long-term partnerships by going to trade shows, visiting client teams or responding to RFI's / RFQ's. You will take ownership of the full sales cycle, including contracts, and pricing, after winning the bid you will be an advocate for the customer to internal teams.




The progression in the role is dependant on your success- not tenure, the next stage is Business manager, there are lucrative stock options at the Senior Level, which divest in 3-5 years which compensate extremely well.




Key Qualifications of the Business Development Manager:




 * Engineering degree (any kind)
 * Customer focused experience in any technical manufacturing industry
 * Strong skills in customer negotiation, strategic selling, and contract development
 * Eligible to work with ITAR-regulated data (U.S. person or eligible for authorization)
 * Willingness to travel up to 40% (varies)




What the Business Development Manager will bring:

 * A strategic mindset with an eye for identifying growth opportunities- like keeping up with the news, the market etc.
 * Passion for engineering, this company have exciting avionic products, they have a team that reflects that excitement
 * A self-starter approach, comfortable managing complex, high-value opportunities
 * Desire to grow into a leadership role with P&L and operational responsibilities
 * Able to work autonomously with minimal hand holding, you still have guidance as the entire Business Unit will sit next to you, but they need a self starter
 * No red tape or bureaucracy







Benefits of the Business Development Manager Opportunity:

 * Clear and structured career progression based on merit not tenure
 * Lucrative stock options available at the Senior Exec level
 * You sit with the Business unit in an open plan setting, the Business Unit guides progress in this company
 * Opportunity to work with cutting-edge aerospace and defense technologies
 * Compensation: $125K–$145K base + 15% bonus
 * Relocation: One-time assistance of $5K available




If you’re ready to turn your sales acumen into a long-term leadership opportunity in a high-impact aerospace organization, please get in touch with our consultant Rabeel Imrane; Rabeel.imrane@rps-recruitment.com for a confidential search.




All candidates with relevant experience will be contacted within 24 hours.","55 applicants","Full-time","Mid-Senior level","Sales, Project Management, and Engineering","Aviation and Aerospace Component Manufacturing, Airlines and Aviation, and Defense and Space Manufacturing","$125,000.00/yr - $145,000.00/yr","Rabeel Imrane","https://www.linkedin.com/in/rabeel-imrane-991832176","18018258","https://www.linkedin.com/jobs/view/business-development-manager-at-round-peg-solutions-rps-4338940949?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)"
"Business Intelligence Analyst","Overland Park, KS","1 day ago","2025-12-01","https://www.linkedin.com/jobs/view/business-intelligence-analyst-at-lucky-orange-4348074468?trk=public_jobs_topcard-title","Lucky Orange","https://www.linkedin.com/company/lucky-orange?trk=public_jobs_topcard-org-name","Do you thrive on transforming complex data into a clear and compelling story? Are you ready to apply creativity and deep attention to detail to solve the toughest business and SaaS product challenges? 

If you’re driven to empower teams through data storytelling to have a real impact on business growth, then we’d love for you to join our team. 

We’re seeking a data and product analyst to join our growing team. This is a challenging role where you’ll design, build and deploy the data infrastructure that powers our decision-making. You’ll uncover crucial insights into customer usage patterns of our flagship product, Lucky Orange, and directly influence strategic business and product decisions. Success in this role requires an analytical mindset, extreme attention to detail and the creative vision to expand on existing data systems to engineer new data management and visualization platforms. 

At Lucky Orange, we help people make sense of the data fog surrounding website analytics. With our newly released Discovery AI, we surface website visitor behaviors that keep people from making a purchase or signing up. We go beyond the numbers provided in traditional website analytics platforms and give people actionable recommendations and visual proof to see exactly where people are getting stuck on their website. 

What’s a day in the life like?

Putting customers first is always our priority, but we’re known for having a relaxed, playful environment at Lucky Orange. On a typical day, you’ll find our team members helping customers, devising growth strategies, writing code and working with industry partners. 

As the newest data and product analyst on our team, your day will be spent executing on high-impact initiatives:

 * Architect and launch real-time business performance dashboards that deliver instant, actionable insights 
 * Analyzing large, complex datasets to identify patterns, trends and growth opportunities
 * Define and govern core business metrics, ensuring the data quality and integrity across the organization 
 * Using tools like SQL, Python, Looker and Jira to manage data and translate data into compelling narratives
 * Collaborate and consult with stakeholders across departments to identify and solve their most critical data needs
 * Investigate and determine the underlying root cause of fluctuations in business KPIs
 * Pioneer new data visualization and reporting methods to maximize data accessibility
 * Working out of our office in Overland Park, Kan. (This role is not eligible for a remote working arrangement.)

What does it take?

 * 4+ years of experience in business, data or product analytics roles
 * Experience using SQL, Python or similar tools to manage and extra insights from data
 * Experience with data visualization platforms such as Looker, PowerBI, Tableau, Databox, etc.
 * Attention to detail, especially when it comes to spotting errors and trends in data
 * Previous examples of dashboards, reports, etc., that show your ability to manage data and provide others with actionable insights
 * Ability to work in a (relaxed) office setting in Overland, Park, Kan., during typical working hours (9 a.m. - 5 p.m.), Monday through Friday.

How do I stand out from the rest of the pack?

 * Demonstrated experience building data management systems from the ground up
 * Familiarity with machine learning concepts, statistical methods and data engineering 
 * Bachelor’s degree in Data Analytics, Business, Computer Science or related field
 * Use or are familiar with Lucky Orange software or other conversion rate optimization (CRO) tools

What’s this gig pay?

 * Competitive salary plus quarterly bonuses

What about the extras?

 * Unlimited paid vacation/sick days
 * 401(k) plan with 4% employer match
 * 100 percent paid health insurance for employees
 * Fun company outings
 * No dress code
 * Quirky office environment with spontaneous and random challenges, video game battles and spirited debates on trivial topics 
 * Monthly “flex days” that allow you to choose where you want to work 
 * Company-sponsored lunches
 * Generous performance incentives
 * Company-sponsored vacations

Who is Lucky Orange?

Lucky Orange, located in Overland Park, Kan., started as a bootstrap analytics and usability software company and is now one of Kansas City’s hottest Software as a Service (SaaS) companies. For the seventh year running, we’ve also been recognized as one of Kansas City Business Journal’s “Best Places to Work.”

Our flagship product sheds new light on user behavior by allowing website owners a peek behind the digital curtain to watch recordings of users, engage with interactive heatmaps, see real-time analytics, provide exceptional support via live chat, analyze forms and create custom polls.

We think it’s a pretty stellar product, and so do our clients who have used Lucky Orange on more than half a million websites worldwide.

What matters the most at Lucky Orange?

We know that workplace culture defines a company. That’s why we had passionate discussions on the words we chose to articulate the Lucky Orange values: Moxie. Honesty. Delight. Creativity. Empathy. Motivation.

Our employees demonstrate these values through: 

 * Gritty, scrappy mentalities that dare to think innovatively and embrace new ideas and fresh approaches
 * Collaboration and respect for one another’s ideas
 *  Putting people first – our customers and our coworkers
 * Continuous improvement – pushing ourselves to constantly be better in our work and finding new opportunities to grow the company
 * Participating in a quarterly company-wide volunteer activity in support of our values

We look forward to working with you!

Lucky Orange is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, gender identity, sexual orientation, national origin, disability status, protected veteran status, or any other characteristic protected by law.","Be among the first 25 applicants","Full-time","Mid-Senior level","Sales, General Business, and Education","Wireless Services, Telecommunications, and Communications Equipment Manufacturing","","","","2936827","https://app.jazz.co/apply/job/1rDnZiZIxj?source=LINKR&source=LINK&source=LINKEDIN&source=LinkedIn&src=Linkedin&gh_src=fa1195541us&LinkedIn=LinkedIn&source=LINK&source=LinkedIn","EXTERNAL",""
"Software Engineer II, Data Engineering","San Francisco, CA","2 weeks ago","2025-11-13","https://www.linkedin.com/jobs/view/software-engineer-ii-data-engineering-at-doordash-4092899847?trk=public_jobs_topcard-title","DoorDash","https://www.linkedin.com/company/doordash?trk=public_jobs_topcard-org-name","About The Team

Data is at the foundation of DoorDash success. The Data Engineering team builds database solutions for various use cases including reporting, product analytics, marketing optimization and financial reporting. By implementing pipelines, data structures, and data warehouse architectures; this team serves as the foundation for decision-making at DoorDash.

About The Role

DoorDash is looking for a Softare Engineer II to be a technical powerhouse to help us scale our data infrastructure, automation and tools to meet growing business needs.

You're excited about this opportunity because you will…


 * Work with business partners and stakeholders to understand data requirements
 * Work with engineering, product teams and 3rd parties to collect required data
 * Design, develop and implement large scale, high volume, high performance data models and pipelines for Data Lake and Data Warehouse
 * Develop and implement data quality checks, conduct QA and implement monitoring routines
 * Improve the reliability and scalability of our ETL processes
 * Manage a portfolio of data products that deliver high-quality, trustworthy data
 * Help onboard and support other engineers as they join the team
   
   

We're excited about you because…


 * 3+ years of professional experience working in data engineering, business intelligence, or a similar role
 * Proficiency in programming languages such as Python/Java
 * 3+ years of experience in ETL orchestration and workflow management tools like Airflow, Flink, Oozie and Azkaban using AWS/GCP
 * Expert in Database fundamentals, SQL and distributed computing
 * 3+ years of experience with the Distributed data/similar ecosystem (Spark, Hive, Druid, Presto) and streaming technologies such as Kafka/Flink.
 * Experience working with Snowflake, Redshift, PostgreSQL and/or other DBMS platforms
 * Excellent communication skills and experience working with technical and non-technical teams
 * Knowledge of reporting tools such as Tableau, Superset and Looker
 * Comfortable working in fast paced environment, self starter and self organizing
 * Ability to think strategically, analyze and interpret market and consumer information
 * You must be located near one of our engineering hubs indicated above
   
   

We use Covey as part of our hiring and / or promotional process for jobs in NYC and certain features may qualify it as an AEDT. As part of the evaluation process we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound on August 21, 2023.

Please see the independent bias audit report covering our use of Covey here.

Compensation

The successful candidate's starting pay will fall within the pay range listed below and is determined based on job-related factors including, but not limited to, skills, experience, qualifications, work location, and market conditions. Base salary is localized according to an employee’s work location. Ranges are market-dependent and may be modified in the future.

In addition to base salary, the compensation for this role includes opportunities for equity grants. Talk to your recruiter for more information.

DoorDash cares about you and your overall well-being. That’s why we offer a comprehensive benefits package to all regular employees, which includes a 401(k) plan with employer matching, 16 weeks of paid parental leave, wellness benefits, commuter benefits match, paid time off and paid sick leave in compliance with applicable laws (e.g. Colorado Healthy Families and Workplaces Act). DoorDash also offers medical, dental, and vision benefits, 11 paid holidays, disability and basic life insurance, family-forming assistance, and a mental health program, among others.

To learn more about our benefits, visit our careers page here.

See Below For Paid Time Off Details


 * For salaried roles: flexible paid time off/vacation, plus 80 hours of paid sick time per year.
 * For hourly roles: vacation accrued at about 1 hour for every 25.97 hours worked (e.g. about 6.7 hours/month if working 40 hours/week; about 3.4 hours/month if working 20 hours/week), and paid sick time accrued at 1 hour for every 30 hours worked (e.g. about 5.8 hours/month if working 40 hours/week; about 2.9 hours/month if working 20 hours/week).
   
   

The national base pay ranges for this position within the United States, including Illinois and Colorado.

I4

$130,600—$192,000 USD

I5

$159,800—$235,000 USD

I6

$193,800—$285,000 USD

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

Our Commitment to Diversity and Inclusion

We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on “protected categories,” we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.

Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.

If you need any accommodations, please inform your recruiting contact upon initial connection.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","","","","3205573","https://www.linkedin.com/jobs/view/software-engineer-ii-data-engineering-at-doordash-4092899847?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Pittsburgh, PA","3 weeks ago","2025-11-05","https://www.linkedin.com/jobs/view/data-engineer-at-bloomfield-4337922004?trk=public_jobs_topcard-title","Bloomfield","https://www.linkedin.com/company/bloomfield-ai?trk=public_jobs_topcard-org-name","About the Company

Bloomfield is a Carnegie Mellon spinout creating a global platform shaping the future of precision agriculture. We scan farms and vineyards at scale (capturing high-resolution imagery and other sensor data), analyze every plant, and derive actionable intelligence to help growers be more efficient and productive. We collaborate with various movement platform companies, from ATV and tractor manufacturers to robotics startups.

About the Role

Our rapidly growing engineering team is searching for a Data Engineer to help build and maintain our data and image processing pipelines. You will be responsible for designing, implementing, and maintaining the various components of our pipelines, which need to support processing more than 75k images per day. You will be involved in all parts of the data engineering lifecycle, including data generation, ingestion, transformation, storage, and serving of our data.

To be successful in this role, you should have a strong background in software engineering and be proficient in Python. Familiarity with AWS technologies such as Lambdas, Step Functions, Redshift, S3, Athena, and Glue is a big plus.

As a Data Engineer, you will be a part of our engineering team, working to ensure that our data ecosystem is efficient, scalable, and able to support our rapidly growing data needs. You will be responsible for ensuring that the data is cleaned, processed, and transformed appropriately to support our data analytics and machine learning efforts.

Responsibilities 

 * Designing, implementing, and maintaining our data pipeline, including data generation, ingestion, transformation, and serving
 * Ensuring the reliability, security, and performance of the data pipelines
 * Troubleshooting and debugging any issues with our data pipelines
 * Working with other engineers  to understand their data needs and ensure that our data ecosystem can support their requirements
 * Optimizing the data pipeline for efficiency, scalability, and reliability
 * Developing and maintaining documentation for the data pipeline

Qualifications

 * Bachelor's or Master's degree in Computer Science, Engineering, or a related field
 * 5+ years of experience as a Data Engineer or a similar role
 * Strong proficiency in Python, Pandas, and SQL
 * Experience with AWS technologies such as Lambdas, Step Functions, Redshift, S3, Athena, Glue, and Kinesis
 * Familiarity with data cleaning, processing, and analytics of image data
 * Strong problem-solving and troubleshooting skills
 * Excellent communication and collaboration abilities.

What We Offer

In addition to the opportunity to apply and develop your skills toward key business objectives, we offer an excellent compensation package including:

 * Competitive base salary
 * Medical, dental and vision insurance
 * 401(k) retirement plan with company match
 * Unlimited PTO 
 * Parental Leave 
 * Incentive stock options

Bloomfield is an equal opportunity employer. We consider qualified applicants without regard to race, color, religion, sex, national origin, sexual orientation, disability, gender identity, protected veteran status, or other protected classes.

In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.","Be among the first 25 applicants","Full-time","Entry level","Sales, General Business, and Education","Wireless Services, Telecommunications, and Communications Equipment Manufacturing","","","","27226585","https://www.linkedin.com/jobs/view/data-engineer-at-bloomfield-4337922004?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Ridgefield, CT","3 weeks ago","2025-11-06","https://www.linkedin.com/jobs/view/data-engineer-at-veracity-software-inc-4337948890?trk=public_jobs_topcard-title","Veracity Software Inc","https://www.linkedin.com/company/veracitysoftwareinc?trk=public_jobs_topcard-org-name","Data Engineer

Location: Ridgefield, Connecticut, United States

Work Arrangement: Flexible work-from-home days (onsite 2-3x per week)

Openings: 2

Step into the future with our Enterprise Data, AI & Platforms (EDP) team! At our company, we harness Data & AI to transform healthcare, positively impacting the lives of millions of patients and animals. As part of the EDP team, you will contribute to building a strong data-driven culture, drive key data transformation initiatives, and shape the future of decision-making across our global organization.

We are seeking a highly skilled and experienced Data Engineer to design, build, and maintain scalable data infrastructure on a cloud platform. You will be responsible for data pipelines, ETL processes, and overall data architecture strategy, ensuring data availability, quality, and integrity for business stakeholders and analytics teams.

Key Responsibilities:


 * Design, develop, and maintain scalable data pipelines and ETL/ELT processes.
 * Collaborate with data architects, modelers, IT, and business stakeholders to define and evolve cloud-based data architecture.
 * Optimize data storage solutions (e.g., S3, Snowflake, Redshift), ensuring data integrity, security, and accessibility.
 * Implement data quality, validation processes, and monitoring frameworks.
 * Maintain documentation for data workflows, architecture, and pipeline processes.
 * Troubleshoot and optimize data pipeline performance.
 * Engage with clients and stakeholders to analyze requirements and recommend data solutions.
 * Stay current with emerging technologies and industry trends in cloud and data engineering.
   
   

Requirements:

Data Engineer:


 * Associate degree in Computer Science/MIS (4+ years experience) or Bachelor's (2+ years) or Master's (1+ year) in related field.
 * Hands-on experience with AWS services (Glue, Lambda, Athena, Step Functions, Lake Formation).
 * Proficiency in Python and SQL.
 * Familiarity with DevOps/CI/CD principles and project lifecycle methodologies.
 * Moderate knowledge of cloud platforms (AWS, Azure, GCP) and data integration concepts.
   
   

Senior Data Engineer:


 * Associate degree (8+ years experience) or Bachelor's (4+ years) or Master's (2+ years) in relevant field.
 * Expert-level experience in cloud platforms, preferably AWS.
 * Advanced SQL skills, data modeling, and data warehousing concepts (Kimball, star/snowflake schemas).
 * Experience with big data frameworks (Spark, Hadoop, Flink) and relational/NoSQL databases.
 * Hands-on experience with ETL/ELT tools (Airflow, dbt, AWS Glue).
 * Knowledge of DevOps/CI/CD for data solutions.
   
   

Desired Skills & Abilities:


 * 4+ years of progressive data engineering experience with cloud-based data platforms.
 * Understanding of data governance, data quality, and metadata management.
 * Familiarity with Snowflake and dbt (data build tool).
 * Strong problem-solving skills in pipeline troubleshooting and optimization.
 * AWS Solutions Architect certification is a plus.
   
   

Technical Skills (Required):


 * AWS services: Glue, Lambda, Athena, Step Functions, Lake Formation
 * Programming Languages: Python, SQL","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","11137552","https://www.linkedin.com/jobs/view/data-engineer-at-veracity-software-inc-4337948890?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI Engineer","New York, NY","3 weeks ago","2025-11-10","https://www.linkedin.com/jobs/view/ai-engineer-at-oscar-4339732393?trk=public_jobs_topcard-title","Oscar","https://uk.linkedin.com/company/oscar?trk=public_jobs_topcard-org-name","AI Engineer - Healthcare Automation Platform



Well-Funded Startup | Healthcare AI | Hybrid (NYC preferred) or Remote



About Us



We're building an AI-powered automation platform that streamlines critical workflows in healthcare operations. Our system processes complex, unstructured data to ensure time-sensitive information gets where it needs to go-reducing delays and improving operational efficiency for healthcare providers.

We're in production with paying enterprise customers and experiencing rapid growth.



The Role



We're looking for a high-agency AI Engineer to bridge the gap between cutting-edge ML research and real-world product delivery. You'll design and build agentic workflows that automate complex operational processes, combining LLMs, vision models, and structured automation to solve challenging infrastructure and workflow problems.

This role involves creating pipelines, evaluation harnesses, and scalable production-grade agents. You'll research and implement the best-fit technology for each workflow, working across the full stack from data collection to orchestration to frontend integration.



What You'll Build


 * Ship full-stack AI systems end-to-end-from prototype to production
 * Build observability and debugging tools to capture model performance, user feedback, and edge cases
 * Go from ideation to working code within hours; iterate rapidly on experiments and data
 * Design agentic workflows powered by LLMs and vision models for document understanding
 * Create evaluation frameworks to test AI system performance beyond raw model accuracy
 * Work directly with cross-functional teams (ML, Sales, Customer Success) to build AI solutions for diverse use cases
   
   

What We're Looking For


 * Full-stack engineering experience with web frameworks, backend systems, and cloud infrastructure
 * Proven track record of building, testing, deploying, scaling, and monitoring LLM-centered software architectures
 * Hands-on expertise with LLM APIs and production AI system deployment
 * Understanding of how to evaluate AI systems holistically-beyond model accuracy alone
 * Strong communication skills-ability to write clear technical documentation and explain complex systems
 * Bonus: Experience in healthcare or working with unstructured documents
   
   

Why Join Us?


 * Drive Impact: High-agency culture where you set the pace and see direct results
 * Own Your Work: End-to-end ownership from research to production deployment
 * Innovate with Purpose: Join a high-caliber team solving real problems at scale
 * Competitive Package: $200K-$240K + equity + comprehensive benefits
 * Great Perks: Unlimited PTO, 100% paid health benefits, 401(k) match, catered lunch, snacks

Location: NYC office 4 days/week preferred (Chelsea), remote considered for exceptional candidates


Desired Skills and Experience

AI Engineer - Healthcare Automation Platform
Well-Funded Startup | Healthcare AI | Hybrid (NYC preferred) or Remote
About Us
We're building an AI-powered automation platform that streamlines critical workflows in healthcare operations. Our system processes complex, unstructured data to ensure time-sensitive information gets where it needs to go-reducing delays and improving operational efficiency for healthcare providers.
We're in production with paying enterprise customers and experiencing rapid growth.
The Role
We're looking for a high-agency AI Engineer to bridge the gap between cutting-edge ML research and real-world product delivery. You'll design and build agentic workflows that automate complex operational processes, combining LLMs, vision models, and structured automation to solve challenging infrastructure and workflow problems.
This role involves creating pipelines, evaluation harnesses, and scalable production-grade agents. You'll research and implement the best-fit technology for each workflow, working across the full stack from data collection to orchestration to frontend integration.
What You'll Build

Ship full-stack AI systems end-to-end-from prototype to production
Build observability and debugging tools to capture model performance, user feedback, and edge cases
Go from ideation to working code within hours; iterate rapidly on experiments and data
Design agentic workflows powered by LLMs and vision models for document understanding
Create evaluation frameworks to test AI system performance beyond raw model accuracy
Work directly with cross-functional teams (ML, Sales, Customer Success) to build AI solutions for diverse use cases

What We're Looking For

Full-stack engineering experience with web frameworks, backend systems, and cloud infrastructure
Proven track record of building, testing, deploying, scaling, and monitoring LLM-centered software architectures
Hands-on expertise with LLM APIs and production AI system deployment
Understanding of how to evaluate AI systems holistically-beyond model accuracy alone
Strong communication skills-ability to write clear technical documentation and explain complex systems
Bonus: Experience in healthcare or working with unstructured documents

Why Join Us?

Drive Impact: High-agency culture where you set the pace and see direct results
Own Your Work: End-to-end ownership from research to production deployment
Innovate with Purpose: Join a high-caliber team solving real problems at scale
Competitive Package: $200K-$240K + equity + comprehensive benefits
Great Perks: Unlimited PTO, 100% paid health benefits, 401(k) match, catered lunch, snacks

Location: NYC office 4 days/week preferred (Chelsea), remote considered for exceptional candidates



Oscar Associates Limited (US) is acting as an Employment Agency in relation to this vacancy.","Over 200 applicants","Full-time","Mid-Senior level","Engineering","Hospitals and Health Care","$200,000.00/yr - $240,000.00/yr","","","64981","https://www.linkedin.com/jobs/view/ai-engineer-at-oscar-4339732393?trk=public_jobs_topcard-title","EASY_APPLY",""
"Product Development Eng.","Austin, TX","2 weeks ago","2025-11-12","https://www.linkedin.com/jobs/view/product-development-eng-at-amd-4339926049?trk=public_jobs_topcard-title","AMD","https://www.linkedin.com/company/amd?trk=public_jobs_topcard-org-name","WHAT YOU DO AT AMD CHANGES EVERYTHING

At AMD, our mission is to build great products that accelerate next-generation computing experiences—from AI and data centers, to PCs, gaming and embedded systems. Grounded in a culture of innovation and collaboration, we believe real progress comes from bold ideas, human ingenuity and a shared passion to create something extraordinary. When you join AMD, you’ll discover the real differentiator is our culture. We push the limits of innovation to solve the world’s most important challenges—striving for execution excellence, while being direct, humble, collaborative, and inclusive of diverse perspectives. Join us as we shape the future of AI and beyond. Together, we advance your career.

The Role

We are seeking a Product Development Engineer to make an immediate impact on our team. This role focuses on designing and delivering scalable data solutions, ensuring data quality, mentoring junior staff, and driving user adoption across AMD’s enterprise data ecosystem.

Key Responsibilities


 * Design and optimize data models for BI and analytics platforms (Snowflake, SQL Server, Databricks).
 * Apply modern data design principles such as Domain-Oriented Design, Logical and Physical Data Modeling, Federated Data Architecture, and Data Mesh Modeling.
 * Implement robust ETL/ELT pipelines using SQL, DBT, and Python.
 * Deliver end-to-end data solutions, from ingestion to visualization, ensuring scalability and performance.
 * Drive cloud migration initiatives and modernize legacy systems.
 * Establish and enforce data governance standards, data quality frameworks, and compliance processes.
 * Utilize tools like Alation for metadata management and data cataloging.
 * Build and maintain dashboards and reports in Power BI, ThoughtSpot, Sigma for operational and strategic insights.
 * Collaborate with business stakeholders to define KPIs and ensure actionable reporting.
 * Mentor junior staff and guide technical development across the BI team.
 * Track and record progress on multiple quarters initiatives aligned with the annual analytics roadmap.
 * Promote data literacy programs across business units to improve BI adoption.
 * Drive end-user self services BI program and change management for new data platforms and processes.
 * Work closely with IT and internal business partners to integrate BI solutions into enterprise systems.
 * Engage with senior leadership and cross-functional stakeholders to prioritize projects and communicate progress effectively.
 * Translate complex technical concepts into clear business value.
   
   
   

Preferred Experience


 * Proven experience in SQL, Python, and BI tools (Power BI, Tableau).
 * Expertise in data modeling, data governance, data quality, and data standards.
 * Strong experience with ETL frameworks, data warehousing, and cloud platforms (Azure, AWS).
 * Familiarity with modern data stack tools (DBT, Databricks) and principles.
 * Experience with Alation, Lightup or similar data catalog and quality tools.
 * Exceptional stakeholder management and communication skills.
 * Ability to lead small projects and mentor junior team members.
 * Strong aptitude for change management and driving user adoption.
   
   
   

Academic Credentials


 * BS, MS, or PhD in Computer Science, Data Engineering, or related field.
   
   
   

LOCATION:

Austin, TX

Benefits offered are described: AMD benefits at a glance.

AMD does not accept unsolicited resumes from headhunters, recruitment agencies, or fee-based recruitment services. AMD and its subsidiaries are equal opportunity, inclusive employers and will consider all applicants without regard to age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third-party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status, or any other characteristic protected by law. We encourage applications from all qualified candidates and will accommodate applicants’ needs under the respective laws throughout all stages of the recruitment and selection process.

","Over 200 applicants","Full-time","Mid-Senior level","Engineering","Semiconductor Manufacturing","$146,400.00/yr - $219,600.00/yr","Andrea Jenkins","https://www.linkedin.com/in/andrea-jenkins-12666159","1497","https://www.linkedin.com/jobs/view/product-development-eng-at-amd-4339926049?trk=public_jobs_topcard-title","EASY_APPLY",""
"Software Engineer II, Data Engineering & Infrastructure","Mountain View, CA","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/software-engineer-ii-data-engineering-infrastructure-at-aurora-4301392867?trk=public_jobs_topcard-title","Aurora","https://www.linkedin.com/company/auroradriver?trk=public_jobs_topcard-org-name","Who We Are

Aurora’s mission is to deliver the benefits of self-driving technology safely, quickly, and broadly.

The Aurora Driver will create a new era in mobility and logistics, one that will bring a safer, more efficient, and more accessible future to everyone.

At Aurora, you will tackle massively complex problems alongside other passionate, intelligent individuals, growing as an expert while expanding your knowledge. For the latest news from Aurora, visit aurora.tech or follow us on LinkedIn.

Aurora hires talented people with diverse backgrounds who are ready to help build a transportation ecosystem that will make our roads safer, get crucial goods where they need to go, and make mobility more efficient and accessible for all. We are seeking a talented and experienced Software Engineer to join our data engineering and infrastructure team. In this role, you will be a key contributor to the design, development, and maintenance of our data platform, building the scalable and reliable systems that enable our organization to leverage data for insights and product innovation. You will work on the core data lake and data warehouse ecosystem infrastructure, data pipelines, and tools that process data at massive scale, ensuring it is accessible, high-quality, and secure.

In this role, you will


 * Design, build, and maintain robust and scalable data pipelines and ETL/ELT processes to ingest, transform, and load data from various sources into our data warehouse.
 * Develop and manage data infrastructure components using AWS cloud services and infrastructure-as-code tools like Terraform.
 * Collaborate with data scientists, analysts, autonomy engineering teams and product teams to understand their data needs and build solutions that meet their requirements.
 * Optimize data processing systems for performance, reliability, and cost-efficiency.
 * Implement monitoring, alerting, and logging for data pipelines and infrastructure to ensure operational stability.
 * Champion best practices in data governance, data quality, and security.
   
   

Required Qualifications


 * Bachelor’s degree in Computer Science, Engineering, or a related field, or equivalent practical experience.
 * 3+ years of professional experience in software engineering, with a focus on data-related projects.
 * Proficiency in at least one programming language commonly used for data engineering (e.g., Python, Go or C++).
 * Solid experience with big data processing frameworks like Apache Spark, Flink, Kinesis Data Stream, or similar technologies.
 * Hands-on experience with cloud platforms (AWS, GCP, or Azure) and their data services (e.g., S3, Redshift, BigQuery, Glue).
 * Strong knowledge of SQL and experience working with relational and NoSQL databases.
 * Intermediate knowledge of data analytics infrastructure, including data transformation tools such as DBT and visualization frameworks and tools
 * Experience with building and managing data pipelines using an orchestrator like Apache Airflow.
 * Able to systematically approach open-ended questions to identify pragmatic data solutions that scale
 * Able to work effectively in a highly cross-functional, fast-moving and high-stakes environment
 * Proven ability to communicate technical, data-driven solutions to both technical and non-technical audiences across stakeholders
   
   

Desirable Qualifications


 * Experience with data warehousing solutions like Snowflake or data lake architectures.
 * Familiarity with modern data stack tools and practices.
 * A passion for building elegant, scalable, and maintainable systems.
 * Experience using Amazon Web Services (AWS) tools
   
   

The base salary wage range for this position is $139,000 - $223,000 per year. Aurora’s pay ranges are determined by role, level, and location. Within the range, the successful candidate’s starting base pay will be determined based on factors including job-related skills, experience, qualifications, relevant education or training, and market conditions. These ranges may be modified in the future. The successful candidate will also be eligible for an annual bonus, equity compensation, and benefits.

#Entry-Level

Working at Aurora

At Aurora, we bring together extraordinarily talented and experienced people united by the strength of our values. We operate with integrity, set outrageous goals, and build a culture where we win together — all without any jerks. Our Careers page provides insight into what it is like to work at Aurora, and you can find all the latest updates in our Newsroom.

Commitment to inclusion

Aurora considers candidates without regard to their race, color, religion, national origin, age, sex, gender, gender identity, gender expression, sexual orientation, marital status, pregnancy status, parent or caregiver status, ancestry, political affiliation, veteran and/or military status, physical or mental disability, or any other status protected by federal or state law. Aurora considers qualified applicants with criminal histories, consistent with applicable federal, state, and local law. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at careersiteaccommodations@aurora.tech.

For California applicants, information collected and processed as part of your application and any job applications you choose to submit is subject to Aurora’s California Employment Privacy Policy.

","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","$139,000.00/yr - $223,000.00/yr","","","17973173","https://aurora.tech/jobs/8171568002?gh_src=b6049de52us","EXTERNAL",""
"Data, AI & Automation Lead - Private-Equity","New York, NY","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/data-ai-automation-lead-private-equity-at-saragossa-4341824299?trk=public_jobs_topcard-title","Saragossa","https://uk.linkedin.com/company/saragossa?trk=public_jobs_topcard-org-name","Data, AI & Automation Lead

Significant opportunity to join a renowned Private Equity Fund based in New York to drive transformation through Data, AI & Automation.




You will be responsible for leading internal approaches to the use of RPA-related technologies, and acting as the organisation’s super-user for AI. You will be expected to drive the implementation and adoption of AI tools at the Fund, through key vendor partnerships.




You will have a data background across engineering, analytics or data science, knowledgeable and with a track record in AI & Automation.




Any experience in buyside financial services will be advantageous, or a regulated environment – but this is an opportunity to move into Private Equity.","80 applicants","Full-time","Mid-Senior level","Information Technology","Venture Capital and Private Equity Principals","$150,000.00/yr - $200,000.00/yr","Ryan Grant","https://www.linkedin.com/in/ryan-grant-1961aa9a","9215489","https://www.linkedin.com/jobs/view/data-ai-automation-lead-private-equity-at-saragossa-4341824299?trk=public_jobs_topcard-title","EASY_APPLY",""
"eCom Data Engineer Specialist","Purchase, NY","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/ecom-data-engineer-specialist-at-pepsico-4309293247?trk=public_jobs_topcard-title","PepsiCo","https://www.linkedin.com/company/pepsico?trk=public_jobs_topcard-org-name","Overview

PepsiCo operates in an environment undergoing immense and rapid change. Big data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences, and IoT. The key to winning in these areas is leveraging enterprise data foundations built on PepsiCo’s global business scale to enable business insights, advanced analytics, and new product development. PepsiCo’s Data Management and Operations team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations, and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.

Responsibilities

As a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and driving a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments, directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners, and business users. You'll be working in a hybrid environment with in-house, on-premise data sources, as well as cloud and remote systems.

Accountabilities:


 * Own data pipeline development end-to-end, spanning data modeling, testing, scalability, operability, and ongoing metrics.
 * Ensure that we build high-quality software by reviewing peer code check-ins.
 * Define best practices for product development, engineering, and coding as part of a world-class engineering team.
 * Collaborate in architecture discussions and architectural decision-making that is part of continually improving and expanding these platforms.
 * Lead feature development in collaboration with other engineers; validate requirements/stories, assess current system capabilities, and decompose feature requirements into engineering tasks.
 * Focus on delivering high-quality data pipelines and tools through careful analysis of system capabilities and feature requests, peer reviews, test automation, and collaboration with other engineers.
 * Develop software in short iterations to quickly add business value.
 * Introduce new tools/practices to improve data and code quality; this includes researching/sourcing 3rd party tools and libraries, as well as developing tools in-house to improve workflow and quality for all data engineers.
 * Support data pipelines developed by your team through good exception handling, monitoring, and, when needed by debugging production issues.
   
   

Compensation and Benefits:


 * The expected compensation range for this position is between $64,900 - $132,550.
 * Location, confirmed job-related skills, experience, and education will be considered in setting actual starting salary. Your recruiter can share more about the specific salary range during the hiring process.
 * A business development incentive equity may be awarded based on eligibility and performance.
 * Paid time off subject to eligibility, including paid parental leave, vacation, sick, and bereavement.
 * In addition to salary, PepsiCo offers a comprehensive benefits package to support our employees and their families, subject to elections and eligibility: Medical, Dental, Vision, Disability, Health, and Dependent Care Reimbursement Accounts, Employee Assistance Program (EAP), Insurance (Accident, Group Legal, Life), Defined Contribution Retirement Plan.
   
   

Qualifications


 * 4+ years of overall technology experience that includes at least 3+ years of hands-on software development, data engineering, and systems architecture.
 * 3+ years of experience in SQL optimization and performance tuning.
 * Experience with data modeling, data warehousing, and building high-volume ETL/ELT pipelines.
 * Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.
 * Experience with data profiling and data quality tools like Apache Griffin, Deequ, or Great Expectations.
   
   

Current skills in the following technologies:


 * Python
 * Orchestration platforms: Airflow, Luigi, Databricks, or similar.
 * Relational databases: Postgres, MySQL, or equivalents.
 * MPP data systems: Snowflake, Redshift, Synapse, or similar.
 * Cloud platforms: AWS, Azure, or similar.
 * Version control (e.g., GitHub) and familiarity with deployment, CI/CD tools.
 * Fluent with Agile processes and tools such as Jira or Pivotal Tracker.
 * Experience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes is a plus.
 * Understanding of metadata management, data lineage, and data glossaries is a plus.
   
   

EEO Statement

Our Company will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Credit Reporting Act, and all other applicable laws, including but not limited to, San Francisco Police Code Sections 4901-4919, commonly referred to as the San Francisco Fair Chance Ordinance; and Chapter XVII, Article 9 of the Los Angeles Municipal Code, commonly referred to as the Fair Chance Initiative for Hiring Ordinance.

All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.

PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender Identity / Age.

If you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.

Please view our Pay Transparency Statement.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Manufacturing and Food and Beverage Services","$64,900.00/yr - $132,550.00/yr","","","1431","https://www.linkedin.com/jobs/view/ecom-data-engineer-specialist-at-pepsico-4309293247?trk=public_jobs_topcard-title","EASY_APPLY",""
"Quantitative Data Engineer","Hartford, CT","21 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/quantitative-data-engineer-at-massmutual-4340193851?trk=public_jobs_topcard-title","MassMutual","https://www.linkedin.com/company/massmutual-financial-group?trk=public_jobs_topcard-org-name","Quantitative Research & Development Team

Full-Time

Springfield, MA or Boston, MA

The Opportunity

As a Quantitative Data Engineer you will work in a fast paced, innovative, and collaborative environment on exciting technology directives. A Quantitative Data Engineer embodies a unique combination of technical, business and people skills. Both emotional intelligence and the ability to solve complex problems and communicate effectively are key to success. Ideally, you have a strong background in Fixed Income data as well as workflow orchestration and CI/CD pipelines. Additionally, it is preferred that you have robust experience in cloud platforms and system architecture.

The Team

As aQuantitative Data Engineer, you will join the Quantitative Investment Platforms team, part of MassMutual’s Investment Management QRD organization. The Quantitative development team is comprised of highly skilled, financial industry savvy professionals who render collaborative and portfolio risk solutions to our portfolio managers. Team members demonstrate high levels of competence in the areas of resilience, accountability, agility, and are focused on continuous improvement and development. The team culture is collaborative, cross-functional, and fosters high performance results with an emphasis on encouraging a healthy work/life balance.

The Impact

Our ideal Quantitative Data Engineeris passionate about data and deploying solutions and workflow automations.


 * You enjoy building data projects from the ground up and are equally comfortable working with business partners to understand requirements as you are developing and delivering robust solutions that meet the highest standards. 
 * Learning new technologies and working in the cloud excite you. 
 * You are team-oriented and a strong communicator.
 * Design, build and maintain complex ELT jobs that deliver business value
 * Translate high-level business requirements into technical specs
 * Ingest data from disparate sources into the various data stores
 * Cleanse and enrich data and apply adequate data quality controls
 * Provide insight and direction to guide the future development of MassMutual’s data platform
 * Develop re-usable tools to help streamline the delivery of new projects
 * Collaborate closely with other developers and provide mentorship
 * Evaluate and recommend tools, technologies, processes and reference architectures 
 * Deploy reusable workflow & orchestration
 * Work in an Agile development environment, attending daily stand-up meetings and delivering incremental improvements
   
   

The Minimum Qualifications


 * A Bachelor’s degree in Math, Engineering, Computer Science, or related field.
 * 5+ Years of experience in the IT and/or finance industry
 * 5+ years ofunderstanding of ELT methodologies and tools via Python
 * 5+ years of experience with GIT and code review/deployment & scheduling part of
 * 5+ years of experience in relational databases (SQLServer/PostgreSQL) and NOSQL databases (Mongo)
   
   

The Ideal Qualifications


 * Master’s degree in Math, Computer Science, Engineering or a related field
 * 7+ Years of experience in the IT and/or finance industry
 * Python: Extensive hands on experience developing with Python and advanced data processing using Python libraries & AWS services.
 * Cloud: Experience working in a cloud environment and basic administration (e.g.AWS)
 * Extensive experience in modeling and tuning relational databases (SQL Server/PostgreSQL) and NOSQL databases (Mongo)
 * Troubleshooting: Experience with troubleshooting and root cause analysis to determine and remediate potential issues
 * Workflow: Good knowledge of orchestration and scheduling tools
 * Reporting: Experience with data reporting (e.g. Micro strategy, Tableau, Looker) or via python libraries
 * Entrepreneurial mindset with the ability to work in a rapid and iterative development environment
 * Experience delivering mobile apps and app store ecosystems
 * Extremely organized, detail-oriented individual who is capable of self-managing and multi-tasking in a fast-paced, demanding environment
 * Excellent written and verbal communication skills, including the ability to effectively present complex information clearly and appropriately handle sensitive information
 * A Data-driven mindset and the ability to use quantitative tools and analyze unstructured feedback to inform the development of solutions
 * The ability to adapt to changing business priorities and a strong work ethic
 * Curiosity regarding emerging digital and technology trends can translate into excellent customer experiences
 * Proven ability to collaborate cross-functionally and influence outcomes
 * Communication: Excellent communication, problem solving and organizational and analytical skills
 * Experience in Agile/SCRUM-specifically in Story/Acceptance criteria development
   
   

What to Expect as Part of MassMutual and the Team


 * Regular meetings with the IM QRD and ETX teams
 * Focused one-on-one meetings with your manager
 * Networking opportunities including access to Asian, Hispanic/Latinx, African American, women, LGBTQIA+, veteran and disability-focused Business Resource Groups
 * Access to learning content on Degreed and other informational platforms
 * Your ethics and integrity will be valued by a company with a strong and stable ethical business with industry leading pay and benefits
   
   

MassMutual is an equal employment opportunity employer. We welcome all persons to apply.

If you need an accommodation to complete the application process, please contact us and share the specifics of the assistance you need.

California residents: For detailed information about your rights under the California Consumer Privacy Act (CCPA), please visit our California Consumer Privacy Act Disclosures page.

","64 applicants","Full-time","Entry level","Information Technology","Financial Services","","","","3631","https://massmutual.easyapply-ats.com/us/linkedin/692d06bcebc5da86b53d7dea?sa_f=692e2c0068f043330648584a","EXTERNAL",""
"Data Engineer","San Francisco, CA","2 days ago","2025-11-30","https://www.linkedin.com/jobs/view/data-engineer-at-cognition%2B-4339848123?trk=public_jobs_topcard-title","Cognition+","https://ca.linkedin.com/company/gocognition?trk=public_jobs_topcard-org-name","We are an applied AI lab building end-to-end software agents.

We’re the makers of Devin, the first AI software engineer. Cognition is building collaborative AI teammates that enable engineers to focus on more interesting problems and empower engineering teams to strive for more ambitious goals.

Our team is small and talent-dense. Among our founding team, we have world-class competitive programmers, former founders, and leaders from companies at the cutting edge of AI including , Scale AI, Cursor, Waymo, Tesla, Lunchclub, Modal, Google DeepMind, and Nuro.

Building Devin is just the first step—our hardest challenges still lie ahead. If you’re excited to solve some of the world’s biggest problems and build AI that can reason on real-world tasks, apply to join us.

About The Role

We’re hiring a technical Data Engineer to own our full data stack – from database architecture and pipelines to integrations and reporting. You’ll design and maintain the systems that keep our data reliable, accessible, and actionable across the company with a particular focus on product and GTM reporting.

In this role you will:


 * Design and manage database architecture and data models
 * Build and maintain ETL/ELT pipelines and orchestration workflows
 * Create and manage new data integrations across internal and external systems
 * Own business reporting: datasets, dashboards, metrics, and self-serve analytics
 * Ensure data quality, observability, governance, and documentation
   
   

Requirements for the role:


 * 4+ years in a data engineering, data science, or full-stack data role
 * Expert SQL and strong Python (or R)
 * Experience with data modeling, warehouse architecture, and BI-oriented schema design
 * Hands-on experience with ETL/ELT tools (dbt, Airflow, Dagster, etc.)
 * Experience building or maintaining BI reporting (Metabase a plus)
 * Strong knowledge of statistics and experimentation
 * Based in SF or NYC
   
   ","Over 200 applicants","Full-time","Entry level","Information Technology","Software Development","","","","42703","https://www.linkedin.com/jobs/view/data-engineer-at-cognition%2B-4339848123?trk=public_jobs_topcard-title","EASY_APPLY",""
"ETL Lead - Seattle,WA (Initial Remote)","Washington, United States","1 month ago","2025-10-27","https://www.linkedin.com/jobs/view/etl-lead-seattle-wa-initial-remote-at-the-dignify-solutions-llc-4341995548?trk=public_jobs_topcard-title","The Dignify Solutions, LLC","https://www.linkedin.com/company/dignify-solutions?trk=public_jobs_topcard-org-name"," * 6 to 10+ years of experience working with hands on development experience in Snowflake on Azure platform- Dataflow, Data Ingestion, Data Storage & Security
 * Good understanding of Migration Approaches, Solution Orchestration on SaaS(Azure, Snowflake) platforms, Reverse Engg, and data model designing.
 * Strong hands-on experience in build custom data models/semantic reporting layer in Snowflake to support customer reporting current platform requirements.
 * Good to have experience in any other ETL tool
 * Create functional design for overall business intelligence solutions
 * Design Data Integration (ETL) projects using the Informatica
 * Participate in the entire project lifecycle including design and development of ETL solutions
 * Design data integration and conversion strategy, exception handing mechanism, data retention and archival strategy
 * Well versed with Reverse/forward engineering in architectural models in Snowflake/Azure platform
 * Ability to communicate platform features/development effectively to customer SME & Technical team.
 * Drive UAT activities with business partners to ensure solutions meet business requirements
 * Experience working with Power BI reporting, Dataflow, Data Lake, Databrick, ADF Pipeline, Security knowledge is added advantage
   
   

Primary Skill:

APEX, Design Patterns, Lead Generation, Quoting, Stored Procedure","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","75031133","https://www.linkedin.com/jobs/view/etl-lead-seattle-wa-initial-remote-at-the-dignify-solutions-llc-4341995548?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist I","Charlotte, NC","4 days ago","2025-11-27","https://www.linkedin.com/jobs/view/data-scientist-i-at-bank-of-america-4339275737?trk=public_jobs_topcard-title","Bank of America","https://www.linkedin.com/company/bank-of-america?trk=public_jobs_topcard-org-name","Job Description:

At Bank of America, we are guided by a common purpose to help make financial lives better through the power of every connection. We do this by driving Responsible Growth and delivering for our clients, teammates, communities and shareholders every day.

Being a Great Place to Work is core to how we drive Responsible Growth. This includes our commitment to being an inclusive workplace, attracting and developing exceptional talent, supporting our teammates’ physical, emotional, and financial wellness, recognizing and rewarding performance, and how we make an impact in the communities we serve.

Bank of America is committed to an in-office culture with specific requirements for office-based attendance and which allows for an appropriate level of flexibility for our teammates and businesses based on role-specific considerations.

At Bank of America, you can build a successful career with opportunities to learn, grow, and make an impact. Join us!

The Data and AI team within Global Payment Solutions (GPS) at Bank of America is looking for a highly technical Research Engineer that is a self-starter who can translate complex concepts and generate actionable insights.

Who we are:

The GPS Data and AI team drives and powers innovation within the one of the largest payment businesses in the world. We are the core data scientists building end-to-end production level solutions at scale. The team is a collection of individuals that welcomes challenging problems because that is where the learning begins. Many of our projects begin with “think tank” sessions with business teams that is later translated to tangible solutions and products.

Representative Projects:


 * Develop advanced statistical methods to determine the optimal interest-rate or product pricing strategies for clients
 * Build a Generative AI-powered search platform that enables sales and product teams to access high quality answers to product, servicing, and client related questions
 * Develop AI models that shift foreign currency conversion “up the payment stream,” reducing reliability on beneficiary banks
 * Apply advanced NLP techniques to generate near real-time insights into what clients are reaching out to servicing teams about, helping servicing teams anticipate client needs and improve service quality
   
   

Who we’re looking for:

As a Research Engineer on the GPS team, you will tackle one of our most import challenges: building models that transform data into revenue-driving insights and products. This role blends research, engineering, and product responsibilities, requiring you to design statistical models, build scalable ML pipelines, and deploy algorithms directly into our production systems. You will work across teams to solve problems in recommendation, stochastic optimization, and time-series forecasting; while running large A/B tests on new methods we design to push the boundaries of what data can achieve.

If you are passionate about working in cross-functional teams and utilizing your skills for technical product management, statistical analytics, predictive modeling, and generating revenue, consider applying to this role.

Responsibilities:


 * Frame abstract business problems using advanced data science and machine learning algorithms
 * Work with stakeholders throughout the organization to identify opportunities for leveraging internal and external data to drive business solutions
 * Own critical research and application development, strengthening the firm's competitive advantage
 * Shape cross-team collaboration to advance the firm's data science capabilities
   
   

Required Skills:


 * Minimum Bachelor’s degree in a quantitative field such as computer science, math, statistics, and physics
 * Minimum 3 years of experience with translating mathematical models and algorithms into code (Python and/or C++)
 * Strong foundation in probability, statistics, and applied machine learning (NLP, time-series analysis, Generative AI)
 * Prior experience working in a highly technical data driven research environment
 * Ability to communicate complex topics in a concise and coherent manner
   
   

Desired Skills:


 * Graduate level degree in a quantitative field such as, computer science, math, statistics, and physics
 * Demonstrated prior experience through work, research or passion projects in RAG, Agentic Frameworks, LLMs, Reinforcement Learning
 * Are energized by the high stakes and intensity of dynamic environments and ready to dive in whenever
 * Are excited to dive into new technical areas on a regular basis
   
   

Shift:

1st shift (United States of America)

Hours Per Week:

40","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Banking","","","","1123","https://www.linkedin.com/jobs/view/data-scientist-i-at-bank-of-america-4339275737?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Richardson, TX","3 weeks ago","2025-11-06","https://www.linkedin.com/jobs/view/data-engineer-at-infosys-4337949172?trk=public_jobs_topcard-title","Infosys","https://in.linkedin.com/company/infosys?trk=public_jobs_topcard-org-name","Job Description :

Infosys is seeking a Google Cloud (GCP) data engineer with experience in Github and python. In this role, you will enable digital transformation for our clients in a global delivery model, research on technologies independently, recommend appropriate solutions and contribute to technology-specific best practices and standards. You will be responsible to interface with key stakeholders and apply your technical proficiency across different stages of the Software Development Life Cycle. You will be part of a learning culture, where teamwork and collaboration are encouraged, excellence is rewarded, and diversity is respected and valued.




Required Qualifications:

 * Candidate must be located within commuting distance of Richardson, TX or be willing to relocate to the area. This position may require travel in the US
 * Bachelor’s degree or foreign equivalent required from an accredited institution. Will also consider three years of progressive experience in the specialty in lieu of every year of education.
 * Candidates authorized to work for any employer in the United States without employer-based visa sponsorship are welcome to apply. Infosys is unable to provide immigration sponsorship for this role at this time
 * At least 4 years of Information Technology experience.
 * Experience working with technologies like – GCP with data engineering – data flow / air flow, pub sub/ kafta, data proc/Hadoop, Big Query.
 * ETL development experience with strong SQL background such as Python/R, Scala, Java, Hive, Spark, Kafka
 * Strong knowledge on Python Program development to build reusable frameworks, enhance existing frameworks.
 * Application build experience with core GCP Services like Dataproc, GKE, Composer,
 * Deep understanding GCP IAM & Github.
 * Must have done IAM set up
 * Knowledge on CICD pipeline using Terraform in Git.

Preferred Qualifications:

 * Good knowledge on Google Big Query, using advance SQL programing techniques to build Big Query Data sets in Ingestion and Transformation layer.
 * Experience in Relational Modeling, Dimensional Modeling and Modeling of Unstructured Data
 * Knowledge on Airflow Dag creation, execution, and monitoring.
 * Good understanding of Agile software development frameworks
 * Ability to work in teams in a diverse, multi-stakeholder environment comprising of Business and Technology teams.
 * Experience and desire to work in a global delivery environment.

The job may entail extensive travel. The job may also entail sitting as well as working at a computer for extended periods of time. Candidates should be able to effectively communicate by telephone, email, and face to face.




EEO/About Us :

Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem.




Infosys provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Information Services","","","","1283","https://www.linkedin.com/jobs/view/data-engineer-at-infosys-4337949172?trk=public_jobs_topcard-title","EASY_APPLY",""
"Force Development LIN Manager","Washington, DC","1 week ago","2025-11-25","https://www.linkedin.com/jobs/view/force-development-lin-manager-at-cape-henry-associates-acquired-by-janus-research-group-4324466061?trk=public_jobs_topcard-title","Cape Henry Associates, Acquired by JANUS Research Group","https://www.linkedin.com/company/cape-henry-associates-inc?trk=public_jobs_topcard-org-name","This Position is Subject to Contract Award

JANUS Research Group is currently seeking a Force Development LIN Manager for a contract to support the Deputy Chief of Staff (DCS, G8. The DCS G-8 is the principal military advisor to the Chief of Staff, Army (CSA) and the Assistant Secretary of the Army, Financial Management and Comptroller (ASA(FMC)) for the Programming phase of the Planning, Programming, Budgeting, and Execution (PPBE) process. The DCS, G-8 coordinates with the Assistant Secretary of the Army, Acquisition, Logistics, and Technology (ASA(ALT)) on all proposed programming and process recommendations related to ongoing and future acquisition programs and science and technology initiatives. The DCS, G-8 coordinates with Army Futures Command (AFC) for program funding for all elements of the future force materiel modernization enterprise.

Position Description: Serves as the Lead Line Item Number (LIN) Manager for DCS G-8 Force Development. Oversees the validation, assignment, and maintenance of LINs across Army systems to ensure accurate tracking of equipment authorizations and modernization visibility. Coordinates with HQDA, ASA(ALT), AMC, and T2COM to align LIN data within AE2S-M, FMSWeb, and AESIP. Develops and enforces configuration and data management standards supporting SPAR, POM, and AROC/JROC processes. Provides audit-ready reports and briefings ensuring transparency and synchronization of equipment and force structure data.

Relevant Competencies / Skill Levels


 * A Bachelor's Degree in Engineering and/or Business
 * A minimum of four (4) years of experience and expertise in Force Development duties
 * Demonstrates expert analytical and technical skills in Line Item Number (LIN) management, equipment authorization, and configuration control. Proficient in maintaining and validating LIN data within systems such as AE2S-M, FMSWeb, and AESIP to ensure accuracy and audit readiness. Skilled in analyzing equipment documentation, modernization updates, and fielding requirements to support force structure alignment. Possesses strong data management and communication abilities to deliver clear, accurate reports supporting Army equipping and modernization decisions
   
   

Benefits: 401(k), Paid Time Off (PTO), Paid Holidays, Medical and Dental Plans, Life and Disability insurance, Education Assistance (and more).

JANUS strives to provide opportunities for career growth through training and development. We also offer an attractive comprehensive benefit package to include health and welfare plans and financial products. As part of a total rewards program, employees can benefit from our referral bonus program, and other various employee awards. JANUS Research Group takes pride in our benefit package and rewards program which has earned us the certification of a Great Place to Work™

JANUS Research Group provides reasonable accommodation so that qualified applicants with a disability may participate in the selection process. Please advise us of any accommodations you request to express interest in a position by e-mailing: Judy Pagac, Chief Human Resources Officer at judy.pagac@janusresearch.com or calling (706) 364-9100. Please state your request for assistance in your message. Only reasonable accommodation requests related to applying for a specific position within JANUS Research Group will be reviewed at the e-mail address and phone number supplied. Thank you for considering a career with JANUS Research Group.

JANUS Research Group participates in the Electronic Employment Verification Program. Please click the E-Verify link below for more information.

E-Verify

JANUS Research Group is an equal opportunity/ affirmative action employer. It is company policy to provide equal opportunity in all areas of employment practice without regard to race, color, religion, sex, sexual orientation, national origin, age, marital status, veteran status, citizenship, or disability.

This contractor and subcontractor shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities and prohibit discrimination against all individuals based on their race, color, religion, sex, or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment qualified individuals without regard to race, color, religion, sex, national origin, protected veteran status or disability.","Be among the first 25 applicants","Full-time","Mid-Senior level","Strategy/Planning and Information Technology","Government Relations","","","","434080","https://www.linkedin.com/jobs/view/force-development-lin-manager-at-cape-henry-associates-acquired-by-janus-research-group-4324466061?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Data Engineer","San Francisco, CA","4 weeks ago","2025-11-03","https://www.linkedin.com/jobs/view/senior-data-engineer-at-baselayer-4333778868?trk=public_jobs_topcard-title","Baselayer","https://www.linkedin.com/company/baselayerhq?trk=public_jobs_topcard-org-name","About Baselayer: 
Trusted by 2,200+ financial institutions, Baselayer is the intelligent business identity platform that helps verify any business, automate KYB, and monitor real-time risk. Baselayer’s B2B risk solutions & identity graph network leverage state & federal government filings and proprietary data sources to prevent fraud, accelerate onboarding, and lower credit losses. 

 

About You:

You want to learn from the best of the best, get your hands dirty, and put in the work to hit your full potential. You’re not just doing it for the win—you’re doing it because you have something to prove and want to be great. You’re hungry to become an elite data engineer, designing rock-solid infrastructure that powers cutting-edge AI/ML products.

 * You have 1–3 years of experience in data engineering, working with Python, SQL, and cloud-native data platforms
 * You’ve built and maintained ETL/ELT pipelines, and you know what clean, scalable data architecture looks like
 * You’re comfortable with structured and unstructured data, and you thrive on building systems that transform chaos into clarity
 * You think in DAGs, love automating things with Airflow or dbt, and sweat the details when it comes to data integrity and reliability
 * You’re curious about AI/ML infrastructure, and you want to be close to the action—feeding the models, not just cleaning up after them
 * You value ethical data practices, especially when dealing with sensitive information in environments like KYC/KYB or financial services
 * You’re a translator between technical and non-technical stakeholders, aligning infrastructure with business outcomes
 * Highly feedback-oriented. We believe in radical candor and using feedback to get to the next level
 * Proactive, ownership-driven, and unafraid of complexity—especially when there’s no playbook

 

 

Responsibilities:

 * Pipeline Development: Design, build, and maintain robust, scalable ETL/ELT pipelines that power analytics and ML use cases
 * Data Infrastructure: Own the architecture and tooling for storing, processing, and querying large-scale datasets using cloud-based solutions (e.g., Snowflake, BigQuery, Redshift)
 * Collaboration: Work closely with data scientists, ML engineers, and product teams to ensure reliable data delivery and feature readiness for modeling
 * Monitoring & Quality: Implement rigorous data quality checks, observability tooling, and alerting systems to ensure data integrity across environments
 * Data Modeling: Create efficient, reusable data models using tools like dbt, enabling self-service analytics and faster experimentation
 * Security & Governance: Partner with security and compliance teams to ensure data pipelines adhere to regulatory standards (e.g., SOC 2, GDPR, KYC/KYB)
 * Performance Optimization: Continuously optimize query performance and cost in cloud data warehouses
 * Documentation & Communication: Maintain clear documentation and proactively share knowledge across teams
 * Innovation & R&D: Stay on the cutting edge of data engineering tools, workflows, and best practices—bringing back what works and leveling up the team

 

Benefits:

 * Hybrid in SF. In office 3 days/week
 * Flexible PTO
 * Healthcare, 401K
 * Smart, genuine, ambitious team

 

Salary Range: $135k – $220k + Equity - 0.05% – 0.25%","Be among the first 25 applicants","Full-time","Mid-Senior level","Information Technology","Technology, Information and Internet","$135,000.00/yr - $220,000.00/yr","","","103398184","https://www.linkedin.com/jobs/view/senior-data-engineer-at-baselayer-4333778868?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI Engineer","New York, NY","21 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/ai-engineer-at-massmutual-4340153775?trk=public_jobs_topcard-title","MassMutual","https://www.linkedin.com/company/massmutual-financial-group?trk=public_jobs_topcard-org-name","Overall Responsibilities


 * Architect and lead end-to-end ML/AI solutionssupporting life insurance underwritingusing LLMs, deep learning, and probabilistic modeling—from ideation to production.
 * Deploy scalable GenAI and Agentic AI systems that directly support business goals.
 * Establish and promote best practices in AI development and responsible AI deployment.
 * Drive innovation by identifyingemerging technologies and translating research into practical applications.
 * Collaborate with engineering teams to build robust, production-grade AI pipelines and APIs.
 * Prototype and deliver AI-powered applications (e.g., web apps, dashboards, visualizations) that enable data-driven decisions.
 * Influence senior leadership by aligning AI initiatives with enterprise strategy and communicating insights effectively.
 * Mentor and develop junior talent, fostering a culture of technical excellence and continuous learning.
   
   

Candidate Requirements


 * Recognized industry expertise in AI/ML, with a track record of delivering impactful solutions.
 * 7+ years of experience in data science, machine learning, or AI engineering roles.
 * Deep understanding of machine learning, statistics, NLP, optimization, and LLMs.
 * Hands-on experience with AI deployment and orchestration frameworks and protocols (e.g., MLflow, llama-index, MCP).
 * Extensive experience testing LLM behavior across a variety of foundation models and benchmarks.
 * Experience building AI-powered applications and collaborating with software engineers and product managers.
 * Strong programming skills in Python. Proficiency in R is a plus.
 * Proficiency in SQL and database design; familiarity with cloud-native data platforms, vector databases, and semantic search is a plus.
 * Exceptional communication skills, with the ability to explain complex concepts to non-technical stakeholders.
   
   

Education

M.S. or Ph.D. in Computer Science, Statistics, Applied Mathematics, Electrical Engineering, Physics, or a related quantitative field.

MassMutual is an equal employment opportunity employer. We welcome all persons to apply.

If you need an accommodation to complete the application process, please contact us and share the specifics of the assistance you need.

California residents: For detailed information about your rights under the California Consumer Privacy Act (CCPA), please visit our California Consumer Privacy Act Disclosures page.","101 applicants","Full-time","Entry level","Engineering and Information Technology","Financial Services","","","","3631","https://www.linkedin.com/jobs/view/ai-engineer-at-massmutual-4340153775?trk=public_jobs_topcard-title","EASY_APPLY",""
"PowerBi and Data Specialist","Abilene, TX","1 month ago","2025-10-31","https://www.linkedin.com/jobs/view/powerbi-and-data-specialist-at-the-newtron-group-4320211825?trk=public_jobs_topcard-title","The Newtron Group","https://www.linkedin.com/company/thenewtrongroup?trk=public_jobs_topcard-org-name","Power BI and Data Systems Specialist




Department: Project Controls

Reports To: Project Controls Manager

Location: on-site (jobsite)




About The Newtron Group




The Newtron Group is one of the largest privately owned specialty electrical construction companies in the United States and a national leader in Industrial Electrical and Instrumentation services. Beyond our construction expertise, we provide innovative and customized Analytical, Automation, Heat Trace, Integration, and Design solutions across a wide range of industries.




With offices throughout the Southeast and West Coast, The Newtron Group has performed work nationwide and established strong, long-term partnerships with clients, manufacturers, and suppliers.

Our 52+ years of experience and commitment to innovation have led to the creation of the Newtron Group Control System (NGCS) — a first-class management platform that integrates project performance data from the field to the executive level. To continue advancing this system and strengthen our data-driven decision-making, we are seeking a Power BI and Data Systems Specialist to join our Project Controls team.




Purpose of the Position




The Power BI and Data Systems Specialist is responsible for designing, building, and maintaining dashboards and data pipelines that deliver actionable insights into project cost, productivity, forecasting, and performance. This position bridges technical expertise and operational understanding — transforming raw construction data into visual intelligence that empowers project managers, executives, and field operations to make faster, smarter decisions.




Key Responsibilities

1. Dashboard Development and Automation




 * Design, develop, and maintain Power BI dashboards and data models visualizing key performance indicators such as labor hours, progress curves, earned vs. burned, change orders, and cost trends.
 * Build and manage ETL workflows that extract, transform, and load data from multiple sources including NGCS, Primavera P6, SharePoint, SQL, and Excel.
 * Automate recurring reporting processes and ensure dashboards update seamlessly with accurate, validated data.
 * Develop standardized KPI templates for consistent performance tracking across projects and business units.

2. Data Analytics and Reporting




 * Analyze project data to identify trends, variances, and inefficiencies in cost, schedule, and labor performance.
 * Generate weekly and monthly reports summarizing project health and forecasting results.
 * Support project managers and leadership with predictive analytics tools that combine historical performance and real-time data.
 * Collaborate with Prefabrication, Estimating, and Field Operations to quantify performance gains and measure improvement initiatives.

3. Data Governance and Integration




 * Establish and maintain data standards, definitions, and governance protocols for all project reporting.
 * Integrate construction management and financial systems into a centralized analytics environment.
 * Work with IT to maintain secure, role-based access and ensure system reliability and data integrity.
 * Troubleshoot data connectivity and accuracy issues between NGCS, Power BI, and other platforms.

4. Stakeholder Engagement and Training




 * Collaborate with department leaders to define reporting needs and translate business questions into clear analytics solutions.
 * Deliver training and guidance for project teams on interpreting dashboards and using analytics tools effectively.
 * Present insights and recommendations to management using concise, executive-level visualizations.

5. Continuous Improvement and Innovation




 * Continuously enhance data systems by identifying automation, integration, and AI opportunities.
 * Research and implement emerging Power BI and AI/ML capabilities for advanced forecasting and risk analysis.
 * Standardize and document reporting processes to improve scalability across regions and clients.




Qualifications and Skills




 * Bachelor’s degree in Data Analytics, Computer Science, Construction Management, Engineering, or related field (preferred).
 * 3–5 years of experience developing Power BI dashboards, DAX measures, and SQL-based data models.
 * Proficiency with Power Query (M language), SQL, Excel (VBA/Macros a plus), and relational database design.
 * Familiarity with Primavera P6, Procore, Viewpoint/Spectrum, or similar construction/project controls systems is highly desirable.
 * Strong analytical and problem-solving abilities with a clear understanding of construction cost and schedule data.
 * Excellent communication and documentation skills; ability to work independently in a fast-paced, team-oriented environment.




Why Join The Newtron Group




 * At The Newtron Group, we combine decades of electrical construction experience with modern, data-driven systems to deliver exceptional results. Joining our team means contributing to one of the most advanced project management ecosystems in the industry — where your work directly enhances operational efficiency, forecasting accuracy, and decision quality across every level of the organization.","Over 200 applicants","Full-time","Entry level","Information Technology","Construction","","","","1509799","https://www.linkedin.com/jobs/view/powerbi-and-data-specialist-at-the-newtron-group-4320211825?trk=public_jobs_topcard-title","EASY_APPLY",""
"Python Risk Model Developer (SQL & Unix)","New York, NY","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/python-risk-model-developer-sql-unix-at-capgemini-4339063049?trk=public_jobs_topcard-title","Capgemini","https://fr.linkedin.com/company/capgemini?trk=public_jobs_topcard-org-name","Choosing Capgemini means choosing a company where you will be empowered to shape your career in the way you’d like, where you’ll be supported and inspired by a collaborative community of colleagues around the world, and where you’ll be able to reimagine what’s possible. Join us and help the world’s leading organizations unlock the value of technology and build a more sustainable, more inclusive world.

Job Location: NY

Works in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.1. Applies scientific methods to analyse and solve software engineering problems.2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.

Job Responsibilities

As a successful candidate you will be given an opportunity to acquire and develop knowledge from related fields:

Collaborate with stakeholders throughout the organization to develop project plans of delivering objects and timelines of model development and implementation.

Develop risk models in Python/R used by risk teams for regulatory stress testing submission and company risk management. Design and build the execution workflow of models to forecast Balance Sheet, Fee Revenues, Macroeconomic Factors,

Expense and calculate risk metrics under various stress scenarios, sensitivity & attribution analysis.

Coordinate with different functional teams to implement models and coordinate coding, testing, implementation and documentation of financial models.

Develop processes and tools to monitor and analyze model performance to ensure the expected application performance levels are achieved. Also, apply various statistical and analytical tests for validating models and results.

Develop presentation decks using visual analytics tools and techniques. (JupyterHub/Python)

Apply data mining, data modelling and machine learning techniques to analyze large financial datasets and enhance the model performance.

Required Skills

Master/MBA/PhD's Degree in a quantitative field (computer science, financial engineering, mathematics, data science or engineering)

Experience using one or more programming languages (Python, R, C++, Java, Matlab, etc.) and manipulating data using SQL and Pandas

Excellent written and verbal communication skills for coordination across teams

Understanding of design, development and implementation of mathematical, financial risk and ML models

Relevant work experience in a related field based on education level

Knowledge of advanced statistical techniques and concepts (regression, time series analysis, statistical tests, etc.)

Life at Capgemini

Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:

Flexible work

Healthcare including dental, vision, mental health, and well-being programs

Financial well-being programs such as 401(k) and Employee Share Ownership Plan

Paid time off and paid holidays

Paid parental leave

Family building benefits like adoption assistance, surrogacy, and cryopreservation

Social well-being benefits like subsidized back-up child/elder care and tutoring

Mentoring, coaching and learning programs

Employee Resource Groups nd Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.

Capgemini is committed to providing reasonable accommodations du

Disaster Relief

The base compensation range for this role in the posted location is:

$110841 to $145000

Capgemini provides compensation range information in accordance with applicable national, state, provincial, and local pay transparency laws. The base compensation range listed for this position reflects the minimum and maximum target compensation Capgemini, in good faith, believes it may pay for the role at the time of this posting. This range may be subject to change as permitted by law.

The actual compensation offered to any candidate may fall outside of the posted range and will be determined based on multiple factors legally permitted in the applicable jurisdiction.

These may include, but are not limited to: Geographic location, Education and qualifications, Certifications and licenses, Relevant experience and skills, Seniority and performance, Market and business consideration, Internal pay equity.

It is not typical for candidates to be hired at or near the top of the posted compensation range.

In addition to base salary, this role may be eligible for additional compensation such as variable incentives, bonuses, or commissions, depending on the position and applicable laws.

Capgemini offers a comprehensive, non-negotiable benefits package to all regular, full-time employees. In the U.S. and Canada, available benefits are determined by local policy and eligibility and may include:


 * Paid time off based on employee grade (A-F), defined by policy: Vacation: 12-25 days, depending on grade, Company paid holidays, Personal Days, Sick Leave
 * Medical, dental, and vision coverage (or provincial healthcare coordination in Canada)
 * Retirement savings plans (e.g., 401(k) in the U.S., RRSP in Canada)
 * Life and disability insurance
 * Employee assistance programs
 * Other benefits as provided by local policy and eligibility
   
   

Important Notice: Compensation (including bonuses, commissions, or other forms of incentive pay) is not considered earned, vested, or payable until it becomes due under the terms of applicable plans or agreements and is subject to Capgemini’s discretion, consistent with applicable laws. The Company reserves the right to amend or withdraw compensation programs at any time, within the limits of applicable legislation.

Disclaimers

Capgemini is an Equal Opportunity Employer encouraging inclusion in the workplace. Capgemini also participates in the Partnership Accreditation in Indigenous Relations (PAIR) program which supports meaningful engagement with Indigenous communities across Canada by promoting fairness, accessibility, inclusion and respect. We value the rich cultural heritage and contributions of Indigenous Peoples and actively work to create a welcoming and respectful environment. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.

This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodation does not pose an undue hardship. Capgemini is committed to providing reasonable accommodation during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.

Please be aware that Capgemini may capture your image (video or screenshot) during the interview process and that image may be used for verification, including during the hiring and onboarding process.

Click the following link for more information on your rights as an Applicant in the United States. http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law

Capgemini is a global business and technology transformation partner, helping organizations to accelerate their dual transition to a digital and sustainable world, while creating tangible impact for enterprises and society. It is a responsible and diverse group of 340,000 team members in more than 50 countries. With its strong over 55-year heritage, Capgemini is trusted by its clients to unlock the value of technology to address the entire breadth of their business needs. It delivers end-to-end services and solutions leveraging strengths from strategy and design to engineering, all fueled by its market leading capabilities in AI, generative AI, cloud and data, combined with its deep industry expertise and partner ecosystem.","66 applicants","Full-time","Mid-Senior level","General Business, Management, and Business Development","IT Services and IT Consulting","$110,841.00/yr - $145,000.00/yr","","","157240","https://www.linkedin.com/jobs/view/python-risk-model-developer-sql-unix-at-capgemini-4339063049?trk=public_jobs_topcard-title","EASY_APPLY",""
"Software Engineer, Data Acquisition","San Francisco, CA","2 days ago","2025-11-29","https://www.linkedin.com/jobs/view/software-engineer-data-acquisition-at-openai-4313836844?trk=public_jobs_topcard-title","OpenAI","https://www.linkedin.com/company/openai?trk=public_jobs_topcard-org-name","Overview

The Data Acquisition team within the Foundations organization at OpenAI is responsible for all aspects of data collection to support our model training operations. Our team manages web crawling and GPTBot services and works closely with Data Processing, Architecture, and Scaling teams. We are looking for a skilled Software Engineer to join our Data Acquisition team.

Responsibilities


 * Own and lead engineering projects in the area of data acquisition including web crawling, data ingestion, and search.
 * Collaborate with other sub-teams, such as Data Processing, Architecture, and Scaling, to ensure smooth data flow and system operability.
 * Work closely with the legal team to handle any compliance or data privacy-related matters.
 * Develop and deploy highly scalable distributed systems capable of handling petabytes of data.
 * Architect and implement algorithms for data indexing and search capabilities.
 * Build and maintain backend services for data storage, including work with key-value databases and synchronization.
 * Deploy solutions in a Kubernetes Infrastructure-as-Code environment and perform routine system checks.
 * Conduct and analyze experiments on data to provide insights into system performance.
   
   

Qualifications


 * BS/MS/PhD in Computer Science or a related field.
 * 4+ years of industry experience in software development.
 * Experience with large web crawlers a plus
 * Strong expertise in large stateful distributed systems and data processing.
 * Proficiency in Kubernetes, and Infrastructure-as-Code concepts.
 * Willingness and enthusiasm for trying new approaches and technologies.
 * Ability to handle multiple tasks and adapt to changing priorities.
 * Strong communication skills, both written and verbal.
   
   

About OpenAI

OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.

We are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.

For additional information, please see OpenAI’s Affirmative Action and Equal Employment Opportunity Policy Statement.

Background checks for applicants will be administered in accordance with applicable law, and qualified applicants with arrest or conviction records will be considered for employment consistent with those laws, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act, for US-based candidates. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.

To notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.

We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.

OpenAI Global Applicant Privacy Policy

At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.

Compensation Range: $325K - $405K","121 applicants","Full-time","Entry level","Research","Research Services","$325,000.00/yr - $405,000.00/yr","","","11130470","https://jobs.ashbyhq.com/openai/41d9d129-2e58-4ad3-be81-2e5096f4da4d/application","EXTERNAL",""
"Senior AI Solutions Engineer","Louisville, KY","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/senior-ai-solutions-engineer-at-ge-appliances-a-haier-company-4324377126?trk=public_jobs_topcard-title","GE Appliances, a Haier company","https://www.linkedin.com/company/geappliancesco?trk=public_jobs_topcard-org-name","We are looking for a dynamic AI Solutions Engineer to join our expanding AI team. This role is ideal for a motivated engineer with strong analytical skills and a keen interest in cutting-edge AI technologies. You will have the opportunity to apply modern machine learning (ML) and Generative AI (GenAI) techniques—such as Large Language Models (LLMs), OpenAI/GPT APIs, Google Gemini, and cloud-native ML tools—to solve real-world business problems.




As an AI Solutions Engineer, you will work closely with cross-functional teams, leveraging your technical expertise and customer-focused insights to design, prototype, and implement AI-driven solutions. Your work will play a crucial role in enhancing enterprise decision-making and automation capabilities. This position offers a unique chance to make a significant impact by integrating advanced AI technologies into business processes.

AI Solution Development:

 * Translate business requirements into comprehensive AI-driven solutions.
 * Integrate software applications, data platforms, and cloud infrastructure.

LLM-Based Application Development:

 * Design and implement applications using advanced Large Language Models (LLMs).
 * Focus on use cases such as conversational AI, semantic search, Retrieval-Augmented Generation (RAG), and multi-agent systems.

Proof-of-Concept Creation:

 * Develop clear and demonstrative AI prototypes.
 * Collaborate with engineering teams to transition successful prototypes into production environments.

Data Pipelines:

 * Design and manage efficient data pipelines to support AI solutions.

Tooling:

 * Utilize and develop tools to streamline AI solution development and deployment.
 * Ensure tools are effectively integrated into existing workflows and processes.




Qualifications:

 * 5+ years of experience in data science, AI, or ML with academic or open-source portfolios.
 * Proficient in Python, and experienced in using Jupyter Notebooks, Pandas, and data visualization libraries.
 * Familiarity with cloud platforms (GCP, AWS, Azure) and data warehouses (e.g., BigQuery, Snowflake).
 * Exposure to OpenAI APIs, Hugging Face, or Google Vertex AI is highly desirable.
 * Understanding of key AI/ML concepts such as supervised learning, embeddings, fine-tuning, model evaluation metrics, and prompt engineering.




Preferred Qualifications:

 * Master’s in Data Science, Computer Science, AI/ML, Statistics, or a related technical field.
 * Hands-on experience with LLMs, embedding models, or semantic search pipelines.
 * Proficiency with LangChain, LlamaIndex, LLMOps, and RAG (Retrieval-Augmented Generation) architectures.
 * Exposure to model monitoring, data drift detection, or CI/CD in ML pipelines.
 * Experience with APIs, microservices, and Python back-end frameworks (FastAPI, Flask).
 * Knowledge of responsible AI principles including fairness, interpretability, and data privacy.

","109 applicants","Full-time","Mid-Senior level","Engineering, Information Technology, and Manufacturing","Manufacturing, Appliances, Electrical, and Electronics Manufacturing, and Retail Appliances, Electrical, and Electronic Equipment","","Rachel Markel","https://www.linkedin.com/in/rachel-markel-5b25b141","1687254","https://www.linkedin.com/jobs/view/senior-ai-solutions-engineer-at-ge-appliances-a-haier-company-4324377126?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Paid maternity leave
Paid paternity leave
Tuition assistance"
"Machine Learning Engineer (Data Science)","Santa Clara, CA","6 days ago","2025-11-26","https://www.linkedin.com/jobs/view/machine-learning-engineer-data-science-at-autonomous-healthcare-4324469709?trk=public_jobs_topcard-title","Autonomous Healthcare","https://www.linkedin.com/company/autonomous-healthcare?trk=public_jobs_topcard-org-name","About Autonomous Healthcare

At Autonomous Healthcare, we are at the forefront of medical innovation, developing the next generation of devices that will revolutionize patient care. Our mission is to commercialize breakthrough medical technologies by leveraging cutting-edge AI and autonomous systems. We believe that the best solutions are built together, and we are looking for a key member to join our collaborative R&D team.




About The Role

Autonomous Healthcare is looking for a skilled Machine Learning Engineer to join our data science team. This role is focused on diving deep into complex datasets to uncover hidden patterns and build predictive models related to pharmacy data. You will be a key player in developing and deploying solutions that directly impact our business, with a special emphasis on analyzing unlabeled data to detect critical anomalies. If you love solving challenging puzzles with data and seeing your models come to life in a production environment, we want to hear from you.




Key Responsibilities

 * Design, develop, and train machine learning models to solve complex business problems.
 * Perform in-depth data analysis and feature engineering on large, complex datasets, with a strong focus on unlabeled data to identify and investigate anomalies.
 * Utilize Python and key libraries (such as Pandas, NumPy, and Scikit-learn) for data manipulation, analysis, and model building.
 * Manage the end-to-end machine learning lifecycle, from data sourcing and model validation to deployment.
 * Deploy and maintain scalable machine learning models in production on AWS (e.g., using SageMaker, Lambda, ECS/EKS).
 * Collaborate with data engineers, software developers, and product managers to integrate ML models into our applications and systems.
 * Monitor model performance, identify drift, and iterate on models to improve accuracy and efficiency.




Required Qualifications

 * Proven professional experience as a Machine Learning Engineer or Data Scientist.
 * Strong programming skills in Python and extensive experience with data science/analytics libraries, especially Pandas.
 * Demonstrable experience in analyzing unlabeled data and building models for anomaly detection (e.g., using clustering, isolation forests, autoencoders, or other techniques).
 * Practical familiarity with deploying machine learning models on AWS cloud infrastructure (e.g., AWS SageMaker, S3, Lambda).
 * Solid understanding of core machine learning concepts, algorithms, and best practices including unsupervised learning and reinforcement learning frameworks.
 * Excellent analytical and problem-solving skills.




Preferred Qualifications (A Plus)

 * Familiarity with discrete event system simulation principles or tools.
 * Experience with other MLOps tools and cloud services.
 * A degree in Computer Science, Data Science, Statistics, or a related quantitative field.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Hospitals and Health Care","","","","11175287","https://www.linkedin.com/jobs/view/machine-learning-engineer-data-science-at-autonomous-healthcare-4324469709?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Detroit, MI","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/data-engineer-at-benzinga-4341910191?trk=public_jobs_topcard-title","Benzinga","https://www.linkedin.com/company/benzinga?trk=public_jobs_topcard-org-name","Job Description

Benzinga is seeking a technical Data Engineer to join our team. In this role, you will be responsible for building out and improving the data platform that collects, stores, and processes our vast amount of web traffic, advertising, financial, and product usage data. Your expertise and collaboration with other members of our team will be crucial in ensuring the integrity, availability, and performance of our data platform, enabling analytics engineers and partners to make data-driven decisions.

Key Responsibilities


 * Build and maintain efficient and reliable ETL software processes that ingest data from various sources into our data platform.
 * Ensure data integrity, quality, and security across all data systems and processes.
 * Collaborate with stakeholders to understand data needs and deliver solutions that meet business requirements.
 * Monitor and troubleshoot data pipeline performance, addressing any issues that arise promptly.
 * Innovate and collaborate with fellow Sr Data Engineer to help design, plan out, and improve the new data platform
 * Implement best practices for data governance, including metadata management, data cataloging, and data privacy compliance.
 * Stay current with emerging technologies and trends in data engineering and apply them to improve our data infrastructure.
   
   

Qualifications


 * Bachelor’s degree in Computer Science, Engineering, a related field, or equivalent experience.
 * 3+ years of experience in data engineering, software development, or a related role
 * Strong experience with cloud platforms like AWS, GCP, or Azure, and familiarity with data warehousing solutions like Snowflake, Redshift, or BigQuery.
 * Knowledge of software design principles, programming best practices, proper code maintenance, and CI/CD pipelines
 * Advanced Python skills
 * Proficiency in SQL
 * Solid understanding of database systems and experience with data modeling and schema design.
   
   

Preferred Experience


 * Experience with Distributed Computing i.e. Spark
 * Experience with Containerization i.e. Docker
 * Exposure to web application, marketing, or advertising data
 * Experience in the financial services or media industry.","Over 200 applicants","Full-time","Entry level","Information Technology","Online Audio and Video Media","","","","1058415","https://www.linkedin.com/jobs/view/data-engineer-at-benzinga-4341910191?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Indianapolis, IN","18 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-engineer-at-lucid-services-group-4340394728?trk=public_jobs_topcard-title","Lucid Services Group","https://www.linkedin.com/company/lucidcorps?trk=public_jobs_topcard-org-name","A client of ours in the Life Sciences space in Indianapolis is looking to expand their team by bringing on a lead Data Engineer. This role is C-H and is requiring onsite availability 2-3 days a week in Indianapolis, IN. The ideal candidate will have hands-on experience building scalable data pipelines, working within Databricks, and implementing modern data architecture patterns—particularly the Medallion Data Model. You will collaborate closely with data analysts, data scientists, and business stakeholders to ensure high-quality, reliable, and accessible data across the organization.




Key Responsibilities

 * Design, build, and maintain scalable ETL/ELT data pipelines using Databricks and related technologies.
 * Implement and optimize data architectures aligned with the Medallion Data Model (Bronze/Silver/Gold).
 * Develop and manage data workflows for ingestion, transformation, and integration from multiple sources.
 * Ensure data quality, reliability, and governance across all stages of the data lifecycle.
 * Optimize data processing performance and cost-efficiency within the Databricks environment.
 * Collaborate with cross-functional teams to support analytics, reporting, and advanced data use cases.
 * Write clear technical documentation and follow best practices for code quality and version control.




Required Skills & Qualifications

 * Bachelor’s degree in Computer Science, Information Systems, Data Engineering, or related field (or equivalent experience).
 * Strong hands-on experience with Databricks (Delta Lake, notebooks, clusters, jobs).
 * Proficient in building ETL/ELT pipelines using Python, SQL, and Spark.
 * Deep understanding of the Medallion Data Architecture and modern data modeling practices.
 * Experience working with cloud platforms (Azure, AWS, or GCP).
 * Familiarity with CI/CD workflows and infrastructure-as-code is a plus.
 * Strong problem-solving, debugging, and analytical skills.




Preferred Qualifications

 * Experience with Delta Live Tables, Unity Catalog, or MLflow.
 * Knowledge of data warehousing concepts and distributed systems.
 * Exposure to workflow orchestration tools (e.g., Airflow, ADF, Prefect).

","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","IT Services and IT Consulting","","","","10890823","https://www.linkedin.com/jobs/view/data-engineer-at-lucid-services-group-4340394728?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist - Hedge Fund","New York, United States","2 weeks ago","2025-11-17","https://www.linkedin.com/jobs/view/data-scientist-hedge-fund-at-upward-trend-4336454156?trk=public_jobs_topcard-title","Upward Trend","https://uk.linkedin.com/company/upward-trend?trk=public_jobs_topcard-org-name","Data Scientist - Alternative Data - Long/Short Hedge Fund




New York




Our client, a multibillion AUM Equity Long/Short Hedge Fund, is currently seeking a Data Scientist to join a growing Quantitative Research and Data Science team in New York City (we also have similar openings in San Francisco and Florida).




The fund was launched by alumni of one of the world's most prestigious hedge funds, and described as the US's ""biggest hedge fund startup of the year"" when it launched.




This is an opportunity to join one of the fastest growing multimanager platforms at a key stage in its growth, and build a successful career as a Quantitative Researcher.




Responsibilities include:




 * Working with Risk models
 * Portfolio Optimization and Construction
 * Factor research
 * Alpha signal generation & backtesting (e.g. from Alternative Data sources)
 * Transaction cost modelling
 * Performance attribution




About you




The ideal candidate will have 1-3 years' experience of Quantitative Research, Data Science, or Data Analytics in an Investment environment (Hedge Fund, Asset Manager, Investment Bank).




Strong preference for candidates with STEM qualifications (especially at postgrad level) from elite universities, and a proven understanding of applied data science, statistics, and financial engineering.","Over 200 applicants","Full-time","Mid-Senior level","Finance and Analyst","Investment Management","","","","75388921","https://www.linkedin.com/jobs/view/data-scientist-hedge-fund-at-upward-trend-4336454156?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Washington, DC","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/data-engineer-at-tcg-4337227386?trk=public_jobs_topcard-title","TCG","https://www.linkedin.com/company/tcginc?trk=public_jobs_topcard-org-name","You've stumbled upon the rare B Corp government contractor!


At TCG, we aim to prove that businesses can be good to their employees and responsible to their community while being profitable. We're an award-winning IT solutions provider to the Federal government seeking a Data Engineer to join our project team at a major Federal agency to help design, develop, and implement database solutions.


This position requires demonstrable experience in data management and reporting, knowledge management skills, the ability to analyze complex federal programs and objectives, and the ability to work collaboratively in teams, while also exhibiting great attention to detail. The ideal candidate is flexible, eager, enthusiastic, a self-starter, and possesses an unyielding work ethic. In this position, you will be expected to excel in a fast-paced environment and prove your high value to the team daily.




US Citizenship is required for this role. In addition, the selected applicant must submit to a government background investigation and be favorably adjudicated before their first day.


While primarily remote, this position may require occasional on-site meetings. The selected candidate must live within commuting distance of Washington, D.C.


RESPONSIBILITIES:


   
   
 * Develop using technologies such as Power BI, Python, ETL scripts and workflows, and SQL queries (including functions and stored procedures) to extract information from data sets for further processing or for display in numerous formats
   
   
 * Work with stakeholders, DBAs, data specialists, system and security personnel, and nomenclature analysts to structure and prepare content for use in database models
   
   
 * Troubleshoot complex technical issues and work closely with Federal technical managers to assist them in their project objectives
   
   
 * Collaborate with stakeholders, project managers, and technical staff to identify business requirements, create user stories with acceptance criteria, design and estimate timelines and costs, and facilitate reports
   
   
 * Take initiative in recommending application enhancements and improvements
   
   
 * Develop new and utilize existing standardized templates to accurately and concisely write requirements specifications
   
   
 * Experience developing and identifying existing and valuable metrics, conducting analysis, and identifying gaps in data
   
   
 * Experience working with relational databases and tools to collect and report financial data
   
   
 * Expertise in Microsoft Excel and pivot tables
   
   
 * Ability to adapt to rapidly changing deadlines and tasks
   
   
 * Strong analytical and problem-solving skills with the ability to decompose requirements into technical development instructions
   
   
 * Ability to work with limited direction to lead, define, develop, and distribute high-quality work products in a timely fashion
   
   
 * Ability to act as a liaison between testers, developers, clients, and other stakeholders during all phases of development
   
   
 * Attention to detail, clear communication, writing, and presentation skills
   
   
 * Ability to present and discuss quantitative data to an executive audience
   
   


REQUIRED SKILLS:


   
   
 * A minimum of 7 years of experience in software engineering, with at least 3 years focused on data management
   
   
 * Ability to work in an agile or iterative development environment, and the self-motivation to work independently
   
   
 * Experience working with Python, particularly modules centered around data movement (pandas, sqlalchemy, pyodbc, etc.)
   
   


PREFERRED SKILLS:


   
   
 * Certification in Cloud-based platforms (AWS and Azure preferred)
   
   
 * Practice working with regulatory, legal, or government data sets
   
   


EDUCATION:


   
   
 * Bachelor's degree required, preferably in Computer Science, Information Technology, or a related field; 4 years of relevant experience may be substituted for the degree requirement
   
   


TCG does not discriminate based on race, sex, color, religion, national origin, age, disability, caste, or veteran status.


Our B Corp mission is reflected in our benefits, including offerings like health care, 401K, parental leave, adoption assistance, financial planning services, student loan repayment assistance, and training budget. There's more; see for yourself.


TCG is recognized for treating employees well. In fact, in 2025, The Washington Post named TCG as a ""Top Workplace"" for the eleventh straight year based on how our employees feel about the company, the benefits TCG offers, and the work/life balance that our staff achieves. In the Washington Post Top Workplace survey, our CEO was ranked best by TCG employees' votes among all midsize companies.


Try us ... we'll make you happy.


Internal title/grade: Software Engineer, E3
Salary Range: $105,000 - $158,000



All individuals being hired to work for TCG must submit to, and successfully pass, a pre-employment background investigation prior to reporting for their first day of work. The pre-employment background investigation will include verification of employment and education, as well as, a criminal and DMV check.Additional documentation and background checks will also be required for positions that require clearance from the Federal government.","Be among the first 25 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","$105,000.00/yr - $158,000.00/yr","","","53638","https://www.linkedin.com/jobs/view/data-engineer-at-tcg-4337227386?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Bellevue, WA","1 month ago","2025-10-27","https://www.linkedin.com/jobs/view/data-engineer-at-the-dignify-solutions-llc-4341985730?trk=public_jobs_topcard-title","The Dignify Solutions, LLC","https://www.linkedin.com/company/dignify-solutions?trk=public_jobs_topcard-org-name","Data Engineering experience primarily on Spark. Someone who has worked on Azure cloud with knowledge on Azure DEVOPS (CI/CD & Infrastructure as a code), ADF, ADW & Power BI. Apache Nifi will be good to have.Power BI: Understand business requirements to set functional specifications for reporting applications Build automated reports and dashboards with the help of Power BI reporting tool Be experienced in tools and systems on MS SQL Server BI Stack, including SSRS and TSQL, Power Query, MDX, PowerBI, and DAX Be able to quickly shape data into reporting and analytics solutions Have knowledge of database fundamentals such as multidimensional database design, relational database design, and more Create functional reporting Study, analyze and understand business requirements in context to business intelligence. Design and map data models to shift raw data into meaningful insights. Utilize Power BI to build interactive and visually appealing dashboards and reports. Spot key performance indicators with apt objectives Run DAX queries and functions in Power BI Should have an edge over making DAX queries in Power BI desktop. Developing visual reports, KPI scorecards, and dashboards using Power BI desktop. Connecting data sources, importing data, and transforming data for Business intelligence.","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","75031133","https://www.linkedin.com/jobs/view/data-engineer-at-the-dignify-solutions-llc-4341985730?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist","Los Angeles, CA","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/data-scientist-at-heygen-4337194713?trk=public_jobs_topcard-title","HeyGen","https://www.linkedin.com/company/heygen?trk=public_jobs_topcard-org-name","About HeyGen

At HeyGen, our mission is to make visual storytelling accessible to all. Over the last decade, visual content has become the preferred method of information creation, consumption, and retention. But the ability to create such content, in particular videos, continues to be costly and challenging to scale. Our ambition is to build technology that equips more people with the power to reach, captivate, and inspire audiences.

Learn more at www.heygen.com. Visit our Mission and Culture doc here.

Position Overview:

We're looking for a talented, curious, driven, and self-starting data scientist to join our team. The ideal candidate is a critical thinker familiar with SaaS products and metrics, has a strong background in statistics and data modeling, can clearly communicate complex concepts to a variety of audiences, and is excited to partner with engineering to implement the data infrastructure and stack for a rapidly growing startup. This is a highly dynamic, fast-paced environment where you'll be trusted with real ownership — from defining our data stack to shaping how insights guide our product roadmap.

You'll help lay the foundation of our data culture, working across engineering, product, and business teams to ensure data drives decisions at every level.

Key Responsibilities:



Data Tooling & Culture


 * Play a critical role in defining and setting up our data and experimentation stack
 * Partner with engineering to ensure our data is clean, scalable, and usable, considering real-world deployment constraints
 * Create and champion best practices to create a data-driven culture
   
   

Product Analytics & Insights


 * Analyze large, complex datasets to uncover patterns, trends, and insights to inform product and business decisions
 * Help define the product roadmap through analysis of the user journey, user behaviors, and product trends
 * Design, launch, and analyze A/B tests or data-led product features
 * Partner with product teams and leadership to define new metrics and make prioritization decisions
   
   

Business Intelligence & Visualizations


 * Build and maintain production-quality dashboards so that team members can access product and business metrics, in a self-serve way
 * Ensure BI tools are dependable and up-to-date
 * Translate complex analyses into simple, visual stories that drive alignment and action.
   
   

Collaboration and Communication


 * Collaborate with cross-functional teams to define and refine model requirements
 * Communicate findings and insights effectively to both technical and non-technical stakeholders
 * Share findings with the rest of the company, helping drive better decision making across marketing, sales, and product teams
   
   

Preferred Qualifications:


 * Bachelor's degree in a quantitative field (Computer Science, Statistics, Mathematics, Business Analytics or related field)
 * 1+ years of relevant work experience in Data Science, Business Intelligence, Product Analytics, or a related function
 * Expert in SQL and proficiency in at least one scripting language (R or Python)
 * Defined, implemented, and operationalized new feature and product-level metrics from scratch
 * Excellent communication skills with demonstrated ability to communicate with product managers, engineers, and executives
 * Excellent problem-solving skills and ability to work in a collaborative team environment
   
   

What HeyGen Offers:


 * Competitive salary and benefits package
 * Dynamic and inclusive work environment focused on innovation and creativity
 * Opportunities for professional growth and skill development
 * Collaborative culture that values teamwork and employee input
 * Access to state-of-the-art technologies and tools
   
   

Salary Range

$120,000 – 145,000 annually

Please note that the salary information is a general guideline only. HeyGen considers factors such as scope and responsibilities of the position, candidate's work experience, education/training, key skills, and internal equity, as well as location, market and business considerations when extending an offer. As part of our total rewards package, HeyGen offers comprehensive benefits including a 401k plan, health benefits, generous PTO, a parental leave program and emotional health resources.

HeyGen is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.

Join us at HeyGen and be part of a team that's reshaping the world of visual storytelling!","Over 200 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Online Audio and Video Media","$120,000.00/yr - $145,000.00/yr","","","82350899","https://grnh.se/k4ssrj7s7us","EXTERNAL",""
"Data Engineer","Denver Metropolitan Area","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/data-engineer-at-viecure-4337110627?trk=public_jobs_topcard-title","VieCure","https://www.linkedin.com/company/viecure?trk=public_jobs_topcard-org-name","Are you interested in leading the transformation of cancer care through putting world-leading scientific data and knowledge in the hands of doctors and other members of the medical team? Do you have a passion for solutions that empower patients to take charge of their care and bring world-class solutions to winning the cancer battle? If so, join our team at VieCure, the company that promises to revolutionize the way cancer care is delivered.




At VieCure, we are dedicated to transforming the oncology space through innovative technology solutions. Our mission is to empower clinicians and patients with data-driven insights, supporting personalized cancer care. Join our team of passionate professionals working to make a difference in people’s lives.




We are seeking a skilled and collaborative Data Engineer to join our team in Denver, CO. The ideal candidate will work alongside our DBA and API/Services team to design, build, and maintain scalable data solutions that support the company's growing needs. This role is critical in ensuring the seamless flow, transformation, and quality of data across systems to drive operational and analytical excellence.




Key Responsibilities:

 * Data Pipeline Development: Design, build, and maintain scalable and reliable ETL/ELT pipelines to support data ingestion, transformation, and loading into Azure SQL and SQL Server databases.
 * Data Integration: Collaborate with the API/Services team to develop seamless integrations between APIs, microservices, and database systems, ensuring efficient data exchange and synchronization.
 * Data Modeling: Work with the DBA to design and implement optimized database schemas and data models that align with application and reporting requirements.
 * Data Quality Assurance: Implement processes and tools to monitor, validate, and ensure the quality and integrity of the data across the pipeline.
 * Cross-Team Collaboration: Act as a liaison between the DBA, API/Services team, and business stakeholders to understand data requirements and deliver solutions that support business goals.
 * Documentation: Maintain comprehensive documentation for pipelines, data models, and processes to ensure smooth knowledge transfer and onboarding.
 * Security & Compliance: Ensure data engineering practices adhere to data security, privacy, and compliance regulations, working alongside the DBA to enforce database-level policies.
 * Data Insights Enablement: Enable analytics and reporting by preparing data for visualization and analysis (e.g., aggregating or transforming data for Power BI, dashboards, etc.).




Experience & Skills:

 * Proven experience with Azure SQL and SQL Server.
 * Hands-on experience building and maintaining ETL/ELT pipelines.
 * Familiarity with data integration best practices and tools.
 * Knowledge of Power BI or similar visualization tools.
 * Strong understanding of relational database design and data modeling.
 * Experience in cross-functional collaboration and stakeholder communication.
 * Understanding of data security, privacy, and compliance considerations.
 * Strong analytical and problem-solving skills.




Preferred Qualifications:

 * Familiarity with tools such as Azure Data Factory or SSIS.
 * Experience working in a healthcare or regulated environment.
 * Certifications such as Azure Data Engineer Associate (preferred but not required).




Work Environment:

This position is full-time, on-site at our Denver, CO office. We value collaboration and teamwork, and our office culture is designed to foster innovation and creativity.




Why Join Us?

 * Competitive salary and benefits package.
 * Opportunity to work on impactful projects in the healthcare technology space.
 * Collaborative and supportive work environment.
 * A chance to make a tangible difference in patients’ lives.




How to Apply: If you are passionate about data engineering and want to contribute to a meaningful mission, we want to hear from you!","Over 200 applicants","Full-time","Mid-Senior level","Engineering, Information Technology, and Health Care Provider","Software Development, IT System Custom Software Development, and Hospitals and Health Care","$115,000.00/yr - $140,000.00/yr","","","10788836","https://www.linkedin.com/jobs/view/data-engineer-at-viecure-4337110627?trk=public_jobs_topcard-title","EASY_APPLY","Vision insurance
Dental insurance
401(k)
Medical insurance
Paid maternity leave"
"Data Analyst, AI Factory Operations","Santa Clara, CA","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/data-analyst-ai-factory-operations-at-nvidia-4337560462?trk=public_jobs_topcard-title","NVIDIA","https://www.linkedin.com/company/nvidia?trk=public_jobs_topcard-org-name","NVIDIA has been transforming computer graphics, PC gaming, and accelerated computing for more than 25 years. It’s a unique legacy of innovation that’s fueled by great technology—and amazing people. Today, we’re tapping into the unlimited potential of AI to define the next era of computing. An era in which our GPU acts as the brains of computers, robots, and self-driving cars that can understand the world. Doing what’s never been done before takes vision, innovation, and the world’s best talent. As an NVIDIAN, you’ll be immersed in a diverse, supportive environment where everyone is inspired to do their best work. Come join the team and see how you can make a lasting impact on the world.

At NVIDIA, we focus on advancing what’s possible in parallel and visual computing. Join our Business Operations team as a Data Analyst in AI Factory Operations. You will have a meaningful role in transforming how we deploy and manage our powerful AI technologies. This outstanding opportunity allows you to apply your data analysis skills alongside operational knowledge to increase efficiency and visibility across our AI initiatives in Santa Clara, CA.

What You'll Be Doing


 * Own and complete the building and development of reporting solutions across SFDC, Wrike, Power BI, and related platforms based on field and management needs.
 * Lead needs assessments and requirements analyses to identify efficient tools and processes for business reporting.
 * Build, analyze, and present data-driven insights and forecasts, offering actionable recommendations to collaborators.
 * Develop and maintain NVIS dashboards that deliver clarity and performance visibility across key operational metrics.
 * Collaborate with cross-functional teams—engineering, operations, planning, OEM partners, and logistics—to document and optimize lifecycle processes.
 * Serve as the primary contact for Data Analytics process blocking issues for lifecycle accountability, ensuring efficient and transparent issue resolution.
 * Monitor operational performance, document workflows, and drive continuous improvement initiatives across data and logistics functions.
   
   

What We Need To See


 * Bachelor’s degree or equivalent experience.
 * 5+ years of experience overall, with at least 4 years in data reporting, process mapping, supply chain, logistics, or related program management.
 * Verified background in building dashboards and analytics through SFDC, Wrike, Power BI, or related tools.
 * Strong understanding of information systems integration, reporting methodologies, and data visualization guidelines.
 * Excellent analytical, problem-solving, and communication skills for cross-functional collaboration.
 * Demonstrated ability to detail and refine processes, manage reporting tasks, and synthesize insights for executive audiences.
   
   

NVIDIA is widely viewed as one of the technology world's most desirable employers due to its groundbreaking technologies. Employee will greatly benefit working at NVIDIA, gain valuable experience in operational excellence, diversity, and expand abilities in machine learning and AI. If you are software and support service operationalization focused, creative and driven, we want to hear from you.

Widely considered to be one of the technology world’s most desirable employers, NVIDIA offers highly competitive salaries and a comprehensive benefits package. As you plan your future, see what we can offer to you and your family www.nvidiabenefits.com/

Your base salary will be determined based on your location, experience, and the pay of employees in similar positions. The base salary range is 92,000 USD - 143,750 USD.

You will also be eligible for equity and benefits .

Applications for this job will be accepted at least until November 23, 2025.NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.

JR2008470

","Over 200 applicants","Full-time","Entry level","Sales","Computer Hardware Manufacturing, Software Development, and Computers and Electronics Manufacturing","$92,000.00/yr - $143,750.00/yr","","","3608","https://www.linkedin.com/jobs/view/data-analyst-ai-factory-operations-at-nvidia-4337560462?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Herndon, VA","2 weeks ago","2025-11-14","https://www.linkedin.com/jobs/view/data-engineer-at-the-swift-group-llc-4334183715?trk=public_jobs_topcard-title","The Swift Group, LLC","https://www.linkedin.com/company/the-swift-group-inc.?trk=public_jobs_topcard-org-name","The Swift Group is a privately held, mission-driven and employee-focused services and solutions company headquartered in Reston, VA. Our capabilities include Software Development, Engineering & IT, Data Science, Cyber Enablement, Logistics, and Training. Founded in 2019, Swift supports Civilian, Defense, and Intelligence Community customers across the country and around the globe.

We are looking for a skilled Data Engineer to join our dynamic team in Herndon, VA. In this role, you will influence how data is designed, governed, moved, and leveraged across critical customer environments. This is an opportunity for an engineer who loves solving complex data problems, thrives in a collaborative environment, and wants to build scalable pipelines and platforms that accelerate outcomes.

Responsibilities


 * Architect, build, and optimize secure, scalable, and automated data pipelines across structured and unstructured sources
 * Design and maintain data models, warehouse schemas, and metadata structures to support analytics, reporting, and decision-making
 * Lead development of ETL/ELT workflows using modern tools, frameworks, and cloud-based technologies
 * Partner with Data Scientists and Software Engineers to prepare, cleanse, transform, and annotate data for use cases
 * Design and implement advanced table structures, indexing strategies, and performance optimizations for large-scale datasets
 * Evaluate and integrate third-party tools, APIs, and open-source libraries for text extraction, transformation, and automation
 * Develop and enhance Python-based data extraction and processing utilities (PDF, MS Word, XML, logs, etc.)
 * Create and maintain relational data structures and loading routines to support analytical workloads
 * Produce real-time and ad-hoc dashboards, metrics, and operational reports to answer mission-critical questions
 * Support and mature data governance and metadata cataloging
 * Document data architectures, pipelines, infrastructure, and automation patterns
 * Participate in Agile ceremonies and contribute to sprint planning, reviews, and technical prioritization
 * Provide technical mentorship and knowledge-sharing to engineering teammates and mission stakeholders
   
   

Requirements


 * 5+ years of experience in data engineering, software engineering, or similar technical roles
 * Proficiency in Python, including custom script development and leveraging external packages / APIs
 * Experience extracting text and structured data from multiple formats (PDF, MS Word, XML, logs, JSON, etc.)
 * Strong experience with SQL development, query optimization, and performance tuning (Oracle strongly preferred)
 * Proven experience designing and implementing ETL/ELT pipelines and data workflows
 * Hands-on experience with regular expressions, data parsing, cleansing, and transformation logic
 * Experience designing and modifying data schemas, relational models, and ingestion patterns
 * Familiarity with data warehousing, metadata management, and data modeling best practices
 * Experience using version control systems (e.g., Git/GitHub)
 * Ability to communicate complex data concepts to both technical and non-technical audiences
 * US Citizenship and an active TS/SCI with Polygraph security clearance required
   
   

Do you know anyone for this position, or other positions open at The Swift Group? We offer a $5,000 bonus for any referral candidate we hire, paid out at the new hire’s 90-day mark.

#Onsite

The Swift Group and Subsidiaries are an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status, or any other protected class.

Pay Range: $49,996.80 - $290,004.00

Pay ranges are a general guideline and not intended as a guaranteed and/or implied final compensation or salary for this job opening. Determination of official compensation or salary relies on several different factors including, but not limited to: level of position, complexity of job responsibilities, geographic location, work experience, education, certifications, Federal Government contract labor categories, and contract wage rates.

At The Swift Group and Subsidiaries, you will receive comprehensive benefits including but not limited to: healthcare, wellness, financial, retirement, education, and time off benefits.

","Be among the first 25 applicants","Full-time","Entry level","Information Technology, Analyst, and General Business","IT Services and IT Consulting","$49,996.80/yr - $290,004.00/yr","Dan Irish","https://www.linkedin.com/in/dtirish","15413468","https://www.linkedin.com/jobs/view/data-engineer-at-the-swift-group-llc-4334183715?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Fort Bliss, TX","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/data-engineer-at-cape-henry-associates-acquired-by-janus-research-group-4323614117?trk=public_jobs_topcard-title","Cape Henry Associates, Acquired by JANUS Research Group","https://www.linkedin.com/company/cape-henry-associates-inc?trk=public_jobs_topcard-org-name","Location: Fort Bliss, TX (routine CONUS travel; OCONUS as mission dictates) or Remote (preference for Ft. Eustis, VA or Austin, TX)

Clearance: Active Secret

About The Role

Join JANUS as a Data Engineer supporting Army modernization. You will design and operate secure, scalable data pipelines that integrate operational, simulation, and enterprise data into analysis-ready formats. Your work will enable real-time dashboards, predictive analytics, and decision support products used across Army event cycles and campaign planning.

Key Responsibilities


 * Build & Operate Pipelines: Design, implement, and optimize ETL/ELT pipelines using SQL, Python, and Azure services (Data & Storage, Databricks, Purview).
 * Integrate Data Sources: Ingest and standardize diverse Army datasets into relational databases with clear lineage, metadata, and quality controls.
 * Support Army Operations: Enable near-real-time data products that inform analytics, dashboards, and assessments supporting Army staff and decision-makers.
 * Cloud Engineering: Leverage Azure PaaS solutions to design scalable, secure data integration strategies aligned with AIMD’s enterprise architecture.
 * Governance & Security: Apply OPSEC, IA, and PII safeguards across workflows; ensure compliance with Army data governance practices.
 * Collaboration: Work with software development teams, stakeholders, and analysts to ensure data solutions meet mission requirements and PRS-driven timelines.
   
   

Qualifications


 * Education: Bachelor’s degree in Computer Science, Information Systems, Engineering, Math, or related field. Equivalent experience may substitute.
 * Clearance: Active Secret clearance required.
 * Experience:
    * 3–5+ years in data engineering, ETL, or data wrangling.
    * Hands-on SQL and scripting/ETL (Python or similar).
    * Experience with Azure cloud services (Data & Storage, Analytics, Databricks, Purview) preferred.
    * Familiarity with DoD/Army datasets, event-driven deliverables, or mission data environments a plus.

 * Skills:
    * Strong problem-solving and analytical skills, including data modeling and blending.
    * Effective communicator, able to document work clearly and engage with Army stakeholders.
    * Motivated team player, comfortable in fast-paced, multi-stakeholder environments.
      

Benefits

401(k), Paid Time Off (PTO), Paid Holidays, Medical and Dental Plans, Life and Disability insurance, Education Assistance (and more).

JANUS strives to provide opportunities for career growth through training and development. We also offer an attractive comprehensive benefit package to include health and welfare plans and financial products. As part of a total rewards program, employees can benefit from our referral bonus program, and other various employee awards. JANUS Research Group takes pride in our benefit package and rewards program which has earned us the certification of a Great Place to Work™

JANUS Research Group provides reasonable accommodation so that qualified applicants with a disability may participate in the selection process. Please advise us of any accommodations you request to express interest in a position by e-mailing: Alisha Pollard, Director of Human Resources at alisha.pollard@janusresearch.com or calling (706) 364-9100. Please state your request for assistance in your message. Only reasonable accommodation requests related to applying for a specific position within JANUS Research Group will be reviewed at the e-mail address and phone number supplied. Thank you for considering a career with JANUS Research Group.

JANUS Research Group participates in the Electronic Employment Verification Program. Please click the E-Verify link below for more information.

E-Verify

JANUS Research Group is an equal opportunity/ affirmative action employer. It is company policy to provide equal opportunity in all areas of employment practice without regard to race, color, religion, sex, sexual orientation, national origin, age, marital status, veteran status, citizenship, or disability.

This contractor and subcontractor shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities and prohibit discrimination against all individuals based on their race, color, religion, sex, or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment qualified individuals without regard to race, color, religion, sex, national origin, protected veteran status or disability.","Be among the first 25 applicants","Full-time","Entry level","Strategy/Planning and Information Technology","Government Relations","","","","434080","https://www.linkedin.com/jobs/view/data-engineer-at-cape-henry-associates-acquired-by-janus-research-group-4323614117?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Manager, Data Engineering","San Francisco, CA","2 weeks ago","2025-11-14","https://www.linkedin.com/jobs/view/senior-manager-data-engineering-at-strava-4340872376?trk=public_jobs_topcard-title","Strava","https://www.linkedin.com/company/strava-inc.?trk=public_jobs_topcard-org-name","About This Role

Strava is the app for active people. With over 150 million athletes in more than 185 countries, Strava is where connection, motivation, and personal bests thrive. No matter your activity, gear, or goals, we help you find your crew, crush your milestones, and keep moving forward. Start your journey with Strava today.

Our mission is simple: to motivate people to live their best active lives. We believe in the power of movement to connect and drive people forward.

We are seeking a strategic and hands-on Senior Manager, Data Engineering to lead a team focused on building and optimizing data pipelines and data models that enable best-in-class data science, analytics, and self-service business intelligence. You will be instrumental in realizing our vision that key decisions and products at Strava are greatly enriched with data to benefit athletes and the business. This role requires a balance of people leadership, technical oversight, and individual contribution to set the strategic direction for our core data assets. You will partner tightly with Analytics, Data Science, and Data Platform teams across the company.

We follow a flexible hybrid model that translates to more than half your time on-site in our San Francisco office — three days per week.

What You’ll Do:


 * Act as the player-coach for our Data Engineering function, fostering a culture of technical excellence and ownership.
 * Define the long-term vision and technical roadmap for Strava’s core data platform, including the development of scalable, robust, and efficient ETL/ELT pipelines.
 * Drive initiatives to significantly improve the quality, integrity, and availability of Strava’s data assets, implementing best-in-class monitoring and alerting systems.
 * Collaborate with Analytics, Data Science, and Product teams to enable advanced data consumption, experimentation, and self-service business intelligence across the company.
 * Represent the Data Engineering team in cross-functional strategic planning and collaborate with the broader data community to elevate our technological craftsmanship and data governance standards.
   
   
   

You Will Be Successful Here By:


 * Translating the company's business objectives into a compelling technical strategy for the Data Engineering team, ensuring all data infrastructure supports business relevance.
 * Prioritizing and driving execution of projects that significantly improve the scalability, efficiency, and extensibility of our data models and systems.
 * Serving as a key technical and organizational mentor for your team, guiding them on complex architectural decisions and best practices for modern data development.
 * Proactively anticipating the data needs of a rapidly growing platform, fostering a culture that prioritizes data integrity, security, and privacy.
   
   
   

What You’ll Bring to the Team:


 * You have 7+ years of experience in data engineering, data platform, or a related quantitative domain.
 * You have 3+ years of experience leading and mentoring high-performing data engineering teams.
 * You are an advanced user of SQL and have developed production-grade data pipelines using languages like Python, Scala, or Java.
 * You have deep experience implementing and maintaining modern ETL/ELT orchestration systems (e.g., Airflow, dbt) and cloud data infrastructure (e.g., Snowflake, BigQuery, AWS, GCP).
 * You have a strong track record of driving data quality, governance, and the implementation of tools for data cataloging and monitoring.
 * You understand underlying infrastructure and engineering best practices (e.g., Kubernetes, CI/CD, software development lifecycle) with the ability to influence architectural decisions.
   
   
   

Compensation Overview:

At Strava, we know our employees are the most important ingredient to our success, and our compensation and total rewards programs reflect that. We take a market-based approach to pay, and pay may vary depending on the department and your location. Salary ranges are categorized into one of three zones based on a cost of labor index for that geographic area. We will determine the candidate’s starting pay based on job-related skills, experience, qualifications, work location, and market conditions. We may modify these ranges in the future. For more information, please contact your talent partner.

Compensation: $255,000 - $271,000. This range reflects base compensation only and does not include equity or benefits. Your recruiter can share more details about the full compensation package during the hiring process.

For more information on benefits, please click here.

Why Join Us?

Movement brings us together. At Strava, we’re building the world’s largest community of active people, helping them stay motivated and achieve their goals.

Our global team is passionate about making movement fun, meaningful, and accessible to everyone. Whether you’re shaping the technology, growing our community, or driving innovation, your work at Strava makes an impact.

When you join Strava, you’re not just joining a company—you’re joining a movement. If you’re ready to bring your energy, ideas, and drive, let’s build something incredible together.

Strava builds software that makes the best part of our athletes’ days even better. Just as we’re deeply committed to unlocking their potential, we’re dedicated to providing a world-class, inclusive workplace where our employees can grow and thrive, too. We’re backed by Sequoia Capital, TCV, Madrone Partners and Jackson Square Ventures, and we’re expanding in order to exceed the needs of our growing community of global athletes. Our culture reflects our community. We are continuously striving to hire and engage teammates from all backgrounds, experiences and perspectives because we know we are a stronger team together.

Strava is an equal opportunity employer. In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

California Consumer Protection Act Applicant Notice","144 applicants","Full-time","Mid-Senior level","Information Technology","Software Development","$255,000.00/yr - $271,000.00/yr","","","279570","https://job-boards.greenhouse.io/strava/jobs/7395474","EXTERNAL",""
"Data Science Analyst","Rochester, MN","2 weeks ago","2025-11-15","https://www.linkedin.com/jobs/view/data-science-analyst-at-mayo-clinic-4336225015?trk=public_jobs_topcard-title","Mayo Clinic","https://www.linkedin.com/company/mayo-clinic?trk=public_jobs_topcard-org-name","City Rochester

State MN

Remote YES

Department Mayo Clinic Platform

Why Mayo Clinic

Mayo Clinic is top-ranked in more specialties than any other care provider according to U.S. News & World Report. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans – to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic.

Benefits Highlights


 * Medical: Multiple plan options.
 * Dental: Delta Dental or reimbursement account for flexible coverage.
 * Vision: Affordable plan with national network.
 * Pre-Tax Savings: HSA and FSAs for eligible expenses.
 * Retirement: Competitive retirement package to secure your future.
   
   

Responsibilities

Data Scientists at Mayo Clinic perform detailed analysis of large bodies of heterogeneous data in order to discover new patterns and insights having an impact upon patient health and augmenting human capabilities. Candidate has expertise in AI, machine learning, deep learning, statistical data processing, regression techniques, neural networks, decision trees, clustering, pattern recognition, probability theory and data science methods used to analyze data.

May work with knowledge architects, informaticians and clinicians at Mayo, and partner outside companies to develop and deploy applications to bring AI and analytic solutions to nontechnical users, often at the point of care. Applies and modifies existing scripts or software applications to support data management, data extraction, data analysis, and AI as required May develop predictive models on datasets to address various business problems by leveraging statistical modeling, operations research, machine learning, or data mining techniques. May provide Consultative Services to departments/divisions and/or support scientific projects under the guidance of a designated senior level data scientist.

Other Responsibilities


 * Provides data insights for business problems that can be approached with analytics techniques to collect, explore, and extract insights from structured and unstructured data.
 * Has expertise in the data science methods used to analyze data, and knowledge of data types, topics, and scientific challenges and approaches.
 * Executes analytical procedures in the framework of a specific project work request.
 * Creates or modifies scripts or software applications to support data management, data extraction and data analysis as required.
 * Contributes to the interpretation of data analysis and to writing reports.
 * Helps customers understand the data set and provide training and suggestions for improvement on the data request.
 * Leverages communication and interpersonal skills and works with subject matter experts
 * Presents findings in easy to understand terms for the business or clinical practice.
   
   

Qualifications

A Bachelor’s degree in a relevant field such as engineering, mathematics, computer science, health science, or other analytical/quantitative and a minimum of three years of professional or research experience in data science will be considered.

The preferred candidate will possess a Master’s degree or a PhD in a relevant field such as engineering, mathematics, computer science, health science, or other analytical/quantitative field and a minimum of one year of professional or research experience in data. Demonstrated ability to develop predictive models to address various business problems through leveraging advanced statistical modeling, machine learning, or data mining techniques. May provide consultative services to departments/divisions and committees. Demonstrated application of several problem-solving methodologies, planning techniques, continuous improvement methods, and analytical tools and methodologies (e.g. machine learning, statistical packages, modeling, etc.) required. Incumbent must have ability to manage a varied workload of projects with multiple priorities and stay current on healthcare trends and enterprise changes. Interpersonal skills and time management skills are required. Requires strong analytical skills and the ability to identify and recommend solutions, advanced computer application skills and a commitment to customer service. Experience with data modeling and date exploration tools.

Exemption Status

Exempt

Compensation Detail

$100,339 - $140,462 / year

Benefits Eligible

Yes

Schedule

Full Time

Hours/Pay Period

80

Schedule Details

Monday - Friday, Business Hours 100% Remote. 10%+ travel This vacancy is not eligible for sponsorship/ we will not sponsor or transfer visas for this position. Also, Mayo Clinic DOES NOT participate in the F-1 STEM OPT extension program.

Weekend Schedule

Not Applicable

International Assignment

No

Site Description

Just as our reputation has spread beyond our Minnesota roots, so have our locations. Today, our employees are located at our three major campuses in Phoenix/Scottsdale, Arizona, Jacksonville, Florida, Rochester, Minnesota, and at Mayo Clinic Health System campuses throughout Midwestern communities, and at our international locations. Each Mayo Clinic location is a special place where our employees thrive in both their work and personal lives. Learn more about what each unique Mayo Clinic campus has to offer, and where your best fit is.

Equal Opportunity

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender identity, sexual orientation, national origin, protected veteran status or disability status. Learn more about the ""EOE is the Law"" . Mayo Clinic participates in E-Verify and may provide the Social Security Administration and, if necessary, the Department of Homeland Security with information from each new employee's Form I-9 to confirm work authorization.

Recruiter

Julie Melton","Over 200 applicants","Full-time","Entry level","Information Technology","Hospitals and Health Care","$100,339.00/yr - $140,462.00/yr","","","4725","https://jobs.mayoclinic.org/job/rochester/data-science-analyst/33647/88432727728","EXTERNAL",""
"Software Engineer II, Data Engineering","Sunnyvale, CA","2 weeks ago","2025-11-13","https://www.linkedin.com/jobs/view/software-engineer-ii-data-engineering-at-doordash-4092898866?trk=public_jobs_topcard-title","DoorDash","https://www.linkedin.com/company/doordash?trk=public_jobs_topcard-org-name","About The Team

Data is at the foundation of DoorDash success. The Data Engineering team builds database solutions for various use cases including reporting, product analytics, marketing optimization and financial reporting. By implementing pipelines, data structures, and data warehouse architectures; this team serves as the foundation for decision-making at DoorDash.

About The Role

DoorDash is looking for a Softare Engineer II to be a technical powerhouse to help us scale our data infrastructure, automation and tools to meet growing business needs.

You're excited about this opportunity because you will…


 * Work with business partners and stakeholders to understand data requirements
 * Work with engineering, product teams and 3rd parties to collect required data
 * Design, develop and implement large scale, high volume, high performance data models and pipelines for Data Lake and Data Warehouse
 * Develop and implement data quality checks, conduct QA and implement monitoring routines
 * Improve the reliability and scalability of our ETL processes
 * Manage a portfolio of data products that deliver high-quality, trustworthy data
 * Help onboard and support other engineers as they join the team
   
   

We're excited about you because…


 * 3+ years of professional experience working in data engineering, business intelligence, or a similar role
 * Proficiency in programming languages such as Python/Java
 * 3+ years of experience in ETL orchestration and workflow management tools like Airflow, Flink, Oozie and Azkaban using AWS/GCP
 * Expert in Database fundamentals, SQL and distributed computing
 * 3+ years of experience with the Distributed data/similar ecosystem (Spark, Hive, Druid, Presto) and streaming technologies such as Kafka/Flink.
 * Experience working with Snowflake, Redshift, PostgreSQL and/or other DBMS platforms
 * Excellent communication skills and experience working with technical and non-technical teams
 * Knowledge of reporting tools such as Tableau, Superset and Looker
 * Comfortable working in fast paced environment, self starter and self organizing
 * Ability to think strategically, analyze and interpret market and consumer information
 * You must be located near one of our engineering hubs indicated above
   
   

We use Covey as part of our hiring and / or promotional process for jobs in NYC and certain features may qualify it as an AEDT. As part of the evaluation process we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound on August 21, 2023.

Please see the independent bias audit report covering our use of Covey here.

Compensation

The successful candidate's starting pay will fall within the pay range listed below and is determined based on job-related factors including, but not limited to, skills, experience, qualifications, work location, and market conditions. Base salary is localized according to an employee’s work location. Ranges are market-dependent and may be modified in the future.

In addition to base salary, the compensation for this role includes opportunities for equity grants. Talk to your recruiter for more information.

DoorDash cares about you and your overall well-being. That’s why we offer a comprehensive benefits package to all regular employees, which includes a 401(k) plan with employer matching, 16 weeks of paid parental leave, wellness benefits, commuter benefits match, paid time off and paid sick leave in compliance with applicable laws (e.g. Colorado Healthy Families and Workplaces Act). DoorDash also offers medical, dental, and vision benefits, 11 paid holidays, disability and basic life insurance, family-forming assistance, and a mental health program, among others.

To learn more about our benefits, visit our careers page here.

See Below For Paid Time Off Details


 * For salaried roles: flexible paid time off/vacation, plus 80 hours of paid sick time per year.
 * For hourly roles: vacation accrued at about 1 hour for every 25.97 hours worked (e.g. about 6.7 hours/month if working 40 hours/week; about 3.4 hours/month if working 20 hours/week), and paid sick time accrued at 1 hour for every 30 hours worked (e.g. about 5.8 hours/month if working 40 hours/week; about 2.9 hours/month if working 20 hours/week).
   
   

The national base pay ranges for this position within the United States, including Illinois and Colorado.

I4

$130,600—$192,000 USD

I5

$159,800—$235,000 USD

I6

$193,800—$285,000 USD

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

Our Commitment to Diversity and Inclusion

We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on “protected categories,” we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.

Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.

If you need any accommodations, please inform your recruiting contact upon initial connection.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","","","","3205573","https://www.linkedin.com/jobs/view/software-engineer-ii-data-engineering-at-doordash-4092898866?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist","Chicago, IL","13 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-scientist-at-fairlife-llc-4340176701?trk=public_jobs_topcard-title","fairlife, LLC","https://www.linkedin.com/company/fairlife-llc?trk=public_jobs_topcard-org-name","fairlife, LLC is a Chicago-based nutrition company that creates great-tasting, nutrition-rich and dairy products to nourish consumers.

With over $3B in annual retail sales, fairlife's portfolio of delicious, lactose-free, real dairy products includes: fairlife® ultra-filtered milk; Core Power® High Protein Shakes, a sports nutrition drink to support post-workout recovery; fairlife® nutrition plan™, a nutrition shake to support the journey to better health.

A wholly owned subsidiary of The Coca-Cola company, fairlife, LLC has been recognized by both Fast Company and Nielsen for its industry leading innovation.

To learn more about fairlife and its complete line of products, please visit fairlife.com.

job purpose: The Data Scientist will play a key role in advancing fairlife's vision of establishing a world-class Decision Intelligence ecosystem. This role entails supporting the design, development, and delivery of AI and ML models including production optimization, quality control and anomaly detection, predictive maintenance, supply chain forecasting, and real-time operational analytics. The role will drive innovation and excellence in data science capability, empowering fairlife to leverage data-driven insights for enhanced decision-making and operational efficiency.

responsibilities:


 * Collaborate with the Senior Data Scientist to design, develop, and deploy AI and ML models supporting analytics and business objectives
 * Engineer and maintain scalable data pipelines for AI/ML workflows
 * Enable AI adoption by developing reusable components, APIs, and automation scripts
 * Support model lifecycle management, including monitoring, retraining, and performance optimization
 * Implement MLOps best practices for version control, CI/CD, and automated deployment
 * Assist in the development of advanced analytics dashboards and tools to communicate model results
 * Apply prompt engineering and model fine-tuning techniques to improve AI solution effectiveness
 * Ensure responsible AI practices, including fairness, transparency, and compliance
 * Gather, clean, and analyze large and complex datasets to support AI initiatives
 * Conduct experiments and statistical analyses to answer business questions and validate AI models
 * Stay current with emerging AI technologies and recommend innovative solutions
   
   

skills/qualifications required:


 * 2-4+ years of relevant experience in data science, AI engineering, or related fields
 * Bachelor's or Master's in Data Science, Computer Science, Statistics, Engineering, or a related STEM field
 * Experience in data cleaning, exploration, and analysis
 * Hands-on experience with machine learning and deep learning frameworks (e.g., TensorFlow, PyTorch, Scikit-learn)
 * Proficiency in Python and SQL for data manipulation, analysis, and model development
 * Familiarity with cloud platforms (Azure/Fabric, AWS, or GCP) for scalable AI/ML deployment
 * Experience with MLOps tools and practices (e.g., MLflow, Kubeflow, CI/CD pipelines)
 * Knowledge of AI enablement concepts, including prompt engineering, model fine-tuning, and responsible AI practices
 * Ability to visualize data and model results using tools like Power BI, Tableau, Matplotlib, or Seaborn
 * Strong communication skills for collaborating with business and technical teams
 * Experience in manufacturing and supply chain (preferred)
   
   

location: Chicago, IL

reports to: Senior Data Scientist, Decision Intelligence

travel: < 10%

exempt vs. nonexempt: exempt


 * Base pay offered may vary depending on geography, job-related knowledge, skills, and experience. A full range of medical, financial, and/or other benefits, dependent on the position, is offered.
   
   

Base pay range:

$80,000—$100,000 USD

fairlife, LLC is an equal opportunity employer. We do not discriminate on the basis of race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. All qualified applicants and employees will be given equal opportunity. Selection decisions are based on job-related factors.

In addition to its nondiscrimination commitment, the Company will also provide reasonable accommodation of qualified individuals with known disabilities unless doing so would impose an undue hardship on the Company. If you have a disability and would like to request accommodation in order to apply for a position with us, please email careers@fairlife.com.

For Recruitment Agencies

At fairlife, we manage the majority of our hiring internally through our dedicated Talent Acquisition team, which is actively engaged in direct candidate sourcing. Most of our roles are filled through applications submitted via our careers site or through direct outreach by our team.

As our recruitment is primarily handled in-house, we work only occasionally with external agencies, and only those on our existing, pre-approved vendor list. At this time, we are not reviewing or expanding that list.

Unsolicited resumes or submissions from external agencies not authorized by our Talent Acquisition team will be considered direct candidate applications. As such, fairlife will not assume responsibility for any placement fees associated with these submissions.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Technology, Information and Internet","$80,000.00/yr - $100,000.00/yr","","","3193489","https://grnh.se/2tx99wba7us","EXTERNAL",""
"Data Engineer","New York, NY","4 days ago","2025-11-28","https://www.linkedin.com/jobs/view/data-engineer-at-candid-health-4339389148?trk=public_jobs_topcard-title","Candid Health","https://www.linkedin.com/company/candid-health?trk=public_jobs_topcard-org-name","The Opportunity

We’re looking for a passionate and skilled Data Engineer to join our fast growing data team to revolutionize healthcare billing products and systems that directly address the needs of our customers. As an early Data Engineer, you’ll play a key role in designing, building, and supporting the next generation of our data infrastructure. This is an opportunity to get in at the ground floor of designing and building something exciting, new, secure, durable, performant, and maintainable.

What You’ll Do


 * Collaborate with leadership and other stakeholders including engineering, delivery, product, and customers to understand Candid’s data needs. Work with product and engineering to understand the long-term product strategy and broader technical architecture. Work with customers to understand their needs and how best to address them in a scalable way.
 * Expansively own Data Engineering team outcomes: Deliver on Data Team outcomes for both internal teams and external customers, which include both operational and analytics workflows.
 * Own the design of new data infrastructure: Research and identify industry best practices and state-of-the-art tools to leverage. Design new systems to support the necessary outcomes in a secure, durable, performant, and maintainable way.
 * Build and support new data products: Build datasets, pipelines, and other solutions to support operational and product outcomes. Develop support systems to scale the team and achievable outcomes.
 * Contribute significantly to building a robust data culture: ensuring data is trusted, accessible, and central to how we identify opportunities and measure our impact.
 * Some systems & projects you might work on: BI Platform Infrastructure, Airflow, BigQuery Tuning, Customer Facing Data Delivery Infrastructure, DBT Deployment, CI/CD, Data Streaming Infrastructure.
   
   

Who You Are


 * You have Bachelors of Science or Bachelors of Art in Computer Science, Computer Engineering, Math or other similar degree.
 * You have 4+ years of experience working with data pipelines, products, and tools.
 * You’ve built and maintained complex data integrations or pipelines.
 * You have well-developed opinions on modern data warehouse architecture, tools, and patterns.
 * You have excellent technical vision; you know the right architecture and patterns to build functional, durable, and maintainable product.
 * You have a customer-first and learner’s mindset, and value teaching others.
 * You make the right trade-offs when considering project scope, which corners are worth cutting, and which are not.
 * You’re a clear and concise communicator; you enjoy the challenge of explaining complicated ideas in simple terms, both in-person and in writing.
 * Experience with the technologies we currently use is a plus, but by no means required: Google Cloud Platform, BigQuery, PostgreSQL, Metabase, Terraform, Python.
   
   

Pay Transparency

The estimated starting annual salary range for this position is $165,000 to $205,000 USD. The listed range is a guideline from Pave data, and the actual base salary may be modified based on factors including job-related skills, experience/qualifications, interview performance, market data, etc. Total compensation for this position may also include equity, sales incentives (for sales roles), and employee benefits. Given Candid Health’s funding and size, we heavily value the potential upside from equity in our compensation package. Further note that Candid Health has minimal hierarchy and titles, but has broad ranges of experience represented within roles.

","Over 200 applicants","Full-time","Entry level","Information Technology","Hospitals and Health Care","$165,000.00/yr - $205,000.00/yr","","","70448411","https://www.linkedin.com/jobs/view/data-engineer-at-candid-health-4339389148?trk=public_jobs_topcard-title","EASY_APPLY",""
"Analyst, Biotech & Generative AI","New York, NY","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/analyst-biotech-generative-ai-at-appliedxl-4338266824?trk=public_jobs_topcard-title","AppliedXL","https://www.linkedin.com/company/appliedxl?trk=public_jobs_topcard-org-name","Job Description: Analyst, Biotech & Generative AI

Reports to: Head of GenAI Content

Location: New York or Philadelphia (Hybrid)

Please include a cover letter outlining your interest in the role and how your skills align with AppliedXL and send to support@appliedxl.com.




About AppliedXL

AppliedXL is redefining how information powers decisions in the age of AI. As more work flows through machines first, data must be structured, contextual, and trusted. We turn raw information into verified, machine-readable signals that help analysts and AI systems detect what’s changing, before it becomes news. 




Starting with biotech, life sciences, and healthcare, our platform surfaces early risks and opportunities weeks ahead of disclosure. Our mission is to deliver news before it becomes news, building the standard for structured intelligence that powers high-stakes decisions across finance, healthcare, and beyond.




By joining AppliedXL, you’ll help shape the trusted signals that humans and machines rely on to see ahead.




The Role

This is not a traditional analyst position. You’ll work at the frontier where data science meets editorial judgment and AI reasoning. Your job is to uncover patterns, design intelligence feeds, and ensure that every signal is accurate, contextual, and actionable.




You’ll collaborate closely with the Head of GenAI Content and help define how humans and AI collaborate to detect emerging insights and explain them clearly. Over time, you’ll take increased ownership of editorial pipelines, signal quality, and content accuracy.




This is a high-impact opportunity for someone eager to shape how domain expertise and AI combine to power better, faster decision-making in life sciences.




What You’ll Do

Detect & Understand

 * Build working knowledge of datasets spanning clinical trials, regulatory filings, and biotech disclosures.
 * Translate complex data and workflows into clear, relevant insights.
 * Connect emerging signals to real-world outcomes that matter to investors and biopharma stakeholders.
 * Collaborate with product and GTM teams to define what truly matters from a user perspective.

Interpret & Explain

 * Explore structured datasets in Python or SQL to identify trends and anomalies.
 * Assess what data changes mean for users and how they map to real-world impact.
 * Partner with data and product teams to test new features or metrics (e.g., enriched trial signals).
 * Form editorial hypotheses and maintain a high bar for analytical clarity and explainability.

Guide AI Reasoning

 * Develop and test prompts that detect scientific or regulatory significance.
 * Evaluate AI outputs for factual accuracy, reasoning quality, and editorial clarity.
 * Document prompt behavior and edge cases to ensure reproducibility and transparency.
 * Bridge human and AI logic to improve how our systems reason, interpret, and communicate.

Integrate & Scale

 * Use internal tools to transform raw data into structured, user-facing intelligence.
 * Apply foundational AI concepts (model reasoning, tokenization, prompt design) in practice.
 * Document and share best practices for scalable human–AI collaboration.
 * Continuously refine and QA editorial quality and AI output across the pipeline that turns raw data → structured insight → actionable foresight.




What We’re Looking For

 * At least 2+ years of direct experience in biosciences or clinical trials, and 5+ years total experience across life sciences, consulting, data analysis, or applied AI.
 * Strong analytical and reasoning skills.
 * Familiarity with Python and/or SQL for data exploration.
 * Experience with AI tools and concepts such as LLMs, prompt engineering, LangChain, and/or RAG (retrieval-augmented generation).
 * Deep curiosity about how scientific data becomes intelligence—and how AI can enhance that process.
 * Proven ability to learn new domains quickly and explain complex ideas clearly.
 * Editorial instincts: you know how to question, frame, and contextualize information for clarity and relevance.
 * Intellectual rigor about AI: you care not just about what models output, but why and how they reason.
 * A curious, disciplined thinker who asks: “What does this signal really mean, and why does it matter?”




Salary Range: $75,000–$90,000




Please include a cover letter outlining your interest in the role and how your skills align with AppliedXL and send to support@appliedxl.com.","175 applicants","Full-time","Entry level","Business Development and Sales","Software Development","$75,000.00/yr - $90,000.00/yr","","","42953396","https://www.linkedin.com/jobs/view/analyst-biotech-generative-ai-at-appliedxl-4338266824?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist","New York, United States","3 weeks ago","2025-11-10","https://www.linkedin.com/jobs/view/data-scientist-at-the-lanes-group-4335214087?trk=public_jobs_topcard-title","The Lanes Group","https://uk.linkedin.com/company/thelanesgroup?trk=public_jobs_topcard-org-name","ML Data Scientist — Search, Ranking & Personalization | New York (Onsite)

Location: Union Square, New York (5 days onsite, flexibility for the right candidate)

Compensation: $170,000 – $200,000 + competitive equity

Visa: H1B transfers welcome (new sponsorships not available)




About the Company




A rapidly growing AI-driven commerce platform is redefining how users shop and discover fashion through intelligent recommendation systems and personalized experiences.

 * Over 650,000 downloads in six months
 * 80% user retention rate
 * $115M in GMV processed through the platform
 * Backed by top-tier investors, including leading venture capital firms and notable angel investors
 * A lean, high-performing team of 16 engineers and former founders




The Role




We are seeking a Machine Learning Data Scientist with 1–3 years of experience in applied machine learning, specializing in search, ranking, recommendation systems, and personalization.

You will play a key role in designing and deploying advanced ML systems that power intelligent product discovery and personalized engagement experiences at scale.




Key Responsibilities

 * Design and train machine learning models for search, ranking, and personalization
 * Develop and scale retrieval systems to support real-time product discovery
 * Build end-to-end ML pipelines, from data ingestion to production deployment
 * Experiment with embeddings, ranking algorithms, and personalization methods to enhance relevance
 * Collaborate closely with engineering and product teams to ensure seamless ML integration




Requirements




Experience and Background




 * 1–3 years of experience in applied machine learning, focused on search, ranking, or personalization
 * Experience with large-scale data processing (e.g., ETL, PySpark)
 * Bachelor’s degree in Computer Science, Data Science, or a related field (Top 50 university preferred)




Technical Skills




 * Strong proficiency in Python
 * Expertise with modern ML frameworks, particularly PyTorch




Soft Skills




 * Strong ownership mindset and ability to deliver high-quality work independently




Why Join




 * Build and deploy production-grade ML systems that directly impact millions of users
 * Join a fast-scaling, venture-backed company with world-class leadership and investors
 * Work alongside top engineers and innovators in a dynamic, ownership-driven environment

","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Technology, Information and Media","$170,000.00/yr - $200,000.00/yr","Alexander Stock","https://uk.linkedin.com/in/alexander-stock-63683545","56415057","https://www.linkedin.com/jobs/view/data-scientist-at-the-lanes-group-4335214087?trk=public_jobs_topcard-title","EASY_APPLY",""
"Machine Learning Engineer","Kirkland, WA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-electronic-arts-ea-4341975744?trk=public_jobs_topcard-title","Electronic Arts (EA)","https://www.linkedin.com/company/electronic-arts?trk=public_jobs_topcard-org-name","Description & Requirements

Electronic Arts creates next-level entertainment experiences that inspire players and fans around the world. Here, everyone is part of the story. Part of a community that connects across the globe. A place where creativity thrives, new perspectives are invited, and ideas matter. A team where everyone makes play happen.

The ATOM team builds the future of AI for testing games. As a Machine Learning Engineer reporting to the Director of AI, you will fulfill high-impact applied research goals and help us bring EA's games to life. Your mission is to discover and evaluate AI methods that increase the velocity and quality of next-generation interactive experiences. Our team impacts every title in EA's portfolio, and you will work with all types of AI technology to improve our titles.

Responsibilities


 * Prototype, train, and ship AI tools that improve game testing efficiency, such as autonomous play-testing agents, test-case generation, anomaly/bug detection, and bug triaging.
 * Translate ATOM's technology roadmap into experiments and deliverables, with support from lead and senior ML scientists
 * Build reliable data pipelines from gameplay logs, video/frames, and telemetry; ensure data quality, labelling strategies, and reproducibility.
 * Stay up-to-date on advancements in deep learning and GenAI through self-study, internal workshops, and external conferences.
 * This job is onsite of hybrid remote/in-office (3 days/week).
   
   

Qualifications


 * BSc degree in Computer Science, Engineering or Mathematics, or equivalent experience.
 * 3+ years of experience spanning across the entire ML lifecycle (frame, gather/curate data, model, evaluate, deploy, observe)
 * Fluent in Python and major ML frameworks (e.g., PyTorch) and skill with software development practices.
 * Experience training models at scale (multi-GPU or distributed), strong understanding of ML fundamentals, MLOps, and best practices (e.g., reproducibility).
   
   

Preferences


 * Graduate degree in Computer Science, Engineering, Mathematics, or related discipline.
 * Experience with: Reinforcement/Imitation Learning, Computer Vision (for video), Agents/LLMs, Uncertainty Quantification, Out-of-distribution detection.
 * Experience with Distributed ML (e.g., DeepSeed).
   
   

Compensation And Benefits

The ranges listed below are what EA in good faith expects to pay applicants for this role in these locations at the time of this posting. If you reside in a different location, a recruiter will advise on the applicable range and benefits. Pay offered will be determined based on a number of relevant business and candidate factors (e.g. education, qualifications, certifications, experience, skills, geographic location, or business needs).

PAY RANGES


 * British Columbia (depending on location e.g. Vancouver vs. Victoria) *$119,600 - $167,300 CAD
 * California (depending on location e.g. Los Angeles vs. San Francisco) *$138,400 - $211,700 USD
 * Washington (depending on location e.g. Seattle vs. Spokane) *$129,500 - $171,800 USD
   
   

In the US, we offer a package of benefits including paid time off (3 weeks per year to start), 80 hours per year of sick time, 16 paid company holidays per year, 10 weeks paid time off to bond with baby, medical/dental/vision insurance, life insurance, disability insurance, and 401(k) to regular full-time employees. Certain roles may also be eligible for bonus and equity.

In British Columbia, we offer a package of benefits including vacation (3 weeks per year to start), 10 days per year of sick time, paid top-up to EI/QPIP benefits up to 100% of base salary when you welcome a new child (12 weeks for maternity, and 4 weeks for parental/adoption leave), extended health/dental/vision coverage, life insurance, disability insurance, retirement plan to regular full-time employees. Certain roles may also be eligible for bonus and equity.

About Electronic Arts

We’re proud to have an extensive portfolio of games and experiences, locations around the world, and opportunities across EA. We value adaptability, resilience, creativity, and curiosity. From leadership that brings out your potential, to creating space for learning and experimenting, we empower you to do great work and pursue opportunities for growth.

We adopt a holistic approach to our benefits programs, emphasizing physical, emotional, financial, career, and community wellness to support a balanced life. Our packages are tailored to meet local needs and may include healthcare coverage, mental well-being support, retirement savings, paid time off, family leaves, complimentary games, and more. We nurture environments where our teams can always bring their best to what they do.

Electronic Arts is an equal opportunity employer. All employment decisions are made without regard to race, color, national origin, ancestry, sex, gender, gender identity or expression, sexual orientation, age, genetic information, religion, disability, medical condition, pregnancy, marital status, family status, veteran status, or any other characteristic protected by law. We will also consider employment qualified applicants with criminal records in accordance with applicable law. EA also makes workplace accommodations for qualified individuals with disabilities as required by applicable law.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Entertainment Providers","","","","1449","https://jobs.ea.com/en_US/careers/JobDetail/Machine-Learning-Engineer/211193?source=LinkedIn","EXTERNAL",""
"Senior Software Engineer - Python - Data Solutions","Mesquite, TX","8 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/senior-software-engineer-python-data-solutions-at-h-e-b-4325392160?trk=public_jobs_topcard-title","H-E-B","https://www.linkedin.com/company/heb?trk=public_jobs_topcard-org-name","Responsibilities

Since H-E-B Digital Technology's inception, we've been investing heavily in our customers' digital experience, reinventing how they find inspiration from food, make food decisions, and ultimately get food into their homes. This is an exciting time to join H-E-B Digital-we're using the best available technologies to deliver modern, engaging, reliable, and scalable experiences to meet the needs of our growing audience.

This is an exciting time to join H-E-B Digital-we're using the best available technologies to deliver modern, engaging, reliable, and scalable experiences to meet the needs of our growing audience. Data Solutions at H-E-B: Building the Future of Retail Through Engineering

At H-E-B, we’re a technology-powered company on a mission to make the lives of Texans better. Our Data Solutions team is at the forefront of this transformation, enabling innovation through scalable software systems, data platforms, and infrastructure. With thriving Tech Hubs in San Antonio, Austin, and Dallas, we’re building the future of omnichannel retail through engineering excellence and a commitment to quality.

Our Data Solutions teams specialize in:


 * Data Modeling
 * Data Governance
 * Data Pipelines & Engineering
 * Data Movement & Transformation
 * Databases & Infrastructure (Private & Public Cloud)
   
   

We’re Hiring: Senior Software Engineers

We’re looking for experienced Senior Software Engineers who are passionate about delivering high-quality, scalable solutions and driving innovation across our data platforms. We design and build the systems that power analytics, machine learning, and real-time decision-making across the enterprise.

What You’ll Do:


 * Deliver complex, production-ready code and lead system design
 * Apply an ML Operations mindset to developing services to support all stages of the Machine Learning lifecycle
 * Build and support microservices and resolve production issues
 * Drive architecture, scalability, and performance improvements
 * Lead team ceremonies, mentor peers, and foster a culture of collaboration
 * Own services end-to-end and influence cross-team technical direction
   
   

Technical Skills:


 * Proficient in Python & SQL
 * Strong understanding of data structures, algorithms, and design patterns
 * Experience architecting cloud solutions (GCP & Vertex AI preferred) leveraging Microservice architecture, REST API's
   
   

Kubernetes, Kafka


 * Experience with infrastructure as code (Terraform) and CI/CD development
 * Familiarity with tools like Git, Jira, Confluence
   
   

What Makes You a Great Fit:


 * 5+ years of software development experience
 * A growth mindset and passion for innovation
 * Strong collaboration and communication skills
 * Ability to thrive in ambiguity and drive results
 * Commitment to quality, performance, and customer service
 * A desire to be part of a Partner-owned company where your work truly matters
   
   

Join Us:

HEART FOR PEOPLE... you're willing to facilitate solutions with multiple engineers, provide upward communication, and mentor others?

HEAD FOR BUSINESS... you consistently demonstrate and uphold the standards of coding, infrastructure, and process?

PASSION FOR RESULTS... you're capable of high-velocity contributions in multiple technical domains?

At H-E-B, you’ll be part of a team that values innovation, ownership, and impact. Whether you’re building scalable systems or leading architectural decisions, your work will help shape the future of retail.

Ready to build what’s next? Join us at H-E-B Data Solutions.

JDENGINEERING","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Retail","","","","164159","https://www.linkedin.com/jobs/view/senior-software-engineer-python-data-solutions-at-h-e-b-4325392160?trk=public_jobs_topcard-title","EASY_APPLY",""
"Software Engineer (Data Platform)","San Francisco, CA","2 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/software-engineer-data-platform-at-the-recruiting-guy-4322017271?trk=public_jobs_topcard-title","The Recruiting Guy","https://www.linkedin.com/company/the-recruitingguy?trk=public_jobs_topcard-org-name","Note: This position is open to remote applicants based in the US only.

Job Title: Software Engineer (Data Platform)

Location: Remote. United States ONLY.

Employment Type: Salaried W2 Full-Time.

Salary: $125,000 - $200,000

About The Company

We represent a rapidly growing data company in NYC that’s redefining how real-world assets are represented and traded on public blockchains. Their platform serves investors, issuers, and financial institutions by providing reliable analytics, market intelligence, and transparent data on tokenized assets across the globe.

They’re trusted by leading players in finance and blockchain for their accuracy, scale, and forward-thinking approach to digital asset infrastructure. It’s an exciting opportunity to join a team that’s helping shape the future of real-world asset tokenization and build technology that’s changing how the financial world connects.

Responsibilities


 * Build and scale core data systems and APIs that serve product-level analytics
 * Collaborate with application engineers to ensure clean data flow between backend systems and end-user features
 * Develop and optimize data pipelines using PySpark and Databricks
 * Work closely with the lead data engineer on system architecture and data infrastructure design
 * Participate in system design discussions focused on scalability, performance, and maintainability
 * Contribute to the full software development lifecycle, from design through deployment
 * Support product and engineering teams by turning raw data into usable insights
   
   

Ideal Background


 * 4 to 5+ years of software engineering experience, preferably focused on large-scale data systems
 * Strong proficiency in Python and experience with PySpark
 * Experience with distributed frameworks such as Apache Spark, Beam, Flink, or Kafka Streams
 * Proven ability to design, build, and maintain production-grade data pipelines and APIs
 * Background in computer science, computer engineering, applied mathematics, or a related field (top 50 university or equivalent rigor preferred)
 * Experience working on data-driven products rather than internal BI or reporting systems
 * Strong communication skills and the ability to explain technical tradeoffs clearly
 * High attention to detail, ownership mindset, and a passion for building high-quality systems
   
   

Nice to Have


 * Experience in fintech, blockchain, or other data-intensive environments
 * Hands-on experience with Databricks or real-time streaming data systems
 * Demonstrated curiosity and craftsmanship through side projects or open-source work
   
   

Skills: beam,apache spark,software engineering,api,flink,python,kafka streams","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Human Resources Services","$125,000.00/yr - $200,000.00/yr","","","105823297","https://www.linkedin.com/jobs/view/software-engineer-data-platform-at-the-recruiting-guy-4322017271?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist","New York, NY","1 week ago","2025-11-22","https://www.linkedin.com/jobs/view/data-scientist-at-tandem-4338490278?trk=public_jobs_topcard-title","Tandem","https://www.linkedin.com/company/withtandem?trk=public_jobs_topcard-org-name","Why you should join us

Tandem is a generational opportunity to rethink how we bring new therapies to market, and our path to doing so is significantly de-risked – we have:


 * Exponential organic growth: We have product-market fit and are growing rapidly through word-of-mouth. Tandem supports thousands of patients every day, is doubling doctor users every quarter, and is working with the largest biopharma companies in the world.
 * An AI-first business model: Our approach is distinctly enabled by AI, but our business will get stronger (not commoditized) as foundation models improve. We are building durability through two-sided network effects that will compound over time.
 * Top tier investors: With the traction to support conviction in our model, we raised significant funding from investors (Thrive Capital and General Catalyst) to build an exceptional team of engineers and operators.
   
   

Our number one priority is scaling to market demand. We are looking for individuals who are high horsepower, high throughput, and hyper resourceful to help us increase capacity and grow. We move fast and need to move faster.

All full-time roles are in person in New York. You can learn more about working with us in the last section of this page.

About The Role

As a Data Scientist on our team, you will not only define and predict our company’s core metrics, you will drive them. This is a role of immense range, stretching from developing advanced analytical models to owning end-to-end strategic project implementation. Your work will be hyper cross-functional, sometimes driving forward technical projects in partnership with an engineer, other times leading an operations workstream. You will also engage directly with Fortune 100 customers to understand their needs and present on Tandem’s performance and relevant insights.

This is a demanding role, with a high level of autonomy and responsibility. You will be expected to ""act like an owner"" and commit yourself to Tandem's success. If you are low-ego, hungry to learn, and excited about intense, impactful work that drives both company growth and accelerated career progression, we want to hear from you.

If you join, you will:


 * Drive strategic projects that require deep data analysis, with accountability for end-to-end execution and business outcomes – this may include:
    * Sourcing and using industry and market data to shape Tandem’s go-to-market and growth strategy
    * Leveraging our internal workflow data to predict operational throughput and bottlenecks and prioritize new workflow automations as we scale
    * Prototyping new modeling approaches to AI problems (e.g., outcome prediction and optimization for insurance-related processes) in collaboration with our Engineering team
    * Building out a unified user interaction model to define Tandem’s consumer and provider product roadmaps

 * Create and rapidly iterate on externally facing data products for Tandem’s key partners and actively participate in priority client engagements
 * Establish Tandem’s core data sources and metrics to empower everyone on the team to answer complex questions about Tandem’s business in real-time
 * Work directly with our CEO and leadership team as a critical partner in making business decisions as we balance speed of growth and long-term profitability
   
   

We’re looking for you if you have:


 * Able to bring clarity to ambiguous problems and lead projects with major strategic/business impact, collaborating across teams and levels to drive sound decisions.
 * An advanced degree in a quantitative field or 4+ years of work experience in an analytics-heavy, business-focused role
 * Strong technical background with exceptional ability to do data analysis using SQL and Python, as well as pick up new tools on the fly
 * Comfort with zooming in and out of problems, jumping between high-level thinking and granular methods of problem-solving
 * Strong written and verbal communication that allows you to be an effective participant in both internal debates and external relationships
 * Track record of moving quickly, finding shortcuts, and going to unreasonable lengths to deliver on goals
 * High NPS with your former teammates
   
   

This is a list of ideal qualifications for this position. If you don't meet every single one of them, you should still consider applying! We’re excited to work with people from underrepresented backgrounds, and we encourage people from all backgrounds to apply.

Working with us

Tandem is based in New York, with our full team working out of a beautiful and spacious office in SoHo.

We run as a high-trust environment with high autonomy, which requires that everyone is fully competent and operates in line with our principles:


 * Commit to audacity. ""Whether you think you can, or you think you can't – you're right.”
 * Do the math. Be rigorous, assume nothing.
 * Find the shortest path. Use hacks, favors, and backdoors. Only take a longer road on purpose.
 * Spit it out. Be direct, invite critique, avoid equivocation – we want right answers.
 * Be demanding and supportive. Expect excellence from everyone and offer help to achieve it.
 * Do what it takes to be number 1. We work hard to make sure we win.
   
   

We provide competitive compensation with meaningful equity (for full-time employees). Everyone who joins early will be a major contributor to our success, and we reflect this through ownership and pay.

We also provide rich benefits to ensure you can focus on creating impact (for full-time employees):


 * Fully covered medical, vision, and dental insurance.
 * Memberships for One Medical, Talkspace, Teladoc, and Kindbody.
 * Unlimited paid time off (PTO) and 16 weeks of parental leave.
 * 401K plan setup, FSA option, commuter benefits, and DashPass.
 * Lunch at the office every day and Dinner at the office after 7 pm.
   
   

Our salary ranges are based on paying competitively for our company’s size and industry, and are one part of the total compensation package that also includes equity, benefits, and other opportunities at Tandem (for full-time employees). Individual pay decisions are ultimately based on a number of factors, including qualifications for the role, experience level, skillset, geography, and balancing internal equity.

Tandem is an equal opportunity employer and does not discriminate on the basis of race, gender, sexual orientation, gender identity/expression, national origin, disability, age, genetic information, veteran status, marital status, pregnancy or related condition, or any other basis protected by law.

Compensation Range: $150K - $250K

","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Technology, Information and Internet","$150,000.00/yr - $250,000.00/yr","","","93670294","https://jobs.ashbyhq.com/tandem/1ae72b76-5611-4423-a2ea-e11933cea33f/application?utm_source=6qaMboprve","EXTERNAL",""
"Data Analytics Engineer","Manassas, VA","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/data-analytics-engineer-at-new-york-technology-partners-4339029051?trk=public_jobs_topcard-title","New York Technology Partners","https://www.linkedin.com/company/new-york-technology-partners?trk=public_jobs_topcard-org-name","Title: Data Analytics Engineer

Location: Manassas, VA (Onsite/ Local Only)

Position: Contract / Contract to Hire




Note: Looking for Citizen and GC Only and Face to Face Interview Must




Job Summary:

• The Data Analytics Engineer will design, develop, and maintain robust data pipelines, analytical workflows, and reporting solutions to support operational and strategic decision-making.

• This role bridges data engineering and analytics by ensuring high-quality data movement across systems, building insightful dashboards, and supporting enterprise analytics initiatives across multiple business domains, including Electric Outage Management, Work Management, GIS, Financials, and Customer Services.




Basic Qualifications:

• Strong experience with ETL design and maintenance using SSIS, Pentaho, and Python.

• Proficiency in SQL scripting for data extraction, transformation, and optimization.

• Experience building and maintaining data pipelines across multiple business systems.

• Hands-on experience with Power BI, Tableau, Crystal Reports, and Report Builder.

• Strong understanding of Microsoft Fabric, including Data Factory, Lakehouse, and Synapse.

• Excellent problem-solving and data modeling skills.

• Ability to translate technical data into actionable business insights.

• Excellent written and oral communication skills; strong documentation discipline.




Desired Skills;

• Experience working within Electric Utility IT environments.

• System Architecture (Virtual and Physical, Cloud, Hybrid, Middle Tear and Client Server)

• Familiarity with Work Management, GIS, Financial, and Customer Service systems.

• Proficiency in data governance, metadata management, and performance tuning.

• Experience with ETL orchestration, job scheduling, and version control.

• Strong collaboration and analytical mindset to work across teams.




Education Requirements:

• Minimum 3 years of experience in data analytics or data engineering.

• At least 2 years working with enterprise reporting or ETL solutions.","Over 200 applicants","Full-time","Mid-Senior level","Finance, Accounting/Auditing, and Information Technology","Electric Power Transmission, Control, and Distribution, Financial Services, and Banking","","Sudarshan Shetty","https://in.linkedin.com/in/sudarshan-shetty-8bb74125","84551","https://www.linkedin.com/jobs/view/data-analytics-engineer-at-new-york-technology-partners-4339029051?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI/ML Quantitative Developer","New York, United States","3 days ago","2025-11-28","https://www.linkedin.com/jobs/view/ai-ml-quantitative-developer-at-acquire-me-4347833935?trk=public_jobs_topcard-title","Acquire Me","https://uk.linkedin.com/company/acquireme?trk=public_jobs_topcard-org-name","About the Company

Our client is a leading technology-driven trading firm where engineers and researchers work side by side to uncover patterns in global markets. It’s a collaborative, curious environment where people are encouraged to experiment, innovate, and see the real impact of their work.




Think - the pace of a startup with the depth of a research lab.




About the Role

We’re looking for an engineer who loves building the systems that power AI and machine learning in live trading. You’ll work directly with quantitative researchers to design and refine ML workflows, from data pipelines and feature generation to model training, evaluation, and deployment.




This is a front-office engineering role with genuine impact: your work helps turn research ideas into trading decisions.




Responsibilities

• Build and improve research frameworks and ML pipelines for large-scale model development and backtesting

• Create tools that accelerate experimentation and simulation workflows

• Collaborate with researchers to move models from prototype to production

• Work across deep learning models, research tooling, and live trading systems




Skills & Experience

• Strong programming fundamentals in Python (C++ useful too)

• Experience with ML or DL frameworks such as PyTorch, TensorFlow, or JAX

• Understanding of data structures, algorithms, and distributed computing

• Background in building or scaling research or simulation tools

• Strong communicator who enjoys working closely with researchers and traders","187 applicants","Full-time","Mid-Senior level","Finance","Financial Services, Capital Markets, and Engineering Services","$250,000.00/yr - $350,000.00/yr","","","11383925","https://www.linkedin.com/jobs/view/ai-ml-quantitative-developer-at-acquire-me-4347833935?trk=public_jobs_topcard-title","EASY_APPLY","401(k)
Paid paternity leave
Paid maternity leave"
"AI engineer","New York, NY","3 days ago","2025-11-29","https://www.linkedin.com/jobs/view/ai-engineer-at-nora-your-shopping-retriever-4339414569?trk=public_jobs_topcard-title","Nora, your shopping retriever","https://www.linkedin.com/company/checkwithnora?trk=public_jobs_topcard-org-name","AI engineer (personal shopping memory & agents) @Nora




Part engineer, part product thinker, part hacker. 100% user obsessed

Full-time or Contract, Remote or NYC, $100K - $150K + Equity




Context

We're building Nora, the personal shopping retriever loyal only to you.




Online shopping gave us infinite choice but zero tools to manage it. So people improvise with 47 browser tabs, screenshots flooding their camera roll, and links texted to themselves. They're drowning in options, missing price drops, and spending hours on research that leads nowhere.




Nora changes everything. Your personal shopping assistant that captures what you browse, what you buy, tracks prices, finds alternatives, verifies reviews, and soon will even negotiate deals on your behalf. All while keeping your data private and eventually earning you money.




Why this matters: We're shifting power back to consumers. For the first time, shoppers will have an AI assistant as sophisticated as what billion-dollar companies use. When you ask ""Should I buy this?"" Nora actually knows your style, budget, and what you've been considering.




Where we are: Just raised $750K from Betaworks & angels. Small team moving fast. Building something people desperately need. We’ve built the capture → memories → knowledge pipeline; now we need someone to make it truly smart and to power the agents that work on the user’s behalf.




Watch https://www.youtube.com/watch?reload=9&v=yULgS3qRWOA for more info.




The Real Job

You'll be the bridge between messy real-world shopping behavior and an assistant that actually understands and works for each user.

This isn't about research in a vacuum or building an internal ML platform. You'll be:

 * Turning noisy data (DOM, clicks, scrolls, screenshots, receipts) into clean, structured memory about each shopper.
 * Teaching Nora everything from “what brands I love” to “my shoe size at different stores” to “what price I consider expensive.”
 * Building agents that go do the work: finding better places to buy, researching alternatives, checking reviews, and surfacing what matters.
 * Shipping intelligence that shows up as real product features, not just dashboards.

Your success = shoppers saying “Nora knows me and does the boring work for me.”




What You'll Actually Do Day-to-DayBuild Nora’s Understanding of Each User
 * Model user tastes, sizes, favorite brands, and price sensitivity from behavior.
 * Use LLMs and embeddings to turn raw capture into entities, attributes, and preferences.
 * Improve our capture → memories → knowledge pipeline so it gets cleaner, richer, and more personal over time.

Build Nora’s Agents
 * Design agents that can:
 * Find alternative places to buy the same product.
 * Suggest similar items that better match the user’s constraints.
 * Check reviews and flag sketchy listings.
 * Track meaningful price changes and surface them at the right time.
 * Wire LLMs to tools and structured data so agents are fast, reliable, and explainable.

Ship Product, Not Just Models
 * Work directly with the founder, designer, and Head of User Love (no PM layer).
 * Watch real users shop with Nora, then adjust models and agents based on what you see.
 * Prototype quickly, run small experiments, and ship improvements weekly.
 * Own the full loop: data → model → API → UI → metrics.

You're Our Person If...You've Done This Before (In Some Form)
 * 2–8+ years working in applied ML / LLMs / search / recommendations / personalization.
 * Shipped at least one real system that powered search, recs, ranking, or an LLM-based feature in production.
 * Comfortable with both modeling and the surrounding engineering (data pipelines, APIs, evaluation).

You Think Like This
 * “We should measure success in user behavior, not just offline metrics.”
 * “We don’t need a bigger model yet—just better features and feedback loops.”
 * “Let’s prototype this as a small agent flow and then harden what works.”

You Work Like This
 * Comfortable with ambiguity (we’re figuring this out together).
 * Can go from idea → prototype → shipped experiment in days, not quarters.
 * Enjoy pairing with designers and user researchers, not just other engineers.




Why This Role Matters

Shopping online is broken. People have 47 tabs open, screenshots everywhere, links lost in texts. They're recreating the same searches daily, missing price drops, buying the wrong size.

We already capture that behavior and turn it into memory.

You’ll make that memory intelligent and build the agents that act on it.

You’ll help us fix shopping for millions of people—not with committees and roadmaps, but by building systems that know users deeply and quietly do work on their behalf.




Why Nora?Build Something New

We’re not just optimizing conversion funnels. We’re creating a new layer for shopping: a personal memory and agent that answers to the user, not the retailer.

Meaningful Equity

Real ownership in something that could change how people shop online. You’re early enough that your equity will matter.

Choose Your Setup

Remote, in-person NYC, or hybrid. Full-time or contract. We care about impact, not hours logged.







The Interview Process

Super straightforward:

 * Quick chat (30 min): Tell us about yourself, we’ll tell you about Nora and our data.
 * Technical working session (60–90 min): We’ll walk through a simplified version of a real problem (e.g., memory search, alternatives, agents). You’ll talk through how you’d approach it. No LeetCode. No trick puzzles.

No whiteboard algorithm drills. Just real conversations about real work.







Compensation Details

Full-time: $100K–$150K base salary + 0.25%–3.0% equity 

Contract: Hourly or project-based, flexible depending on scope and location.

We're flexible and transparent — tell us what works for you.




Ready?

Send us:

 * Try the product and tell us why are you excited about Nora specifically?
 * Your best example of an ML/LLM/search/recs system you shipped and what you learned.
 * Links to anything you've built/written/created (optional but helpful).

Email: sid@checkwithnora.me  or drop 30 mins on my calendar: calendly.com/sid-banothu/30min-hold


","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Technology, Information and Internet","$100,000.00/yr - $150,000.00/yr","","","108295304","https://www.linkedin.com/jobs/view/ai-engineer-at-nora-your-shopping-retriever-4339414569?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist","Palo Alto, CA","1 month ago","2025-10-23","https://www.linkedin.com/jobs/view/data-scientist-at-tencent-4323906362?trk=public_jobs_topcard-title","Tencent","https://cn.linkedin.com/company/tencentglobal?trk=public_jobs_topcard-org-name","About The Hiring Team

Level Infinite is Tencent’s global gaming brand. It is a global game publisher offering a comprehensive network of services for games, development teams, and studios around the world.

We are dedicated to delivering engaging and original gaming experiences to a worldwide audience, whenever and wherever they choose to play while building a community that fosters inclusivity, connection, and accessibility. Level Infinite also provides a wide range of services and resources to our network of developers and partner studios around the world to help them unlock the true potential of their games.

What The Role Entails

Tencent Games was established in 2003. We are a leading global platform for game development, operations and publishing, and the largest online game community in China.

Tencent Games has developed and operated over 140 games. We provide cross-platform interactive entertainment experience for more than 800 million users in over 200 countries and regions around the world. Honor of Kings, PUBG MOBILE, and League of Legends, are some of our most popular titles around the world. Meanwhile, we actively promote the development of esports industry, work with global partners to build an open, collaborative and symbiotic industrial ecology, and create high-quality digital life experiences for players.

Level Infinite is Tencent’s global gaming brand. It is a global game publisher offering a comprehensive network of services for games, development teams, and studios around the world. We are dedicated to delivering engaging and original gaming experiences to a worldwide audience, whenever and wherever they choose to play while building a community that fosters inclusivity, connection, and accessibility. Level Infinite also provides a wide range of services and resources to our network of developers and partner studios around the world to help them unlock the true potential of their games.

About Us

Tencent Games Global Data Insight is a world-class data science team empowering game development, publishing, and operations across our global portfolio. Our mission is to solve complex challenges in the gaming industry through advanced data science, experimentation, and machine learning — transforming insights into actions that shape the future of play for billions of gamers.

What You’ll Do As a Data Scientist at Tencent Games:


 * Leverage large-scale data to uncover insights, guide decision-making, and drive measurable business impact across R&D, marketing, and live-ops stages.
 * Build computational workflows using Python, SQL, and big-data ecosystems to process and analyze complex datasets.
 * Design and deploy scalable, automated frameworks for A/B testing, statistical modeling, and machine learning.
 * Partner with product, engineering, and business stakeholders to design end-to-end data solutions that optimize player experience, monetization, and operational efficiency.
 * Contribute to a culture of experimentation and scientific rigor through analytics innovation, reproducibility, and continuous learning.
   
   

Who We Look For

What We’re Looking For:


 * Ph.D in Computer Science, Statistics, Mathematics, or a related quantitative discipline.
 * Deep understanding of mathematical modeling, statistical inference, and machine learning techniques applied to real-world data.
 * Strong proficiency in Python and SQL; experience with data visualization tools (e.g., Tableau, Power BI, Looker) is a plus.
 * Proven ability to translate complex data into actionable business insights and communicate findings effectively to non-technical audiences.
 * Passion for gaming and enthusiasm for using data to improve player engagement and business outcomes.
   
   

Why Tencent Games Global


 * Scale & Impact: Access data from our players worldwide and make decisions that shape the global gaming landscape.
 * Innovation & Growth: Collaborate with world-class experts across data science, game design, and AI research.
 * Culture & Collaboration: Thrive in a friendly, cross-cultural environment that values curiosity, ownership, and creativity.
 * Global Opportunities: Work with teams across Shenzhen, Shanghai, and Palo Alto — where data meets global gaming innovation.
   
   

Location State(s)

US-California-Palo Alto

The expected base pay range for this position in the location(s) listed above is $118,100.00 to $274,600.00 per year. Actual pay may vary depending on job-related knowledge, skills, and experience. Employees hired for this position may be eligible for a sign on payment, relocation package, and restricted stock units, which will be evaluated on a case-by-case basis. Subject to the terms and conditions of the plans in effect, hired applicants are also eligible for medical, dental, vision, life and disability benefits, and participation in the Company’s 401(k) plan. The Employee is also eligible for up to 15 to 25 days of vacation per year (depending on the employee’s tenure), up to 13 days of holidays throughout the calendar year, and up to 10 days of paid sick leave per year. Your benefits may be adjusted to reflect your location, employment status, duration of employment with the company, and position level. Benefits may also be pro-rated for those who start working during the calendar year.

Equal Employment Opportunity at Tencent

As an equal opportunity employer, we firmly believe that diverse voices fuel our innovation and allow us to better serve our users and the community. We foster an environment where every employee of Tencent feels supported and inspired to achieve individual and common goals.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","$118,100.00/yr - $274,600.00/yr","","","166328","https://tencent.wd1.myworkdayjobs.com/en-US/Tencent_Careers/job/US-California-Palo-Alto/Data-Scientist_R106300?source=10100001","EXTERNAL",""
"Data Engineer II","Kansas City, MO","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/data-engineer-ii-at-spring-venture-group-4341845612?trk=public_jobs_topcard-title","Spring Venture Group","https://www.linkedin.com/company/springventuregroup?trk=public_jobs_topcard-org-name","Company Description

Who We Are:

Spring Venture Group is a leading digital direct-to-consumer sales and marketing company with product offerings focused on the senior market. We specialize in distributing Medicare Supplement, Medicare Advantage, and related products via our family of brands and dedicated team of licensed insurance agents. Powered by our unique technologies that combine sophisticated marketing, comparison shopping, sales execution, and customer engagement – we help thousands of seniors across the country navigate the complex world of Medicare every day.

Overview

Job Description

The Data Management team is responsible for all things data at Spring Venture Group. Most importantly, our team is responsible for constructing high quality datasets that enable our business stakeholders and world-class Analytics department to make data informed decisions. Data engineers, combining Software Engineering and Database Engineering, serve as a primary resource for expertise with writing scripts and SQL queries, monitoring our database stability, and assisting with data governance ensuring availability for business-critical systems. The DE II works with a team of engineers of varying levels to design, develop, test, and maintain data applications and programs. The DE II will be expected to work independently when needed to solve moderately complex problems.

We are unable to sponsor for this role at anytime, so this includes not being able to consider OPT or EAD candidates or C2C candidates. You must also CURRENTLY be in the Kansas City area.

REPORTS TO

The Data Engineer II reports to the Manager of Data Management in the Technology Department.

Essential Duties

The essential duties for this role include, but are not limited to:


 * Implement changes to existing Data Management systems with respect to data integrity, documentation, and reporting
 * Write advanced Extract, Transform, and Load (ETL) scripts to integrate data of various formats into enterprise data stores.
 * Write complex SQL queries, scripts, and stored procedures to reliably and consistently modify data throughout our organization according to business requirements
 * Collaborate directly and independently with stakeholders to build familiarity, fully understand their needs, and create custom, modular, and reliable solutions to resolve their problems
 * Work with Project Managers, Solution Architects, and Software Development teams to produce architected solutions for Company Initiatives on time, on budget, and on value.
 * Document and demonstrate solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code.
 * Collaborate with more senior engineers on problems of high complexity, and architect solutions to problems of medium complexity, and advise newer engineers on problems of standard complexity.
 * Create data pipelines using appropriate and applicable technologies from Amazon Web Services (AWS) to serve the specific needs of the business.
 * Ensure 99.95% uptime of our company’s services monitoring data anomalies, batch failures, and our support chat for one week per team cycle from 8am-9pm.
 * Follow and embrace procedures of both the Data Management team and SVG Software Development Life Cycle (SDLC), including obtaining and retaining IT Security Admin III clearance.
 * Support after hours and weekend releases from our internal Software Development teams.
 * Actively participate in code review and weekly technicals with another more senior engineer or manager.
 * Assist departments with time-critical SQL execution and debug database performance problems.
   
   
   

Qualifications

ROLE COMPETENCIES

The competencies for this role include, but are not limited to:


 * Emotional Intelligence
 * Drive for Results
 * Continuous Improvement
 * Communication
 * Strategic Thinking
 * Teamwork and Collaboration
   
   
   

Position Requirements


 * Bachelor's degree in Computer Science, or a related technical field.
 * 2-4 years of practical production work in Data Engineering.
 * Advanced at reading code independently and understanding its intent.
 * Advanced at writing readable, modifiable code that solves business problems.
 * Ability to construct reliable and robust data pipelines to support both scheduled and event based workflows.
 * Working directly with stakeholders to create solutions.
 * Strong knowledge of the Python programming language.
 * Strong understanding of SQL, databases, & query optimization.
   
   
   

Benefits

Additional Information

The Company offers the following benefits for this position, subject to applicable eligibility requirements:


 * Competitive Compensation
 * Medical, Dental and vision benefits after a short waiting period
 * 401(k) matching program
 * Life Insurance, and Short-term and Long-term Disability Insurance
 * Optional enrollment includes HSA/FSA, AD&D, Spousal/Dependent Life Insurance, Travel Assist and Legal Plan
 * Generous paid time off (PTO) program starting off at 15 days your first year
 * 15 paid Holidays (includes holiday break between Christmas and New Years)
 * 10 days of Paid Parental Leave and 5 days of Paid Birth Recovery Leave
 * Annual Volunteer Time Off (VTO) and a donation matching program
 * Employee Assistance Program (EAP) - health and well-being on and off the job
 * Rewards and Recognition
 * Diverse, inclusive and welcoming culture
 * Training program and ongoing support throughout your Venture Spring Venture Group career
   
   
   

Security Responsibilities


 * Operating in alignment with policies and standards
 * Reporting Security Incidents Completing assigned training
 * Protecting assigned organizational assets
   
   
   

Spring Venture Group is an Equal Opportunity Employer","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Insurance","","","","860648","https://www.linkedin.com/jobs/view/data-engineer-ii-at-spring-venture-group-4341845612?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist","Seattle, WA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/data-scientist-at-opendoor-4338405965?trk=public_jobs_topcard-title","Opendoor","https://www.linkedin.com/company/opendoor-com?trk=public_jobs_topcard-org-name","Location: Seattle, WA

Work Model: Hybrid - 4 days in office per week

Department: Data

About The Role

We are seeking an exceptional Senior Data Scientist to join our centralized Data organization. In this role, you will be embedded within our consumer and seller experience groups, working closely with cross-functional partners across product, engineering, design, and leadership. You will leverage data to generate deep insights that drive product strategy and create a world-class experience for our users. You'll work with terabytes of data to understand user behavior and directly impact customer satisfaction and business growth.

What You'll Do



 * Develop and implement advanced analytics to drive product strategy and enhance the consumer and seller experience.
 * Conduct deep-dive statistical analyses on large datasets to uncover user behavior insights and identify key business opportunities.
 * Partner with product, engineering, and operations teams to identify opportunities to improve the user journey through data-driven insights.
 * Design and execute A/B tests and other experiment types, like multi-armed bandit tests, to measure the impact of product changes and optimize the user experience.
 * Build scalable data pipelines and reporting dashboards to deliver insights to stakeholders.
 * Present findings and strategic recommendations to executive leadership.
 * Contribute to the team and company knowledge base.
   
   
   

What You'll Need



 * Advanced proficiency in SQL for complex data manipulation and analysis.
 * Strong skills in Python for data analysis and visualization.
 * Deep understanding of statistics, A/B testing, and experimental design.
 * Excellent communication skills with the ability to present to executive leadership.
 * Strong business intuition and the ability to translate technical findings into business recommendations.
 * A self-motivated individual with a desire to solve complex, open-ended problems.
   
   
   

Education & Experience

Bachelor's degree or higher in a quantitative field such as Statistics, Economics, Mathematics, or Computer Science.

5+ years of experience in a data science, product analytics, or a similar quantitative role.

3+ years of experience in e-commerce, two-sided marketplaces, or consumer-facing products preferred.

What We Offer



 * Executive-level visibility with a direct impact on core business metrics.
 * Opportunity to work on high-impact analytics projects that shape product strategy.
 * Hybrid work model: 4 days in office, 1 day remote flexibility.
 * Collaborative culture with cross-functional team integration.
 * A fast-paced, high-growth environment with significant learning opportunities
   
   
   

Compensation

The base pay range for this position is $130,000 - $182,600 annually, plus RSUs and bonuses. Pay within this range varies by work location and may also depend on your qualifications, job-related knowledge, skills, and experience. We also offer a comprehensive package of benefits including unlimited PTO, medical/dental/vision insurance, life insurance, and 401(k) to eligible employees.

About us…. Powering life’s progress, one move at a time

Since 2014, we’ve been reinventing life’s most important transaction with a new, simple way to buy and sell a home. The traditional real estate process is broken, and our mission is clear: build a digital, end-to-end experience that makes buying and selling a home simple and certain.

We’re a team of problem solvers, innovators, and operators building the largest, most trusted platform for residential real estate. Whether it’s starting a family, taking a new job, or making a life change, we help people move forward with confidence.

This work isn’t easy, and it’s not for everyone. But if you want to be part of a team that’s tilting the world in favor of people who want to sell, buy, or own a home then you’ll find purpose here.

Opendoor Values Openness

We believe that being open about who we are and what we do allows us to be better. Individuals seeking employment at Opendoor are considered without regard to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, sexual orientation, gender identity or other protected status under all applicable laws, regulations, and ordinances. We collect, use, and disclose applicant personal information as described in our personnel privacy policies. To learn more, you can find the policy details for California residents here and for Canada residents here.

We are committed to assisting members of the military community in utilizing their skills at Opendoor. U.S. candidates are able to review your military job classification at MyNextMove.org and apply for positions that align with your expertise.

At Opendoor, we are committed to providing reasonable accommodations throughout our recruitment processes for candidates with disabilities, pregnancy, religious beliefs, or other reasons protected by applicable laws. If you require assistance or a reasonable accommodation, please contact us at TAops-accomodations@opendoor.com.","Over 200 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Real Estate","$130,000.00/yr - $182,600.00/yr","","","9398436","https://www.linkedin.com/jobs/view/data-scientist-at-opendoor-4338405965?trk=public_jobs_topcard-title","EASY_APPLY",""
"Software Engineer (Data Platform)","New York, United States","2 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/software-engineer-data-platform-at-the-recruiting-guy-4321837713?trk=public_jobs_topcard-title","The Recruiting Guy","https://www.linkedin.com/company/the-recruitingguy?trk=public_jobs_topcard-org-name","Note: This position is open to remote applicants based in the US only.

Job Title: Software Engineer (Data Platform)

Location: Remote. United States ONLY.

Employment Type: Salaried W2 Full-Time.

Salary: $125,000 - $200,000

About The Company

We represent a rapidly growing data company in NYC that’s redefining how real-world assets are represented and traded on public blockchains. Their platform serves investors, issuers, and financial institutions by providing reliable analytics, market intelligence, and transparent data on tokenized assets across the globe.

They’re trusted by leading players in finance and blockchain for their accuracy, scale, and forward-thinking approach to digital asset infrastructure. It’s an exciting opportunity to join a team that’s helping shape the future of real-world asset tokenization and build technology that’s changing how the financial world connects.

Responsibilities


 * Build and scale core data systems and APIs that serve product-level analytics
 * Collaborate with application engineers to ensure clean data flow between backend systems and end-user features
 * Develop and optimize data pipelines using PySpark and Databricks
 * Work closely with the lead data engineer on system architecture and data infrastructure design
 * Participate in system design discussions focused on scalability, performance, and maintainability
 * Contribute to the full software development lifecycle, from design through deployment
 * Support product and engineering teams by turning raw data into usable insights
   
   

Ideal Background


 * 4 to 5+ years of software engineering experience, preferably focused on large-scale data systems
 * Strong proficiency in Python and experience with PySpark
 * Experience with distributed frameworks such as Apache Spark, Beam, Flink, or Kafka Streams
 * Proven ability to design, build, and maintain production-grade data pipelines and APIs
 * Background in computer science, computer engineering, applied mathematics, or a related field (top 50 university or equivalent rigor preferred)
 * Experience working on data-driven products rather than internal BI or reporting systems
 * Strong communication skills and the ability to explain technical tradeoffs clearly
 * High attention to detail, ownership mindset, and a passion for building high-quality systems
   
   

Nice to Have


 * Experience in fintech, blockchain, or other data-intensive environments
 * Hands-on experience with Databricks or real-time streaming data systems
 * Demonstrated curiosity and craftsmanship through side projects or open-source work
   
   

Skills: beam,apache spark,software engineering,api,flink,python,kafka streams","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Human Resources Services","$125,000.00/yr - $200,000.00/yr","","","105823297","https://www.linkedin.com/jobs/view/software-engineer-data-platform-at-the-recruiting-guy-4321837713?trk=public_jobs_topcard-title","EASY_APPLY",""
"Machine Learning Engineer","Brooklyn, NY","3 weeks ago","2025-11-04","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-city-of-new-york-4337387931?trk=public_jobs_topcard-title","City of New York","https://www.linkedin.com/company/city-of-new-york?trk=public_jobs_topcard-org-name","The Fire Department of the City of New York (FDNY) is the largest Fire Department in the United States and universally is recognized as the world's busiest and most highly skilled emergency response agency. The Department's main goal is to provide fire protection, emergency medical care, and other critical public safety services to residents and visitors in the five boroughs. FDNY members are sworn to serve and protect life and property and the Department works to continually educate the public in fire, life safety and disaster preparedness, along with enforcing public safety codes. Since its inception in 1865, FDNY has helped lead efforts to make New York the safest big city in the nation. This accomplishment requires a steadfast and daily commitment to maintaining the Department's core values.

Reporting to the Deputy Director of Industrial Engineering, the Machine Learning Engineer will play a key role in our mission to optimize the Fire Department's emergency responses and other processes. The ideal candidate will leverage a wide variety of data analysis techniques to analyze departmental data. This includes utilizing casual inference techniques (such as BART, BCF, DiD, Double ML, etc.) to evaluate the effects of pilots, and time series forecasting (LSTM, SARIMAX, VARMAX, Prophet, etc.) to predict future demand for resources. The ideal candidate will also leverage advanced deep learning architectures, including transformers, to develop and deploy data-driven solutions. The ideal candidate should be experienced in using tools such as MLFlow and Comet to track experiments, as well as being experienced in deploying and monitoring models. The ideal candidate will be experienced in building robust pipelines and systems. This role demands a strong technical background and a pragmatic approach, focusing on creating and implementing models that deliver a quantifiable impact. The ideal candidate will collaborate closely with various technical and operational teams, including GIS, Data Quality, Strategic Initiatives, and IT, to ensure a seamless transition from concept to practice.

CITY RESEARCH SCIENTIST - 21744

Minimum Qualifications


 * For Assignment Level I (only physical, biological and environmental sciences and public health) A master's degree from an accredited college or university with a specialization in an appropriate field of physical, biological or environmental science or in public health.
   
   

To be appointed to Assignment Level II and above, candidates must have:


 * A doctorate degree from an accredited college or university with specialization in an appropriate field of physical, biological, environmental or social science and one year of full-time experience in a responsible supervisory, administrative or research capacity in the appropriate field of specialization; or
 * A master's degree from an accredited college or university with specialization in an appropriate field of physical, biological, environmental or social science and three years of responsible full-time research experience in the appropriate field of specialization; or
 * Education and/or experience which is equivalent to ""1"" or ""2"" above. However, all candidates must have at least a master's degree in an appropriate field of specialization and at least two years of experience described in ""2"" above. Two years as a City Research Scientist Level I can be substituted for the experience required in ""1"" and ""2"" above.
   
   

Note

Probationary Period

Appointments to this position are subject to a minimum probationary period of one year.

Preferred Skills


 * Proficiency in Python and SQL for data manipulation, analysis, and feature engineering -Demonstrable knowledge of deep learning architectures (including transformers), with specific experience in implementing and fine-tuning models in PyTorch -Expertise in deploying, monitoring, and maintaining machine learning models in a production environment using cloud platforms , containerization, and MLOps tools to ensure reliability -Experience in developing and orchestrating agents using frameworks like LangChain/LangGraph/AutoGen/n8n to create multi-step, complex, and collaborative workflows
   
   

Public Service Loan Forgiveness

As a prospective employee of the City of New York, you may be eligible for federal loan forgiveness programs and state repayment assistance programs. For more information, please visit the U.S. Department of Education’s website at https://studentaid.gov/pslf/.

Residency Requirement

New York City residency is generally required within 90 days of appointment. However, City Employees in certain titles who have worked for the City for 2 continuous years may also be eligible to reside in Nassau, Suffolk, Putnam, Westchester, Rockland, or Orange County. To determine if the residency requirement applies to you, please discuss with the agency representative at the time of interview.

Additional Information

The City of New York is an inclusive equal opportunity employer committed to recruiting and retaining a diverse workforce and providing a work environment that is free from discrimination and harassment based upon any legally protected status or protected characteristic, including but not limited to an individual's sex, race, color, ethnicity, national origin, age, religion, disability, sexual orientation, veteran status, gender identity, or pregnancy.

, $98,159.00 – $128,995.00","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Government Administration","","","","2904","https://cityjobs.nyc.gov/job/machine-learning-engineer-in-brooklyn-jid-37835","EXTERNAL",""
"Analytics Engineer - Weights & Biases","San Francisco, CA","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/analytics-engineer-weights-biases-at-weights-biases-4341622873?trk=public_jobs_topcard-title","Weights & Biases","https://www.linkedin.com/company/wandb?trk=public_jobs_topcard-org-name","CoreWeave, the AI Hyperscaler™, acquired Weights & Biases to create the most powerful end-to-end platform to develop, deploy, and iterate AI faster. Since 2017, CoreWeave has operated a growing footprint of data centers covering every region of the US and across Europe, and was ranked as one of the TIME100 most influential companies of 2024. By bringing together CoreWeave’s industry-leading cloud infrastructure with the best-in-class tools AI practitioners know and love from Weights & Biases, we’re setting a new standard for how AI is built, trained, and scaled.

The integration of our teams and technologies is accelerating our shared mission: to empower developers with the tools and infrastructure they need to push the boundaries of what AI can do. From experiment tracking and model optimization to high-performance training clusters, agent building, and inference at scale, we’re combining forces to serve the full AI lifecycle — all in one seamless platform.

Weights & Biases has long been trusted by over 1,500 organizations — including AstraZeneca, Canva, Cohere, OpenAI, Meta, Snowflake, Square,Toyota, and Wayve — to build better models, AI agents and applications. Now, as part of CoreWeave, that impact is amplified across a broader ecosystem of AI innovators, researchers, and enterprises.

As we unite under one vision, we’re looking for bold thinkers and agile builders who are excited to shape the future of AI alongside us. If you're passionate about solving complex problems at the intersection of software, hardware, and AI, there's never been a more exciting time to join our team.

What You’ll Do

The Data group at Weights & Biases works across the full range of data-related topics:


 * We help business partners set goals, make decisions, and understand the levers to achieve their goals.
 * We build reporting to keep the business attuned and aligned.
 * We build datasets and pipelines to support self-service analysis.
 * We train models to understand our customer growth, churn risk, and detect spam and abuse.
 * We’re exploring novel benchmarks and recs for model training.
 * We build and maintain a massive data platform to power it all.
   
   

About The Role

We’re hiring a Data Analytics Engineer who will focus primarily on analytics engineering while remaining a core member of the broader data platform team. You’ll be the dedicated owner of our dbt layer and related analytics infrastructure, driving operational excellence, cost/performance optimization, and self-service analytics at scale. You’ll partner closely with analysts, data scientists, and platform engineers to harden our foundations and enable better decision-making across the company.

Who You Are


 * Deep knowledge of data engineering and analytics engineering workflows at scale, with a track record of operational excellence
 * Expert with dbt (core or Cloud): model design, incremental strategies, macros/packages, testing, documentation, CI/CD
 * Strong SQL and warehouse design for BigQuery (partitioning, clustering, materializations, cost/perf tuning at multi-TB/PB scale)
 * Experience with orchestration (Dagster preferred; Airflow acceptable) and production-grade deployment practices
 * Familiar with data quality frameworks (e.g., dbt tests, Great Expectations, data contracts) and SLA/SLO design
 * Proficient in Python for orchestration, utilities, and light data tooling; Git-based workflows
 * Understanding of product telemetry, logging standards, and event modeling for web apps/SaaS
 * Excellent communication and documentation; able to align analysts, engineers, and stakeholders on semantics and standards
   
   

Preferred: (if applicable)


 * Hex (or similar BI) performance tuning and governance experience
 * Experience building semantic/metrics layers and catalogs (e.g., dbt exposures/semantics, OpenLineage, DataHub/Amundsen/Atlan)
 * Prior work migrating dbt Cloud → Dagster or similar orchestrator
 * Familiarity with AI/ML workflows and terminology
 * Terraform/infra-as-code exposure on GCP
 * Experience designing anomaly detection or rule-based alerting for KPIs
   
   

Why Us?

About

We work hard, have fun, and move fast! We’re in an exciting stage of hyper-growth that you will not want to miss out on. We’re not afraid of a little chaos, and we’re constantly learning. Our team cares deeply about how we build our product and how we work together, which is represented through our core values:


 * Be Curious at Your Core
 * Act Like an Owner
 * Empower Employees
 * Deliver Best-in-Class Client Experiences
 * Achieve More Together
   
   

We support and encourage an entrepreneurial outlook and independent thinking. We foster an environment that encourages collaboration and provides the opportunity to develop innovative solutions to complex problems. As we get set for takeoff, the growth opportunities within the organization are constantly expanding. You will be surrounded by some of the best talent in the industry, who will want to learn from you, too. Come join us!

The base salary range for this role is $139,000 to $204,000. The starting salary will be determined based on job-related knowledge, skills, experience, and market location. We strive for both market alignment and internal equity when determining compensation. In addition to base salary, our total rewards package includes a discretionary bonus, equity awards, and a comprehensive benefits program (all based on eligibility).

What We Offer

The range we’ve posted represents the typical compensation range for this role. To determine actual compensation, we review the market rate for each candidate which can include a variety of factors. These include qualifications, experience, interview performance, and location.

In addition to a competitive salary, we offer a variety of benefits to support your needs, including:


 * Medical, dental, and vision insurance - 100% paid for by CoreWeave
 * Company-paid Life Insurance
 * Voluntary supplemental life insurance
 * Short and long-term disability insurance
 * Flexible Spending Account
 * Health Savings Account
 * Tuition Reimbursement
 * Ability to Participate in Employee Stock Purchase Program (ESPP)
 * Mental Wellness Benefits through Spring Health
 * Family-Forming support provided by Carrot
 * Paid Parental Leave
 * Flexible, full-service childcare support with Kinside
 * 401(k) with a generous employer match
 * Flexible PTO
 * Catered lunch each day in our office and data center locations
 * A casual work environment
 * A work culture focused on innovative disruption
   
   

Our Workplace

While we prioritize a hybrid work environment, remote work may be considered for candidates located more than 30 miles from an office, based on role requirements for specialized skill sets. New hires will be invited to attend onboarding at one of our hubs within their first month. Teams also gather quarterly to support collaboration

California Consumer Privacy Act - California applicants only

CoreWeave is an equal opportunity employer, committed to fostering an inclusive and supportive workplace. All qualified applicants and candidates will receive consideration for employment without regard to race, color, religion, sex, disability, age, sexual orientation, gender identity, national origin, veteran status, or genetic information.

As part of this commitment and consistent with the Americans with Disabilities Act (ADA), CoreWeave will ensure that qualified applicants and candidates with disabilities are provided reasonable accommodations for the hiring process, unless such accommodation would cause an undue hardship. If reasonable accommodation is needed, please contact: careers@coreweave.com.

Export Control Compliance

This position requires access to export controlled information. To conform to U.S. Government export regulations applicable to that information, applicant must either be (A) a U.S. person, defined as a (i) U.S. citizen or national, (ii) U.S. lawful permanent resident (green card holder), (iii) refugee under 8 U.S.C.


 * 1157, or (iv) asylee under 8 U.S.C.
 * 1158, (B) eligible to access the export controlled information without a required export authorization, or (C) eligible and reasonably likely to obtain the required export authorization from the applicable U.S. government agency. CoreWeave may, for legitimate business reasons, decline to pursue any export licensing process.","102 applicants","Full-time","Entry level","Information Technology","Software Development","$139,000.00/yr - $204,000.00/yr","","","18593641","https://coreweave.com/careers/job?4610861006&board=weights_and_biases&gh_jid=4610861006","EXTERNAL",""
"Data Scientist","Richardson, TX","3 weeks ago","2025-11-06","https://www.linkedin.com/jobs/view/data-scientist-at-infosys-4337829562?trk=public_jobs_topcard-title","Infosys","https://in.linkedin.com/company/infosys?trk=public_jobs_topcard-org-name","Job Description :

Infosys Limited is seeking an AI Engineer. In this role, you will enable digital transformation for our clients in a global delivery model, research on technologies independently, recommend appropriate solutions and contribute to technology-specific best practices and standards. You will provide inputs for identifying best-fit architectural solutions for one or more projects; develop design of applications, provide regular support and guidance to project teams on complex coding and issue resolution with the objective of ensuring best-fit and high-quality technical solutions within the area of technology specialization and in compliance with guidelines, policies and norms of Infosys. You will be part of a learning culture, where teamwork and collaboration are encouraged, excellence is rewarded, and diversity is respected and valued.




Required Qualifications:

 * Bachelor’s degree or foreign equivalent required from an accredited institution. Will also consider three years of progressive experience in the specialty in lieu of every year of education.
 * Candidate must be located within commuting distance of Richardson, TX or Raleigh, NC or Hartford, CT or Tempe, AZ or Indianapolis, IN or be willing to relocate to the area.
 * At least 4 years of experience in Information Technology
 * At least 2 years of experience in AI, data engineering, creating data pipelines and processing huge volume of data.
 * At least 2 years of experience in Machine learning engineering /MLE, data science and data engineering with a proven track record of delivering impactful solutions
 * Scalable AI Solution Deployment - Experience in designing and implementing scalable AI and Data Science solutions capable of handling large-scale, distributed data and compute workloads across hybrid and cloud-native environments (OCI)
 * Performance Tuning for AI/ML and GenAI Workloads - Experience in hyperparameter tuning and performance optimization for AI/ML and Generative AI models to maximize accuracy, efficiency, and resource utilization
 * AI Full stack: Experience in in any full stack /development experience in Python or Java, or .Net or React, Node.js, Flask/Django, REST APIs, Terraform automation
 * Proficiency in Python, SQL, and machine learning frameworks such as scikit-learn, TensorFlow, or PyTorch, NLP
 * Candidates authorized to work for any employer in the United States without employer-based visa sponsorship are welcome to apply. Infosys is unable to provide immigration sponsorship for this role at this time

Preferred Qualifications:

 * Good understanding of Agile software development frameworks
 * Strong communication and Analytical skills
 * Ability to work in teams in a diverse, multi-stakeholder environment comprising of Business and Technology teams
 * Experience and desire to work in a global delivery environment

The job entails sitting as well as working at a computer for extended periods of time. Should be able to communicate by telephone, email or face to face. Travel may be required as per the job requirements.




EEO/About Us :

About Us

Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem.




EEO

Infosys provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability. Infosys provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Information Services","","","","1283","https://www.linkedin.com/jobs/view/data-scientist-at-infosys-4337829562?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI Agents Engineer (Python)","New York City Metropolitan Area","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/ai-agents-engineer-python-at-realm-4338729082?trk=public_jobs_topcard-title","Realm","https://uk.linkedin.com/company/the-realmgroup?trk=public_jobs_topcard-org-name","AI (AGENTS) ENGINEER - PYTHON | AI INFRA START UP | UP TO $300k + EQUITY | ONSITE NY




Realm is supporting an NY-based AI infra startup that’s already profitable and backed by some of the best investors in the game.




They’re building something genuinely novel and pushing the limits of AI. The team is small (<50 engineers), extremely sharp (ex-Datadog, DE Shaw, MIT), and hands-on with Go, Python, and C++ - the kind of engineers who care deeply about performance, reliability, and correctness.




We’re looking for an AI Engineer to join the AI Agents team, a high-performing team responsible for deploying frontier LLMs in production, optimizing multi-step reasoning workflows, and improving the performance and accuracy of agentic architectures across distributed systems.




In this role, you’ll:

 * Design and implement AI agent architectures, building multi-step reasoning workflows that combine LLMs with supporting systems to analyze large-scale observability data.
 * Develop prompting and orchestration tooling, including prompt engineering frameworks, function-calling interfaces, and agentic workflows optimized for latency, reliability, and performance.
 * Deploy AI components to production, integrating models and orchestration layers into a highly scalable, low-latency environment with strict uptime requirements.
 * Experiment with new approaches, prototyping and testing LLMs, prompting strategies, and fine-tuning methods to improve accuracy, coverage, and overall agent quality.
 * Collaborate across engineering teams, partnering with backend, infrastructure, and product stakeholders to ensure AI agents fit seamlessly into the broader system architecture.
 * Build observability and debugging tooling, creating evaluation systems and monitoring pipelines that track agent performance and reliability in production workloads.




Interview process: 3 stages

Compensation: Up to $300k + equity

Location: New York City (in-office)




If this sounds interesting, please apply directly to this job posting or email rsampson@realmgroup.io.










#AI #Observability #OpenTelemetry #OTel #Agents #AIAgents #Infrastructure #Go #Python #Rust","Over 200 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Engineering Services, Information Services, and IT Services and IT Consulting","","","","86253160","https://www.linkedin.com/jobs/view/ai-agents-engineer-python-at-realm-4338729082?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
401(k)"
"Data Scientist","New York, NY","2 weeks ago","2025-11-17","https://www.linkedin.com/jobs/view/data-scientist-at-schonfeld-4336742460?trk=public_jobs_topcard-title","Schonfeld","https://www.linkedin.com/company/schonfeld-group?trk=public_jobs_topcard-org-name","The Role

We are seeking a talented individual to join the Data Science team. The data science team is responsible for creating high-impact analytical datasets, conducting deep-dive research to extract systematic features, and generating forecasts that power our investment strategies.

What You’ll Do

As a Data Scientist, you will partner with market data specialists, data engineers, and sector data analysts to ingest, clean, and explore new data sources, building a comprehensive understanding of each dataset and its potential applications. You will collaborate closely with portfolio manager teams to derive insights from complex datasets and translate them into systematic features that feed the alpha‑generation process. Additionally, you will leverage your domain expertise to produce curated data products across multiple financial asset classes to standardize research, conduct quantitative analysis to generate ideas, and validate hypotheses through back‑testing. The ideal candidate is passionate about data science methodologies, thrives in a collaborative environment, and possesses a strong interest in financial markets.

What You’ll Bring

What you need:


 * 5+ years exp in data science, quantitative research, or related discipline
 * Advanced knowledge of Python, SQL, or other programming languages
 * Proven experience in conducting quantitative analysis using statistical and machine learning packages
 * Deep understanding of feature engineering, model training, evaluation, and deployment
 * Knowledge of financial asset classes such as equity, futures, and fixed Income
 * Attention to detail and strong communication skills
 * Master’s or PhD degree in a quantitative field such as data science, statistics and financial engineering
   
   

We’d Love If You Had


 * Experience conducting data analysis on complex financial datasets, such as alternative data and market micro-structure datasets
 * Knowledge in programming languages such as C++ and Java
 * Experience in designing, building and testing systematic signals
 * Experience working with big data analysis
 * Experience with any of the following technologies: Spark, Kafka, Docker, Airflow
   
   

Who We Are

Schonfeld is a global multi-manager hedge fund that strives to deliver industry-leading risk-adjusted returns for our investors. We leverage both internal and external portfolio manager teams around the world, seeking to capitalize on inefficiencies and opportunities within the markets. We draw from decades of experience and a significant investment in proprietary technology, infrastructure and risk analytics to invest across four main strategies: Quant, Tactical, Fundamental Equity and Discretionary Macro & Fixed Income.

Our Culture

At Schonfeld, we’ll invest in you. Attracting and retaining top talent is at the heart of what we do, because we believe that exceptional outcomes begin with exceptional people. We foster a culture where talent is empowered to continually learn, innovate and pursue ambitious goals. We are teamwork-oriented, collaborative and encourage ideas—at all levels—to be shared. As an organization committed to investing in our people, we provide learning and educational offerings and opportunities to make an impact. We encourage community through internal networks, external partnerships and service initiatives that promote inclusion and purpose beyond the firm’s walls.

The base pay for this role is expected to be between $185k and $225k. The expected base pay range is based on information at the time this post was generated. This role may also be eligible for other forms of compensation such as a performance bonus and a competitive benefits package. Actual compensation for the successful candidate will be determined based on a variety of factors such as skills, qualifications, and experience.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Financial Services","$185,000.00/yr - $225,000.00/yr","","","147507","https://job-boards.greenhouse.io/schonfeld/jobs/7370027?gh_src=e73f47fb1us","EXTERNAL",""
"Software Engineer (Data Platform)","Austin, TX","2 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/software-engineer-data-platform-at-the-recruiting-guy-4321787895?trk=public_jobs_topcard-title","The Recruiting Guy","https://www.linkedin.com/company/the-recruitingguy?trk=public_jobs_topcard-org-name","Note: This position is open to remote applicants based in the US only.

Job Title: Software Engineer (Data Platform)

Location: Remote. United States ONLY.

Employment Type: Salaried W2 Full-Time.

Salary: $125,000 - $200,000

About The Company

We represent a rapidly growing data company in NYC that’s redefining how real-world assets are represented and traded on public blockchains. Their platform serves investors, issuers, and financial institutions by providing reliable analytics, market intelligence, and transparent data on tokenized assets across the globe.

They’re trusted by leading players in finance and blockchain for their accuracy, scale, and forward-thinking approach to digital asset infrastructure. It’s an exciting opportunity to join a team that’s helping shape the future of real-world asset tokenization and build technology that’s changing how the financial world connects.

Responsibilities


 * Build and scale core data systems and APIs that serve product-level analytics
 * Collaborate with application engineers to ensure clean data flow between backend systems and end-user features
 * Develop and optimize data pipelines using PySpark and Databricks
 * Work closely with the lead data engineer on system architecture and data infrastructure design
 * Participate in system design discussions focused on scalability, performance, and maintainability
 * Contribute to the full software development lifecycle, from design through deployment
 * Support product and engineering teams by turning raw data into usable insights
   
   

Ideal Background


 * 4 to 5+ years of software engineering experience, preferably focused on large-scale data systems
 * Strong proficiency in Python and experience with PySpark
 * Experience with distributed frameworks such as Apache Spark, Beam, Flink, or Kafka Streams
 * Proven ability to design, build, and maintain production-grade data pipelines and APIs
 * Background in computer science, computer engineering, applied mathematics, or a related field (top 50 university or equivalent rigor preferred)
 * Experience working on data-driven products rather than internal BI or reporting systems
 * Strong communication skills and the ability to explain technical tradeoffs clearly
 * High attention to detail, ownership mindset, and a passion for building high-quality systems
   
   

Nice to Have


 * Experience in fintech, blockchain, or other data-intensive environments
 * Hands-on experience with Databricks or real-time streaming data systems
 * Demonstrated curiosity and craftsmanship through side projects or open-source work
   
   

Skills: beam,apache spark,software engineering,api,flink,python,kafka streams","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Human Resources Services","$125,000.00/yr - $200,000.00/yr","","","105823297","https://www.linkedin.com/jobs/view/software-engineer-data-platform-at-the-recruiting-guy-4321787895?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Columbus, OH","2 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/data-engineer-at-mckesson-4335435260?trk=public_jobs_topcard-title","McKesson","https://www.linkedin.com/company/mckesson?trk=public_jobs_topcard-org-name","McKesson is an impact-driven, Fortune 10 company that touches virtually every aspect of healthcare. We are known for delivering insights, products, and services that make quality care more accessible and affordable. Here, we focus on the health, happiness, and well-being of you and those we serve – we care.

What you do at McKesson matters. We foster a culture where you can grow, make an impact, and are empowered to bring new ideas. Together, we thrive as we shape the future of health for patients, our communities, and our people. If you want to be part of tomorrow’s health today, we want to hear from you.

CoverMyMeds’ Data & Analytics is looking for a Specialist, Data Engineering to join our Data Engineering team. Of note, our Data Engineering Team is a highly technical group of results driven Engineers, Analysts and Architects focused on providing our internal and external clients with high quality, repeatable and scalable data solutions. Together with our various business units, the work our Data Engineering team does ultimately helps get more people the medicine they need to live healthier lives. 

 

What You'll Do 

The Specialist, Data Engineering will support and expand the data platforms that process, store, organize the data critical for the Data and Analytics team. This role will participate in the technical strategy and execution to provide trusted, stable, reliable, responsive, and secure solutions and proactively inform business partners on Data & Analytics platform and product health, and problem resolution. The Specialist, Data Engineering will work collaboratively with our Data Systems Analysts as well as our Analytics and Technology partners to solve business problems and deliver solutions.

Position Description


 * Design and develop solutions and commissions of complex data across systems for McKesson/CoverMyMeds internal and external customers.
 * Develop Data Ingestion and Integration pipelines from various sources to Data Warehouse
 * Work with databases, files and unstructured data to identify, transport and quality test the data required to drive our data synchronization tasks to perform regular and incremental loads of data.
 * Write program/code in SQL and / or cloud based tools such as Snowflake or Databricks to cleanse, apply business logic and standardize the data according to business rules, enabling more effective data governance along with clear and efficient end-user reporting.
 * Design conceptual data model based on business reporting requirements, interacting with business partners to understand the business logic and end-use of the data.
 * Work with the application development teams to determine data flow in the source system and architect an appropriate flow into the data warehouse.
   
   
   

Minimum Qualifications

Degree or equivalent and typically requires 4+ years of relevant experience

Education


 * Bachelor's degree in. Computer Science, Information Systems, or related field.
   
   
   

Critical Skills


 * 4+ years of technical and professional experience as a data engineer
 * Strong (4+ years'), hands-on experience as a technologist working with data warehouse solutions, cloud technology, relational databases and dashboarding tools such as Databricks, Oracle, MySQL, Qlik, Tableau, SQL Server, etc. 
 * 4 years' experience working with structured and unstructured data and within batch and real-time data streaming environments.
 * Experience supporting Reporting and Analytics, Real time Analytics, Systems Integration, and Data Governance.
 * Demonstrated expertise in database design and modeling.
 * Expert knowledge of cloud data technologies (MS Azure)
 * Experience with business-critical applications.
 * Experience on large-scale implementation programs.
   
   
   

Preferred Skills


 * Excellent written and verbal communication skills; timely communication with clear expectations. An active listener and clear communicator; can lead by influence.
 * Ability to find creative solutions to complex problems.
 * Exhibit a strong sense of urgency and ownership for task/project completion.
 * Highly adept at working collaboratively across multiple business and technical functions to achieve results.
   
   
   

We are proud to offer a competitive compensation package at McKesson as part of our Total Rewards. This is determined by several factors, including performance, experience and skills, equity, regular job market evaluations, and geographical markets. The pay range shown below is aligned with McKesson's pay philosophy, and pay will always be compliant with any applicable regulations. In addition to base pay, other compensation, such as an annual bonus or long-term incentive opportunities may be offered. For more information regarding benefits at McKesson, please click here.

Our Base Pay Range for this position

$105,500 - $175,900

McKesson is an Equal Opportunity Employer

McKesson provides equal employment opportunities to applicants and employees and is committed to a diverse and inclusive environment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, age or genetic information. For additional information on McKesson’s full Equal Employment Opportunity policies, visit our Equal Employment Opportunity page.

Join us at McKesson!","Over 200 applicants","Full-time","Entry level","Information Technology","Hospitals and Health Care","$105,500.00/yr - $175,900.00/yr","","","1900","https://careers.mckesson.com/en/job/-/-/733/88283924416?source=rd_linkedin","EXTERNAL",""
"Senior Data Engineer, Integrations","Ann Arbor, MI","4 days ago","2025-11-28","https://www.linkedin.com/jobs/view/senior-data-engineer-integrations-at-mariana-minerals-4339319750?trk=public_jobs_topcard-title","Mariana Minerals","https://www.linkedin.com/company/mariana-minerals?trk=public_jobs_topcard-org-name","About Mariana Minerals

Mariana Minerals is a software-first, vertically integrated minerals company on a mission to supply the critical minerals powering modern energy, AI, and defense technologies.

We’re reimagining how minerals are sourced, refined, and optimized by combining deep industrial expertise with software, automation, and data-driven decision-making. Join us as we build the future of responsible mineral sourcing and supply.

The Opportunity

We’re looking for a Senior Data & Integrations Engineer to own the data platform that connects our industrial systems to ML models—building the semantic layer between process engineering and AI-driven operations.

This role goes beyond traditional ETL. You’ll design and build robust Python-based data pipelines and semantic models that translate real-world industrial processes into structured, meaningful data for our machine learning and software teams. Your work will directly enable reinforcement learning algorithms that control physical equipment—where data engineering meets real-world impact.

What You’ll Do

Core Responsibilities (≈70%)


 * Design, build, and maintain data pipelines in Python that integrate with our digital twin simulator, ML infrastructure, and operational systems.
 * Develop semantic data models and analytics layers that bridge process engineering, ML model requirements, and business metrics.
 * Architect data systems that support both real-time operations and historical analysis, prioritizing semantic accuracy and data quality over massive scale.
 * Evolve our data platform as we scale from our first facility to multiple operations—defining the foundations of a modern, industrial data stack.
 * Partner with ML engineers and process experts to ensure data is clean, consistent, and fit for model training and inference.
   
   

Integrations & Cross-Functional Work (≈30%)


 * Build and maintain API integrations with enterprise and industrial systems (PLCs, LIMS, historians, engineering tools).
 * Support real-time data exchange between control systems, dashboards, and analytics platforms.
 * Collaborate across software, process, and ML teams to translate complex operational data into actionable insights.
   
   

Required

What You’ll Bring


 * 5+ years of Python development experience, focused on data engineering and modeling.
 * Proven experience creating semantic layers and analytics models bridging technical and business contexts.
 * Strong software engineering fundamentals—version control, testing, documentation, and maintainable code.
 * Hands-on experience with modern data tools (Airflow/Dagster, dbt, data quality frameworks).
 * Clear communication and collaboration skills; ability to work with ML, software, and operations teams.
 * A structured yet creative problem-solving mindset and comfort with ambiguity.
   
   

Nice to Have


 * API integration experience (REST, OAuth, rate limiting, retries).
 * Familiarity with time-series or industrial data (PLCs, LIMS, SCADA).
 * Exposure to ML pipelines and real-time data processing.
 * Experience designing data systems in manufacturing, energy, or process industries.
   
   

Why This Role Matters

This isn’t a big-data problem—it’s a smart-data challenge. You’ll create the connective tissue between industrial operations and AI systems, turning complex process signals into meaningful data that drives real outcomes.

Your work will directly shape how AI optimizes mineral processing and define the foundation of Mariana’s data strategy as we grow.

Why Join Mariana Minerals


 * Build systems that bridge the physical and digital worlds.
 * Work alongside engineers, data scientists, and industrial experts solving hard problems that matter.
 * Join a culture that values Extreme Ownership, Engineering Out Requirements, then Automating, and Sharing Your Legos.
   
   

Be part of building the future of intelligent mineral processing.

Compensation Range: $150K - $210K

","45 applicants","Full-time","Mid-Senior level","Information Technology","Metal Ore Mining","$150,000.00/yr - $210,000.00/yr","","","105053468","https://www.linkedin.com/jobs/view/senior-data-engineer-integrations-at-mariana-minerals-4339319750?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Denver, CO","4 days ago","2025-11-28","https://www.linkedin.com/jobs/view/data-engineer-at-candid-health-4339269407?trk=public_jobs_topcard-title","Candid Health","https://www.linkedin.com/company/candid-health?trk=public_jobs_topcard-org-name","The Opportunity

We’re looking for a passionate and skilled Data Engineer to join our fast growing data team to revolutionize healthcare billing products and systems that directly address the needs of our customers. As an early Data Engineer, you’ll play a key role in designing, building, and supporting the next generation of our data infrastructure. This is an opportunity to get in at the ground floor of designing and building something exciting, new, secure, durable, performant, and maintainable.

What You’ll Do


 * Collaborate with leadership and other stakeholders including engineering, delivery, product, and customers to understand Candid’s data needs. Work with product and engineering to understand the long-term product strategy and broader technical architecture. Work with customers to understand their needs and how best to address them in a scalable way.
 * Expansively own Data Engineering team outcomes: Deliver on Data Team outcomes for both internal teams and external customers, which include both operational and analytics workflows.
 * Own the design of new data infrastructure: Research and identify industry best practices and state-of-the-art tools to leverage. Design new systems to support the necessary outcomes in a secure, durable, performant, and maintainable way.
 * Build and support new data products: Build datasets, pipelines, and other solutions to support operational and product outcomes. Develop support systems to scale the team and achievable outcomes.
 * Contribute significantly to building a robust data culture: ensuring data is trusted, accessible, and central to how we identify opportunities and measure our impact.
 * Some systems & projects you might work on: BI Platform Infrastructure, Airflow, BigQuery Tuning, Customer Facing Data Delivery Infrastructure, DBT Deployment, CI/CD, Data Streaming Infrastructure.
   
   

Who You Are


 * You have Bachelors of Science or Bachelors of Art in Computer Science, Computer Engineering, Math or other similar degree.
 * You have 4+ years of experience working with data pipelines, products, and tools.
 * You’ve built and maintained complex data integrations or pipelines.
 * You have well-developed opinions on modern data warehouse architecture, tools, and patterns.
 * You have excellent technical vision; you know the right architecture and patterns to build functional, durable, and maintainable product.
 * You have a customer-first and learner’s mindset, and value teaching others.
 * You make the right trade-offs when considering project scope, which corners are worth cutting, and which are not.
 * You’re a clear and concise communicator; you enjoy the challenge of explaining complicated ideas in simple terms, both in-person and in writing.
 * Experience with the technologies we currently use is a plus, but by no means required: Google Cloud Platform, BigQuery, PostgreSQL, Metabase, Terraform, Python.
   
   

Pay Transparency

The estimated starting annual salary range for this position is $165,000 to $205,000 USD. The listed range is a guideline from Pave data, and the actual base salary may be modified based on factors including job-related skills, experience/qualifications, interview performance, market data, etc. Total compensation for this position may also include equity, sales incentives (for sales roles), and employee benefits. Given Candid Health’s funding and size, we heavily value the potential upside from equity in our compensation package. Further note that Candid Health has minimal hierarchy and titles, but has broad ranges of experience represented within roles.

","Over 200 applicants","Full-time","Entry level","Information Technology","Hospitals and Health Care","$165,000.00/yr - $205,000.00/yr","","","70448411","https://www.linkedin.com/jobs/view/data-engineer-at-candid-health-4339269407?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist - Financial Analytics","New York, NY","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/data-scientist-financial-analytics-at-rippling-4338738936?trk=public_jobs_topcard-title","Rippling","https://www.linkedin.com/company/rippling?trk=public_jobs_topcard-org-name","About Rippling

Rippling gives businesses one place to run HR, IT, and Finance. It brings together all of the workforce systems that are normally scattered across a company, like payroll, expenses, benefits, and computers. For the first time ever, you can manage and automate every part of the employee lifecycle in a single system.

Take onboarding, for example. With Rippling, you can hire a new employee anywhere in the world and set up their payroll, corporate card, computer, benefits, and even third-party apps like Slack and Microsoft 365—all within 90 seconds.

Based in San Francisco, CA, Rippling has raised $1.4B+ from the world’s top investors—including Kleiner Perkins, Founders Fund, Sequoia, Greenoaks, and Bedrock—and was named one of America's best startup employers by Forbes.

We prioritize candidate safety. Please be aware that all official communication will only be sent from @Rippling.com addresses.

About The Role

Rippling's Payments Data & Analytics team is seeking an experienced and highly skilled Data Scientist to join our rapidly expanding team. In this pivotal role, you will be responsible for designing, building, and maintaining services that automatically process vast amounts of financial data, providing comprehensive visibility into every stage of the money movement lifecycle within Rippling's payments product ecosystem.

This is an exciting opportunity to become a foundational member of the Payments Analytics team, ensuring accurate settlement between our customers, external financial institutions, and Rippling for every transaction. This is a highly cross-functional role with significant visibility, including with the executive team. You will empower the Accounting, Finance, Biz Ops, Payments, and Product teams by delivering accurate data that is critical to Rippling’s finances and essential for the correct functioning of product systems.

What You Will Do


 * Collaborate cross-functionally with engineering, accounting, financial partnerships, and product teams to analyze and account for billions of dollars flowing through the Rippling payment platform.
 * Build full-cycle analyses using SQL, Python, or other scripting and statistical tools, and develop real-time metrics dashboards to manage key financial and operating levers of the business.
 * Monitor payment flows between systems, banks, processors, and inter-company accounts, perform daily account reconciliations, and follow up on any discrepancies.
 * React swiftly to emerging issues, summarize facts, and provide recommendations for the timely resolution of critical financial matters.
 * Collaborate with key stakeholders (Accounting, Compliance, Treasury, etc.) to understand business requirements and develop scalable solutions for reporting and reconciliation automation, including internal tool development and/or the implementation of third-party tools.
 * Develop and maintain comprehensive documentation of reconciliation processes and procedures.
 * Prepare and deliver data and reporting solutions supporting month-end close, regulatory & compliance reporting, and Internal and External Audit reporting.
 * Communicate findings and recommendations to stakeholders through clear and concise presentations and reports.
   
   

What You Will Need


 * Master’s degree or Bachelor's degree in Computer Science, Engineering, Statistics, MIS or other quantitative fields.
 * 5+ years demonstrated experience in applying statistical analysis, modeling, machine learning and/or exploratory analysis to large datasets, ideally in payments processing, quote-to-cash financial reporting.
 * Experience with data warehousing, ETL, and reporting tools (e.g. Snowflake, Tableau, dbt, Dagster).
 * Extensive experience with SQL, Python, or other scripting languages and their application to all phases of the data science development process (initial analysis and model development through deployment).
 * Experience working with engineering, finance, and accounting teams to assess their data needs and build automated reporting pipelines.
 * Strong problem-solving and communication skills, with the ability to communicate findings and recommendations clearly to both technical and non-technical audiences.
 * Ability to interface with multiple stakeholders and senior leadership (C-suite) across the organization.
 * Bonus points if you have experience with general accounting principles, with the general ledger close process, and regulatory compliance.
   
   

Additional Information

Rippling is an equal opportunity employer. We are committed to building a diverse and inclusive workforce and do not discriminate based on race, religion, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, veteran or military status, or any other legally protected characteristics, Rippling is committed to providing reasonable accommodations for candidates with disabilities who need assistance during the hiring process. To request a reasonable accommodation, please email accomodations@rippling.com

Rippling highly values having employees working in-office to foster a collaborative work environment and company culture. For office-based employees (employees who live within a defined radius of a Rippling office), Rippling considers working in the office, at least three days a week under current policy, to be an essential function of the employee's role.

This role will receive a competitive salary + benefits + equity. The salary for US-based employees will be aligned with one of the ranges below based on location; see which tier applies to your location here.

A variety of factors are considered when determining someone’s compensation–including a candidate’s professional background, experience, and location. Final offer amounts may vary from the amounts listed below.

The pay range for this role is:

108,000 - 189,000 USD per year(US San Francisco Bay Area)","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","$108,000.00/yr - $189,000.00/yr","","","17988315","https://ats.rippling.com/rippling/jobs/94fd776b-96f3-4927-9bff-ae0725e5f888?jobSite=LinkedIn","EXTERNAL",""
"Senior Data Analyst","Jersey City, NJ","3 weeks ago","2025-11-10","https://www.linkedin.com/jobs/view/senior-data-analyst-at-nuts-com-4335390036?trk=public_jobs_topcard-title","Nuts.com","https://www.linkedin.com/company/nutsdotcom?trk=public_jobs_topcard-org-name","Hi, we're Nuts.com!

Nuts.com is a self-funded, profitable, rapidly growing multi-channel DTC specialty food and wellness company with over 550 people on our team. We're changing the landscape of snacking on nuts, dried fruit, chocolate and more! We planted our roots in Newark, New Jersey during the Great Depression, selling premium nuts on Mulberry Street's open-air market. We've come quite a long way since then, taking our multi-generational family business online in 1999. Even after 96 years, we continue to pride ourselves in expertly sourcing the highest quality foods and treating our customers like family.

What's our team like? We're driven, collaborative and entrepreneurial. Energy and passion power our business and we look for candidates who share in that excitement to help us continue to build something special.

The Role

At Nuts.com, we love our customers, and we love the data that tells their story. We're building our business on that foundation of data—and we're looking for a Senior Data Analyst to help us make it faster, more reliable, and more insightful.

As a Senior Data Analyst, you'll sit at the intersection of data, strategy, and storytelling - turning complex datasets into actionable insights that shape decisions across Marketing, Product, Finance, and Operations. Reporting into the Manager of Data & Analytics, you'll own analyses from end to end: defining the question, querying data using SQL and dbt models, visualizing trends in Looker, and delivering recommendations that drive measurable business outcomes. You'll collaborate closely with data engineers to ensure reliable pipelines, and partner with business stakeholders to translate analytical findings into strategies that improve acquisition, retention, and profitability. This is a highly visible role for someone who loves both the technical side of analytics and the art of communicating insights that move the business forward.

We have thousands of items, data-driven fulfillment centers, a robust order management system, an exhaustive tagging footprint, a growing number of media outlets, and happy, engaged customers... If you're already imagining all the cool stuff we'll be able to build with that, then we should talk.

What You'll Do


 * Own Analytical Insights: Lead end-to-end analysis from defining the business question to delivering actionable insights that drive revenue, retention, and profitability across DTC and B2B channels.
 * Design & Build Reports: Develop intuitive, scalable dashboards and reports in Looker, ensuring stakeholders have clear visibility into key KPIs across Marketing, Merchandising, Product, Operations, and Finance.
 * Model & Transform Data: Collaborate with data engineers to define data models in dbt and write performant SQL that powers clean, reliable datasets for analytics.
 * Drive Business Performance: Analyze customer behavior, campaign performance, and product trends to identify growth opportunities and operational improvements.
 * Collaborate Cross-Functionally: Work closely with product managers, marketers, merchants and finance partners to translate insights into strategic actions and measurable outcomes.
 * Experiment & Test: Design, analyze, and interpret A/B and multivariate tests to measure the impact of product changes, promotions, and customer experiences - partnering with stakeholders to turn experiment results into scalable business strategies.
 * Support Strategic Projects: Contribute analytical rigor to company-wide initiatives such as pricing strategy, retention forecasting, customer segmentation, and marketing attribution.
   
   

What You'll Bring


 * Education & Experience: Bachelor's degree in Finance, Computer Science, Economics, Statistics, or a related analytical field, with 4–6+ years of experience in a data or analytics role.
 * Technical Mastery: Advanced proficiency in SQL and strong fluency in Python for data transformation, automation, and experimentation analysis.
 * Modern Data Stack Expertise: Hands-on experience with tools such as dbt, Fivetran, Airbyte, Redshift, Mixpanel and Looker, ideally within a cloud-based analytics environment.
 * Analytical Rigor: Proven ability to structure ambiguous business problems, design analyses that drive measurable impact, and synthesize findings into clear, actionable insights.
 * Experimentation Mindset: Comfortable designing and interpreting A/B tests, with an understanding of statistical significance, lift analysis, and business context.
 * Communication & Influence: Excellent written and verbal communication skills — able to translate complex data into compelling narratives and recommendations for non-technical audiences.
 * Collaboration: Track record of working cross-functionally with marketing, product, finance, and engineering teams to align insights with business goals.
   
   

What We Offer


 * A high-growth and rewarding role in a foundationally strong and rapidly evolving business
 * Annual Salary Range: $100,000 - $120,000 plus annual bonus
 * Excellent benefits including a 401K Match
 * Paid Maternity, Adoption and Paternity leave
 * And all the Nuts.com snacks your heart desires + a 40% employee discount
   
   

EEO STATEMENT



Nuts.com is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard of actual or perceived race, color, creed, religion, national origin, ancestry, citizenship status, immigration status, age, sex or gender (including pregnancy), gender identity or expression (including transgender status), sexual orientation, marital status, veteran status, physical or mental disability, genetic information, or any other characteristic protected by applicable federal, state, or local laws.

Applicants with disabilities who require assistance or accommodation during the application or interview process should reach out to us at people@nuts.com","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Manufacturing","$100,000.00/yr - $120,000.00/yr","","","951477","https://www.linkedin.com/jobs/view/senior-data-analyst-at-nuts-com-4335390036?trk=public_jobs_topcard-title","EASY_APPLY",""
"Business Analyst","Manhattan, NY","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/business-analyst-at-city-of-new-york-4347549749?trk=public_jobs_topcard-title","City of New York","https://www.linkedin.com/company/city-of-new-york?trk=public_jobs_topcard-org-name","Note: This position is open only to current employees of the City of New York serving in a permanent (not provisional) civil service title of either Associate Staff Analyst or Computer Associate (Software). Please clearly indicate your permanent civil service title on your resume and cover letter.

The New York City Comptroller’s Office works to promote the financial health, integrity, and effectiveness of New York City government, in order to strengthen trust, secure a thriving future for all New Yorkers, and build a more just, equitable, and resilient city. Led by an independently elected citywide official, the comptroller’s office provides checks and balances needed to hold City government accountable for budgeting wisely, investing responsibly, operating efficiently, acting fairly, living up to its obligations and promises, and paying attention to the long-term challenges we face together.

The Office of the Comptroller’s Bureau of Information Systems provides a full range of technology support services for key business functions and Charter mandated responsibilities of the Comptroller’s Office. These services include technology strategic planning, web site development, graphic design, disaster recovery, systems development, network administration, audio/visual services, business process re-engineering, change management, program management, security administration, service desk, computer operations, telecommunications, and document management.

Under the direction of the Director of the Asset Management Systems, the Business Analyst is responsible for working with the Bureau of Asset Management on their various IT initiatives and documenting existing business processes, implementing management plans for each project, compiling analysis reports and documenting user requirements. The Business Analyst will be expected to report on these initiatives following Office and industry-wide standards and keep Bureau leadership informed of the latest status, risks and accomplishments.

Duties and responsibilities of the position include, but are not limited to the following:


 * Facilitate and capture business/technical requirements from existing systems for modernization.
 * Deliver elements of system design migration rules, business rules, wireframes, or other detailed deliverables.
 * Ensure project priorities are clearly communicated and understood.
 * Identify opportunities to improve enterprise systems and business processes and help drive solutions.
 * Serve as a liaison between business users and technical team, providing clear communication, translate technical jargon into business terms.
 * Utilize SQL to extract, manipulate, and analyze large datasets from various databases, ensuring accurate and timely information for business decision-making and reporting.
 * Leverage Power Query to cleanse, transform, and integrate data from multiple sources, creating efficient and automated data workflows for reporting and analysis.
   
   

Minimum Qualifications/Requirements: This position is open only to current employees of the City of New York serving in a permanent (not provisional) civil service title of either Associate Staff Analyst or Computer Associate (Software). Please clearly indicate your permanent civil service title on your resume and cover letter.

ASSOCIATE STAFF ANALYST - 12627

Minimum Qualifications


 * A master's degree from an accredited college in economics, finance, accounting, business or public administration, public health, human resources management, management science, operations research, organizational behavior, industrial psychology, statistics, personnel administration, labor relations, psychology, sociology, human resources development, political science, urban studies or a Juris Doctor degree from an accredited law school, and one year of satisfactory full-time professional experience in one or a combination of the following: working with the budget of a large public or private concern in budget administration, accounting, economic or financial administration, or fiscal or economic research; in management or methods analysis, operations research, organizational research or program evaluation; in personnel or public administration, recruitment, position classification, personnel relations, labor relations, employee benefits, staff development, employment program planning/administration, labor market research, economic planning, social services program planning/evaluation, or fiscal management, or in a related area; or
 * A baccalaureate degree from an accredited college and three years of satisfactory full-time professional experience in the areas described in ""1"" above.
 * An associate degree or completion of 60 semester credits from an accredited college and five years of satisfactory full-time professional experience as described in “1” above.
 * A four-year high school diploma or its educational equivalent approved by a State’s department of education or a recognized accrediting organization and seven years of satisfactory full-time professional experience as described in “1” above.
 * A combination of education and/or experience equivalent to “1”, “2”, “3”, or “4” above. College education may be substituted for professional experience at the rate of 30 semester credits from an accredited college for one year of experience. However, all candidates must have a high school diploma and at least one year of experience as described in “1” above.
   
   

Preferred Skills


 * Experience with multiple asset class and the investment financial space. Familiarity with .Net Code , SQL Data Base stored procedures and views, - Experience with technology that supports multiple asset classes and functions in the financial services and investment space. - Track record in re-engineering processes via the creation and implementation of technology tools. - Proficiency in Microsoft Office 365 suite. - Proficiency in storing, querying and manipulating data in MS SQL Server (SQL, Stored Procedures, Triggers, SSIS) is desired. - Experience using Power Bi and Power Querry
   
   

55a Program

This position is also open to qualified persons with a disability who are eligible for the 55-a Program. Please indicate at the top of your resume and cover letter that you would like to be considered for the position through the 55-a Program.

Public Service Loan Forgiveness

As a prospective employee of the City of New York, you may be eligible for federal loan forgiveness programs and state repayment assistance programs. For more information, please visit the U.S. Department of Education’s website at https://studentaid.gov/pslf/.

Residency Requirement

New York City residency is generally required within 90 days of appointment. However, City Employees in certain titles who have worked for the City for 2 continuous years may also be eligible to reside in Nassau, Suffolk, Putnam, Westchester, Rockland, or Orange County. To determine if the residency requirement applies to you, please discuss with the agency representative at the time of interview.

Additional Information

The City of New York is an inclusive equal opportunity employer committed to recruiting and retaining a diverse workforce and providing a work environment that is free from discrimination and harassment based upon any legally protected status or protected characteristic, including but not limited to an individual's sex, race, color, ethnicity, national origin, age, religion, disability, sexual orientation, veteran status, gender identity, or pregnancy.

, $82,056.00 – $100,000.00","86 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Government Administration","","","","2904","https://cityjobs.nyc.gov/job/business-analyst-in-manhattan-jid-38337","EXTERNAL",""
"Quality Assurance (QA) Engineer","Roanoke, VA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/quality-assurance-qa-engineer-at-virginia-transformer-corp-4339121807?trk=public_jobs_topcard-title","Virginia Transformer Corp","https://www.linkedin.com/company/virginia-transformer-corp_2?trk=public_jobs_topcard-org-name","Quality Assurance (QA) Engineer

Location: Roanoke, VA



Join a Company Built to Grow – Powered by People

At Virginia Transformer, we’re not just manufacturing custom transformers — we’re building power solutions that move the world. As a privately held, organically growing company, we thrive on momentum, innovation, and grit.

If you love the thrill of manufacturing, the strategy of an endurance race, and the energy of a fast-moving train — this is your track. We train hard, grow together, and lead with purpose. Every transformer we build is custom, every challenge unique, and every team member essential.

We’re looking for those ready to lead, fueled by commitment, and driven by impact. One team. One mission. One source.




About the Role

The QA Engineer is responsible for ensuring product quality, reliability, and compliance throughout the manufacturing process. This role supports engineering, production, and customer teams by driving root-cause analysis, corrective and preventive actions (CAPA), and continuous improvement initiatives. The ideal candidate has strong technical problem-solving skills, an understanding of manufacturing processes, and experience working within ISO or similar quality systems.




Key Responsibilities

Quality Assurance & Compliance

 * Ensure products meet internal quality standards, customer specifications, and industry requirements.
 * Interpret engineering drawings, specifications, and standards to verify compliance.
 * Support audits (internal, customer, and external certifying bodies) and maintain documentation for ISO 9001 or equivalent systems.
 * Develop and maintain quality inspection processes, work instructions, and control plans.

Root Cause Analysis & Corrective Actions

 * Lead and facilitate structured problem-solving (8D, 5 Whys, Fishbone, FMEA).
 * Investigate nonconformance's and drive corrective and preventive action implementation.
 * Track quality issues and provide recommendations to prevent recurrence.

Testing & Inspection

 * Perform in-process and final product inspections, including mechanical, electrical, or dimensional checks depending on product requirements.
 * Support qualification testing, factory acceptance testing (FAT), or customer witness testing.
 * Validate and calibrate inspection and measurement equipment.

Data Analysis & Reporting

 * Analyze quality data trends (scrap, rework, defects, warranty claims) and recommend improvement actions.
 * Prepare reports, dashboards, and KPIs for leadership review.
 * Drive use of statistical tools (SPC, MSA, sampling plans).

Cross-Functional Collaboration

 * Work closely with Engineering, Manufacturing, Supply Chain, and Customer Support teams to resolve quality concerns and improve processes.
 * Support supplier quality activities, including incoming inspection and supplier corrective actions.
 * Engage directly with customers when needed to address quality concerns or clarify requirements.

Continuous Improvement

 * Support Lean, Six Sigma, and Kaizen initiatives focused on reducing waste, improving process reliability, and increasing first-pass yield.
 * Recommend improvements to quality systems, manufacturing processes, and product design where appropriate.




Qualifications

Education & Experience

 * Bachelor’s degree in Engineering (Mechanical, Electrical, Industrial, or related field) preferred; equivalent experience considered.
 * 2+ years of experience in a quality engineering role within a manufacturing environment.
 * Experience with ISO 9001, IATF 16949, or similar quality management systems.

Technical Skills

 * Strong understanding of engineering drawings, GD&T, and manufacturing processes.
 * Proficiency with statistical analysis tools (Minitab, Excel, SPC, MSA).
 * Familiarity with CAPA, 8D, PFMEA, Control Plans, and Root Cause Analysis.

Soft Skills

 * Strong communication, documentation, and presentation skills.
 * Ability to influence cross-functional teams and lead problem-solving discussions.
 * Detail-oriented with strong analytical and organizational skills.




Preferred Qualifications

 * Experience with electrical equipment, heavy industrial products, or transformer components.
 * ASQ certifications (CQE, CQA, CSSGB) are a plus.
 * Experience supporting customer audits or specification reviews.
 * Lean or Six Sigma training/certification.




Why Join Us

 * Be part of a rapidly growing engineering and manufacturing team.
 * Work with complex, custom-built industrial products.
 * Competitive pay, strong career growth opportunities, and a culture focused on continuous improvement.

","75 applicants","Full-time","Mid-Senior level","Quality Assurance","Engines and Power Transmission Equipment Manufacturing, Manufacturing, and Electrical Equipment Manufacturing","","","","1072910","https://www.linkedin.com/jobs/view/quality-assurance-qa-engineer-at-virginia-transformer-corp-4339121807?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)"
"Data Operations Analyst","San Francisco, CA","3 weeks ago","2025-11-07","https://www.linkedin.com/jobs/view/data-operations-analyst-at-teal-health-4334752471?trk=public_jobs_topcard-title","Teal Health","https://www.linkedin.com/company/teal-healthco?trk=public_jobs_topcard-org-name","About Teal Health:

Teal Health is on a mission to provide women with the tools, access, and resources they need to make their own, informed decisions regarding their health—starting with cervical cancer screenings. We’ve created the first FDA authorized at-home cervical cancer screening. We’re replacing the in-office pap smear with a cervical cancer screening that is comfortable, convenient, and designed for women. Teal Health’s solution includes a patented Teal Wand collection device and a modern telehealth platform to make it easy for women to speak with a doctor, screen at home and understand their results.

Our Values:

We boldly champion the future women deserve. And we do this through our values, which are to elevate women, expect exceptional, and learning, every day. The Teal team lives our values and uses them to guide our decisions when building Teal.

Why we are hiring for this role:

Teal is looking for a data operations analyst to establish the foundation of a reliable and scalable data ecosystem. You’ll play a critical role in ensuring that our data is accurate, accessible, and actionable by building the systems and processes that transform raw data into clear, digestible insights.

We’re seeking an experienced data operations leader who thrives on ownership and is eager to drive data initiatives from strategy through execution. In this role, you’ll design and implement data workflows, enforce best practices around quality and governance, and deliver reporting that empowers teams across the company to make confident, data-driven decisions. You’d be joining a small but mighty team eager to profoundly change women’s health!

Role expectations & responsibilities:


 * Love data, love asking questions of the data and have an operations and business mindset to use data to drive business decisions.
 * Own the end-to-end data ecosystem — from pipeline reliability and governance to reporting and insights delivery.
 * Lay the groundwork for scalable insights by building the first reporting structures, including self-serve dashboards, and ensuring teams have access to accurate, timely data.
 * Translate data into impact by reporting business outcomes across the organization, surfacing actionable insights, and making recommendations that move company objectives and KPIs forward.
 * Lead data reviews and syncs with leadership to align on metrics, insights, and business outcomes.
 * Create and maintain a six month roadmap for data infrastructure, tooling, and analytics priorities, including resourcing needs.
 * Have an operator’s mindset—focused on delivering accurate, actionable insights that directly impact business outcomes.
 * Thrive in ambiguity and like building things from scratch.
   
   

Success in the first 12-18 months:


 * Conduct a full audit of Teal’s data stack to ensure that the correct data is being captured in the product and across the various tools (Google Analytics, HubSpot, Healthie, Stripe, Quickbooks, etc.) we are using.
 * Set up, configure and manage a data analytics platform to create visibility into the data across tools and across the product lifecycle via dashboards (with funnels for customer conversions and key user journey steps) as well as unique data reports (for appointments, kit tracking, etc.).
 * Develop and manage data pipelines and dashboards for end-to-end marketing insights—from originating sources via Google Analytics and ad platforms (e.g., Meta, Google Ads, LinkedIn) to platform data — to create a full-funnel view of the lead-to-customer journey and campaign performance.
 * Work with the executive team to define key metrics and create automated dashboards for easy visibility into the state of the business.
 * Create custom reports upon request to help solve issues as they arise.
 * Identify and drive operational improvements by surfacing areas of high volume activity, operational inefficiencies, high cost activities, or bottlenecks to scale. Quantify and prioritize improvements based on business and financial impact.
 * Develop and evolve Teal’s data dictionary, establish governance processes, and operationalize data by automating recurring reports (team meetings, investor updates, and board prep).
 * Document what’s been built, including identifying areas where data ops or analytics engineering support is needed.
   
   

Qualifications:


 * Have 3–5 years in data analytics, data science, business intelligence, or data operations.
 * Is fluent in SQL and can write clean, modular, and production-ready queries.
 * Proficiency with Python, R, and other data science programming languages and related libraries.
 * Experience with data analysis and visualization tools like Looker and/or PostHog and with integrating external data sources with these tools.
 * Demonstrated ability to translate data insights into business recommendations or product decisions.
 * Can communicate tradeoffs between technical constraints and business needs.
 * Familiarity with experimentation techniques (e.g., A/B testing, power analysis, hypothesis testing).
 * Previous experience and willingness to work across distributed teams.
 * Experience working with healthcare or patient-facing data (e.g., EHRs, lab results, appointment flows, claims, or device data), including understanding of PHI and HIPAA-compliant data practices.
 * Familiarity with startup operational models and velocity (e.g., weekly metrics reviews, GTM dashboards).
 * Bachelor’s or Master’s degree in a quantitative field (e.g., Statistics, Computer Science, Mathematics, Economics, Engineering, or similar).
   
   

Benefits offered include:

Equity Compensation

HSA / FSA

401K

Parental leave for eligible employees

Flexible PTO

","Over 200 applicants","Full-time","Mid-Senior level","Management and Manufacturing","Hospitals and Health Care","","","","82514510","https://jobs.ashbyhq.com/teal-health/e1b6dd29-868b-42bc-b968-f508b7038238/application?utm_source=nM7m1XJBRL","EXTERNAL",""
"Chief Engineer","Michigan, United States","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/chief-engineer-at-clm-search-4347508222?trk=public_jobs_topcard-title","CLM Search","https://uk.linkedin.com/company/clmsearch?trk=public_jobs_topcard-org-name","Job Title: Chief Engineer

Location: Michigan, USA




About the Client and Role

Our client, a global engineering and manufacturing organisation, is seeking a Chief Engineer to lead technical strategy, execution, and delivery for a major product portfolio. This role oversees multidisciplinary engineering teams, ensures technical excellence, and acts as the key interface between customers, internal functions, and global technical centres. The Chief Engineer will drive innovation, guide development processes, and ensure solutions meet performance, quality, cost, and timing expectations.




Responsibilities

 * Lead all engineering activities across the full product development lifecycle, ensuring high-quality, robust, and cost-effective technical solutions.
 * Provide strategic and technical direction to engineering teams, enabling effective reviews, issue resolution, and adoption of best practices.
 * Oversee the creation, validation, and release of engineering designs, documentation, and specifications using internal development systems and processes.
 * Support manufacturability assessments and collaborate with operations, supply chain, and quality teams to ensure production readiness.
 * Act as the primary technical contact for customer engineering topics, ensuring clear communication, alignment of requirements, and proactive issue management.
 * Facilitate cross-functional integration across mechanical, electrical, software, materials, testing, and advanced engineering groups.
 * Drive continuous improvement through structured methodologies, data-driven analysis, and systematic lessons-learned practices.
 * Manage engineering budgets, resource planning, and workload distribution to support programme execution.
 * Develop, coach, and mentor engineers to strengthen capability and support long-term organisational growth.
 * Coordinate with global teams to share knowledge, align technical standards, and support worldwide programme execution.
 * Ensure compliance with internal processes, regulatory requirements, and safety and quality standards.




Skills and Qualifications

 * Bachelor’s degree in Engineering or related field; advanced degrees or equivalent experience preferred.
 * 10–15 years of experience in product development or engineering leadership.
 * Minimum 5 years managing engineering teams or leading complex technical programmes.
 * Strong understanding of mechanical, electrical, or systems engineering principles and development processes.
 * Proficiency with engineering tools, CAD systems, and product lifecycle management systems.
 * Excellent communication, leadership, and stakeholder-management skills.
 * Strong organisational capability with experience managing multiple programmes concurrently.
 * Familiarity with tools such as DFMEA, structured problem solving, validation planning, and continuous improvement methodologies.
 * Ability to travel domestically and internationally as needed.




At CLM, we specialise in executive search across manufacturing, energy and technology. With decades of international experience building leadership teams, we’re committed to delivering a search experience that puts people first - for both our candidates and our clients.

Unfortunately, due to the high level of applications, we are not physically able to get back to every candidate that applies. Please follow our CLM page on Linkedin for regular job updates and we hope to support you with your next venture.

","45 applicants","Full-time","Mid-Senior level","Engineering","Motor Vehicle Manufacturing","","Ashley Falloon","https://uk.linkedin.com/in/ashley-falloon-56a800123","42904015","https://www.linkedin.com/jobs/view/chief-engineer-at-clm-search-4347508222?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Data Engineer","New York, United States","19 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/senior-data-engineer-at-oakwell-hampton-group-4340744000?trk=public_jobs_topcard-title","Oakwell Hampton Group","https://uk.linkedin.com/company/oakwell-hampton?trk=public_jobs_topcard-org-name","Senior Data Engineer - Series A Start up

New York City

$250,000 salary




My client is an early stage but well backed company building data products that demand strong engineering instincts and real craftsmanship. They are looking for a Senior Data Engineer to own pipelines and systems that operate at massive scale. You will work closely with founders and senior engineers, shaping data quality, infrastructure, and operations end to end.




What the successful Senior Data Engineer will do




 * Own ingestion, normalization, entity resolution, enrichment, and delivery across the data lifecycle
 * Build resilient ELT and ETL pipelines with clear contracts, lineage, and idempotency
 * Stand up monitoring for freshness, completeness, and accuracy with real RCA and prevention
 * Create internal tools that make data discoverable and usable by engineering and product
 * Manage BPO vendors and run SLAs with external data partners
 * Tune storage and compute for performance, cost efficiency, and predictable unit economics
 * Influence system design with thoughtful, well reasoned technical decisions




Ideal Senior Data Engineer




 * Strong Python skills with experience using Dagster and DuckDB
 * Confident running large scale pipelines and owning data quality end to end
 * Opinionated in a grounded way with the ability to dive deep into new technologies
 * Experience working in a company who's primary product is data
 * US citizenship only







What is on offer for the Senior Data Engineer




 * Equity on offer
 * In office culture in Midtown Manhattan Monday through Friday with flexibility for travel days
 * Health, dental, and vision coverage
 * Three percent automatic 401k contribution
 * Paid lunches, wellness support, and a Citi Bike benefit




Please don't apply if you require sponsorship now or at any point in the future","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Staffing and Recruiting","$165,000.00/yr - $250,000.00/yr","Dylan C.","https://www.linkedin.com/in/dylan-c-usa","10439554","https://www.linkedin.com/jobs/view/senior-data-engineer-at-oakwell-hampton-group-4340744000?trk=public_jobs_topcard-title","EASY_APPLY",""
"Finance Data Connectivity","Alpharetta, GA","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/finance-data-connectivity-at-genpact-4347626343?trk=public_jobs_topcard-title","Genpact","https://www.linkedin.com/company/genpact?trk=public_jobs_topcard-org-name","Role: Finance Data Connectivity

Location: Alpharetta, GA (Hybrid- 3 days from Office from day one)

Role Type: Fulltime



Responsibilities

 * Define and execute the product roadmap for AI tooling and data integration initiatives, driving products from concept to launch in a fast-paced, Agile environment.
 * Translate business needs and product strategy into detailed requirements and user stories.
 * Collaborate with engineering, data, and AI/ML teams to design and implement data connectors that enable seamless access to internal and external financial datasets.
 * Partner with data engineering teams to ensure reliable data ingestion, transformation, and availability for analytics and AI models.
 * Evaluate and work to onboard new data sources, ensuring accuracy, consistency, and completeness of fundamental and financial data.
 * Continuously assess opportunities to enhance data coverage, connectivity, and usability within AI and analytics platforms.
 * Monitor and analyze product performance post-launch to drive ongoing optimization and inform future investments.
 * Facilitate alignment across stakeholders, including engineering, research, analytics, and business partners, ensuring clear communication and prioritization.




Minimum qualifications

 * Bachelor’s degree in Computer Science, Finance, or related discipline. MBA/Master’s Degree desired.
 * 5+ years of experience in a similar role
 * Strong understanding of fundamental and financial datasets, including company financials, market data, and research data.
 * Proven experience in data integration, particularly using APIs, data connectors, or ETL frameworks to enable AI or analytics use cases.
 * Familiarity with AI/ML data pipelines, model lifecycle, and related tooling.
 * Experience working with cross-functional teams in an Agile environment.
 * Strong analytical, problem-solving, and communication skills with the ability to translate complex concepts into actionable insights.
 * Prior experience in financial services, investment banking, or research domains.
 * Excellent organizational and stakeholder management abilities with a track record of delivering data-driven products.




Preferred qualifications

 * Deep understanding of Python, SQL, or similar scripting languages
 * Knowledge of cloud data platforms (AWS, GCP, or Azure) and modern data architectures (data lakes, warehouses, streaming)
 * Familiarity with AI/ML platforms
 * Understanding of data governance, metadata management, and data security best practices in financial environments.
 * Experience with API standards (REST, GraphQL) and data integration frameworks.
 * Demonstrated ability to partner with engineering and data science teams to operationalize AI initiatives.




Genpact is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. Genpact is committed to creating a dynamic work environment that values diversity and inclusion, respect and integrity, customer focus, and innovation. For more information, visit www.genpact.com . Follow us on Twitter, Facebook, LinkedIn, and YouTube.




Furthermore, please do note that Genpact does not charge fees to process job applications and applicants are not required to pay to participate in our hiring process in any other way. Examples of such scams include purchasing a 'starter kit,' paying to apply, or purchasing equipment or training.","27 applicants","Full-time","Mid-Senior level","Information Technology","Information Services","","Dushyaant Singh Negi","https://www.linkedin.com/in/dushyaant-singh-negi-8a8a47118","210064","https://www.linkedin.com/jobs/view/finance-data-connectivity-at-genpact-4347626343?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI Engineer","Boston, MA","21 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/ai-engineer-at-massmutual-4340753300?trk=public_jobs_topcard-title","MassMutual","https://www.linkedin.com/company/massmutual-financial-group?trk=public_jobs_topcard-org-name","Overall Responsibilities


 * Architect and lead end-to-end ML/AI solutionssupporting life insurance underwritingusing LLMs, deep learning, and probabilistic modeling—from ideation to production.
 * Deploy scalable GenAI and Agentic AI systems that directly support business goals.
 * Establish and promote best practices in AI development and responsible AI deployment.
 * Drive innovation by identifyingemerging technologies and translating research into practical applications.
 * Collaborate with engineering teams to build robust, production-grade AI pipelines and APIs.
 * Prototype and deliver AI-powered applications (e.g., web apps, dashboards, visualizations) that enable data-driven decisions.
 * Influence senior leadership by aligning AI initiatives with enterprise strategy and communicating insights effectively.
 * Mentor and develop junior talent, fostering a culture of technical excellence and continuous learning.
   
   

Candidate Requirements


 * Recognized industry expertise in AI/ML, with a track record of delivering impactful solutions.
 * 7+ years of experience in data science, machine learning, or AI engineering roles.
 * Deep understanding of machine learning, statistics, NLP, optimization, and LLMs.
 * Hands-on experience with AI deployment and orchestration frameworks and protocols (e.g., MLflow, llama-index, MCP).
 * Extensive experience testing LLM behavior across a variety of foundation models and benchmarks.
 * Experience building AI-powered applications and collaborating with software engineers and product managers.
 * Strong programming skills in Python. Proficiency in R is a plus.
 * Proficiency in SQL and database design; familiarity with cloud-native data platforms, vector databases, and semantic search is a plus.
 * Exceptional communication skills, with the ability to explain complex concepts to non-technical stakeholders.
   
   

Education

M.S. or Ph.D. in Computer Science, Statistics, Applied Mathematics, Electrical Engineering, Physics, or a related quantitative field.

MassMutual is an equal employment opportunity employer. We welcome all persons to apply.

If you need an accommodation to complete the application process, please contact us and share the specifics of the assistance you need.

California residents: For detailed information about your rights under the California Consumer Privacy Act (CCPA), please visit our California Consumer Privacy Act Disclosures page.","83 applicants","Full-time","Entry level","Engineering and Information Technology","Financial Services","","","","3631","https://www.linkedin.com/jobs/view/ai-engineer-at-massmutual-4340753300?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Dearborn, MI","3 days ago","2025-11-28","https://www.linkedin.com/jobs/view/data-engineer-at-stefanini-group-4339813165?trk=public_jobs_topcard-title","Stefanini Group","https://br.linkedin.com/company/stefanini?trk=public_jobs_topcard-org-name","Job Description

Stefanini Group is hiring!

Stefanini is looking for a Senior Data Engineer Dearborn, MI (Onsite)

For quick apply, please reach out Fardeen Ali at 248-582-6473/fardeen.ali2@stefanini.com

You are responsible for designing, building, and maintaining data solutions including data infrastructure, pipelines, etc. for collecting, storing, processing and analyzing large volumes of data efficiently and accurately.

Responsibilities


 * Collaborate with business and technology stakeholders to understand current and future data requirements
 * Design, build and maintain reliable, efficient and scalable data infrastructure for data collection, storage, transformation, and analysis
 * Plan, design, build and maintain scalable data solutions including data pipelines, data models, and applications for efficient and reliable data workflow
 * Design, implement and maintain existing and future data platforms like data warehouses, data lakes, data lakehouse etc. for structured and unstructured data
 * Design and develop analytical tools, algorithms, and programs to support data engineering activities like writing scripts and automating tasks
 * Ensure optimum performance and identify improvement opportunities
   
   

Experience Required


 * 5+ years of experience in Data Engineering
 * Experience with GCP (Google Cloud Platform)
 * Strong experience with Python
 * Expertise with SQL
   
   

Experience Preferred


 * 5+ years of experience in the automotive industry, particularly in auto remarketing and sales
 * Master's degree in a relevant field (e.g., Computer Science, Data Science, Engineering)
 * Proven ability to thrive in dynamic environments, managing multiple priorities and delivering high-impact results even with limited information
 * Exceptional problem-solving skills, a proactive and strategic mindset, and a passion for technical excellence and innovation in data engineering
 * Demonstrated commitment to continuous learning and professional development
 * Familiarity with machine learning libraries, such as TensorFlow, PyTorch, or Scikit-learn
 * Experience with MLOps tools and platforms
   
   

Education Required


 * Bachelor's Degree
 * Listed salary ranges may vary based on experience, qualifications, and local market. Also, some positions may include bonuses or other incentives***
   
   

Stefanini takes pride in hiring top talent and developing relationships with our future employees. Our talent acquisition teams will never make an offer of employment without having a phone conversation with you. Those face-to-face conversations will involve a description of the job for which you have applied. We also speak with you about the process, including interviews and job offers.

About Stefanini Group

The Stefanini Group is a global provider of offshore, onshore and near shore outsourcing, IT digital consulting, systems integration, application, and strategic staffing services to Fortune 1000 enterprises around the world. Our presence is in countries like the Americas, Europe, Africa, and Asia, and more than four hundred clients across a broad spectrum of markets, including financial services, manufacturing, telecommunications, chemical services, technology, public sector, and utilities. Stefanini is a CMM level 5, IT consulting company with a global presence. We are a CMM Level 5 company.

","48 applicants","Full-time","Entry level","Information Technology","Business Consulting and Services","","","","20402093","https://www.adzuna.com/details/5519681577?v=F72DD127FAD560C758F51A3D4C17701DD6688DB9&ccd=6984d9dcb7426ad0ff4671183f4b743f&r=20758277&frd=e67a0f64efc92520fb1690bf6960ac90&utm_source=linkedin7&utm_medium=organic&chnlid=1931&title=Data%20Engineer&a=e","EXTERNAL",""
"Data Science Specialist","Plano, TX","3 weeks ago","2025-11-06","https://www.linkedin.com/jobs/view/data-science-specialist-at-infosys-4337839643?trk=public_jobs_topcard-title","Infosys","https://in.linkedin.com/company/infosys?trk=public_jobs_topcard-org-name","Infosys is seeking an AI/ML & Generative AI Engineer with deep expertise in designing, developing, and deploying advanced AI solutions, including Large Language Models (LLMs) and Agentic AI architectures. The ideal candidate will collaborate with clients to understand complex business challenges, architect scalable AI solutions, and deploy them using modern cloud platforms such as Azure ML and GCP AI Services.

This role offers the opportunity to work on cutting-edge technologies in Generative AI, LLM fine-tuning, agentic orchestration, and vector databases, while shaping impactful consulting solutions across industries like Banking, Finance, and Capital Markets.




Required Qualifications:

 * Bachelor’s degree or foreign equivalent required from an accredited institution. Will also consider three years of progressive experience in the specialty in lieu of every year of education.
 * Candidate must live within commuting distance of Plano, TX OR Charlotte, NC or be willing to relocate. This position may require travel in the US.
 * At least 4 years of experience in Information Technology
 * Applicants authorized to work for any employer in the United States without employer-based visa sponsorship are welcome to apply. Infosys is unable to provide immigration sponsorship for this role at this time
 * At least 4 years of experience in Python programming, including OOPs, data structures (queues, stacks, linked lists), and API development.
 * At least 3 years of experience in Big Data technologies (e.g., BigQuery, Hadoop).
 * At least 2 years of experience in cloud platforms (Azure, GCP) and their AI/ML services.
 * At least 2 years of experience in ML model development, data engineering, and software engineering principles.
 * At least 3 years of experience in MLOps and AI/ML deployment (e.g., SageMaker, Snowflake).
 * At least 2 years of hands-on experience in Generative AI, LLMs, and agentic frameworks.

Preferred Qualifications:

 * Experience with API Gateway development and deployment on Azure/GCP.
 * Hands-on experience with vector databases and RAG pipelines.
 * Familiarity with CI/CD, DevOps, and automation tools in AI/ML contexts.
 * Strong problem-solving skills and ability to evaluate multiple solution paths.
 * Excellent communication and stakeholder management skills.
 * Domain expertise in Banking, Finance, or Capital Markets is a plus.

The job may entail extensive travel. The job may also entail sitting as well as working at a computer for extended periods of time. Candidates should be able to effectively communicate by telephone, email, and face to face.

EEO/About Us :

About Us

Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem.




EEO

Infosys provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability. Infosys provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Information Services","","","","1283","https://www.linkedin.com/jobs/view/data-science-specialist-at-infosys-4337839643?trk=public_jobs_topcard-title","EASY_APPLY","401(k)
Medical insurance
Vision insurance
Dental insurance"
"Clinical Data Scientist","Silver Spring, MD","13 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/clinical-data-scientist-at-drt-strategies-4340706705?trk=public_jobs_topcard-title","DRT Strategies","https://www.linkedin.com/company/drt-strategies?trk=public_jobs_topcard-org-name","Overview

DRT Strategies delivers expert management consulting and information technology (IT) solutions to large federal agencies, the U.S. Navy, state and local government and commercial clients in health care, technology, and financial services industries.

The three letters of our name, DRT, stand for Driving Resolution Together, which is the core philosophy on which the company was founded. That is, we collaborate with our clients to solve their most pressing challenges - together.

We are problem solvers dedicated to your success, combining Fortune 500 experience with small business responsiveness. We have established a reputation with our clients as a forward-thinking consulting firm with demonstrated success in implementing solutions that lead to meaningful results. Our world-class consultants unite people to work collaboratively to achieve project goals and make vision a reality.

Project Description

This project is designed to support FDA CDER Office of Quality Surveillance (OQS) with developing and implementing modern and innovative techniques to achieve comprehensive surveillance and estimate the state of quality. The objective of this project is to conduct thorough research and implement efficient methods for ingesting publicly available regulatory data. The contractor will provide support for data extraction and analytics that are needed to enhance OQS's dossier program.

Job Summary

Non-technical activities: Extract valuable insights from the acquired and existing data by employing advanced techniques such as time-series analysis, trend analysis, and machine learning (including clustering, natural language processing, and outlier identification). These techniques are intended to maximize the value derived from the available data, foster a proactive approach, and effectively identify high-risk facilities.

Technical activities: Serves as a specialist in the application of data science, operations research, computer science, mathematics, and statistics, to design data modeling processes, conduct data mining operations, uncover hidden patterns in the data, and create algorithms and predictive models to extract insights.

Responsibilities


 * Strong git and collaborative development experience required
 * Pyspark/Spark experience required
 * Strong R/RShiny skills required
 * Strong Python skills required
 * Advanced SQL experience required
 * Familiarity with a broad range of ML techniques and their implementation
 * Excellent written and verbal communication skills
 * Excellent analytical skills with an emphasis on data exploration and data wrangling
 * Databricks experience preferred
 * Biological science/pharmaceutical background preferred
 * Utilize data mining techniques and web scraping tools to extract valuable insights and information from various sources, such as websites and databases.
 * Apply experience with business intelligence, analytics, reporting, and data transformation skills to drive insights.
 * Apply knowledge and experience in analytics and statistics to analyze and interpret the data effectively.
 * Apply knowledge of data types, formats, data architecture, and pipeline optimization techniques to effectively manage and process data.
 * Technical strategy: Demonstrate analytical capabilities and critical thinking skills and ability to identify new issues, trends, and opportunities from data.
 * Operational Excellence: Ensure the reliability, efficiency, and quality of data services and pipelines.
 * Perform hands-on work with data analysis, validation, and quality assurance.
 * Prepares and delivers presentations.
 * Research and identifies root cause/data issues. Ensure timely delivery of reports and manage conflicting priorities and customer expectations.
 * Performs periodic check-ins for status and feedback. Identifies gaps in the system and communicate them to the solution project leads/program manager.
   
   

Required Experience:


 * MS in a qualitative technical field such as computer science, engineering, statistics, or related field.
 * Minimum 5 years of experience in at least one of the following work areas: analytics, biopharmaceutical manufacturing, quality analytics, biotechnology research and development, or other area relevant research programs.
 * Demonstrate familiarity with Databricks and expertise in either R or Python.
 * Must have expertise in web scraping, time-series analysis, and machine learning techniques, with proven ability to apply these skills effectively. At least 3 years of Full stack data scientist experience.
   
   

Preferred Experience:


 * FDA experience
 * PhD preferred
   
   

Education & Training:


 * MS in a qualitative technical field such as computer science, engineering, statistics, or related field.
   
   

Salary Range:


 * $95,000-$125,000
 * Salary commensurate with experience.
   
   

DRT Strategies, Inc. (DRT) follows the guidelines outlined by the Equal Employment Opportunity Commission (EEOC) to provide all employees and qualified applicants employment without regard to race, color, religion, sex (including pregnancy, childbirth, or related conditions, transgender status, and sexual orientation), national origin, age, genetic information, disability, protected veteran status, or any other protected characteristic under federal, state, or local law.

Reasonable accommodations for applicants and employees with disabilities will be provided. If a reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact Human Resources by emailing HR@drtstrategies.com, or by dialing 571-482-2517.

For additional information, please review the Know Your Rights: Workplace Discrimination is Illegal, E-Verify (English), E-Verify (Spanish). Right to Work (English), Right to Work (Spanish).

Please be aware of recruitment fraud where malicious individuals might pose as DRT Strategies. Only job postings and emails from drtstrategies.com are authentic and legitimate communications regarding DRT Strategies employment opportunities. Please contact Human Resources at hr@drtstrategies.com if you believe you have received a fraudulent email.","28 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","IT Services and IT Consulting","$95,000.00/yr - $125,000.00/yr","","","142595","https://www.linkedin.com/jobs/view/clinical-data-scientist-at-drt-strategies-4340706705?trk=public_jobs_topcard-title","EASY_APPLY",""
"Analytics Engineer - Weights & Biases","Bellevue, WA","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/analytics-engineer-weights-biases-at-weights-biases-4341452867?trk=public_jobs_topcard-title","Weights & Biases","https://www.linkedin.com/company/wandb?trk=public_jobs_topcard-org-name","CoreWeave, the AI Hyperscaler™, acquired Weights & Biases to create the most powerful end-to-end platform to develop, deploy, and iterate AI faster. Since 2017, CoreWeave has operated a growing footprint of data centers covering every region of the US and across Europe, and was ranked as one of the TIME100 most influential companies of 2024. By bringing together CoreWeave’s industry-leading cloud infrastructure with the best-in-class tools AI practitioners know and love from Weights & Biases, we’re setting a new standard for how AI is built, trained, and scaled.

The integration of our teams and technologies is accelerating our shared mission: to empower developers with the tools and infrastructure they need to push the boundaries of what AI can do. From experiment tracking and model optimization to high-performance training clusters, agent building, and inference at scale, we’re combining forces to serve the full AI lifecycle — all in one seamless platform.

Weights & Biases has long been trusted by over 1,500 organizations — including AstraZeneca, Canva, Cohere, OpenAI, Meta, Snowflake, Square,Toyota, and Wayve — to build better models, AI agents and applications. Now, as part of CoreWeave, that impact is amplified across a broader ecosystem of AI innovators, researchers, and enterprises.

As we unite under one vision, we’re looking for bold thinkers and agile builders who are excited to shape the future of AI alongside us. If you're passionate about solving complex problems at the intersection of software, hardware, and AI, there's never been a more exciting time to join our team.

What You’ll Do

The Data group at Weights & Biases works across the full range of data-related topics:


 * We help business partners set goals, make decisions, and understand the levers to achieve their goals.
 * We build reporting to keep the business attuned and aligned.
 * We build datasets and pipelines to support self-service analysis.
 * We train models to understand our customer growth, churn risk, and detect spam and abuse.
 * We’re exploring novel benchmarks and recs for model training.
 * We build and maintain a massive data platform to power it all.
   
   

About The Role

We’re hiring a Data Analytics Engineer who will focus primarily on analytics engineering while remaining a core member of the broader data platform team. You’ll be the dedicated owner of our dbt layer and related analytics infrastructure, driving operational excellence, cost/performance optimization, and self-service analytics at scale. You’ll partner closely with analysts, data scientists, and platform engineers to harden our foundations and enable better decision-making across the company.

Who You Are


 * Deep knowledge of data engineering and analytics engineering workflows at scale, with a track record of operational excellence
 * Expert with dbt (core or Cloud): model design, incremental strategies, macros/packages, testing, documentation, CI/CD
 * Strong SQL and warehouse design for BigQuery (partitioning, clustering, materializations, cost/perf tuning at multi-TB/PB scale)
 * Experience with orchestration (Dagster preferred; Airflow acceptable) and production-grade deployment practices
 * Familiar with data quality frameworks (e.g., dbt tests, Great Expectations, data contracts) and SLA/SLO design
 * Proficient in Python for orchestration, utilities, and light data tooling; Git-based workflows
 * Understanding of product telemetry, logging standards, and event modeling for web apps/SaaS
 * Excellent communication and documentation; able to align analysts, engineers, and stakeholders on semantics and standards
   
   

Preferred: (if applicable)


 * Hex (or similar BI) performance tuning and governance experience
 * Experience building semantic/metrics layers and catalogs (e.g., dbt exposures/semantics, OpenLineage, DataHub/Amundsen/Atlan)
 * Prior work migrating dbt Cloud → Dagster or similar orchestrator
 * Familiarity with AI/ML workflows and terminology
 * Terraform/infra-as-code exposure on GCP
 * Experience designing anomaly detection or rule-based alerting for KPIs
   
   

Why Us?

About

We work hard, have fun, and move fast! We’re in an exciting stage of hyper-growth that you will not want to miss out on. We’re not afraid of a little chaos, and we’re constantly learning. Our team cares deeply about how we build our product and how we work together, which is represented through our core values:


 * Be Curious at Your Core
 * Act Like an Owner
 * Empower Employees
 * Deliver Best-in-Class Client Experiences
 * Achieve More Together
   
   

We support and encourage an entrepreneurial outlook and independent thinking. We foster an environment that encourages collaboration and provides the opportunity to develop innovative solutions to complex problems. As we get set for takeoff, the growth opportunities within the organization are constantly expanding. You will be surrounded by some of the best talent in the industry, who will want to learn from you, too. Come join us!

The base salary range for this role is $139,000 to $204,000. The starting salary will be determined based on job-related knowledge, skills, experience, and market location. We strive for both market alignment and internal equity when determining compensation. In addition to base salary, our total rewards package includes a discretionary bonus, equity awards, and a comprehensive benefits program (all based on eligibility).

What We Offer

The range we’ve posted represents the typical compensation range for this role. To determine actual compensation, we review the market rate for each candidate which can include a variety of factors. These include qualifications, experience, interview performance, and location.

In addition to a competitive salary, we offer a variety of benefits to support your needs, including:


 * Medical, dental, and vision insurance - 100% paid for by CoreWeave
 * Company-paid Life Insurance
 * Voluntary supplemental life insurance
 * Short and long-term disability insurance
 * Flexible Spending Account
 * Health Savings Account
 * Tuition Reimbursement
 * Ability to Participate in Employee Stock Purchase Program (ESPP)
 * Mental Wellness Benefits through Spring Health
 * Family-Forming support provided by Carrot
 * Paid Parental Leave
 * Flexible, full-service childcare support with Kinside
 * 401(k) with a generous employer match
 * Flexible PTO
 * Catered lunch each day in our office and data center locations
 * A casual work environment
 * A work culture focused on innovative disruption
   
   

Our Workplace

While we prioritize a hybrid work environment, remote work may be considered for candidates located more than 30 miles from an office, based on role requirements for specialized skill sets. New hires will be invited to attend onboarding at one of our hubs within their first month. Teams also gather quarterly to support collaboration

California Consumer Privacy Act - California applicants only

CoreWeave is an equal opportunity employer, committed to fostering an inclusive and supportive workplace. All qualified applicants and candidates will receive consideration for employment without regard to race, color, religion, sex, disability, age, sexual orientation, gender identity, national origin, veteran status, or genetic information.

As part of this commitment and consistent with the Americans with Disabilities Act (ADA), CoreWeave will ensure that qualified applicants and candidates with disabilities are provided reasonable accommodations for the hiring process, unless such accommodation would cause an undue hardship. If reasonable accommodation is needed, please contact: careers@coreweave.com.

Export Control Compliance

This position requires access to export controlled information. To conform to U.S. Government export regulations applicable to that information, applicant must either be (A) a U.S. person, defined as a (i) U.S. citizen or national, (ii) U.S. lawful permanent resident (green card holder), (iii) refugee under 8 U.S.C.


 * 1157, or (iv) asylee under 8 U.S.C.
 * 1158, (B) eligible to access the export controlled information without a required export authorization, or (C) eligible and reasonably likely to obtain the required export authorization from the applicable U.S. government agency. CoreWeave may, for legitimate business reasons, decline to pursue any export licensing process.","141 applicants","Full-time","Entry level","Information Technology","Software Development","$139,000.00/yr - $204,000.00/yr","","","18593641","https://www.linkedin.com/jobs/view/analytics-engineer-weights-biases-at-weights-biases-4341452867?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr. AI/ML Data Engineer","Plano, TX","1 week ago","2025-11-18","https://www.linkedin.com/jobs/view/sr-ai-ml-data-engineer-at-public-storage-4336717965?trk=public_jobs_topcard-title","Public Storage","https://www.linkedin.com/company/public-storage?trk=public_jobs_topcard-org-name","Since opening our first self-storage facility in 1972, Public Storage has grown to become the largest owner and operator of self-storage facilities in the world. With thousands of locations across the U.S. and Europe, and more than 170 million net rentable square feet of real estate, we're also one of the largest landlords.



We've been recognized as A Great Place to Work by the Great Place to Work Institute. And, our employees have also voted us as having Best Career Growth, ranked us in the Top 5% for Work Culture, and in the Top 10% for Diversity and Inclusion.



We're a member of the S&P 500 and FT Global 500. Our common and preferred stocks trade on the New York Stock Exchange.



**Sponsorship for Work Authorization is not available for this posting. Candidates must be authorized to work in the U.S. without requiring sponsorship now or in the future**





Job Description



Overview



Public Storage is the world’s best owner and operator of self-storage facilities, serving millions of customers across 3,000+ locations. Public Storage’s Data and AI organization operates like a high-velocity startup inside the enterprise—modern cloud stack, rapid iteration, small expert teams, and direct impact on revenue-critical decisions every day. Our platform is built on Google Cloud (BigQuery, Vertex AI, Pub/Sub, DataFlow, Cloud Run, GKE/Terraform), dbt cloud, Airflow/Cloud Composer, and modern CI/CD practices. We build solutions that driver significant business impact across both digital and physical. Engineers on our team work end-to-end: designing systems, shipping production workloads, influencing architecture, and shaping how AI is applied at national scale.



We build for both short and long-term – we are a dynamic, high-velocity engineering team that moves quickly from idea to production. This is a role for someone who wants to own key parts of the data & ML platform, make immediate impact, and thrive in an environment where requirements evolve, decisions matter, and results are visible.





You are a passionate, full-stack data & ML engineer who loves to write code, build systems, fun and spirited debates about the “right” architecture for the specific use case. In addition to tech skills, we believe in teaching the soft leadership skills you need to advance your career over the long term.



Data Engineering & Pipeline Development (Primary) (60%)



 * Architect, build and maintain batch and streaming pipelines using BigQuery, dbt, Airflow/Cloud Composer, and Pub/Sub
 * Define and implement layered data models, semantic layers, and modular pipelines that scale as use-cases evolve
 * Establish and enforce data-quality, observability, lineage, and schema governance practices
 * Drive efficient BigQuery design (clustering, partitioning, cost-awareness) for structured tabluar data primarily and unstructured data (web logs, call center transcripts, images/videos etc) when the use case requires it.
 * Leverage ML/DS capabilities in BQML for anomaly detection and disposition
 * You will be accountable for delivering reliable, performant pipelines that enable downstream ML and analytics

ML/AI Platform Engineering (20%)



 * Transform prototype notebooks / models into production-grade, versioned, testable Python packages
 * Deploy and manage training and inference workflows on GCP (Cloud Run, GKE, Vertex AI) with CI/CD, version tracking, rollback capabilities
 * Evaluate new products from GCP or vendors; build internal toolkits, shared libraries and pipeline templates that accelerate delivery across teams
 * You will enable the ML team to ship faster with fewer failure-modes

Applied AI & Real-Time Decisioning (20%)



 * Support real-time, event‐driven inference and streaming feature delivery for mission-critical decisions such as but not limited to real time recommendation systems, dynamice A/B testing and agentic AI interfacing
 * Contribute to internal LLM-based assistants, retrieval-augmented decision models, and automation agents as the platform evolves
 * Implement model monitoring, drift detection, alerting, and performance tracking frameworks

Cross-Functional Collaboration



 * Partner with data scientists and engineers to operationalize models, semantic layers and pipelines into maintainable production systems
 * Work with pricing, digital product, analytics, and business teams to stage rollouts, support experiments and define metric-driven success
 * Participate in architecture reviews, mentor engineers, and drive technical trade-offs with clarity
   
   

Qualifications


 * MS in CS + 4+ years experience or BS in CS + 6+ years experience.
 * 3+ years hands-on building data pipelines in a code-first environment (Python, SQL, dbt)
 * At least 1 year experience in real-time or event-driven systems (Pub/Sub, DataFlow batch/streaming frameworks)
 * At least 2 years owning technical decisions or leading engineering direction
 * Demonstrated expert proficiency in:
   * SQL & BigQuery (schema design, query performance, modeling)
   * dbt (semantic modeling, macros, testing frameworks)
   * Airflow/Cloud Composer (DAG patterns, retries, alerting, SLAs)
   * GCP fundamentals (IAM, networking, container deployments)
   * Python (structure, testing, packaging)
 * You can explain why you chose a data model, how you improved it, what it mattered and how you measured it

Preferred Experience



 * GCP or AWS cloud experience
 * Experience with ML monitoring or platform tooling (MLflow, Evidently, Vertex AI)
 * Knowledge of semantic search, vector embeddings, or LLM orchestration (RAG workflows)
 * Domain familiarity in pricing, recommendations, forecasting or large-scale customer analytics
 * Awareness of geospatial data / map-based modeling (nice to have)
 * Some JavaScript experience (for lightweight UI/prototyping)

Why This Role Will Excite You



 * You’ll work in a fast-moving environment where decisions aren’t put on hold and you’ll see your work drive real business outcomes
 * You’ll own meaningful parts of the platform, not just small tasks or legacy maintenance
 * You’ll build end-to-end: from raw data ingestion to ML inference and finally into production integrations
 * You’ll learn fast—new challenges, new tools, new domains every quarter
   
   

Additional Information



Workplace



 * One of our values pillars is to work as OneTeam and we believe that there is no replacement for in-person collaboration but understand the value of some flexibility. Public Storage teammates are expected to work in the office five days each week with the option to take up to three flexible remote days per month.
   * Our office is based in Plano, TX - 2201 K. Ave, Plano, TX 75074

Public Storage is an equal opportunity employer and embraces diversity. We do not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or any other protected status. All qualified candidates are encouraged to apply.



**Sponsorship for Work Authorization is not available for this posting. Candidates must be authorized to work in the U.S. without requiring sponsorship now or in the future**







REF3481D

","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering","Software Development and IT Services and IT Consulting","","","","16670","https://www.linkedin.com/jobs/view/sr-ai-ml-data-engineer-at-public-storage-4336717965?trk=public_jobs_topcard-title","EASY_APPLY",""
"Business Development Manager","Middlesex County, NJ","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/business-development-manager-at-round-peg-solutions-rps-4339021702?trk=public_jobs_topcard-title","Round-Peg Solutions (RPS)","https://uk.linkedin.com/company/round-peg-solutions-rps-?trk=public_jobs_topcard-org-name","We are seeking a talented Program Manager or Technical Sales individual to join a team of passionate engineers/ program managers turned Sales in targeting niche engineering teams within aerospace.




Job Summary of the Business Development Manager:




As a Business Development Manager, you will lead strategic growth efforts by identifying and securing new opportunities with niche high-value customers in aerospace, defense, and industrial markets. You’ll build long-term partnerships by going to trade shows, visiting client teams or responding to RFI's / RFQ's. You will take ownership of the full sales cycle, including contracts, and pricing, after winning the bid you will be an advocate for the customer to internal teams.




The progression in the role is dependant on your success- not tenure, the next stage is Business manager, there are lucrative stock options at the Senior Level, which divest in 3-5 years which compensate extremely well.




Key Qualifications of the Business Development Manager:




 * Engineering degree (any kind)
 * Customer focused experience in any technical manufacturing industry
 * Strong skills in customer negotiation, strategic selling, and contract development
 * Eligible to work with ITAR-regulated data (U.S. person or eligible for authorization)
 * Willingness to travel up to 40% (varies)




What the Business Development Manager will bring:

 * A strategic mindset with an eye for identifying growth opportunities- like keeping up with the news, the market etc.
 * Passion for engineering, this company have exciting avionic products, they have a team that reflects that excitement
 * A self-starter approach, comfortable managing complex, high-value opportunities
 * Desire to grow into a leadership role with P&L and operational responsibilities
 * Able to work autonomously with minimal hand holding, you still have guidance as the entire Business Unit will sit next to you, but they need a self starter
 * No red tape or bureaucracy







Benefits of the Business Development Manager Opportunity:

 * Clear and structured career progression based on merit not tenure
 * Lucrative stock options available at the Senior Exec level
 * You sit with the Business unit in an open plan setting, the Business Unit guides progress in this company
 * Opportunity to work with cutting-edge aerospace and defense technologies
 * Compensation: $125K–$145K base + 15% bonus
 * Relocation: One-time assistance of $5K available




If you’re ready to turn your sales acumen into a long-term leadership opportunity in a high-impact aerospace organization, please get in touch with our consultant Rabeel Imrane; Rabeel.imrane@rps-recruitment.com for a confidential search.




All candidates with relevant experience will be contacted within 24 hours.","25 applicants","Full-time","Mid-Senior level","Sales and Business Development","Aviation and Aerospace Component Manufacturing, Airlines and Aviation, and Manufacturing","$125,000.00/yr - $145,000.00/yr","Rabeel Imrane","https://www.linkedin.com/in/rabeel-imrane-991832176","18018258","https://www.linkedin.com/jobs/view/business-development-manager-at-round-peg-solutions-rps-4339021702?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)"
"Senior Manager, Product Analytics","New York, NY","1 week ago","2025-11-22","https://www.linkedin.com/jobs/view/senior-manager-product-analytics-at-clear-4333388543?trk=public_jobs_topcard-title","CLEAR","https://www.linkedin.com/company/clear-by-alclear-llc?trk=public_jobs_topcard-org-name","Have you ever had that green-light feeling? When you hit every green light and the day just feels like magic. CLEAR's mission is to create frictionless experiences where every day has that feeling. With more than 30+ million passionate members and hundreds of partners around the world, CLEAR’s identity platform is transforming the way people live, work, and travel. Whether it’s at the airport, stadium, or right on your phone, CLEAR connects you to the things that make you, you - unlocking easier, more secure, and more seamless experiences - making them all feel like magic.

As we scale, we’re investing deeply in data, experimentation, and analytics to improve how we make decisions and serve our members. We’re looking for a talented, hands-on Product Analytics Senior Manager to join us at a moment when foundational decisions matter most. 

This is not a “steady state” role. Instead, you’ll scale the product analytics function at CLEAR from an early stage: defining strategy, designing systems, shaping instrumentation, and moving us toward mature experimentation and user understanding.

You’ll roll up your sleeves, influence cross-functional teams, and help instill a culture of measurement and data-driven decision-making across product, marketing, and engineering.

What You’ll Do:

Foundational Design & Execution

 * Drive adoption of CLEAR’s front-end measurement and tracking framework: taxonomy, event definitions, data governance, instrumentation standards.
 * Standardize the workflow around experimentation across our product surfaces.
 * Build reliable analytics pipelines in collaboration with Data Engineering, ensuring data quality, consistency, and scalability. Evangelize the perspective that data is a first-class product coming from our systems.
 * Define and socialize core metrics and KPIs across product lines and verticals. Drive a culture of accountability around performance.

Enable Data-Driven Decisions

 * Deliver dashboards and analyses that distill complexity into clarity for product teams, leadership, and business stakeholders.
 * Create frameworks for feature evaluation, long-term holdout analyses, funnel optimization, and user behavior deep dives.
 * Empower teams via self-service tooling and documented analytics processes to reduce requests for ad-hoc data and analysis support.
 * Build learning loops: lead post-mortems, root-cause analyses, and knowledge sharing across the org.

Lead, Mentor, & Scale

 * Build, lead, and grow a team of product analysts and data scientists.
 * Mentor and elevate analyst capabilities, instilling rigor around experiment design, causal reasoning, and communication of uncertainty.
 * Be a bridge across functions. Partner tightly with Product, Engineering, Design, Data, and Operations teams to align on goals and guardrails.
 * Advocate for analytics infrastructure and tooling investments — recommend platforms, augment the stack, and help scale our capabilities.

Advance Our Frontier

 * Evaluate new methodologies that factor in our complicated airport environment. Drive the evolution of A/B testing  toward more complex test frameworks like multi-armed bandits, sequential tests, and causal inference, then establish best practices.
 * Stay current on industry trends and bring in novel ideas that move the needle.

Who You Are:

 * 7+ years experience in product analytics, data science, business analytics, or related fields with 2+ years leading teams.
 * Proven track record standing up or significantly scaling product analytics and experimentation capabilities in a tech or consumer product environment.
 * Fluency in SQL, experiment design (statistical rigor, power analysis, etc.), attribution, funnel & cohort analysis, and metric design. Experience with leading decisions around third party experimentation tooling.
 * Strong hands-on experience with product analytics tools (e.g. Heap, Amplitude, Mixpanel, etc.) and BI / dashboarding systems.
 * Solid understanding of data infrastructure, ETL pipelines, event logging, data governance, and how to ensure data integrity.
 * Exceptional communicator: you can translate complex analyses into clear, compelling narratives that drive decisions.
 * Strategic but pragmatic: you know when to ship “good enough” and when to perfect.
 * Bias for action, comfort with ambiguity, and willingness to get your hands dirty.
 * Leadership presence, collaborative spirit, and the ability to influence across functions.

Why You’ll Love This Role:

 * Impact at scale: You’ll architect analytics at a pivotal growth stage, influencing how CLEAR makes decisions now and forms its future.
 * Autonomy & ownership: This role gives you real freedom to define the vision, build the team, and set the standards.
 * Mission-driven work: You’ll help us deliver experiences that truly matter — letting people move through life simply being themselves.
 * Culture that moves: A team that values curiosity, iteration, direct feedback, and bold thinking.
 * Great benefits & growth: Competitive compensation, equity, professional development support, and the chance to leave your mark.

How You'll be Rewarded:

At CLEAR, we help YOU move forward - because when you’re at your best, we’re at our best. You’ll work with talented team members motivated by our mission of making experiences safer and easier. Our offices are bright and energetic with an open concept and plenty of conference rooms and casual co-working spaces. We also offer catered lunches every day and have fully stocked kitchens. Outside of the office, we invest in your well-being and learning & development with stipends and reimbursement programs. 

We offer holistic total rewards, including comprehensive healthcare plans, family-building benefits (fertility and adoption/surrogacy support), flexible time off, annual wellness stipend, free OneMedical memberships for you and your dependents, a CLEAR Plus membership, and a 401(k) retirement plan with employer match. The base salary range for this role is $200,000-$230,000, depending on levels of skills and experience.

The base salary range represents the low and high end of CLEAR’s salary range for this position. Salaries will vary depending on various factors which include, but are not limited to location, education, skills, experience and performance. The range listed is just one component of CLEAR’s total compensation package for employees and other rewards may include annual bonuses, commission, Restricted Stock Units

CLEAR provides reasonable accommodation to qualified individuals with disabilities or protected needs. Please let us know if you require a reasonable accommodation to apply for a job or perform your job. Examples of reasonable accommodation include, but are not limited to, time off, extra breaks, making a change to the application process or work procedures, policy exceptions, providing documents in an alternative format, live captioning or using a sign language interpreter, or using specialized equipment.



 ","31 applicants","Full-time","Mid-Senior level","Product Management and Marketing","Consumer Services","$200,000.00/yr - $230,000.00/yr","","","961661","https://www.linkedin.com/jobs/view/senior-manager-product-analytics-at-clear-4333388543?trk=public_jobs_topcard-title","EASY_APPLY",""
"Machine Learning Engineer","San Francisco, CA","16 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-adsgency-ai-4325216141?trk=public_jobs_topcard-title","AdsGency AI","https://www.linkedin.com/company/adsgency-ai?trk=public_jobs_topcard-org-name","⚙️ Senior Machine Learning Engineer – Applied AI / Agent Systems




Company: AdsGency AI

📍 Location: Onsite (San Francisco City)

💼 Employment Type: Full-Time

🚚 Relocation to San Francisco City Required

🛂 We Sponsor OPT / CPT / STEM-OPT / DO NOT sponsor H1B Transfer




🚀 About AdsGency AI




We’re AdsGency AI — an AI-native startup building a multi-agent automation layer for digital advertising.




Our system uses LLM and ML-driven agents to autonomously launch, scale, and optimize ad campaigns across Google, Meta, TikTok, and more — no human marketer required.




Our mission: build the operating system where AI runs performance marketing better than humans ever could.




We’re backed by top-tier investors and moving fast. This is your chance to join early — and help design the ML foundation that powers the next evolution of ad intelligence.




🧠 The Role – Senior Machine Learning Engineer




As a Senior Machine Learning Engineer, you’ll design, train, and deploy AI models that drive AdsGency’s agent intelligence — from ad performance prediction to cross-channel optimization and creative generation.




You’ll bridge the gap between data science, engineering, and systems design, shaping the brain of our multi-agent OS.




This role sits at the core of AdsGency’s intelligence layer — where models don’t just predict, but act.




🔧 What You’ll Build




• 🧠 Agent Intelligence Models: Develop and fine-tune models that predict campaign performance, bid pacing, and creative success.

• 📊 Reinforcement & Decision Systems: Build RL and multi-objective optimization frameworks enabling agents to learn from feedback and improve autonomously.

• 🧬 LLM + ML Hybrid Systems: Integrate generative agents (OpenAI, Claude, LangGraph) with quantitative models for adaptive decision-making.

• ⚙️ Data Pipelines: Architect and maintain scalable feature pipelines and embeddings for multi-platform ad data.

• 🔍 Measurement & Attribution: Design models to unify performance signals across Google, Meta, TikTok, etc., handling delayed and biased feedback.

• 📈 Experimentation Frameworks: Develop A/B testing and counterfactual learning systems to validate model improvements.

• 🚀 ML Infrastructure: Own the training → evaluation → deployment lifecycle using modern MLOps practices (e.g., Weights & Biases, Airflow, Docker).




💻 Tech Stack




Modeling & ML: PyTorch, TensorFlow, Scikit-learn, XGBoost, LightGBM, Hugging Face, Transformers

Languages: Python, Go (for systems), SQL

Infra & MLOps: AWS/GCP, Docker, Kubernetes, Airflow, Weights & Biases, MLflow

Data Systems: Kafka, PostgreSQL, Redis, Supabase, Qdrant/Weaviate (vector DBs)

AI Layer: OpenAI, Claude, LangChain, LangGraph, CrewAI




💡 What You Bring




✅ 4–8 years of experience in ML engineering or applied data science

✅ Strong foundation in ML algorithms, model lifecycle, and feature engineering

✅ Proficiency in Python and ML frameworks (PyTorch/TensorFlow)

✅ Experience building models that go into production, not just notebooks

✅ Understanding of distributed systems, data pipelines, and model serving

✅ Experience with A/B testing, reinforcement learning, or online learning

✅ Curiosity about how LLMs and agents can augment traditional ML systems

✅ Startup mindset — fast iteration, ownership, and bias for impact




🧩 Bonus Points




✨ Experience in AdTech / MarTech, especially prediction, attribution, or bidding systems

🧠 Experience integrating LLMs with structured data pipelines

⚙️ Knowledge of reinforcement learning, causal inference, or bandit algorithms

🌱 Prior work in early-stage or high-growth startups

🎯 Strong sense of product impact — you ship models that move metrics




💰 Why Join AdsGency AI?




• Competitive salary + meaningful equity

• Core ownership in a fast-scaling AI company

• Work directly with founders and research engineers on frontier agentic systems

• Culture of speed, autonomy, and craftsmanship — no corporate bureaucracy

• Build systems that redefine how advertising learns and optimizes itself

• Visa sponsorship (OPT / CPT / STEM-OPT / no H1B Transfer)




Industry: AI & Software Development

Employment Type: Full-Time

Location: Onsite (San Francisco City)","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","","","","90745208","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-adsgency-ai-4325216141?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI Engineer","New York, NY","3 weeks ago","2025-11-06","https://www.linkedin.com/jobs/view/ai-engineer-at-gyde-4334518514?trk=public_jobs_topcard-title","Gyde","https://www.linkedin.com/company/gydeinc?trk=public_jobs_topcard-org-name","About Us


 * Insurance brokers sit at the intersection of care, cost, and access — yet remain one of the most underleveraged assets in the $5T healthcare value chain. They guide millions of Americans through plan selection, coverage questions, and care navigation, yet still rely on spreadsheets, manual workflows, and outdated tools that limit their growth and impact.
 * Gyde is reimagining this. We’re building the first AI-native insurance brokerage platform—a system that learns from every client interaction to automate operations, power intelligent voice and chat experiences, and predict the right coverage and products for every individual or business.
 * Our approach combines acquisition and AI: we acquire traditional brokerages and transform them into next-generation, data-driven organizations. Through Gyde’s platform, agencies run more efficiently, serve clients more personally, and scale faster than ever before.
 * Join us if you’re excited to:
    * Redefine how millions of people access and understand their healthcare coverage, by building systems that turn unstructured data, human conversations, and fragmented processes into intelligence.
    * Build AI systems that improve how people access healthcare
    * Design production-grade voice, chat, and predictive models for a highly regulated domain
    * Launch technologies that augment human judgment and make complex decisions transparent and scalable
    * Help reinvent an entire industry from the inside out

 * We’re creating the future of brokerage — where every interaction, insight, and decision is powered by intelligence.
 * Our founding team boasts pedigrees from Oscar, Stripe, and Spark. Lightspeed led Gyde’s Seed financing, with participation from Virtue and Crystal Venture Partners, and angels from Oscar, Uber, and more.
   

Role Summary

You will lead the development and delivery of key applications within Gyde’s AI-native brokerage platform—encompassing voice, chat, personalization, and real-time analytics—to drive growth, automation, and insights across acquired agencies. You’ll partner with our COO on AI-driven workflows, and Product on roadmap prioritization.

Key Responsibilities


 * Build AI-driven applications. Develop applications that use LLMs, voice, and chat to automate broker workflows, unlock revenue growth opportunities, and improve member engagement.
 * Ship quality products fast and compliantly. Build tools and infrastructure with a focus on security, reliability, and HIPAA compliance.
 * Integrate with third-party systems. Connect to platforms like AgencyBloc, Sunfire, HealthSherpa, and Ideon to streamline agent and member experiences.
 * Design for scale. Contribute to a modular, multi-tenant architecture that supports tens of agencies and millions of members on our platform, as well as key capabilities that enable agent growth, carrier contracting, commission processing, and reporting.
 * Collaborate across functions. Partner with Ops, Value Creation, and Data teams to translate real-world brokerage problems into elegant, scalable engineering solutions.
   
   

What You Bring And Who You Are


 * Strong product sense, fluent in user needs, and an ability to build with empathy for both agents and end consumers (we’ll be in agency offices frequently!).
 * A passion for building on the frontier of AI, and, ideally, experience building AI applications.
 * A high degree of ownership, urgency, and pragmatism. You thrive in ambiguity and take pride in tackling challenging tasks effectively.
 * You will only work with world-class talent, and you are both highly team-oriented and competitive.
 * Bachelor’s or advanced degree in CS, Engineering, AI/ML, or equivalent.
 * 3+ years of engineering leadership, and 1+ years building AI/ML products at scale
 * Familiarity with health insurance distribution, healthcare, financial services, and HIPAA compliance is preferred but not required.
   
   

What We Offer

Gyde offers a competitive benefits package to all employees.


 * Top of the market compensation
 * Flexible (Unlimited) Paid Time Off
 * Remote, or Hybrid Work in Austin or NYC
 * Medical, Dental, and Vision benefits for you and your family
 * Retirement Plan (e.g., 401K)
 * Parental Leave","Over 200 applicants","Full-time","Entry level","Engineering","Construction, Software Development, and IT Services and IT Consulting","","","","109051250","https://grnh.se/jh0xba9k9us","EXTERNAL",""
"Data Engineer II","Seattle, WA","2 weeks ago","2025-11-15","https://www.linkedin.com/jobs/view/data-engineer-ii-at-intepros-4340583934?trk=public_jobs_topcard-title","IntePros","https://www.linkedin.com/company/intepros?trk=public_jobs_topcard-org-name","Summary

We are seeking an experienced Data Engineer to design, build, and operate scalable data systems supporting a global media and entertainment organization. This role will develop automated data pipelines, architect analytical infrastructure, and deliver high-impact reporting and forecasting solutions used by finance and business stakeholders.

Success in this position requires strong data modeling expertise, advanced data engineering skills, and the ability to translate complex operational and financial datasets into scalable, well-architected solutions. The ideal candidate can balance hands-on development with strategic thinking, operating independently within a fast-paced environment.

Duration: 12 months

Schedule: Monday–Friday, 40 hours/week (on-site only)

Reason for Opening: Parental leave coverage

Potential for Extension/Conversion: Yes

Key Responsibilities


 * Architect and develop end-to-end scalable data applications and automated data pipelines.
 * Build reporting solutions across modern visualization platforms (e.g., Quicksight).
 * Establish efficient, repeatable processes for analytics, dashboards, reporting, and model development.
 * Query, program, and analyze large datasets using SQL and Python.
 * Build and maintain data infrastructure, including compute, storage, and big-data services (EC2, RDS, Redshift, EMR, etc.).
 * Partner with cross-functional teams to extract, transform, validate, and load data from diverse sources.
 * Participate in data strategy discussions, contributing to data warehouse design, architectural decisions, and long-term roadmap planning.
 * Support the buildout of financial systems and transformation of operational and financial data feeds.
   
   

Top 3 Must-Have Skills (stack-ranked)


 * Designing & Building Reporting Solutions
 * Expertise creating scalable analytics and visualization frameworks (e.g., Quicksight).
 * Building & Managing Cloud Data Infrastructure
 * Hands-on experience with AWS services such as EC2, RDS, Redshift, and EMR.
 * Advanced SQL & Python for Large-Scale Data Processing
 * Ability to query, transform, and analyze large datasets efficiently.
   
   

Candidate Requirements


 * Leadership principle demonstrated: Deep Dive and Ownership.
 * Technical Requirements:
    * Strong experience with AWS platforms (Redshift, EC2, RDS, EMR).
    * Advanced SQL and Python proficiency.
    * Experience designing scalable reporting and visualization solutions.

 * Experience: 3+ years of data engineering or related technical experience.
 * Education: Degree in Data Engineering, Computer Engineering, or related field.
 * Disqualifiers: Limited or no experience in core AWS data tools.
 * Ideal Candidate: Demonstrated success building data platforms and automating complex data flows.
 * Performance Indicators: Quality of work delivered, timeliness of code implementation, reliability of reporting infrastructure.
   ","Over 200 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","","","","23997","https://www.linkedin.com/jobs/view/data-engineer-ii-at-intepros-4340583934?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI Software Engineer","New York, NY","4 days ago","2025-11-28","https://www.linkedin.com/jobs/view/ai-software-engineer-at-gallatin-ai-inc-4339359328?trk=public_jobs_topcard-title","Gallatin AI, Inc.","https://www.linkedin.com/company/gallatinai?trk=public_jobs_topcard-org-name","About Gallatin

At Gallatin, we are rebuilding defense logistics for the warfighters of the United States and allied forces. We take an AI-first approach to improve defense readiness through software products that streamline and modernize logistics operations from factory to foxhole and result in better decisions and outcomes.

We believe that you won’t change the world by phoning it in and as such we work from our office in El Segundo, California.

About The Role

We’re looking for an AI/ML Software Engineer to play a foundational role in developing and deploying AI-powered solutions for our core product. You’ll work across the full AI/ML lifecycle—from defining and building models to evaluating and deploying large scale ML pipelines and real-time inference systems—while collaborating with cross-functional teams to deliver impactful, real-world AI applications.

What You'll Do


 * Build and Deploy AI/ML Models
    * Own and develop an AI model aligned with our core product needs within the first three months.
    * Validate AI-driven product features through real-world testing and feedback from warfighters.
    * Establish scalable MLOps pipelines and real-time inference services to streamline model training, deployment, runtime, and monitoring.
    * Own high model reliability and uptime by implementing monitoring across your work.

 * Data Collection & Processing
    * Identify and integrate structured, unstructured, real-time, and batch data sources.
    * Work with internal logs, APIs, user interactions, and third-party datasets to improve model training quality.

 * Continuous Improvement & Best Practices
    * Stay ahead of AI trends and emerging technologies to improve model performance.
    * Document and share best practices for AI/ML development.
    * Contribute to the hiring and mentoring of AI/ML talent as we grow our team.
    * Teach the wider team about the latest trends and significance in novel approaches in AI.
      

What We’re Looking For


 * Strong Programming Skills
    * Expertise in at least one: Python, C++, or C.

 * ML Framework Proficiency
    * Hands-on experience with AI/ML training and fine-tuning frameworks, including:
       * PyTorch, TensorFlow, CUDA, Jupyter Notebooks
       * Large Language Models (LLMs) and Open-Source Models (Llama, Anthropic, Mistral)
       * LangChain, Retrieval-Augmented Generation (RAG), Hugging Face, Exo Labs

 * MLOps & Data Engineering Knowledge
    * Experience with data processing and pipeline frameworks such as Apache Kafka, Apache Airflow, AWS Kinesis, pandas, and dbt.
    * Understanding of AI model performance monitoring, data drift detection, and observability tools like Grafana or Kibana.

 * AI Fundamentals & Security Awareness
    * Deep understanding of deep neural networks (DNNs), LLMs, over/underfitting, prompt engineering, and LLM security (jailbreaking risks and protections).

 * Growth Mindset
    * Passion for continuous learning and staying current with the latest advancements in AI/ML, as well as teaching others
      

Bonus Points


 * Experience mentoring and upskilling junior engineers.
 * Familiarity with legacy systems and working with public sector customers.
 * Contributions to open-source (AI/ML) projects.
   
   

Why Gallatin?


 * Join a mission-driven, high-impact, and fast-moving startup where your work directly improves defense logistics readiness for the warfighters of the United States and allied forces.
 * Work alongside a team of passionate engineers, designers, and industry experts.
 * Competitive compensation incl. generous options grant, 100% employer-paid health insurance premiums, 401k, opportunities for rapid career growth, unlimited PTO, free lunches and snacks in the office.
   
   

This position requires the ability to obtain and maintain relevant security clearances. The successful candidate must be able to work in a classified environment when necessary.

If you’re not excited about working hard, and solving the hard problems of building AI decisions-support systems that enhance our warfighters, don’t apply.

The following ranges are based on the cost of labor across US geographic areas. The base ranges from our lowest geographic market to our highest geographic market.

Software Engineer I $80,000-$120,000

Software Engineer II $84,000-$175,000

SR Software Engineer $134,000-$210,000

","99 applicants","Full-time","Entry level","Engineering and Information Technology","Information Services","","","","106410794","https://www.linkedin.com/jobs/view/ai-software-engineer-at-gallatin-ai-inc-4339359328?trk=public_jobs_topcard-title","EASY_APPLY",""
"Product Analyst","San Francisco, CA","2 weeks ago","2025-11-13","https://www.linkedin.com/jobs/view/product-analyst-at-kodiak-4335845763?trk=public_jobs_topcard-title","Kodiak","https://www.linkedin.com/company/kodiakai?trk=public_jobs_topcard-org-name","Kodiak Robotics, Inc. was founded in 2018 and has become a leader in autonomous ground transportation committed to a safer and more efficient future for all. The company has developed an artificial intelligence (AI) powered technology stack purpose-built for commercial trucking and the public sector. The company delivers freight daily for its customers across the southern United States using its autonomous technology. In 2024, Kodiak became the first known company to publicly announce delivering a driverless semi-truck to a customer. Kodiak is also leveraging its commercial self-driving software to develop, test and deploy autonomous capabilities for the U.S. Department of Defense.

Kodiak is seeking a Product Analyst to provide actionable insights that directly shape product development and customer-facing outcomes for commercially deployed driverless trucks. You’ll partner with Product, Engineering, Data and Operations teams to define success metrics, analyze system and product performance, interpret the underlying drivers and root causes and work across teams to translate findings into actions that accelerate product improvement and reliability.

In this role you will:


 * Define, track, and analyze product KPIs related to autonomy and operational performance, safety, customer experience and impact, productivity and reliability.
 * Partner across teams to understand root causes, derive insights and actionable recommendations, and define next steps
 * Partner across teams to design and evaluate experiments (e.g., feature rollouts, A/B tests).
 * Conduct deep-dive analyses on commercial deployments and customer usage to identify feature gaps and prioritize improvements.
 * Collaborate with the data team to improve tracking and instrumentation pipelines.
 * Build dashboards, reports, and lightweight GenAI automations (e.g., Zapier workflows, Replit-based prototypes) to give product and engineering teams visibility into performance trends.
 * Support executive and board-level discussions with product insights and customer impact metrics.
 * Occasional travel might be required to visit Kodiak’s commercial deployment and operations locations.
   
   

What you'll bring:


 * Analytical Rigor: 3+ years of experience in product analytics, data analysis, or related roles in high-growth tech environments; comfort structuring ambiguous problems into clear, data-driven insights.
 * Technical Fluency: Proficiency with BI tools (Looker, Tableau, etc), and the ability to query large datasets efficiently. Comfort with Zapier, Replit, GPT-based tools, or similar platforms to prototype dashboards, automate reporting, and accelerate delivery of insights.
 * Business Acumen: Ability to connect the dots between technical metrics and real-world business outcomes (e.g., fleet utilization, cost per mile, customer adoption).
 * Storytelling Skills: Ability to translate complex data into narratives that influence product direction and decision-making.
 * Cross-Functional Collaboration: Track record of partnering closely with Product Managers, Engineers, Data and Ops teams to align data insights with customer and product priorities.
 * Domain Curiosity: Interest in autonomous systems, logistics, or mobility technology — eager to learn the nuances of safety, reliability, and scaling operations in autonomy.
 * Technical background with Masters degree or above in engineering, computer science or related field
   
   

What we offer:


 * Competitive compensation package including equity and biannual bonuses
 * Excellent Medical, Dental, and Vision plans through Kaiser Permanente, Anthem, and Guardian (including a medical plan with infertility benefits)
 * Flexible PTO and generous parental leave policies
 * Our office is centrally located in Mountain View, CA
 * Office perks: dog-friendly, free catered lunch, a fully stocked kitchen, and free EV charging
 * Long Term Disability, Short Term Disability, Life Insurance
 * Wellbeing Benefits - Headspace, One Medical, Gympass, Spring Health
 * Fidelity 401(k)
 * Commuter, FSA, Dependent Care FSA, HSA
 * Various incentive programs (referral bonuses, patent bonuses, etc.)
   
   

The pay range listed below reflects the base salary across several internal levels Actual starting pay will be based on job-related factors including: work location, experience, relevant training, education, skill level and performance during interview. Total compensation at Kodiak includes base pay, equity, bonus and a competitive benefits package.

California Pay Range: $150,000 USD - $190,000 USD

At Kodiak, we strive to build a diverse community working towards our common company goals in a safe and collaborative environment where harassment of any kind is strictly prohibited. Kodiak is committed to equal opportunity employment regardless of race, ethnicity, religion, gender identity, sexual orientation, age, disability, or veteran status, or any other basis protected by applicable law.

In alignment with its business operations, Kodiak adheres to all relevant statutes, regulations, and administrative prerequisites. Accordingly, roles that carry more sensitive requirements may be limited to candidates that can satisfy additional scrutiny and eligibility for such positions may hinge on verification of a candidate’s residence, U.S. person status, and/or citizenship status. Should the position require, and Kodiak determines that a candidate’s residence, U.S. person status, and/or citizenship status necessitate an export license, bar the candidate from the position, or otherwise fall under national security-related restrictions, Kodiak will consider the candidate for alternative positions unaffected by such restrictions, under terms and conditions set forth at Kodiak’s sole discretion, or, as an alternative, opt not to proceed with the candidate’s application. If applicable, Kodiak may provide visa sponsorship for eligible candidates.","Over 200 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Construction, Software Development, and IT Services and IT Consulting","$150,000.00/yr - $190,000.00/yr","","","18596386","https://grnh.se/iwnwp5rk9us","EXTERNAL",""
"Data Engineering Lead","New York, NY","1 month ago","2025-10-22","https://www.linkedin.com/jobs/view/data-engineering-lead-at-daydream-4318500795?trk=public_jobs_topcard-title","Daydream","https://www.linkedin.com/company/daydream-ing?trk=public_jobs_topcard-org-name","About Daydream

Daydream is a conversational fashion search and discovery platform built exclusively for fashion. Designed to redefine how people search and discover fashion, Daydream offers a personalized, conversational experience powered by advanced AI and natural language understanding. Backed by top-tier investors including Forerunner Ventures, Index Ventures, Google Ventures, and True Ventures, our team is committed to shaping the future of shopping.

About The Role

Are you passionate about the intersection of high fashion and cutting-edge artificial intelligence? Are you passionate about building the data foundations that power truly intelligent systems? As a Data Engineering Lead at Daydream, you will be a foundational member of the team, responsible for designing and building the entire data ecosystem that fuels our AI Personal Stylist. This is a unique opportunity to solve complex technical challenges while directly shaping a product that will revolutionize how people shop online.

What you’ll do:


 * Design, build, and optimize scalable, parallel data processing pipelines on Google Cloud to handle massive volumes of offline data.
 * Implement and manage large-scale LLM batch inference jobs, processing millions of data points to enrich our product catalog with sophisticated, AI-generated attributes.
 * Architect and own the data infrastructure for our Fashion Knowledge Graph, leveraging BigQuery and parallel data processing frameworks.
 * Develop and maintain robust feature generation pipelines to craft high-quality signals for both the training and inference of our machine learning models.
 * Orchestrate complex workflows of data processing jobs, implementing robust monitoring, alerting, and data quality validation systems to ensure reliability and trust in our data.
 * Collaborate closely with data science and machine learning teams to understand data requirements and deliver production-grade data solutions.
 * Champion engineering best practices, including writing clean, maintainable Python and SQL, and drive a culture of high-quality data and operational excellence.
   
   

Who You Are


 * You have extensive experience building and deploying data solutions on a major cloud platform (preferable Google Cloud Platform)
 * You are highly proficient with distributed data processing frameworks such as Apache Spark, Flink, or Polars.
 * You possess exceptional Python coding skills, with a deep understanding of writing efficient, testable, and maintainable code for data applications.
 * You have expert-level SQL skills and deep experience with modern cloud data warehouses like BigQuery, Snowflake, or Redshift.
 * You have hands-on experience with workflow orchestration tools like Airflow, Argo or Kubeflow.
 * You are a pragmatic and proactive builder who thrives in a fast-paced, autonomous startup environment, capable of driving projects from concept to production.
 * You are an empathetic and collaborative teammate, skilled at communicating complex technical ideas and passionate about building the reliable infrastructure that empowers your colleagues.
 * You are a natural leader who enjoys mentoring and developing teammates and aligning work to provide growth opportunities while ensuring priorities are aligned with broader company goals
   
   

What we offer


 * Competitive salary, equity and benefits (medical, dental, vision, 401k, etc.)
 * Flexible vacation and remote working
 * The opportunity to be part of a groundbreaking, AI-focused company
 * Collaborative work environment with a team of talented, fun-loving individuals.
 * Opportunity to learn and grow in your career while shaping the future of fashion, shopping and technology
   
   

Commitment to Diversity

Daydream is proud to be an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees, regardless of race, color, religion, gender, sexual orientation, gender identity, age, national origin, or disability status.

","40 applicants","Full-time","Mid-Senior level","Information Technology","Technology, Information and Internet","","","","101346841","https://www.linkedin.com/jobs/view/data-engineering-lead-at-daydream-4318500795?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr. Data Engineer","Fremont, CA","6 days ago","2025-11-26","https://www.linkedin.com/jobs/view/sr-data-engineer-at-tesla-4339145927?trk=public_jobs_topcard-title","Tesla","https://www.linkedin.com/company/tesla-motors?trk=public_jobs_topcard-org-name","What To Expect
As a Data Engineer, you will build and scale solutions to directly support Tesla’s Environmental, Health, Safety, and Security (EHS&S) goals. You will collaborate closely with EHS&S specialists, operations teams, IT applications, and business intelligence teams to deliver accurate and reliable data to power analytics (across global business units), reporting (internal and external), and machine learning (deep insights to make real impact). Data is deeply embedded in the culture at Tesla. We rely on data – lots of it – to improve our products, to optimize results, and to proactively detect opportunities for advancement. A successful candidate is a hands-on engineer who thrives on solving complex problems, leading end-to-end projects with competing priorities, and is a team player with strong communication skills.

What You'll Do

Collaborate with stakeholders to frame and solve business challenges, identify key opportunities, and ensure seamless integration and adoption of EHS systems, processes, and metricsEnsure safe, secure, compliant, documented, and trusted data by implementing high standardsDevelop, manage, and optimize data pipelines, warehousing, orchestration, and overall infrastructure end-to-endCreate and refine dimensional data models that enable powerful reporting and analyticsCapable of proposing key recommendations to influence business leaders through strong reporting and analytics, presentation skills, and verbal and written communicationExplore new tools, frameworks, and technologies to keep our data platform cutting-edge


What You'll Bring

3+ years of experience in data engineering, data analytics, data modelling, and data managementDegree in Computer Science, Mathematics, Data Engineering, or equivalent experienceOpen-minded, collaborative, and team-oriented attitude with the ability to think outside the box for solutions to complex challengesAbility to effectively communicate concepts and strategies to technical and non-technical audiencesStrong organizational, planning, and project management skills to work independently and focusedKnowledgeable in Python, SQL, APIs, Data Orchestration, CI/CD, Data Operations, and Modern Data Warehousing; experience with Airflow, dbt, Kafka, and Power BI is a plusEagerness to learn about novel ways to make impact in the environmental, health, safety, and security domain; existing knowledge is a plus


Benefits
Compensation and Benefits
Along with competitive pay, as a full-time Tesla employee, you are eligible for the following benefits at day 1 of hire:
Aetna PPO and HSA plans > 2 medical plan options with $0 payroll deduction Family-building, fertility, adoption and surrogacy benefits Dental (including orthodontic coverage) and vision plans, both have options with a $0 paycheck contribution Company Paid (Health Savings Account) HSA Contribution when enrolled in the High Deductible Aetna medical plan with HSA Healthcare and Dependent Care Flexible Spending Accounts (FSA) 401(k) with employer match, Employee Stock Purchase Plans, and other financial benefits Company paid Basic Life, AD&D, short-term and long-term disability insurance Employee Assistance Program Sick and Vacation time (Flex time for salary positions), and Paid Holidays Back-up childcare and parenting support resources Voluntary benefits to include: critical illness, hospital indemnity, accident insurance, theft & legal services, and pet insurance Weight Loss and Tobacco Cessation Programs Tesla Babies program Commuter benefits Employee discounts and perks program


Expected Compensation

$108,000 - $186,000/annual salary + cash and stock awards + benefits

Pay offered may vary depending on multiple individualized factors, including market location, job-related knowledge, skills, and experience. The total compensation package for this position may also include other elements dependent on the position offered. Details of participation in these benefit plans will be provided if an employee receives an offer of employment.

, Tesla","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Motor Vehicle Manufacturing, Renewable Energy Semiconductor Manufacturing, and Utilities","","","","15564","https://www.linkedin.com/jobs/view/sr-data-engineer-at-tesla-4339145927?trk=public_jobs_topcard-title","EASY_APPLY",""
"FBI Special Agent: Data Science & Intelligence Expertise","Plano, TX","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/fbi-special-agent-data-science-intelligence-expertise-at-federal-bureau-of-investigation-fbi-4338355997?trk=public_jobs_topcard-title","Federal Bureau of Investigation (FBI)","https://www.linkedin.com/company/fbi?trk=public_jobs_topcard-org-name","JOB DESCRIPTION




The position advertised has been exempted from the federal civilian hiring freeze.




As an FBI special agent with data engineering and big data experience, you'll directly impact national security. By harnessing your background to transition into federal law enforcement, you can help shape the Bureau’s approach to safeguarding our nation. At the FBI, you will have the opportunity to channel your data science, cloud infrastructure, or IoT systems expertise to protect our nation from cyberattacks, terrorism, fraud, and evolving threats. From conducting high-stakes investigations with your proficiency in advanced statistical modeling and data governance to leveraging your depth of knowledge in predictive modeling to identify trends and prevent criminal activity, your technical skills are essential to investigating crimes that threaten public safety. Your transition from a specialized career to a special agent role will be transformative as you employ your expertise to tackle national security challenges in innovative ways. Every day brings new challenges that demand your adaptability and resilience, but you’re not alone in this journey. The Bureau matches your dedication with a commitment to professional growth, a supportive work environment, and a robust benefits package that prioritizes you. Set yourself apart. Apply Today.




HOW TO APPLY




STEP 1: Click on the “Apply” button to be directed to the FBIJobs Careers website.




STEP 2: Click the “Start” button to begin. You will be prompted to either sign in to continue or register with FBIJobs if you don’t already have an account.




STEP 3: Follow the step-by-step process to submit your interest. You will be guided through each step. You must complete all sections of the form AND ALL REQUIRED DOCUMENTS MUST BE ATTACHED to successfully submit your interest.




 1. Your resume, specifically noting relevant work experience and associated start and end dates. Please note your resume MUST NOT exceed two (2) pages.
 2. Other supporting documents:

 * College transcripts, if qualifying based on education or if there is a positive education requirement.
 * Veterans: DD 214; Disabled Veterans: DD 214, SF-15, and VA letter dated 1991 or later.




Please see instructions on the site for attaching documents.




SALARY LEVEL




Pay level for this position:

 * $99,461.00–$128,329.00




Salary is commensurate with base, locality, and availability pay.




MAJOR DUTIES

 * Plan and conduct investigations of potential violations of federal laws, cybersecurity, and public safety.
 * Exercise judgment, resourcefulness, and versatility in meeting investigative demands.
 * Create and maintain effective liaison relationships with federal, state, local, tribal, territorial, and international law enforcement agencies.
 * Maintain a level of physical fitness to ensure the readiness required to perform law enforcement duties.




KEY REQUIREMENTS

 * Must be a U.S. citizen.
 * Must be able to obtain a Top Secret Sensitive Compartmented Information (SCI) Clearance.
 * Must be willing to travel as required.
 * Must meet the FBI’s Employment Eligibility requirements.
 * Must have a master's degree or higher from a U.S. accredited college or university.




The FBI is an Equal Opportunity Employer, and all qualified applicants will receive consideration for this vacancy. Unless explicitly authorized by law, selection will be made without regard to, and there will be no discrimination because of, color, race, religion, national origin, marital status, parental status, physical or mental disability, genetic information, age (40 or over), sex, pregnancy and related conditions, or on the basis of personal favoritism, or any other nonmerit factors.","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering","Higher Education, Software Development, and IT Services and IT Consulting","$99,461.00/yr - $128,329.00/yr","","","6408","https://apply.fbijobs.gov/psc/ps/EMPLOYEE/HRMS/c/HRS_HRAM_FL.HRS_CG_SEARCH_FL.GBL?Page=HRS_APP_JBPST_FL&Action=U&FOCUS=Applicant&SiteId=1&JobOpeningId=61572&PostingSeq=1&utm_source=LinkedIn&utm_medium=JobPosting&utm_campaign=LIJP_SACaliber&utm_content=DataSci","EXTERNAL",""
"Mechanical Design Engineer","Cincinnati Metropolitan Area","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/mechanical-design-engineer-at-cindavi-4324426824?trk=public_jobs_topcard-title","Cindavi","https://www.linkedin.com/company/cindavi?trk=public_jobs_topcard-org-name","Ready to take ownership of projects, mentor others, and make an impact across design and manufacturing?




Position Summary

We’re looking for a Product Engineer to drive innovative, cost-effective product designs and ensure seamless collaboration between engineering, production, and operations. This role combines hands-on technical design work with cross-functional leadership, making you the go-to expert for product quality, manufacturability, and continuous improvement.




Key Responsibilities

 * Lead the implementation and maintenance of efficient, reliable, and cost-effective product designs using CAD software
 * Manage engineering change notices (ECNs) to resolve quality issues and ensure timely updates to production teams
 * Act as a technical product expert, supporting internal teams with escalated technical, operational, and production issues
 * Collaborate with suppliers, vendors, and Supplier Development Engineers on new product launches and supply chain readiness
 * Provide documentation, repair, and update support for field campaigns and customer service needs
 * Partner with production staff to review drawings, implement process improvements, and reduce costs
 * Maintain accurate part numbers, bills of materials, and ERP system data in collaboration with Production Administration
 * Mentor co-ops by reviewing designs for alignment with specifications, safety, and reliability standards
 * Participate in project gate meetings, status updates, and cross-functional design reviews




Qualifications

 * Bachelor’s in Mechanical Engineering Technology (MET) or Mechanical Engineering (ME)
 * 2–4 years of engineering-related experience (co-op or professional)
 * Proficiency with CAD design software and ERP systems




What We Offer

 * Opportunity to be a key contributor in product development and continuous improvement initiatives
 * Competitive compensation and benefits
 * Exposure to new product launches, supplier collaboration, and advanced manufacturing technologies
 * Growth opportunities, including mentoring responsibilities and cross-functional leadership
 * A collaborative, innovation-driven environment where your ideas and solutions make a direct impact","109 applicants","Full-time","Mid-Senior level","Engineering, Design, and Product Management","Appliances, Electrical, and Electronics Manufacturing, Commercial and Service Industry Machinery Manufacturing, and Agriculture, Construction, Mining Machinery Manufacturing","$80,000.00/yr - $95,000.00/yr","Alex Doyle","https://www.linkedin.com/in/alex-doyle-223114148","98566796","https://www.linkedin.com/jobs/view/mechanical-design-engineer-at-cindavi-4324426824?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Paid paternity leave
Paid maternity leave"
"Analytics Engineer - Weights & Biases","Sunnyvale, CA","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/analytics-engineer-weights-biases-at-weights-biases-4341652822?trk=public_jobs_topcard-title","Weights & Biases","https://www.linkedin.com/company/wandb?trk=public_jobs_topcard-org-name","CoreWeave, the AI Hyperscaler™, acquired Weights & Biases to create the most powerful end-to-end platform to develop, deploy, and iterate AI faster. Since 2017, CoreWeave has operated a growing footprint of data centers covering every region of the US and across Europe, and was ranked as one of the TIME100 most influential companies of 2024. By bringing together CoreWeave’s industry-leading cloud infrastructure with the best-in-class tools AI practitioners know and love from Weights & Biases, we’re setting a new standard for how AI is built, trained, and scaled.

The integration of our teams and technologies is accelerating our shared mission: to empower developers with the tools and infrastructure they need to push the boundaries of what AI can do. From experiment tracking and model optimization to high-performance training clusters, agent building, and inference at scale, we’re combining forces to serve the full AI lifecycle — all in one seamless platform.

Weights & Biases has long been trusted by over 1,500 organizations — including AstraZeneca, Canva, Cohere, OpenAI, Meta, Snowflake, Square,Toyota, and Wayve — to build better models, AI agents and applications. Now, as part of CoreWeave, that impact is amplified across a broader ecosystem of AI innovators, researchers, and enterprises.

As we unite under one vision, we’re looking for bold thinkers and agile builders who are excited to shape the future of AI alongside us. If you're passionate about solving complex problems at the intersection of software, hardware, and AI, there's never been a more exciting time to join our team.

What You’ll Do

The Data group at Weights & Biases works across the full range of data-related topics:


 * We help business partners set goals, make decisions, and understand the levers to achieve their goals.
 * We build reporting to keep the business attuned and aligned.
 * We build datasets and pipelines to support self-service analysis.
 * We train models to understand our customer growth, churn risk, and detect spam and abuse.
 * We’re exploring novel benchmarks and recs for model training.
 * We build and maintain a massive data platform to power it all.
   
   

About The Role

We’re hiring a Data Analytics Engineer who will focus primarily on analytics engineering while remaining a core member of the broader data platform team. You’ll be the dedicated owner of our dbt layer and related analytics infrastructure, driving operational excellence, cost/performance optimization, and self-service analytics at scale. You’ll partner closely with analysts, data scientists, and platform engineers to harden our foundations and enable better decision-making across the company.

Who You Are


 * Deep knowledge of data engineering and analytics engineering workflows at scale, with a track record of operational excellence
 * Expert with dbt (core or Cloud): model design, incremental strategies, macros/packages, testing, documentation, CI/CD
 * Strong SQL and warehouse design for BigQuery (partitioning, clustering, materializations, cost/perf tuning at multi-TB/PB scale)
 * Experience with orchestration (Dagster preferred; Airflow acceptable) and production-grade deployment practices
 * Familiar with data quality frameworks (e.g., dbt tests, Great Expectations, data contracts) and SLA/SLO design
 * Proficient in Python for orchestration, utilities, and light data tooling; Git-based workflows
 * Understanding of product telemetry, logging standards, and event modeling for web apps/SaaS
 * Excellent communication and documentation; able to align analysts, engineers, and stakeholders on semantics and standards
   
   

Preferred: (if applicable)


 * Hex (or similar BI) performance tuning and governance experience
 * Experience building semantic/metrics layers and catalogs (e.g., dbt exposures/semantics, OpenLineage, DataHub/Amundsen/Atlan)
 * Prior work migrating dbt Cloud → Dagster or similar orchestrator
 * Familiarity with AI/ML workflows and terminology
 * Terraform/infra-as-code exposure on GCP
 * Experience designing anomaly detection or rule-based alerting for KPIs
   
   

Why Us?

About

We work hard, have fun, and move fast! We’re in an exciting stage of hyper-growth that you will not want to miss out on. We’re not afraid of a little chaos, and we’re constantly learning. Our team cares deeply about how we build our product and how we work together, which is represented through our core values:


 * Be Curious at Your Core
 * Act Like an Owner
 * Empower Employees
 * Deliver Best-in-Class Client Experiences
 * Achieve More Together
   
   

We support and encourage an entrepreneurial outlook and independent thinking. We foster an environment that encourages collaboration and provides the opportunity to develop innovative solutions to complex problems. As we get set for takeoff, the growth opportunities within the organization are constantly expanding. You will be surrounded by some of the best talent in the industry, who will want to learn from you, too. Come join us!

The base salary range for this role is $139,000 to $204,000. The starting salary will be determined based on job-related knowledge, skills, experience, and market location. We strive for both market alignment and internal equity when determining compensation. In addition to base salary, our total rewards package includes a discretionary bonus, equity awards, and a comprehensive benefits program (all based on eligibility).

What We Offer

The range we’ve posted represents the typical compensation range for this role. To determine actual compensation, we review the market rate for each candidate which can include a variety of factors. These include qualifications, experience, interview performance, and location.

In addition to a competitive salary, we offer a variety of benefits to support your needs, including:


 * Medical, dental, and vision insurance - 100% paid for by CoreWeave
 * Company-paid Life Insurance
 * Voluntary supplemental life insurance
 * Short and long-term disability insurance
 * Flexible Spending Account
 * Health Savings Account
 * Tuition Reimbursement
 * Ability to Participate in Employee Stock Purchase Program (ESPP)
 * Mental Wellness Benefits through Spring Health
 * Family-Forming support provided by Carrot
 * Paid Parental Leave
 * Flexible, full-service childcare support with Kinside
 * 401(k) with a generous employer match
 * Flexible PTO
 * Catered lunch each day in our office and data center locations
 * A casual work environment
 * A work culture focused on innovative disruption
   
   

Our Workplace

While we prioritize a hybrid work environment, remote work may be considered for candidates located more than 30 miles from an office, based on role requirements for specialized skill sets. New hires will be invited to attend onboarding at one of our hubs within their first month. Teams also gather quarterly to support collaboration

California Consumer Privacy Act - California applicants only

CoreWeave is an equal opportunity employer, committed to fostering an inclusive and supportive workplace. All qualified applicants and candidates will receive consideration for employment without regard to race, color, religion, sex, disability, age, sexual orientation, gender identity, national origin, veteran status, or genetic information.

As part of this commitment and consistent with the Americans with Disabilities Act (ADA), CoreWeave will ensure that qualified applicants and candidates with disabilities are provided reasonable accommodations for the hiring process, unless such accommodation would cause an undue hardship. If reasonable accommodation is needed, please contact: careers@coreweave.com.

Export Control Compliance

This position requires access to export controlled information. To conform to U.S. Government export regulations applicable to that information, applicant must either be (A) a U.S. person, defined as a (i) U.S. citizen or national, (ii) U.S. lawful permanent resident (green card holder), (iii) refugee under 8 U.S.C.


 * 1157, or (iv) asylee under 8 U.S.C.
 * 1158, (B) eligible to access the export controlled information without a required export authorization, or (C) eligible and reasonably likely to obtain the required export authorization from the applicable U.S. government agency. CoreWeave may, for legitimate business reasons, decline to pursue any export licensing process.","72 applicants","Full-time","Entry level","Information Technology","Software Development","$139,000.00/yr - $204,000.00/yr","","","18593641","https://www.linkedin.com/jobs/view/analytics-engineer-weights-biases-at-weights-biases-4341652822?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI Engineer","Pittsburgh, PA","3 weeks ago","2025-11-05","https://www.linkedin.com/jobs/view/ai-engineer-at-bloomfield-4337792508?trk=public_jobs_topcard-title","Bloomfield","https://www.linkedin.com/company/bloomfield-ai?trk=public_jobs_topcard-org-name","About the Company

Plant level knowledge is vital to satisfying the food production needs from projected a forty percent increase in world population over the next thirty years. We support that goal by continuously and automatically assessing the health and performance of the world’s +$1T specialty crops, one plant at a time, with deep learning and imaging. Currently, Bloomfield is focused on wine, table, and juice grapes as well as, more recently, blueberries. Our portable Flash cameras and supporting platform capture, geo-locate and share the condition of each vine, tree and bush, along with the various features of that plant. This information, in turn, informs a variety of decisions and actions that growers take every day to increase the size, quality and consistency of yields and doing so without increasing the resources used to produce those yields. 
 

About the Role

Our rapidly growing engineering team is in search of an AI Engineer to lead the design and development of deep learning models on large amounts of high resolution image data, as well as analytical modeling solutions at scale on a cloud platform. 

As an AI Engineer, you will work at start-up speed and can plan and develop roadmaps, adapting along the way to dynamic conditions. You should have a detail-oriented engineering and algorithmic mindset, and enjoy building, instrumenting, testing, and documenting large systems. You will have broad responsibilities, build a team as we grow, and be a part of the senior team.  This is a full-time, exempt position that reports to the Head of Product.

Responsibilities 

 * Deep model development: develop new image processing models that include feature detection and instance segmentation. 
 * Develop and track model performance metrics across a variety of applications and data sets. 
 * Integrate model development and deployment into cloud-based automated data processing pipeline. 
 * Develop processes and algorithms for effective model retraining as necessary. You should have
 * Data labeling: develop image labeling strategies for new model training and validation, including processes for on-going Q&A of deployed models. Evaluate labeling tools, including compatibility with AI training and validation systems. 
 * Train and deploy models using Pytorch, MLFlow, Sagemaker in AWS

Requirements

 * 3+ years of experience developing cloud-based AI solutions
 * Proficient in common deep learning tools, including PyTorch, PyTorch Lightning, and TensorFlow
 * Experience with multi-class models and hierarchical classification
 * Proficient in common programming languages, including Python, C++, Java

Bonus Points

 * MS degree in computer science, mathematics, engineering, or similar field
 * Proficient in Machine Learning Operations management, with extensive AWS experience, and demonstrated experience with complete model lifecycle management
 * Previous projects implementing Mask-RCNN and/or AWS Sagemaker
 * Experience with stereo and multi-view image data 
   

What We Offer

In addition to the opportunity to apply and develop your skills toward key business objectives, we offer an excellent compensation package including:

 * Competitive base salary and bonus
 * Medical, Dental and Vision Insurance
 * 401(k) retirement plan
 * Unlimited PTO policy
 * Parental Leave 
 * Training & Development Stipend

Bloomfield is an equal opportunity employer. We consider qualified applicants without regard to race, color, religion, sex, national origin, sexual orientation, disability, gender identity, protected veteran status, or other protected classes.

In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.



 ","125 applicants","Full-time","Entry level","Sales, General Business, and Education","Wireless Services, Telecommunications, and Communications Equipment Manufacturing","","","","27226585","https://app.jazz.co/apply/job/85ZPX1DwX0?source=LINKR&source=LINK&source=LINKEDIN&source=LinkedIn&src=Linkedin&gh_src=fa1195541us&LinkedIn=LinkedIn&source=LINK&source=LinkedIn","EXTERNAL",""
"Data Engineer","New York, NY","2 weeks ago","2025-11-14","https://www.linkedin.com/jobs/view/data-engineer-at-sesamm-4336241375?trk=public_jobs_topcard-title","SESAMm","https://fr.linkedin.com/company/sesamm-sas?trk=public_jobs_topcard-org-name","SESAMm

SESAMm (www.sesamm.com) extracts behavioral insights from millions of unstructured text data sources across the public internet in over 100 languages, helping clients distill valuable intelligence on businesses and their customers to make investment decisions and manage risk.

We work with many well-known firms around the world in private equity, investment banking, insurance, and asset management to apply Natural Language Processing and Artificial Intelligence algorithms to track e-reputation, competitive positioning, sentiment analysis, risk and ESG factors.

SESAMm is growing quickly, with over 70 team members around the globe and offices in Paris, New York, London, Metz, Tunis, and Tokyo.

Key technologies: Alternative Data, Natural Language Processing, Machine Learning and Quantitative Analysis.

Are you looking for a new challenge? Do you dream of joining a growing company, proposing new ideas, and taking part in innovative processes?

At SESAMm, everyone brings their ideas, skills, and creativity. We value collaboration, support and teamwork. We learn every day from the experience of this great team and we constantly take up new challenges. We are proud of the work accomplished and to participate in the success of this great adventure!

The Data Engineer Role



SESAMm, in partnership with one of the largest private equity (PE) firms in the United States, is seeking a data engineer to join an exciting AI platform project designed to transform investment analysis. This project is at the cutting edge of private equity, leveraging advanced artificial intelligence (AI) to improve data-driven decision-making. As a data engineer, you will contribute to a groundbreaking platform used by deal teams to accelerate and enhance due diligence.

Key Responsibilities


 * Data Architecture & Pipeline Development: Design, build, and maintain robust data pipelines and architectures to support private equity investment workflows. Ensure seamless ingestion, transformation, and integration of large, diverse datasets (financial, ESG, market, and alternative data) from multiple internal and external sources.
 * Scalability, Performance & Reliability: Develop scalable data infrastructure, monitor and optimize data flow performance, reliability, and data quality. Ensure compliance with security, privacy, and governance standards.
 * Collaboration with Data Science & Investment Teams: Partner with data scientists, investment professionals, and operations teams to operationalize analytics. Enable efficient data access, versioning, and reproducibility across the AI and analytics platform.
 * Automation & Continuous Improvement: Automate data workflows, implement CI/CD pipelines, and contribute to the continuous improvement of data engineering practices. Evaluate new tools and architectures to enhance efficiency, scalability, and cost-effectiveness.
   
   

Desired Background and Skills

Education


 * Master's degree in Data Engineering, Computer Science, or a related technical field.
   
   

Experience


 * 3–5 years of hands-on experience designing and maintaining large-scale data pipelines.
 * Proven experience working with structured and unstructured financial data or other complex data domains.
 * Experience collaborating in finance, consulting, or private equity environments is a must.
   
   

Skills


 * Advanced proficiency in Python and SQL for data processing and transformation.
 * Hands-on experience with cloud data platforms (e.g. AWS, Azure, GCP, or Databricks) and data workflow orchestration tools (e.g. Airflow, Prefect, or Dagster).
 * Strong understanding of data modeling, schema design, and API integration.
 * Experience with big data frameworks (Spark, Kafka, Delta Lake, etc.) is highly desirable.
 * Familiarity with version control (Git) and DevOps practices (CI/CD pipelines).
 * Strong communication skills and ability to work cross-functionally with non-technical stakeholders. Fluency in English; French is a plus.
   
   

Benefits of Working at SESAMm

Flexibility: Team members can work remotely and have the opportunity to work with colleagues around the world.

Work Environment: SESAMm is multicultural, with technology, sales, and management teams in the US, France, and Tunisia making important contributions to the company's growth.

Career Development: SESAMm is growing rapidly, creating ongoing opportunities for personal and professional growth. This dynamic environment allows you to shape the company's culture and evolution.

Professional Development: Work alongside industry-leading experts and gain valuable exposure to advanced AI and ML technologies applied in private equity. This role offers a unique opportunity to deepen your expertise in these cutting-edge applications.

Mentorship & Training: SESAMm provides structured training and mentorship, with a strong emphasis on knowledge-sharing. Internally and externally led training sessions are organized, and we offer access to educational platforms, encouraging you to expand your AI skill set.

Global Perspective: Collaborate with teams based across Europe and the United States, gaining hands-on international experience in a fast-paced, high-impact environment. This global perspective helps broaden your skill set and provides insights into international market dynamics.

Transparency: You will be kept apprised of the company's continuing evolution and performance through monthly ""Ask Me Anything"" meetings, frequent business/finance updates, and strategy-sharing discussions.

Well-being: Building a good culture is key to building a good business at SESAMm. We focus on being a learning organization that values and supports teamwork, thoughtfulness, and work/life balance.","Over 200 applicants","Full-time","Entry level","Information Technology","Financial Services","","","","4827418","https://grnh.se/subj8gh94us","EXTERNAL",""
"Data Engineer, Penn Wharton Budget Model","Philadelphia, PA","2 weeks ago","2025-11-17","https://www.linkedin.com/jobs/view/data-engineer-penn-wharton-budget-model-at-university-of-pennsylvania-4335944343?trk=public_jobs_topcard-title","University of Pennsylvania","https://www.linkedin.com/school/university-of-pennsylvania/?trk=public_jobs_topcard-org-name","University Overview

The University of Pennsylvania, the largest private employer in Philadelphia, is a world-renowned leader in education, research, and innovation. This historic, Ivy League school consistently ranks among the top 10 universities in the annual U.S. News & World Report survey. Penn has 12 highly-regarded schools that provide opportunities for undergraduate, graduate and continuing education, all influenced by Penn’s distinctive interdisciplinary approach to scholarship and learning. As an employer Penn has been ranked nationally on many occasions with the most recent award from Forbes who named Penn one of America’s Best Large Employers in 2023.

Penn offers a unique working environment within the city of Philadelphia. The University is situated on a beautiful urban campus, with easy access to a range of educational, cultural, and recreational activities. With its historical significance and landmarks, lively cultural offerings, and wide variety of atmospheres, Philadelphia is the perfect place to call home for work and play.

The University offers a competitive benefits package that includes excellent healthcare and tuition benefits for employees and their families, generous retirement benefits, a wide variety of professional development opportunities, supportive work and family benefits, a wealth of health and wellness programs and resources, and much more.

Posted Job Title

Data Engineer, Penn Wharton Budget Model

Job Profile Title

Application Developer Senior

Job Description Summary

Wharton School Overview

Founded in 1881 as the world’s first collegiate business school, the Wharton School of the University of Pennsylvania is shaping the future of business by incubating ideas, driving insights, and creating leaders who change the world. With campuses in both Philadelphia and San Francisco, Wharton has over 850 staff, a faculty population of more than 235 renowned professors, and 5,000 undergraduate, MBA, executive MBA, and doctoral students. Each year 13,000 professionals from around the world advance their careers through Wharton Executive Education’s individual, company-customized, and online programs. More than 104,000 Wharton alumni form a powerful global network of leaders who transform business every day. Wharton is home to a dynamic community of staff, bringing a wide range of skills, experiences, and perspectives. To learn more, visit www.wharton.upenn.edu.

The Penn Wharton Budget Model (PWBM) is a non-partisan, research-based initiative that provides analysis to policymakers to assess the effects of policy on budgetary outcomes (government revenues and costs) and various economic variables. PWBM’s work is widely cited and has been influential in many key recent policy discussions, including tax reform, budget reconciliation, immigration, Social Security, health care, infrastructure, pre-K education, paid family leave, universal income, and the federal debt. The PWBM team consists of roughly 30 Ph.D. economists, policy analysts, research analysts, software engineers, and developers.

PWBM has a unique model – even relative to other scoring entities – that relies on a workflow between data processing, microsimulation (which utilizes large-scale Monte Carlo simulations), dozens of policy modules (including several tax calculators), and a large-scale stochastic macroeconomic overlapping generations (OLG) lifecycle model. An extensive code base, mostly in Python, underlies this workflow, and the model utilizes cutting-edge economic modeling, data science, machine learning, and cloud computing to project policy impacts. The models are frequently updated to reflect the latest economics and empirical research, and many of them require (large) datasets to calibrate them. PWBM is currently building a model automation pipeline to automate the forecasting process.

The Data Engineer will be a member of the software engineering team and work closely with PWBM domain experts – economists, policy analysts, and research analysts – responsible for building and calibrating models using large, publicly and privately available datasets. The Data Engineer will design, build, and maintain the data infrastructure with the software engineering team; establish best practices for data ingestion and storage; and coach domain experts to write maintainable extract-transform-load (ETL) code. The Data Engineer will also contribute their expertise and insights to the model automation project to help make the automation pipeline robust to data changes.


 * Position contingent upon funding.
   
   
   

Job Description

Job Responsibilities


 * The data engineer will work with the software engineering team to design, build, and maintain data infrastructure that houses data obtained from external sources and PWBM model output and enables PWBM and external collaborators easy access to information that is versioned, accurate, and consistent.
 * Establish best practices for data ingestion, storage, and retrieval. Work with PWBM domain experts to implement best practices in extract-transform-load (ETL) code, including producing readable, modular, and testable code.
 * Help the Director of Engineering and Data and domain experts plan future infrastructure development.
 * Mentor junior engineers, research analysts, and graduate students.
 * Perform additional duties as assigned
   
   
   

Qualifications

Required Skills/Experience:


 * A bachelor's degree in a relevant field, such as computer science, software engineering, statistics, mathematics, or engineering; and 3-5 years of experience; or equivalent.
 * More than 2 years of post-degree experience as a data engineer in a team setting, and familiarity with current cloud data storage options, data modeling, data extraction (e.g., web scraping or using web APIs), automation (e.g., pipelining), and alerting/monitoring with process insights in mind.
 * Demonstrated ability to write readable, modular, and testable code.
 * Experience with modern software engineering best practices (e.g. automated testing, pair programming, and continuous integration).
 * Solid ability to understand mathematical and statistical models.
 * Strong written and verbal communication skills and the ability to collaborate successfully with teammates who have diverse technical backgrounds. The data engineer will work with individuals across a range of technical experience levels, so the candidate should be able to distill their thoughts into non-technical terms.
 * Experience working with LLM-based coding tools.
 * Experience with data frame packages/libraries in any programming language.
 * Solid ability to identify requirements from discussions with domain experts and parse them into smaller stories/tasks.
   
   
   

Preferred Skills


 * Knowledge of Python and pandas.
 * Experience working with survey data or other microdata.
 * Familiarity with major economic and demographic data sources (e.g. Census Bureau, Bureau of Labor Statistics, and Bureau of Economic Analysis).
 * Experience working with data scientists or economists.
 * Formal training in economics, public policy, or in quantitative disciplines such as statistics, engineering, and mathematics.
   
   
   

Additional Information

Staff positions at the Penn Wharton Budget Model are funded by external gifts and grants. This position is contingent upon both the continued availability of funding sources and the ongoing need for the role. It is an initial two-year term position, with potential renewal at the discretion of the faculty director. The position may be discontinued if funding sources are no longer available, if suitable replacement funding sources are not identified, or if the need for the position ceases to exist.

Job Location - City, State

Philadelphia, Pennsylvania

Department / School

Wharton School

Pay Range

$83,500.00 - $130,000.00 Annual Rate

Salary offers are made based on the candidate’s qualifications, experience, skills, and education as they directly relate to the requirements of the position, and in alignment with salary ranges based on external market data for the job’s level. Internal organization and peer data at Penn are also considered.

Equal Opportunity Statement

The University of Pennsylvania is an equal opportunity employer. Candidates are considered for employment without regard to race, color, sex, sexual orientation, religion, creed, national origin (including shared ancestry or ethnic characteristics), citizenship status, age, disability, veteran status or any class protected under applicable federal, state or local law.

Special Requirements

Background checks may be required after a conditional job offer is made. Consideration of the background check will be tailored to the requirements of the job.

University Benefits


 * Health, Life, and Flexible Spending Accounts: Penn offers comprehensive medical, prescription, behavioral health, dental, vision, and life insurance benefits to protect you and your family’s health and welfare. You can also use flexible spending accounts to pay for eligible health care and dependent care expenses with pre-tax dollars.
 * Tuition: Take advantage of Penn's exceptional tuition benefits. You, your spouse, and your dependent children can get tuition assistance here at Penn. Your dependent children are also eligible for tuition assistance at other institutions.
 * Retirement: Penn offers generous retirement plans to help you save for your future. Penn’s Basic, Matching, and Supplemental retirement plans allow you to save for retirement on a pre-tax or Roth basis. Choose from a wide variety of investment options through TIAA and Vanguard.
 * Time Away from Work: Penn provides you with a substantial amount of time away from work during the course of the year. This allows you to relax, take vacations, attend to personal affairs, recover from illness or injury, spend time with family—whatever your personal needs may be.
 * Long-Term Care Insurance: In partnership with Genworth Financial, Penn offers faculty and staff (and your eligible family members) long-term care insurance to help you cover some of the costs of long-term care services received at home, in the community or in a nursing facility. If you apply when you’re newly hired, you won’t have to provide proof of good health or be subject to underwriting requirements. Eligible family members must always provide proof of good health and are subject to underwriting.
 * Wellness and Work-life Resources: Penn is committed to supporting our faculty and staff as they balance the competing demands of work and personal life. That’s why we offer a wide variety of programs and resources to help you care for your health, your family, and your work-life balance.
 * Professional and Personal Development: Penn provides an array of resources to help you advance yourself personally and professionally.
 * University Resources: As a member of the Penn community, you have access to a wide range of University resources as well as cultural and recreational activities. Take advantage of the University’s libraries and athletic facilities, or visit our arboretum and art galleries. There’s always something going on at Penn, whether it’s a new exhibit at the Penn Museum, the latest music or theater presentation at the Annenberg Center, or the Penn Relays at Franklin Field to name just a few examples. As a member of the Penn community, you’re right in the middle of the excitement—and you and your family can enjoy many of these activities for free.
 * Discounts and Special Services: From arts and entertainment to transportation and mortgages, you'll find great deals for University faculty and staff. Not only do Penn arts and cultural centers and museums offer free and discounted admission and memberships to faculty and staff. You can also enjoy substantial savings on other goods and services such as new cars from Ford and General Motors, cellular phone service plans, movie tickets, and admission to theme parks.
 * Flexible Work Hours: Flexible work options offer creative approaches for completing work while promoting balance between work and personal commitments. These approaches involve use of non-traditional work hours, locations, and/or job structures.
 * Penn Home Ownership Services: Penn offers a forgivable loan for eligible employees interested in buying a home or currently residing in West Philadelphia, which can be used for closing costs or home improvements.
 * Adoption Assistance: Penn will reimburse eligible employees on qualified expenses in connection with the legal adoption of an eligible child, such as travel or court fees, for up to two adoptions in your household.
   
   
   

To learn more, please visit: https://www.hr.upenn.edu/PennHR/benefits-pay","162 applicants","Full-time","Entry level","Information Technology","Higher Education","$83,500.00/yr - $130,000.00/yr","","","3165","https://www.linkedin.com/jobs/view/data-engineer-penn-wharton-budget-model-at-university-of-pennsylvania-4335944343?trk=public_jobs_topcard-title","EASY_APPLY",""
"FBI Special Agent: Data Science & Intelligence Expertise","Irvine, CA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/fbi-special-agent-data-science-intelligence-expertise-at-federal-bureau-of-investigation-fbi-4338355998?trk=public_jobs_topcard-title","Federal Bureau of Investigation (FBI)","https://www.linkedin.com/company/fbi?trk=public_jobs_topcard-org-name","JOB DESCRIPTION




The position advertised has been exempted from the federal civilian hiring freeze.




As an FBI special agent with data engineering and big data experience, you'll directly impact national security. By harnessing your background to transition into federal law enforcement, you can help shape the Bureau’s approach to safeguarding our nation. At the FBI, you will have the opportunity to channel your data science, cloud infrastructure, or IoT systems expertise to protect our nation from cyberattacks, terrorism, fraud, and evolving threats. From conducting high-stakes investigations with your proficiency in advanced statistical modeling and data governance to leveraging your depth of knowledge in predictive modeling to identify trends and prevent criminal activity, your technical skills are essential to investigating crimes that threaten public safety. Your transition from a specialized career to a special agent role will be transformative as you employ your expertise to tackle national security challenges in innovative ways. Every day brings new challenges that demand your adaptability and resilience, but you’re not alone in this journey. The Bureau matches your dedication with a commitment to professional growth, a supportive work environment, and a robust benefits package that prioritizes you. Set yourself apart. Apply Today.




HOW TO APPLY




STEP 1: Click on the “Apply” button to be directed to the FBIJobs Careers website.




STEP 2: Click the “Start” button to begin. You will be prompted to either sign in to continue or register with FBIJobs if you don’t already have an account.




STEP 3: Follow the step-by-step process to submit your interest. You will be guided through each step. You must complete all sections of the form AND ALL REQUIRED DOCUMENTS MUST BE ATTACHED to successfully submit your interest.




 1. Your resume, specifically noting relevant work experience and associated start and end dates. Please note your resume MUST NOT exceed two (2) pages.
 2. Other supporting documents:

 * College transcripts, if qualifying based on education or if there is a positive education requirement.
 * Veterans: DD 214; Disabled Veterans: DD 214, SF-15, and VA letter dated 1991 or later.




Please see instructions on the site for attaching documents.




SALARY LEVEL




Pay level for this position:

 * $99,461.00–$128,329.00




Salary is commensurate with base, locality, and availability pay.




MAJOR DUTIES

 * Plan and conduct investigations of potential violations of federal laws, cybersecurity, and public safety.
 * Exercise judgment, resourcefulness, and versatility in meeting investigative demands.
 * Create and maintain effective liaison relationships with federal, state, local, tribal, territorial, and international law enforcement agencies.
 * Maintain a level of physical fitness to ensure the readiness required to perform law enforcement duties.




KEY REQUIREMENTS

 * Must be a U.S. citizen.
 * Must be able to obtain a Top Secret Sensitive Compartmented Information (SCI) Clearance.
 * Must be willing to travel as required.
 * Must meet the FBI’s Employment Eligibility requirements.
 * Must have a master's degree or higher from a U.S. accredited college or university.




The FBI is an Equal Opportunity Employer, and all qualified applicants will receive consideration for this vacancy. Unless explicitly authorized by law, selection will be made without regard to, and there will be no discrimination because of, color, race, religion, national origin, marital status, parental status, physical or mental disability, genetic information, age (40 or over), sex, pregnancy and related conditions, or on the basis of personal favoritism, or any other nonmerit factors.","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering","Higher Education, Software Development, and IT Services and IT Consulting","$99,461.00/yr - $128,329.00/yr","","","6408","https://www.linkedin.com/jobs/view/fbi-special-agent-data-science-intelligence-expertise-at-federal-bureau-of-investigation-fbi-4338355998?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Alpharetta, GA","1 week ago","2025-11-22","https://www.linkedin.com/jobs/view/data-engineer-at-mission-us-4324251033?trk=public_jobs_topcard-title","Mission US","https://www.linkedin.com/company/mission-underwriting-managers-llc?trk=public_jobs_topcard-org-name","About Mission Underwriting Services

At Mission Underwriters, we provide the capital, issuing paper, and reinsurance access you need to launch your own Program Administrator (PA) business quickly and efficiently. We offer non-recourse capital for qualified underwriters, giving you a manageable risk profile with potential equity upside. By taking care of administrative complexities like compliance, risk management, accounting, and HR, we free you to focus on what you do best—underwriting and distribution. Our turnkey platform gets you into the market in just a few months, minimizing disruption to your key relationships. With access to our network of highly rated issuing carriers and reinsurance partners, you can secure coverage with less stress and uncertainty. Built from the ground up, our purpose-driven technology simplifies workflows, enhances responsiveness, and eliminates the burden of outdated legacy systems.

What We Offer


 * Remote First Work Environment (US Based)
 * Medical, Dental, Vision
 * 401K, 401K Match
 * Life and Disability Benefits
 * Unaccrued Paid Time Off
 * 11 Paid Holidays
 * Employee Discounts
 * Employee Assistance Program
 * Educational Assistance Program
 * Employee Referral Program
 * Paid Parental Leave
   
   

About The Role

The Data Engineer will support the development and optimization of Mission’s data infrastructure as part of our modern data platform initiative. This hands-on role will focus on implementing scalable data pipelines, enabling a centralized enterprise data warehouse, and supporting business reporting needs. The ideal candidate will collaborate across technology, operations, product, and analytics teams to deliver high-quality, governed, and reusable data assets in alignment with Mission’s long-term architecture.

What You'll Do


 * Contribute to the implementation of scalable data pipelines to ingest, transform, and store data from third-party vendors and internal systems using APIs, files, and databases.
 * Support the development of a cloud-based data warehouse solution in partnership with architects, ensuring clean, normalized, and performant data models.
 * Establish and monitor reliable data ingestion processes across systems with varying grain and cadence, ensuring data quality and completeness.
 * Collaborate with API and integration teams to develop secure, robust data exchange processes with external vendors and internal services.
 * Set up and manage data connections from the warehouse to BI tools (e.g., Power BI, Looker, Tableau) to enable self-service analytics and dashboarding.
 * Document data flows, schemas, and definitions, and help drive data governance and standardization efforts across the organization.
 * Implement data validation, cleansing, and enrichment processes to ensure high-quality data for financial reporting and analytics
 * Ensure compliance with data standards, regulatory requirements (e.g., NAIC, SOX), and data security best practices
 * Collaborate with senior team members to apply data engineering best practices, including version control, CI/CD for data pipelines, testing, and observability.
 * Assist with building dashboards in BI tools.
   
   

Required Qualifications


 * 2-5 years of experience in data engineering, data warehousing, or a related field.
 * Strong SQL and performance tuning skills, ideally in Microsoft SQL Server environments.
 * Experience working with data warehouses or data marts using dimensional modeling.
 * Familiar with data ingestion via RESTful APIs, JSON/XML, flat files, message queues, or CDC.
 * Understanding of data governance, metadata management, and access control.
 * Experience with version control (e.g., Git) and basic CI/CD workflows.
 * Experience with BI tools like Power BI, Looker, or Tableau.
 * Bachelor’s degree in Computer Science, Engineering, Information Systems, or equivalent experience.
   
   

Preferred Qualification


 * Experience in the commercial insurance industry or with regulated data environments.
 * Hands-on experience with Azure data services.
 * Familiarity with data cleanup, fuzzy matching, or enrichment workflows.
 * Experience with Python, dbt, or Azure Functions.
 * Strong communication skills and ability to work cross-functionally.
 * Ability to travel up to 10% of the year.
   
   

Knowledge, Skills And Abilities


 * Understanding of data warehousing principles, dimensional modeling, and ETL/ELT architecture, with hands-on experience building analytics-ready structures preferably in Azure SQL and SSMS.
 * Ability to interpret business concepts in P&C insurance industry to inform data modeling.
 * Proficient in building scalable data pipelines using Azure Data Factory and SQL.
 * Skilled in integrating with diverse data sources and managing ingestion at different grains.
 * Familiar with core Azure services supporting cloud-native data engineering workflows.
 * Able to model and prepare data for downstream BI tools and support dashboard creation.
   
   

Additional Information

This is a remote position. Planned, in-office activities may be required on occasion (typically 2-4x per year).

You must live in the United States and be authorized to work in the United States without requirement of employment sponsorship/visa.","101 applicants","Full-time","Entry level","Information Technology","Insurance","","","","73803510","https://www.linkedin.com/jobs/view/data-engineer-at-mission-us-4324251033?trk=public_jobs_topcard-title","EASY_APPLY",""
"Machine Learning Engineer","Brentwood, TN","1 week ago","2025-11-24","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-bluwave-lp-4338815989?trk=public_jobs_topcard-title","BluWave, LP","https://www.linkedin.com/company/bluwave-lp?trk=public_jobs_topcard-org-name","Build the AI that Powers Private Equity Connections

At BluWave, we run the leading marketplace that connects private equity firms and top business leaders with elite, third-party service providers. Data and AI are the engine behind our success, and we're looking for a Machine Learning Engineer to be at the heart of it.

As our new Machine Learning Engineer, you will architect and evolve the core recommendation systems that drive our business. You'll join a nimble, hands-on technology team where your ideas move quickly from concept to production. The systems you build will directly influence high-stakes investment decisions and make a measurable impact in the real world.

Our Tech Stack

Our current tech stack includes Python, Docker, and Azure, interacting with Snowflake and Milvus. We're always evolving and welcome your expertise with related technologies (e.g., AWS, Java, Pinecone, Databricks).

What You'll Do


 * Own the ML Lifecycle: You will design, build, and operate the end-to-end lifecycle of our recommendation engine, from research and prototyping to deployment, monitoring, and continuous improvement
 * Innovate and Experiment: You'll have the autonomy to explore the frontiers of ML/AI, prototype cutting-edge solutions, and directly influence our technical roadmap
 * Collaborate and Build: Work within a collaborative and experienced technology team, led by a hands-on technical manager, to build elegant, high-impact solutions
   
   

What Success Looks Like


 * 3 Months: You are comfortable with our workflows and can complete well-scoped tasks with minimal guidance
 * 6 Months: You navigate our codebase with confidence, deliver features independently, and are an active voice in technical discussions
 * 1 Year: You are a key driver of innovation, proactively generating new project ideas based on business needs and the latest research
   
   

Qualifications


 * BS/MS in Computer Science, Machine Learning, Physics, or another quantitative field
 * 2-3 years of professional experience building and deploying machine learning models (or equivalent experience through research, internships, or significant personal projects)
 * Proficiency in Python and its core data science libraries (e.g., scikit-learn, pandas, numpy)
 * Experience building and maintaining APIs for data-centric applications (e.g., FastAPI, Flask)
 * A strong foundation in software engineering best practices, including version control (Git), testing, and writing clean, maintainable code
 * Experience with Docker and deploying containerized applications
 * Proficiency with SQL for data querying and analysis
   
   

Preferred Qualifications


 * Prior experience contributing to a production machine learning system
 * Experience with vector databases (e.g., Milvus, Pinecone) and an understanding of modern search and recommendation techniques
 * Experience applying LLMs to solve real-world problems
   
   

Nice to Haves


 * A portfolio of personal or open-source projects that showcases your passion and problem-solving skills
 * Experience using AI-powered coding assistants
   
   

The BluWave Values

We place great importance on adding team members that align with our company values. We live and breathe these every day, and we are looking for someone to join the team who appreciates the importance of company values and culture as much as we do.


 * Team: We’re a “we” not “me” people
 * Value: We bring value with value
 * Grow: We are always growing our business and our selves
 * Win: Winning for our clients
   
   

BluWave is a top tier destination for differentiated individuals to grow their long-term careers. We are building the best intelligent B2B marketplace in the world.

BluWave encourages anyone to apply to join our team. BluWave is an inclusive workplace that considers all applicants regardless of gender, race, ethnicity, sexual orientation or identification, background, disability or status.

Future Opportunities

As BluWave grows, numerous opportunities will present themselves to talented, ambitious, team-oriented individuals who have proven themselves in this role. Please include your resume and a cover letter to let us know why you would be a good fit for this position.

Job Type: Full-time

Powered by JazzHR

OUGEj3goAY","Over 200 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Internet Publishing","","","","15173876","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-bluwave-lp-4338815989?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Data Engineer","Calabasas, CA","3 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/senior-data-engineer-at-amh-4340070750?trk=public_jobs_topcard-title","AMH","https://www.linkedin.com/company/amhliving?trk=public_jobs_topcard-org-name","Since 2012, we've grown to become one of the leading single-family rental companies and homebuilders in the country, recently recognized as a top employer by Fortune and Great Place To Work®.  At AMH, our goal is to simplify the experience of leasing a home through professional management and maintenance support, so our residents can focus on what really matters to them, wherever they are in life. 

The Senior Data Engineer is responsible for designing, building, and managing the data platform and tools to allow for the efficient processing and analysis of large data sets. Develops and maintains scalable data pipelines, ensures data quality, and deploys machine learning models to production. Collaborates with business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision-making across the organization. Builds real-time and batch pipelines to handle large volumes of data efficiently. Collaborates with cross-functional teams and translate business requirements into scalable data solutions.

Responsibilities: 


 * Design, develop, and maintain real-time or batch data pipelines to process and analyze large volumes of data. Designs and develops programs and tools to support ingestion, curation, and provisioning of complex first party and third-party data to achieve analytics, reporting, and data science. Design and develop Advanced Data Products and Intelligent API’s. Monitors the system performance by performing regular tests, troubleshoots, and integrates new features.
 * Lead in analysis of data and the design the data architecture to support BI, AI/ML and data products.
 * Designs and implements data platform architecture to meet organization analytical requirements. Ensures the solution designs address operational requirements such as scalability, maintainability, extensibility, flexibility, and integrity.
 * Provide technical leadership and mentorship to team members. Leads peer development and code reviews with focus on test driven development and Continuous Integration and Continuous Development (CICD).
   
   

Requirements: 


 * Bachelor’s degree in computer science, information systems, data science, management information systems, mathematics, physics, engineering, statistics, economics, and/or a related field required.
 * Master’s degree in computer science, information systems, data science, management information systems, mathematics, physics, engineering, statistics, economics, and/or a related field preferred.
 * Minimum of eight (8) years of experience as a data engineer with full-stack capabilities
 * Minimum of ten (10) years of Experience in programming
 * Minimum of five (5) years in Cloud technologies like Azure, Aws or Google.
 * Strong SQL Knowledge
 * Experience in ML and ML Pipeline a plus
 * Experience in real-time integration, developing intelligent apps and data products.
 * Proficiency in Python and experience with CI/CD practices
 * Strong background in IAAS platforms and infrastructure
 * Hands-on experience with Databricks, Spark, Fabric, or similar technologies
 * Experience in Agile methodologies
 * Hands-on experience in the design and development of data pipelines and data products
 * Experience in developing data ingestion, data processing, and analytical pipelines for big data, NoSQL, and data warehouse solutions.
 * Hands-on experience implementing data migration and data processing using Azure services: ADLS, Azure Data Factory, Event Hub, IoT Hub, Azure Stream Analytics, Azure Analysis Service, HDInsight, Databricks Azure Data Catalog, Cosmo Db, ML Studio, AI/ML, etc.
 * Extensive experience in Big Data technologies such as Apache Spark and streaming technologies such as Kafka, EventHub, etc.
 * Extensive experience in designing data applications in a cloud environment.
 * Intermediate experience in RESTful APIs, messaging systems, and AWS or Microsoft Azure.
 * Extensive experience in Data Architecture and data modeling
 * Expert in data analysis and data quality frameworks.
 * Knowledgeable with BI tools such as Power BI and Tableau.
 * May occasionally work evenings and/or weekends.
   
   

Compensation

The anticipated pay range/scale for this position is $121,116.00 to $151,395.00 Annually. Actual starting base pay within this range will depend on factors including geographic location, education, training, skills, and relevant experience.

Additional Compensation

This position is eligible to receive a discretionary annual bonus.

Perks and Benefits

Employees have the opportunity to participate in medical, dental and vision insurance; flexible spending accounts and/or health savings accounts; dependent savings accounts; 401(k) with company matching contributions; employee stock purchase plan; and a tuition reimbursement program. The Company provides 9 paid holidays per year, and, upon hire, new employees will accrue paid time off (PTO) at a rate of 0.0577 hours of PTO per hour worked, up to a maximum of 120 hours per year.

CA Privacy Notice: To learn more about what information we collect when you apply for a job, and how we use that information, please see our CA Job Applicant Privacy Notice found at https://www.amh.com/ca-privacy-notice.

","192 applicants","Full-time","Mid-Senior level","Information Technology","Real Estate","$121,116.00/yr - $151,395.00/yr","","","2723098","https://www.linkedin.com/jobs/view/senior-data-engineer-at-amh-4340070750?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist","McLean, VA","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/data-scientist-at-tla-llc-4337241682?trk=public_jobs_topcard-title","TLA-LLC","https://www.linkedin.com/company/tla-llc?trk=public_jobs_topcard-org-name","TLA is seeking an experienced and curious Data Scientist to join our team and transform complex data into actionable insights that drive strategic business decisions. The ideal candidate will combine expertise in statistics, programming, and machine learning to solve real-world problems and enable smarter business processes through analytics. You will work cross-functionally to define requirements, build predictive models, and communicate findings to technical and non-technical stakeholders.

Key Responsibilities


 * Data Collection & Preparation: Collect, clean, and preprocess large, complex datasets from various internal and external sources to ensure data integrity and usability
 * Exploratory Data Analysis (EDA): Perform in-depth exploratory data analysis to identify patterns, trends, anomalies, and uncover hidden opportunities
 * Model Development & Implementation: Design, develop, test, and validate statistical and machine learning models (e.g., classification, regression, clustering) to forecast trends, optimize operations, and improve product offerings
 * Data Storytelling & Communication: Translate complex technical findings and data insights into clear, compelling narratives and visualizations (reports, dashboards, presentations) for key decision-makers across the organization
 * Collaboration: Partner with data engineers, software developers, and business stakeholders (marketing, product, operations) to implement data-driven solutions and integrate models into production environments
 * Experimentation: Design and execute A/B testing and other experiments to measure the effectiveness of new initiatives and continuously improve model performance
   
   

Innovation: Stay up-to-date with the latest tools, technologies, and methodologies in the data science field, including AI and large language models (LLMs), to drive innovation

Requirements


 * Education: Bachelor's or Master's degree in a quantitative field such as Statistics, Mathematics, Computer Science, Engineering, or a related discipline
 * Experience: 3+ years of hands-on industry experience in a data science or machine learning role
 * Programming Languages: Strong proficiency in Python or R for data analysis and statistical modeling, and advanced knowledge of SQL for data extraction and manipulation
 * Machine Learning: Practical experience applying a range of machine learning techniques and algorithms (e.g., scikit-learn, TensorFlow, PyTorch)
 * Data Visualization: Experience with data visualization tools (e.g., Tableau, Power BI, Matplotlib, Seaborn) to present data insights effectively
 * Analytical Skills: Strong analytical and problem-solving abilities, with an emphasis on critical thinking and the scientific method
 * Communication: Excellent verbal and written communication skills with the ability to explain complex data science concepts to non-technical audiences
   
   

Preferred Certifications


 * Microsoft Certified: Azure Data Scientist Associate
 * IBM Data Science Professional Certificate
 * Certified Analytics Professional (CAP)
 * AWS Certified Machine Learning - Specialty
   
   

TensorFlow Developer Certificate

Benefits

At TLA, we build solutions that matter—supporting national security missions through technology innovation, collaboration, and excellence. Our team is passionate about leveraging modern technologies to deliver impactful, mission-focused outcomes for our customers.

We offer a competitive and comprehensive benefits package including:


 * Competitive salary and performance bonuses
 * Medical, dental, and vision coverage
 * Paid time off and federal holidays
 * 401(k) with company match
 * Education and certification reimbursement
 * Training and professional development opportunities
 * Employee referral bonuses and team events
   
   

TLA is proud to be an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.","Be among the first 25 applicants","Full-time","Entry level","Other","IT Services and IT Consulting","","","","93641815","https://www.linkedin.com/jobs/view/data-scientist-at-tla-llc-4337241682?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI Engineer","Hartford, CT","21 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/ai-engineer-at-massmutual-4340373548?trk=public_jobs_topcard-title","MassMutual","https://www.linkedin.com/company/massmutual-financial-group?trk=public_jobs_topcard-org-name","Overall Responsibilities


 * Architect and lead end-to-end ML/AI solutionssupporting life insurance underwritingusing LLMs, deep learning, and probabilistic modeling—from ideation to production.
 * Deploy scalable GenAI and Agentic AI systems that directly support business goals.
 * Establish and promote best practices in AI development and responsible AI deployment.
 * Drive innovation by identifyingemerging technologies and translating research into practical applications.
 * Collaborate with engineering teams to build robust, production-grade AI pipelines and APIs.
 * Prototype and deliver AI-powered applications (e.g., web apps, dashboards, visualizations) that enable data-driven decisions.
 * Influence senior leadership by aligning AI initiatives with enterprise strategy and communicating insights effectively.
 * Mentor and develop junior talent, fostering a culture of technical excellence and continuous learning.
   
   

Candidate Requirements


 * Recognized industry expertise in AI/ML, with a track record of delivering impactful solutions.
 * 7+ years of experience in data science, machine learning, or AI engineering roles.
 * Deep understanding of machine learning, statistics, NLP, optimization, and LLMs.
 * Hands-on experience with AI deployment and orchestration frameworks and protocols (e.g., MLflow, llama-index, MCP).
 * Extensive experience testing LLM behavior across a variety of foundation models and benchmarks.
 * Experience building AI-powered applications and collaborating with software engineers and product managers.
 * Strong programming skills in Python. Proficiency in R is a plus.
 * Proficiency in SQL and database design; familiarity with cloud-native data platforms, vector databases, and semantic search is a plus.
 * Exceptional communication skills, with the ability to explain complex concepts to non-technical stakeholders.
   
   

Education

M.S. or Ph.D. in Computer Science, Statistics, Applied Mathematics, Electrical Engineering, Physics, or a related quantitative field.

MassMutual is an equal employment opportunity employer. We welcome all persons to apply.

If you need an accommodation to complete the application process, please contact us and share the specifics of the assistance you need.

California residents: For detailed information about your rights under the California Consumer Privacy Act (CCPA), please visit our California Consumer Privacy Act Disclosures page.","96 applicants","Full-time","Entry level","Engineering and Information Technology","Financial Services","","","","3631","https://massmutual.easyapply-ats.com/us/linkedin/692d0d2bebc5da86b53da722?sa_f=692e2c0068f043330648584a","EXTERNAL",""
"Data Engineer","Chicago, IL","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/data-engineer-at-fintal-partners-4324892702?trk=public_jobs_topcard-title","Fintal Partners","https://www.linkedin.com/company/fintalpartners?trk=public_jobs_topcard-org-name","A leading global trading organization is looking to bring on a Senior Data Engineering Specialist to help strengthen the backbone of its real-time and large-scale data ecosystem. This group sits at the intersection of engineering, quantitative research, and high-performance trading — meaning the work you do will directly support complex strategies operating across global markets.




If you enjoy working on massive datasets, architecting resilient systems, and partnering with developers and quants to solve meaningful problems, this is a place where your ideas truly shape the next generation of trading technology.




What You’ll Work On

 * Architect large-scale data environments, including modern streaming and storage ecosystems built on technologies like Kafka, Hadoop, and Dremio.
 * Develop and optimize advanced data pipelines using Java, Python, Spark, and Flink, designed for both high throughput and low latency.
 * Enhance data modeling and ingestion layers, ensuring smooth integration across research, engineering, and trading teams.
 * Drive reliability and availability of mission-critical datasets used across the firm’s analytics and trading functions.
 * Deploy, scale, and manage containerized workloads using Kubernetes and Docker across distributed environments.
 * Monitor and tune system performance using tools such as Prometheus, Grafana, Alert Manager, and related observability platforms.
 * Troubleshoot complex production issues, applying strong statistical reasoning, root-cause analysis, and systems-level thinking.
 * Automate repetitive workflows with Unix scripting (bash, Python) to improve efficiency across teams.
 * Serve as a key technical advisor, helping stakeholders understand best practices in data engineering, architecture, and scaling.




What You Bring

 * Several years of hands-on experience in a mature data engineering environment supporting demanding workloads.
 * Deep familiarity with distributed streaming systems and experience building or maintaining real-time applications.
 * Strong foundation working with modern big-data storage layers and distributed computation frameworks.
 * Proficiency in Java, Python, and SQL for building and optimizing data workflows.
 * Experience working with containerized deployments and orchestrators in production environments.
 * Comfort with monitoring, alerting, and observability tooling for mission-critical systems.
 * A problem-solver’s mindset: the ability to diagnose issues, trace root causes, and design durable fixes.
 * Solid experience with scripting and Linux-based environments.

","Over 200 applicants","Full-time","Mid-Senior level","Engineering","Capital Markets","$175,000.00/yr - $225,000.00/yr","","","105475451","https://www.linkedin.com/jobs/view/data-engineer-at-fintal-partners-4324892702?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)"
"Senior Data Engineer","Thousand Oaks, CA","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/senior-data-engineer-at-takeda-4341403357?trk=public_jobs_topcard-title","Takeda","https://jp.linkedin.com/company/takeda-pharmaceuticals?trk=public_jobs_topcard-org-name","By clicking the “Apply” button, I understand that my employment application process with Takeda will commence and that the information I provide in my application will be processed in line with Takeda’s Privacy Notice and Terms of Use. I further attest that all information I submit in my employment application is true to the best of my knowledge.

Job Description:

About the role:

As the Senior Data Engineer, you will design and operate enterprise‑grade data pipelines that power analytics and AI for manufacturing and quality. Based at our Biologics site in Thousand Oaks (TO), CA, this role reports to the TO Head of Data Digital & Technology (DD&T) and partners with site teams and global DD&T colleagues. You’ll lead cross‑functional initiatives to standardize data ingestion and modeling, ensure data quality and governance, and deploy secure, scalable solutions—while mentoring engineers and driving globally aligned practices.

How you will contribute:


 * Design and optimize data pipelines: (ETL/ELT, batch/stream) using DD&T platforms like Databricks and Dataiku, ensuring strong observability and reliability.
 * Develop reusable ingestion and transformation patterns: to standardize processes and minimize redundant work across sites.
 * Create and maintain modular data models: (e.g., lakehouse/medallion) and semantic layers aligned with global architecture standards.
 * Ensure data quality and compliance: by implementing validation controls, governance frameworks, and audit-ready practices for regulated environments.
 * Deploy and operate data services in cloud environments: (AWS/Azure) using CI/CD, IaC, and DataOps best practices for performance and scalability.
 * Collaborate with stakeholders:—including product owners, data scientists, and global teams—to translate requirements into robust engineering solutions.
 * Document and share technical designs and best practices:, contributing to engineering standards and promoting reusability across programs.
 * Provide technical leadership and mentorship:, guiding engineers, reviewing designs/code, and influencing global best practices.
   
   

Minimum Requirements/Qualifications:


 * Education: Bachelor’s or Master’s degree in Computer Science, Statistics, Mathematics, or related field, or equivalent experience in data engineering/digital product development.
 * Technical Skills:
    * In depth programming in Python, Java, or Scala.
    * Experience with data modeling, big data technologies (e.g., Hadoop, Spark), and database systems (SQL/NoSQL).
    * Familiarity with data warehousing and cloud platforms (AWS/Azure).

 * Certifications: AWS Data Engineering or Cloud certification (preferred AWS Certified Data Engineer / Architect Associate; Databricks Certified Data Engineer Professional).
 * Tools & Frameworks: Hands-on experience with Dataiku and/or Databricks; knowledge of CI/CD and Agile/SAFe practices.
 * Other: Strong analytical/problem-solving skills, proficiency in data visualization, and ability to work in multi-stakeholder, agile environments with a collaborative, professional attitude.
   

More about us:

At Takeda, we are transforming patient care through the development of novel specialty pharmaceuticals and best in class patient support programs. Takeda is a patient-focused company that will inspire and empower you to grow through life-changing work.

Certified as a Global Top Employer, Takeda offers stimulating careers, encourages innovation, and strives for excellence in everything we do. We foster an inclusive, collaborative workplace, in which our teams are united by an unwavering commitment to deliver Better Health and a Brighter Future to people around the world.

Takeda Compensation and Benefits Summary:

We understand compensation is an important factor as you consider the next step in your career. We are committed to equitable pay for all employees, and we strive to be more transparent with our pay practices.

For Location:

USA - CA - Thousand Oaks - Rancho Conejo

U.S. Base Salary Range :

$111,800.00 - $175,670.00

The estimated salary range reflects an anticipated range for this position. The actual base salary offered may depend on a variety of factors, including the qualifications of the individual applicant for the position, years of relevant experience, specific and unique skills, level of education attained, certifications or other professional licenses held, and the location in which the applicant lives and/or from which they will be performing the job. The actual base salary offered will be in accordance with state or local minimum wage requirements for the job location.

U.S. based employees may be eligible for short-term and/ or long-term incentives. U.S. based employees may be eligible to participate in medical, dental, vision insurance, a 401(k) plan and company match, short-term and long-term disability coverage, basic life insurance, a tuition reimbursement program, paid volunteer time off, company holidays, and well-being benefits, among others. U.S. based employees are also eligible to receive, per calendar year, up to 80 hours of sick time, and new hires are eligible to accrue up to 120 hours of paid vacation.

EEO Statement:

Takeda is proud in its commitment to creating a diverse workforce and providing equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, gender expression, parental status, national origin, age, disability, citizenship status, genetic information or characteristics, marital status, status as a Vietnam era veteran, special disabled veteran, or other protected veteran in accordance with applicable federal, state and local laws, and any other characteristic protected by law.

Locations:

USA - CA - Thousand Oaks - Rancho Conejo

Worker Type:

Employee

Worker Sub-Type:

Regular

Time Type:

Full time

Job Exempt:

Yes","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Pharmaceutical Manufacturing","$111,800.00/yr - $175,670.00/yr","","","5482","https://ad.doubleclick.net/ddm/clk/477638375;283784093;d?https://www.takedajobs.com/job/-/-/1113/88594402880?source=tmp_takeda_linkedin_jobads&utm_source=linkedin.com&utm_medium=job_posting&utm_campaign=Enterprise&utm_content=social_media&utm_term=283784093&ss=paid","EXTERNAL",""
"Data Engineering Manager","Los Angeles, CA","4 days ago","2025-11-27","https://www.linkedin.com/jobs/view/data-engineering-manager-at-eleven-recruiting-4320816487?trk=public_jobs_topcard-title","Eleven Recruiting","https://www.linkedin.com/company/11recruiting?trk=public_jobs_topcard-org-name","About Eleven Recruiting

We are a specialized technology staffing agency supporting professional and financial services companies. Why do we stand out in technology staffing? We listen and act as advisors for our candidates on how they can best add value, find interesting projects, and pave a path for career advancement. We advocate for best pay, diversity in tech, and best job-fit for every candidate we place.




Our client, an investment firm, is seeking an experienced Data Engineering Manager to join their team in Los Angeles, CA!




Responsibilities

 * Lead and mentor a team of data engineers and integration specialists.
 * Define and implement best practices for data integration, ETL/ELT processes, and data governance.
 * Collaborate with business stakeholders to understand integration requirements and translate them into technical solutions.
 * Oversee the development and optimization of data pipelines using Python, Snowflake, and Azure services.
 * Integrate AI and machine learning models into data workflows for predictive analytics and automation.
 * Implement document processing solutions for extracting and structuring data from unstructured sources.
 * Ensure data quality, security, and compliance across all integration processes.
 * Utilize GitHub and Azure DevOps for source control, code reviews, and deployment automation.
 * Stay current with emerging technologies and recommend improvements to existing architecture.




Required Qualifications

 * Bachelor’s degree in Computer Science, Information Systems, or related field (Master’s preferred).
 * 7+ years of experience in data engineering or integration roles, with at least 2 years in a leadership capacity.
 * Strong proficiency in Python, SQL, and scripting languages (e.g., PowerShell, Bash).
 * Hands-on experience with Snowflake, Azure functionality, and cloud-based data solutions.
 * Familiarity with GitHub and Azure DevOps for CI/CD and version control.
 * Experience implementing AI/ML models using frameworks such as TensorFlow, PyTorch, or scikit-learn.
 * Experience with document processing frameworks (e.g., OCR, NLP).
 * Bonus Skills: Experience with Fivetran, SQL Server, SSIS, Astronomer, Airflow, and Tableau.
 * Excellent communication and leadership skills.




Preferred Qualifications

 * Previous work experience in a financial institution environment.
 * Possess strong analytical skills and ability to solve practical problems and deal with a variety of concrete variables in situations where only limited standardization may exist.
 * Ability to interpret a variety of instructions furnished in written, oral, diagram, or schedule form.




Salary: $160,000 - $185,000","84 applicants","Full-time","Mid-Senior level","Engineering, Management, and Information Technology","Investment Management","$160,000.00/yr - $185,000.00/yr","","","18617400","https://www.linkedin.com/jobs/view/data-engineering-manager-at-eleven-recruiting-4320816487?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Dental insurance
401(k)
Vision insurance"
"Senior Data Engineer/ Data Engineering Architect","San Jose, CA","1 day ago","2025-11-30","https://www.linkedin.com/jobs/view/senior-data-engineer-data-engineering-architect-at-petlibro-4347859763?trk=public_jobs_topcard-title","Petlibro","https://www.linkedin.com/company/petlibro?trk=public_jobs_topcard-org-name","Benefits:


 * 401(k)
 * 401(k) matching
 * Dental insurance
 * Health insurance
 * Paid time off
 * Vision insurance
 * Wellness resources
   
   
   

Responsibilities


 * Design robust and scalable data system architecture to collect, process, and store large volumes of data from IoT devices.
 * Design and build data systems that support real-time, customer facing data applications, ensuring data integrity and efficient retrieval processes.
 * Design and build a data validation framework to guarantee the accuracy and consistency of data across all stages of the pipeline, ensuring reliable insights and decision-making.
 * Implement data architectures to continuously improve AI models through automated feedback loops and data collection processes.
 * Optimize data processing workflows for AIoT tasks.
 * Collaborate with product owners to translate data requirements into actionable data engineering solutions.
 * Collaborate with other engineers, product owners to solve challenging problems.
 * Evangelize software engineering best practices and lead by example.
   
   
   

Qualifications


 * Bachelor's degree in Computer Science, Data Science, Engineering, or a related field.
 * 5+ years of proven experience in data engineering, with a strong focus on data warehousing and data system architecture.
 * Expertise in design and build IoT data systems.
 * Expertise in architecting that power high-volume consumer application.
 * Expertise in big data and streaming technologies (Python, Java, Kafka, Spark,Spark Streaming).
 * Expertise in moderen database technology (MongoDB, ElasticSearch, StarRocks, S3, Snowflake, Bigquery etc).
 * Experience with data annotation tools and processes for machine learning datasets.
 * Familiarity with MLOps practices and tools for managing AI model lifecycles.
 * Knowledge about deploying systems into a production Cloud Native Environment (AWS or similar).
 * Experience in Java Spring Framework is a plus
 * Experience with video data handling and image processing is a plus","62 applicants","Full-time","Mid-Senior level","Information Technology","Technology, Information and Internet","","","","54363614","https://designlibro-inc.careerplug.com/j/02tkq11","EXTERNAL",""
"Data Engineer","Columbus, OH","2 weeks ago","2025-11-13","https://www.linkedin.com/jobs/view/data-engineer-at-battelle-4336004021?trk=public_jobs_topcard-title","Battelle","https://www.linkedin.com/company/battelle?trk=public_jobs_topcard-org-name","Battelle delivers when others can’t. We conduct research and development, manage national laboratories, design and manufacture products and deliver critical services for our clients—whether they are a multi-national corporation, a small start-up or a government agency.

We recognize and appreciate the value and contributions of individuals from a wide range of backgrounds and experiences and welcome all qualified individuals to apply.

Job Summary

As a Data Engineer within Battelle’s Cyber business area, you will support a program mission to deliver comprehensive technical expertise and testing support to our government customer, contributing to the evaluation, customization, and operationalization of cutting-edge systems and payloads ensuring they meet the customer’s evolving requirements for effectiveness, safety, and security.

Responsibilities


 * Design and implement data acquisition systems for test environments, enabling real-time collection, processing, and analysis of technical and operational data from flight tests, component assessments, and system integration activities.
 * Develop and maintain robust data pipelines that support the ingestion, transformation, and storage of test data from diverse instrumentation sources, ensuring high data integrity and traceability throughout the test lifecycle.
 * Collaborate with systems engineers and test specialists to define data requirements, integrate instrumentation outputs, and optimize data flows for real-time monitoring and post-test analysis.
 * Implement real-time data processing solutions to support rapid assessment of system performance, technical maturity, and operational readiness during test events.
 * Develop and deploy data visualization tools and dashboards that provide stakeholders with actionable insights from test data, including key findings, trends, and risk factors relevant to system selection and integration.
 * Ensure secure management and compliance of test data, including configuration management, audit readiness, and integration with digital engineering environments (e.g., MBSE repositories, digital twin libraries).
 * Support the creation of technical analysis reports and comparative matrices by integrating real-time and post-test data from instrumentation, modeling, and simulation outputs.
 * Contribute to supply chain risk analysis by managing and analyzing hardware/software bill of materials (BOM) data, supporting vulnerability assessments, and maintaining requirements traceability within digital engineering workflows.
 * Prepare and deliver comprehensive data packages, analysis summaries, and supporting documentation for technical reviews, risk assessments, and operational recommendations.
   
   

Key Qualifications


 * Bachelor’s degree in a related field with 5+ years of experience, or an equivalent combination of education and experience.
 * Strong background in modeling and simulation of complex systems.
 * Proven ability to lead technical discussions and communicate complex concepts to both technical and non-technical stakeholders.
 * Strong problem-solving, analytical, and teamwork skills.
   
   

Nice to Have


 * Experience with model-based systems engineering (MBSE) methodologies.
 * Familiarity with SysML diagramming tools (e.g., Cameo Systems Modeler, IBM Rhapsody).
 * Experience with DoD Architecture Framework (DoDAF) and/or Unified Architectural Framework (UAF).
 * Experience with embedded systems, microelectronics, FPGA, or circuit card design.
 * Programming experience in MATLAB, Python, C++, or other object-oriented languages.
 * Experience supporting DoD programs.
 * Active Top-Secret Clearance.
   
   

Benefits: Live an Extraordinary Life

We care about your well-being, not just on the job. Battelle offers comprehensive and competitive benefits to help you live your best life.


 * Balance life through a compressed work schedule: Most of our team follows a flexible, compressed work schedule that allows for every other Friday off—giving you a dedicated day to accomplish things in your personal life without using vacation time.
 * Enjoy enhanced work flexibility, including a hybrid arrangement: You have options for where and when you work. Our Together with Flexibility model allows you to work 60% in-office and 40% remote, with Monday and Tuesday as common in-office days, dependent on team and position needs.
 * Take time to recharge: You get paid time off to support work-life balance and keep motivated.
 * Prioritize wellness: Stay healthy with medical, dental, and vision coverage with wellness incentives and benefits plus a variety of optional supplemental benefits.
 * Better together: Coverage for partners, gender-affirming care and health support, and family formation support.
 * Build your financial future: Build financial stability with an industry-leading 401(k) retirement savings plan. For most employees, we put in 5 percent whether you contribute or not, and match your contributions on top of that.
 * Advance your education: Tuition assistance is available to pursue higher education.
   
   

A Work Environment Where You Succeed

For brilliant minds in science, technology, engineering and business operations, Battelle is the place to do the greatest good by solving humanity’s most pressing challenges and creating a safer, healthier and more secure world.

You will have the opportunity to thrive in a culture that inspires you to:


 * Apply your talent to challenging and meaningful projects
 * Receive select funding to pursue ideas in scientific and technological discovery
 * Partner with world-class experts in a collaborative environment
 * Nurture and develop the next generation of scientific leaders
 * Give back to and improve our communities
   
   

Vaccinations & Safety Protocols

Battelle may require employees, based on job duties, work location, and/or its clients’ requirements to follow certain safety protocols and to be vaccinated against a variety of viruses, bacteria, and diseases as a condition of employment and continued employment and to provide documentation that they are fully vaccinated. If applicable, Battelle will provide reasonable accommodations based on a qualified disability or medical condition through the Americans with Disabilities Act or the Rehabilitation Act or for a sincerely held religious belief under Title VII of the Civil Rights Act of 1964 (and related state laws).

Battelle is an equal opportunity employer. We provide employment and opportunities for advancement, compensation, training, and growth according to individual merit, without regard to race, color, religion, sex (including pregnancy), national origin, sexual orientation, gender identity or expression, marital status, age, genetic information, disability, veteran-status veteran or military status, or any other characteristic protected under applicable Federal, state, or local law. Our goal is for each staff member to have the opportunity to grow to the limits of their abilities and to achieve personal and organizational objectives. We will support positive programs for equal treatment of all staff and full utilization of all qualified employees at all levels within Battelle.

The above statements are intended to describe the nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, activities and skills required of staff members. No statement herein is intended to imply any authorities to commit Battelle unless special written permission is granted by Battelle's Legal Department.

For more information about our other openings, please visit www.battelle.org/careers","Over 200 applicants","Full-time","Entry level","Information Technology","Aviation and Aerospace Component Manufacturing, Defense and Space Manufacturing, and Biotechnology Research","","","","162650","https://jobs.battelle.org/us/en/job/BMIBMIUS75881EXTERNALENUS/Data-Engineer?utm_source=LinkedIn&utm_medium=phenom-feeds","EXTERNAL",""
"AI Software Engineer","Palo Alto, CA","4 days ago","2025-11-28","https://www.linkedin.com/jobs/view/ai-software-engineer-at-gallatin-ai-inc-4339329473?trk=public_jobs_topcard-title","Gallatin AI, Inc.","https://www.linkedin.com/company/gallatinai?trk=public_jobs_topcard-org-name","About Gallatin

At Gallatin, we are rebuilding defense logistics for the warfighters of the United States and allied forces. We take an AI-first approach to improve defense readiness through software products that streamline and modernize logistics operations from factory to foxhole and result in better decisions and outcomes.

We believe that you won’t change the world by phoning it in and as such we work from our office in El Segundo, California.

About The Role

We’re looking for an AI/ML Software Engineer to play a foundational role in developing and deploying AI-powered solutions for our core product. You’ll work across the full AI/ML lifecycle—from defining and building models to evaluating and deploying large scale ML pipelines and real-time inference systems—while collaborating with cross-functional teams to deliver impactful, real-world AI applications.

What You'll Do


 * Build and Deploy AI/ML Models
    * Own and develop an AI model aligned with our core product needs within the first three months.
    * Validate AI-driven product features through real-world testing and feedback from warfighters.
    * Establish scalable MLOps pipelines and real-time inference services to streamline model training, deployment, runtime, and monitoring.
    * Own high model reliability and uptime by implementing monitoring across your work.

 * Data Collection & Processing
    * Identify and integrate structured, unstructured, real-time, and batch data sources.
    * Work with internal logs, APIs, user interactions, and third-party datasets to improve model training quality.

 * Continuous Improvement & Best Practices
    * Stay ahead of AI trends and emerging technologies to improve model performance.
    * Document and share best practices for AI/ML development.
    * Contribute to the hiring and mentoring of AI/ML talent as we grow our team.
    * Teach the wider team about the latest trends and significance in novel approaches in AI.
      

What We’re Looking For


 * Strong Programming Skills
    * Expertise in at least one: Python, C++, or C.

 * ML Framework Proficiency
    * Hands-on experience with AI/ML training and fine-tuning frameworks, including:
       * PyTorch, TensorFlow, CUDA, Jupyter Notebooks
       * Large Language Models (LLMs) and Open-Source Models (Llama, Anthropic, Mistral)
       * LangChain, Retrieval-Augmented Generation (RAG), Hugging Face, Exo Labs

 * MLOps & Data Engineering Knowledge
    * Experience with data processing and pipeline frameworks such as Apache Kafka, Apache Airflow, AWS Kinesis, pandas, and dbt.
    * Understanding of AI model performance monitoring, data drift detection, and observability tools like Grafana or Kibana.

 * AI Fundamentals & Security Awareness
    * Deep understanding of deep neural networks (DNNs), LLMs, over/underfitting, prompt engineering, and LLM security (jailbreaking risks and protections).

 * Growth Mindset
    * Passion for continuous learning and staying current with the latest advancements in AI/ML, as well as teaching others
      

Bonus Points


 * Experience mentoring and upskilling junior engineers.
 * Familiarity with legacy systems and working with public sector customers.
 * Contributions to open-source (AI/ML) projects.
   
   

Why Gallatin?


 * Join a mission-driven, high-impact, and fast-moving startup where your work directly improves defense logistics readiness for the warfighters of the United States and allied forces.
 * Work alongside a team of passionate engineers, designers, and industry experts.
 * Competitive compensation incl. generous options grant, 100% employer-paid health insurance premiums, 401k, opportunities for rapid career growth, unlimited PTO, free lunches and snacks in the office.
   
   

This position requires the ability to obtain and maintain relevant security clearances. The successful candidate must be able to work in a classified environment when necessary.

If you’re not excited about working hard, and solving the hard problems of building AI decisions-support systems that enhance our warfighters, don’t apply.

The following ranges are based on the cost of labor across US geographic areas. The base ranges from our lowest geographic market to our highest geographic market.

Software Engineer I $80,000-$120,000

Software Engineer II $84,000-$175,000

SR Software Engineer $134,000-$210,000

","123 applicants","Full-time","Entry level","Engineering and Information Technology","Information Services","","","","106410794","https://www.linkedin.com/jobs/view/ai-software-engineer-at-gallatin-ai-inc-4339329473?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Alpharetta, GA","3 weeks ago","2025-11-05","https://www.linkedin.com/jobs/view/data-engineer-at-global-payments-inc-4334440708?trk=public_jobs_topcard-title","Global Payments Inc.","https://www.linkedin.com/company/global-payments?trk=public_jobs_topcard-org-name","Description

About Us:

Global Payments Inc is a globally leading fintech company with an emphasis on merchant based services such as payment processing, merchant hardware and SaaS based software solutions to assist with running and growing businesses. The Customer Engagement business unit in Merchant Technology especially focuses on such SaaS based software meant to run and grow merchants’ businesses. We empower businesses to deepen customer relationships through cutting-edge technology and data-driven insights. As we continue to innovate and grow, we are seeking a highly skilled Data & BI Engineer to take a leading role in advancing our data infrastructure and analytics capabilities.

Job Description:

As a Data & BI Engineer at Global Payments, you will be pivotal in shaping the data architecture and analytics strategies that drive critical business decisions. You will lead the development and maintenance of scalable, efficient data pipelines and ensure the accuracy, accessibility, and security of our data. Your collaborative efforts with cross-functional teams and mentorship of junior team members will be key to fostering a data-driven culture.

Key Responsibilities:


 * Lead the design, implementation, and optimization of efficient, secure, and scalable data pipelines.
 * Develop and refine complex SQL queries for data analysis, ensuring performance optimization.
 * Integrate BigQuery for handling large-scale data analytics and cloud services.
 * Utilize Python and other programming languages to automate data processes and ensure seamless data manipulation.
 * Partner with business stakeholders to understand data needs, providing strategic insights and data-driven solutions.
 * Develop, optimize, and maintain Looker dashboards to provide clear, actionable business insights.
 * Implement data governance standards to ensure data accuracy, security, and compliance with industry regulations.
 * Exploration and integration of AI into data solutions, pipelines, etc. (Example: Looker data agents)
 * Mentor and guide junior data engineers and analysts, fostering a collaborative and innovative team environment.
   
   

Requirements:


 * Bachelor’s or Master’s degree in Computer Science, Engineering, or a related field.
 * 2-4 years of experience in data engineering or a related role, with a proven track record of success in managing complex data environments.
 * Experience with the following:
    * Strong proficiency in SQL, including advanced query optimization techniques.
    * Experience with Python for data manipulation and automation tasks.
    * Experience with Java, C#, Scala, or other statically-typed programming languages in a work setting
    * NoSQL (Mongo or similar)

 * Expertise in cloud-based data platforms, especially Google BigQuery.
 * Experience with Apache Spark, Apache Flink, Apache Kafka, Apache Airflow or other similar Big Data technologies.
 * Proficient with Looker or similar BI tools for building and optimizing dashboards.
 * Strong understanding of data governance, security, and compliance best practices.
 * Demonstrated ability to collaborate with leadership to drive data strategies.
 * Excellent communication skills with the ability to convey technical concepts to non-technical stakeholders.
   
   

Preferred Skills:


 * Proven experience in a SaaS environment managing large-scale data sets.
 * Expertise in data modeling and ETL processes.
 * Experience in architecting and managing data warehouses.
 * Familiarity with additional programming languages or advanced analytics tools (e.g., R, Spark, etc.) is a plus.
 * Proficiency in Data Science disciplines and hands-on experience with LLM Engines implementation within different processes and services, Agents in pipelines and BI.
 * Previous mentorship experience within data engineering teams.","Over 200 applicants","Full-time","Entry level","Information Technology","Financial Services and IT Services and IT Consulting","","","","164006","https://www.linkedin.com/jobs/view/data-engineer-at-global-payments-inc-4334440708?trk=public_jobs_topcard-title","EASY_APPLY",""
"Business Intelligence Specialist","Denver, CO","2 weeks ago","2025-11-15","https://www.linkedin.com/jobs/view/business-intelligence-specialist-at-einstein-bros-bagels-4336155200?trk=public_jobs_topcard-title","Einstein Bros Bagels","https://www.linkedin.com/company/einstein-bros-bagels?trk=public_jobs_topcard-org-name","Brand:

Bagel Brands

Bagel Brands is the parent company for your favorite breakfast brands, Einstein Bros. Bagels, Bruegger's Bagels, Noah's NY Bagels, and Manhattan Bagel. We believe in the bagel and how it has the unique ability to bring people together. Our team has a standard set of values and behaviors that allow us to spread a little more joy and happiness in the world. They let us laugh, smile, and enjoy each other’s company a little more. These are the behaviors that guide how we work, how we treat each other, and how we treat our guests. We believe that there is no better way to make someone’s day than with a warm, fresh-baked bagel and a heart-felt good morning.

We are seeking a highly skilled Business Intelligence (BI) Specialist with deep expertise in Power BI and data visualization to transform complex data into compelling, actionable insights. This position will provide analytic support across the organization with exceptional focus on Marketing and Financial KPIs. The ideal candidate has a strong analytical mindset, technical proficiency in BI tools, and a creative eye for designing intuitive, high-impact dashboards that drive business decisions.

As part of the Finance & Analytics team, the BI Specialist will collaborate with departments across the organization to design and develop impactful reporting solutions and visualizations that inform performance management, strategic decisions, and planning.

Please Note: The range provided below encompasses a wide range of Bagel Brands roles. The specific salary range for this role is


 * Department: Finance
 * Base Salary Range: $100,000–$120,000 annually
 * Bonus: 10% annual incentive target
   
   

Role-specific Abilities

Provide Insights


 * Design, build, document, and maintain accurate, consistent and interactive Power BI dashboards and reports from various data sources.
 * Perform data analysis, including data profiling into data warehouses, to obtain a good understanding of data availability, relationships, and nuances for consideration of reporting design.
 * Collaborate with stakeholders across departments (Finance, Marketing, Operations, HR etc.) to translate business questions into analytical solutions.
 * Collaborate effectively with internal end-users, cross-functional software development teams, Data Engineering teams etc. to solve problems and implement new solutions.
 * Administer/Support Bagel Brands’ reporting environment and published report processes.
 * Triage, troubleshoot and resolve report issues from end users as well as support data integrity tickets with urgency.
 * Educate and support business users on the use of Power BI reporting assets
 * Ensure data integrity and accuracy through checking values, metrics, and calculations displayed in Power BI reports.
 * Develop functional specifications and reporting design specifications for assigned projects.
 * Identify data needs and driving data quality improvement projects while staying current on PowerBI and BI Industry trends to continuously improve analytics capabilities.
 * Develop training materials and train end users on available reporting and usage.
 * Produce regular and ad-hoc analyses, reports and presentations.
   
   

Cultural Fit:

Personal fit with the Company’s culture—where in a support center role, we operate in a way that gives our Field Leadership world class support so they can deliver an incredible and consistent guest experience. This comes through in our Company Values:


 * Obsess over our guests
 * Supporting one another
 * Taking Ownership
 * Have Fun
   
   

End-to-End Planning:

Talent for functioning strategically and tactically in day-to-day needs; executing in the details and thinking about the bigger picture; thinks end-to-end and articulates a process that motivates those around him or her to participate

Ability to critically review and improve business processes

Critical Thinking, Analysis & Planning:


 * Strong analytical thinking for translating and comprehending data from a variety of data sources
 * Able to integrate internal and external data/factors in analyses, bringing forth relevant assumptions and trends for consideration
 * Shown ability to simplify the agenda and create clarity from many inputs.
   
   

Education – Training – Experience

Required:


 * Bachelor’s degree in a related field (e.g., Computer Science, Analytics, Data Science, Finance)
 * Expert-level proficiency in Power BI
 * Three or more years of relevant work experience.
 * Familiarity with UI/UX principles for dashboard design.
 * Experience with DAX development and dynamic measure creation.
 * Experience working with databases (dimensional and relational) and in visualizing large and complex datasets in a commercial/business environment.
 * Experience with data modeling, analytics, and presentation creation
 * Self-starter with high level of intellectual and analytical curiosity having and problem-solving mindset
 * Excellent project execution capabilities; strong attention to detail; able to define timelines and ensure projects stay on-track
   
   

Highly Desired:

Experience in Retail analytics with preferred experience in QSR or Fast-Casual analytics having a deep understand of POS data

Experience working with large volumes of data, combining and reconciling data from different sources, and knowledge of ETL process


 * Ranges reflect what employer reasonably and in good faith expects to pay for such position.
   
   

Address: | 1720 S Bellaire St. Skybox , Denver, Colorado 80222 |

The physical demands for this position are sits, stands, bends, lifts, and moves intermittently during working hours. These physical requirements may be accomplished with or without reasonable accommodations.

The duties of this position may change from time to time. Bagel Brands reserves the right to add or delete duties and responsibilities at the discretion of the company or its managers. This job description is intended to describe the general level of work being performed. It is not intended to be all-inclusive.

Bagel Brands is committed to providing equal employment opportunity, and fair treatment in employment without regard to race, ethnicity, color, religion, gender/gender identity or expression, sexual orientation, age, national origin or ancestry, physical or mental disability, military status or any other basis in protected by applicable federal, state and local law. Bagel Brands makes employment decisions based solely on qualifications for the position.","131 applicants","Full-time","Entry level","Business Development and Sales","Restaurants","$100,000.00/yr - $120,000.00/yr","","","8339057","https://www.linkedin.com/jobs/view/business-intelligence-specialist-at-einstein-bros-bagels-4336155200?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI Software Engineer","Austin, TX","4 days ago","2025-11-28","https://www.linkedin.com/jobs/view/ai-software-engineer-at-gallatin-ai-inc-4339279771?trk=public_jobs_topcard-title","Gallatin AI, Inc.","https://www.linkedin.com/company/gallatinai?trk=public_jobs_topcard-org-name","About Gallatin

At Gallatin, we are rebuilding defense logistics for the warfighters of the United States and allied forces. We take an AI-first approach to improve defense readiness through software products that streamline and modernize logistics operations from factory to foxhole and result in better decisions and outcomes.

We believe that you won’t change the world by phoning it in and as such we work from our office in El Segundo, California.

About The Role

We’re looking for an AI/ML Software Engineer to play a foundational role in developing and deploying AI-powered solutions for our core product. You’ll work across the full AI/ML lifecycle—from defining and building models to evaluating and deploying large scale ML pipelines and real-time inference systems—while collaborating with cross-functional teams to deliver impactful, real-world AI applications.

What You'll Do


 * Build and Deploy AI/ML Models
    * Own and develop an AI model aligned with our core product needs within the first three months.
    * Validate AI-driven product features through real-world testing and feedback from warfighters.
    * Establish scalable MLOps pipelines and real-time inference services to streamline model training, deployment, runtime, and monitoring.
    * Own high model reliability and uptime by implementing monitoring across your work.

 * Data Collection & Processing
    * Identify and integrate structured, unstructured, real-time, and batch data sources.
    * Work with internal logs, APIs, user interactions, and third-party datasets to improve model training quality.

 * Continuous Improvement & Best Practices
    * Stay ahead of AI trends and emerging technologies to improve model performance.
    * Document and share best practices for AI/ML development.
    * Contribute to the hiring and mentoring of AI/ML talent as we grow our team.
    * Teach the wider team about the latest trends and significance in novel approaches in AI.
      

What We’re Looking For


 * Strong Programming Skills
    * Expertise in at least one: Python, C++, or C.

 * ML Framework Proficiency
    * Hands-on experience with AI/ML training and fine-tuning frameworks, including:
       * PyTorch, TensorFlow, CUDA, Jupyter Notebooks
       * Large Language Models (LLMs) and Open-Source Models (Llama, Anthropic, Mistral)
       * LangChain, Retrieval-Augmented Generation (RAG), Hugging Face, Exo Labs

 * MLOps & Data Engineering Knowledge
    * Experience with data processing and pipeline frameworks such as Apache Kafka, Apache Airflow, AWS Kinesis, pandas, and dbt.
    * Understanding of AI model performance monitoring, data drift detection, and observability tools like Grafana or Kibana.

 * AI Fundamentals & Security Awareness
    * Deep understanding of deep neural networks (DNNs), LLMs, over/underfitting, prompt engineering, and LLM security (jailbreaking risks and protections).

 * Growth Mindset
    * Passion for continuous learning and staying current with the latest advancements in AI/ML, as well as teaching others
      

Bonus Points


 * Experience mentoring and upskilling junior engineers.
 * Familiarity with legacy systems and working with public sector customers.
 * Contributions to open-source (AI/ML) projects.
   
   

Why Gallatin?


 * Join a mission-driven, high-impact, and fast-moving startup where your work directly improves defense logistics readiness for the warfighters of the United States and allied forces.
 * Work alongside a team of passionate engineers, designers, and industry experts.
 * Competitive compensation incl. generous options grant, 100% employer-paid health insurance premiums, 401k, opportunities for rapid career growth, unlimited PTO, free lunches and snacks in the office.
   
   

This position requires the ability to obtain and maintain relevant security clearances. The successful candidate must be able to work in a classified environment when necessary.

If you’re not excited about working hard, and solving the hard problems of building AI decisions-support systems that enhance our warfighters, don’t apply.

The following ranges are based on the cost of labor across US geographic areas. The base ranges from our lowest geographic market to our highest geographic market.

Software Engineer I $80,000-$120,000

Software Engineer II $84,000-$175,000

SR Software Engineer $134,000-$210,000

","76 applicants","Full-time","Entry level","Engineering and Information Technology","Information Services","","","","106410794","https://www.gallatin.ai/careers?ashby_jid=603f34f0-5c8f-457f-a1ff-5ac96f06918d&utm_source=2VOvQ1B7jl","EXTERNAL",""
"Data Scientist","New York, NY","2 weeks ago","2025-11-14","https://www.linkedin.com/jobs/view/data-scientist-at-sesamm-4336241376?trk=public_jobs_topcard-title","SESAMm","https://fr.linkedin.com/company/sesamm-sas?trk=public_jobs_topcard-org-name","SESAMm

SESAMm (www.sesamm.com) extracts behavioral insights from millions of unstructured text data sources across the public internet in over 100 languages, helping clients distill valuable intelligence on businesses and their customers to make investment decisions and manage risk.

We work with many well-known firms around the world in private equity, investment banking, insurance, and asset management to apply Natural Language Processing and Artificial Intelligence algorithms to track e-reputation, competitive positioning, sentiment analysis, risk and ESG factors.

SESAMm is growing quickly, with over 70 team members around the globe and offices in Paris, New York, London, Metz, Tunis, and Tokyo.

Key technologies: Alternative Data, Natural Language Processing, Machine Learning and Quantitative Analysis.

Are you looking for a new challenge? Do you dream of joining a growing company, proposing new ideas, and taking part in innovative processes?

At SESAMm, everyone brings their ideas, skills, and creativity. We value collaboration, support and teamwork. We learn every day from the experience of this great team and we constantly take up new challenges. We are proud of the work accomplished and to participate in the success of this great adventure!

The Data Scientist Role



SESAMm, in partnership with one of the largest private equity (PE) firms in the United States, is seeking a data scientist to join an exciting AI platform project designed to transform investment analysis. This project is at the cutting edge of private equity, leveraging advanced artificial intelligence (AI) to improve data-driven decision-making. As a data scientist, you will contribute to a groundbreaking platform used by deal teams to accelerate and enhance due diligence.

Key Responsibilities


 * Advanced Data Analysis & Modeling: Conduct in-depth data analysis to support private equity investment decisions. Develop and implement analytical models — including feature engineering, statistical modeling, and machine learning — to extract insights from complex financial and extra-financial datasets. Ensure results are robust, explainable, and aligned with investment objectives. Translate analytical findings into actionable insights for investment and operational teams.
 * Data Engineering & Integration: Design and maintain efficient data pipelines for collecting, cleaning, and integrating large, diverse data sources (financial statements, market data, ESG signals, alternative datasets, etc.). Leverage Python and SQL to optimize processing performance, ensure data quality, and enable scalable analytics across investment workflows.
 * Cross-Functional Collaboration: Work closely with investment, operations, and data science teams to identify high-impact analytical use cases. Communicate complex results clearly to both technical and non-technical stakeholders.
   
   

Desired Background and Skills

Education


 * Master's degree in Data Science, Applied Mathematics, Statistics, or a related quantitative field.
   
   

Experience


 * 3–5 years of hands-on experience in data science or analytics, including internships.
 * Proven experience with feature engineering, statistical modeling, and building or evaluating ML models.
 * Experience working with large, heterogeneous datasets.
 * Prior experience in commercial consulting, investment banking, private equity diligence, or a client-oriented analytical role is a must.
   
   

Skills


 * Strong proficiency in Python (Pandas, NumPy, Scikit-learn) and SQL.
 * Familiarity with cloud data environments (AWS, Azure, or Databricks) is a plus.
 * Ability to synthesize complex data into clear business insights.
 * Strong communication and presentation skills; fluent English required, French is a plus.
   
   

Benefits of Working at SESAMm

Flexibility: Team members can work remotely and have the opportunity to work with colleagues around the world.

Work Environment: SESAMm is multicultural, with technology, sales, and management teams in the US, France, and Tunisia making important contributions to the company's growth.

Career Development: SESAMm is growing rapidly, creating ongoing opportunities for personal and professional growth. This dynamic environment allows you to shape the company's culture and evolution.

Professional Development: Work alongside industry-leading experts and gain valuable exposure to advanced AI and ML technologies applied in private equity. This role offers a unique opportunity to deepen your expertise in these cutting-edge applications.

Mentorship & Training: SESAMm provides structured training and mentorship, with a strong emphasis on knowledge-sharing. Internally and externally led training sessions are organized, and we offer access to educational platforms, encouraging you to expand your AI skill set.

Global Perspective: Collaborate with teams based across Europe and the United States, gaining hands-on international experience in a fast-paced, high-impact environment. This global perspective helps broaden your skill set and provides insights into international market dynamics.

Transparency: You will be kept apprised of the company's continuing evolution and performance through monthly ""Ask Me Anything"" meetings, frequent business/finance updates, and strategy-sharing discussions.

Well-being: Building a good culture is key to building a good business at SESAMm. We focus on being a learning organization that values and supports teamwork, thoughtfulness, and work/life balance.","185 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Financial Services","","","","4827418","https://www.linkedin.com/jobs/view/data-scientist-at-sesamm-4336241376?trk=public_jobs_topcard-title","EASY_APPLY",""
"FBI Special Agent: Data Science & Intelligence Expertise","Edison, NJ","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/fbi-special-agent-data-science-intelligence-expertise-at-federal-bureau-of-investigation-fbi-4337646389?trk=public_jobs_topcard-title","Federal Bureau of Investigation (FBI)","https://www.linkedin.com/company/fbi?trk=public_jobs_topcard-org-name","JOB DESCRIPTION




The position advertised has been exempted from the federal civilian hiring freeze.




As an FBI special agent with data engineering and big data experience, you'll directly impact national security. By harnessing your background to transition into federal law enforcement, you can help shape the Bureau’s approach to safeguarding our nation. At the FBI, you will have the opportunity to channel your data science, cloud infrastructure, or IoT systems expertise to protect our nation from cyberattacks, terrorism, fraud, and evolving threats. From conducting high-stakes investigations with your proficiency in advanced statistical modeling and data governance to leveraging your depth of knowledge in predictive modeling to identify trends and prevent criminal activity, your technical skills are essential to investigating crimes that threaten public safety. Your transition from a specialized career to a special agent role will be transformative as you employ your expertise to tackle national security challenges in innovative ways. Every day brings new challenges that demand your adaptability and resilience, but you’re not alone in this journey. The Bureau matches your dedication with a commitment to professional growth, a supportive work environment, and a robust benefits package that prioritizes you. Set yourself apart. Apply Today.




HOW TO APPLY




STEP 1: Click on the “Apply” button to be directed to the FBIJobs Careers website.




STEP 2: Click the “Start” button to begin. You will be prompted to either sign in to continue or register with FBIJobs if you don’t already have an account.




STEP 3: Follow the step-by-step process to submit your interest. You will be guided through each step. You must complete all sections of the form AND ALL REQUIRED DOCUMENTS MUST BE ATTACHED to successfully submit your interest.




 1. Your resume, specifically noting relevant work experience and associated start and end dates. Please note your resume MUST NOT exceed two (2) pages.
 2. Other supporting documents:

 * College transcripts, if qualifying based on education or if there is a positive education requirement.
 * Veterans: DD 214; Disabled Veterans: DD 214, SF-15, and VA letter dated 1991 or later.




Please see instructions on the site for attaching documents.




SALARY LEVEL




Pay level for this position:

 * $99,461.00–$128,329.00




Salary is commensurate with base, locality, and availability pay.




MAJOR DUTIES

 * Plan and conduct investigations of potential violations of federal laws, cybersecurity, and public safety.
 * Exercise judgment, resourcefulness, and versatility in meeting investigative demands.
 * Create and maintain effective liaison relationships with federal, state, local, tribal, territorial, and international law enforcement agencies.
 * Maintain a level of physical fitness to ensure the readiness required to perform law enforcement duties.




KEY REQUIREMENTS

 * Must be a U.S. citizen.
 * Must be able to obtain a Top Secret Sensitive Compartmented Information (SCI) Clearance.
 * Must be willing to travel as required.
 * Must meet the FBI’s Employment Eligibility requirements.
 * Must have a master's degree or higher from a U.S. accredited college or university.




The FBI is an Equal Opportunity Employer, and all qualified applicants will receive consideration for this vacancy. Unless explicitly authorized by law, selection will be made without regard to, and there will be no discrimination because of, color, race, religion, national origin, marital status, parental status, physical or mental disability, genetic information, age (40 or over), sex, pregnancy and related conditions, or on the basis of personal favoritism, or any other nonmerit factors.","26 applicants","Full-time","Mid-Senior level","Engineering","Higher Education, Software Development, and IT Services and IT Consulting","$99,461.00/yr - $128,329.00/yr","","","6408","https://www.linkedin.com/jobs/view/fbi-special-agent-data-science-intelligence-expertise-at-federal-bureau-of-investigation-fbi-4337646389?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist - Feed","San Francisco, CA","1 week ago","2025-11-18","https://www.linkedin.com/jobs/view/data-scientist-feed-at-nextdoor-4334503477?trk=public_jobs_topcard-title","Nextdoor","https://www.linkedin.com/company/nextdoor-com?trk=public_jobs_topcard-org-name","#TeamNextdoor

Nextdoor (NYSE: NXDR) is the essential neighborhood network. Neighbors, public agencies, and businesses use Nextdoor to connect around local information that matters in more than 340,000 neighborhoods across 11 countries. Nextdoor builds innovative technology to foster local community, share important news, and create neighborhood connections at scale. Download the app and join the neighborhood at nextdoor.com.

Meet Your Future Neighbors

As a Data Scientist at Nextdoor, you will help design and oversee product experiments and own complex analyses to drive company and product strategy. We use a semi-embedded team structure, in which a group of data team members works on a specific product or pillar, interfacing directly with product and engineering stakeholders. The Data Science group consists of people from a diverse set of backgrounds and perspectives, trained in fields as wide-ranging as economics, physics, statistics, and operations research. We are an integral part of the product development organization and play an active and collaborative role in building and improving the product.

At Nextdoor, we offer a warm and inclusive work environment that embraces a hybrid employment experience, providing a flexible experience for our valued employees.

The Impact You'll Make

Feed is a mission-critical surface within our platform – helping neighbors discover meaningful content through an intuitive interface and surfacing the right content through intelligent ranking. As a Data Scientist on the Feed team, you will partner with Analytics Engineers to advance our data foundation, collaborate with our cross-functional teams to develop and execute product roadmaps, and define/own the ways we measure success and elevate experimentation capabilities of the team.

We are seeking an entrepreneurial and driven data scientist to accelerate our efforts and play a significant role in our data-centric culture. This person will work closely with various cross-functional teams, such as product, engineering, and design, to develop and deliver metrics, analyses, solutions, and insights.

Successful candidates will demonstrate technical acumen, product expertise, and business acumen, and be enthusiastic about making a positive impact through timely execution. You are passionate about leveraging the power of data to drive product changes with quality and agility.

Your Responsibilities Will Include


 * Partner with cross-functional teams - including product management, design, engineering, research - to support product development efforts
 * Experiments: design and measure experiments to inform feature decisions
 * Develop key strategic insights through exploratory data analysis, to inform future investments or pivot in strategy
 * Build scalable metrics and dashboards to empower efficient decision-making at Nextdoor
 * Participate in in-person Nextdoor events such as trainings, off-sites, volunteer days, and team-building exercises
 * Build in-person relationships with team members and contribute to Nextdoor's company culture
   
   

What You'll Bring To The Team


 * 3-5 years of data science and product analytics experience
 * BS and/or MS in a quantitative discipline: statistics, operations research, computer science, engineering, applied mathematics, physics, economics, etc.
 * Experience in designing trustworthy experimentation and analyzing complex product a/b testing results
 * Experience identifying, designing, and delivering ergonomic tables to amplify speed + accuracy of key analysis and self-serve reports
 * Expert knowledge of SQL, Python programming, including common scientific computing packages and data science tools such as numpy, pandas, and scikit-learn
 * Excellent communication skills, with the ability to synthesize, simplify, and explain complex problems to different types of audiences, including executives, and compile compelling narratives
 * Innate curiosity around finding meaningful insights that inform the way we think about and develop both our product and our business strategies
 * Eagerness to explore and apply AI and emerging technologies to reimagine how work gets done
   
   

Rewards

Compensation, benefits, perks, and recognition programs at Nextdoor come together to create one overall rewards package.

The starting base salary for this role for the San Francisco, CA area is expected to range from $175,000 to $203,000 on an annualized basis, or potentially greater in the event that your 'level' of proficiency exceeds the level expected for the role. Compensation may also vary by geography. We also expect to award a meaningful equity grant for this role. With quarterly vesting, your first vest date would be within the first 3 months of your start date.

Overall, total compensation will vary depending on your relevant skills, experience, and qualifications. We have you covered! Nextdoor employees can choose between a variety of great health plans.

At Nextdoor, we empower our employees to build stronger local communities. To create a platform where all feel welcome, we want our workforce to reflect the diversity of the neighbors we serve. We encourage everyone interested in our mission to apply. We do not discriminate on the basis of race, gender, religion, sexual orientation, age, or any other trait that unfairly targets a group of people. In accordance with the San Francisco Fair Chance Ordinance, we always consider qualified applicants with arrest and conviction records.

For information about our collection and use of applicants’ personal information, please see Nextdoor's Personnel Privacy Notice, found here.","Over 200 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Technology, Information and Internet","$175,000.00/yr - $203,000.00/yr","","","1916708","https://www.linkedin.com/jobs/view/data-scientist-feed-at-nextdoor-4334503477?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr. Manager, Data Engineering & Architecture","Bellevue, WA","2 weeks ago","2025-11-12","https://www.linkedin.com/jobs/view/sr-manager-data-engineering-architecture-at-t-mobile-4318186940?trk=public_jobs_topcard-title","T-Mobile","https://www.linkedin.com/company/t-mobile?trk=public_jobs_topcard-org-name","At T-Mobile, we invest in YOU! Our Total Rewards Package ensures that employees get the same big love we give our customers. All team members receive a competitive base salary and compensation package - this is Total Rewards. Employees enjoy multiple wealth-building opportunities through our annual stock grant, employee stock purchase plan, 401(k), and access to free, year-round money coaches. That’s how we’re UNSTOPPABLE for our employees!


Job Overview

The Sr Manager, Data Engineering oversees a team of data engineers who are responsible for analysis, architecture, design and development of data warehouse and business analytics solutions. The Sr Manager, Data Engineering is responsible for the planning and roadmap for the Data Engineering team and is responsible for the quality for the data pipelines the team builds.

We pride ourselves on encouraging a culture of innovation, advocating for agile methodologies, and promoting transparency in all that we do. Join us in embodying the spirit of the 'Un-carrier' and make a tangible impact! If you are passionate about driving perfection and want to make a significant impact, apply today!

Job Responsibilities:


 * Manage a team of data engineers and software engineers that build custom data movement frameworks and off the shelf tooling
 * Create, manage, and communicate plans via roadmaps and presentations for the products and solutions supported by the Data Engineering team
 * Provide thought leadership and technical and business solution advice to Data Engineer team members and internal customers
 * Work across multiple teams in high visibility roles and be responsible for the solution end-to-end. Interface with engineers, product managers, and product analysts to understand data needs
 * Build framework for auditing, error logging and master data management for the team’s pipelines
 * Collaborate on analysis, architecture, design, and development of data warehouse and business analytics solutions
 * Also responsible for other Duties/Projects as assigned by business management as needed.
   
   
   

Education and Work Experience:


 * Bachelor's Degree Computer Engineering, Computer Science, a related subject area or equivalent experience (Required)
 * Master's/Advanced Degree Mathematics, Computer Science, Engineering, Finance, Statistics, or related technical field and/or MBA (Preferred)
 * 8+ years’ experience working with large scale complicated datasets; experience with relevant technologies and of enterprise-level system implementations such as data warehouse, ETL automation, BI visualization tools, and cloud-based data management tools Required
 * 5-7 years’ experience leading and/or coaching senior engineers Required
 * Experience with the Software Development Life Cycle (SDLC) and Agile/Scrum methods
   
   
   

Knowledge, Skills and Abilities:


 * Demonstrated ability to manage global projects or programs including work prioritization, planning, and coordination (Required)
 * Strong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams (Preferred)
 * Ability to work cross-functionally, building and maintaining trust with internal stakeholders (Preferred)
 * Passionate about learning new technologies (Preferred)
 * Previous experience managing technology solutions and services as products (Required)
   
   
   

Preferred Skills :


 * Cloud Platforms – Azure (Primary), (GCP/AWS secondary)
 * On-Prem Platforms – Hadoop (Cloudera)
 * Data Tools and Workload Processors - Databricks, Snowflake, Azure Data and Analytics services
 * Agile Frameworks - Kanban, Scrum
 * CI/CD - Gitlab, Jenkins, Terraform
 * Data Lake, Data Lakehouse and Data Warehouse concepts, data modeling and tools preferable on the cloud e.g., Azure Data Lake (ADLS), Snowflake, Databricks Lake House etc.
 * Designing data pipelines via tools like Apache Nifi, Azure Data Factory, Apache Spark
 * Kafka, Event Hub
 * Designing and developing custom data collection frameworks
 * Programming Languages - Java, Scala, or Python (any 2)
 * Linux Administration
 * Network and Security foundations (e.g., VPC, IAM)
 * Experience with infrastructure including hosting, container-based deployments, storage systems and cloud platforms.
 * Experience with Relational and NoSQL databases
 * Experience writing SQL
 * Experience optimizing and scaling data lake performance (ADLS/HDFS)
 * Experience with data visualization products, Power BI, Tableau
 * Grafana, InfluxDB, Prometheus
 * At least 18 years of age
 * Legally authorized to work in the United States
   
   
   

Travel:

Travel Required (Yes/No): No

DOT Regulated:

DOT Regulated Position (Yes/No): No

Safety Sensitive Position (Yes/No): No

Base Pay Range: $141,100 - $254,600

Corporate Bonus Target: 20%

The pay range above is the general base pay range for a successful candidate in the role. The successful candidate’s actual pay will be based on various factors, such as work location, qualifications, and experience, so the actual starting pay will vary within this range.

At T-Mobile, employees in regular, non-temporary roles are eligible for an annual bonus or periodic sales incentive or bonus, based on their role. Most Corporate employees are eligible for a year-end bonus based on company and/or individual performance and which is set at a percentage of the employee’s eligible earnings in the prior year. Certain positions in Customer Care are eligible for monthly bonuses based on individual and/or team performance. To find the pay range for this role based on hiring location, copy and paste this link into your browser: https://paylookup.t-mobile.com/paylookup?reqID=REQ332972

At T-Mobile, our benefits exemplify the spirit of One Team, Together! A big part of how we care for one another is working to ensure our benefits evolve to meet the needs of our team members. Full and part-time employees have access to the same benefits when eligible. We cover all of the bases, offering medical, dental and vision insurance, a flexible spending account, 401(k), employee stock grants, employee stock purchase plan, paid time off and up to 12 paid holidays - which total about 4 weeks for new full-time employees and about 2.5 weeks for new part-time employees annually - paid parental and family leave, family building benefits, back-up care, enhanced family support, childcare subsidy, tuition assistance, college coaching, short- and long-term disability, voluntary AD&D coverage, voluntary accident coverage, voluntary life insurance, voluntary disability insurance, and voluntary long-term care insurance. We don't stop there - eligible employees can also receive mobile service & home internet discounts, pet insurance, and access to commuter and transit programs! To learn about T-Mobile’s amazing benefits, check out www.t-mobilebenefits.com.

Never stop growing!

As part of the T-Mobile team, you know the Un-carrier doesn’t have a corporate ladder–it’s more like a jungle gym of possibilities! We love helping our employees grow in their careers, because it’s that shared drive to aim high that drives our business and our culture forward. By applying for this career opportunity, you’re living our values while investing in your career growth–and we applaud it. You’re unstoppable!

T-Mobile USA, Inc. is an Equal Opportunity Employer. All decisions concerning the employment relationship will be made without regard to age, race, ethnicity, color, religion, creed, sex, sexual orientation, gender identity or expression, national origin, religious affiliation, marital status, citizenship status, veteran status, the presence of any physical or mental disability, or any other status or characteristic protected by federal, state, or local law. Discrimination, retaliation or harassment based upon any of these factors is wholly inconsistent with how we do business and will not be tolerated.

Talent comes in all forms at the Un-carrier. If you are an individual with a disability and need reasonable accommodation at any point in the application or interview process, please let us know by emailing ApplicantAccommodation@t-mobile.com or calling 1-844-873-9500. Please note, this contact channel is not a means to apply for or inquire about a position and we are unable to respond to non-accommodation related requests.","198 applicants","Full-time","Mid-Senior level","Information Technology","Telecommunications","$141,100.00/yr - $254,600.00/yr","","","1392","https://www.linkedin.com/jobs/view/sr-manager-data-engineering-architecture-at-t-mobile-4318186940?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI/ML Engineer- Supply Chain","Miramar, FL","1 week ago","2025-11-24","https://www.linkedin.com/jobs/view/ai-ml-engineer-supply-chain-at-southern-glazer-s-wine-spirits-4338865250?trk=public_jobs_topcard-title","Southern Glazer's Wine & Spirits","https://www.linkedin.com/company/southern-wine-&-spirits?trk=public_jobs_topcard-org-name","What You Need To Know

Shape a remarkable future with us. Build a career working for an industry leader that truly invests in their people – and equips them with leading technology, continuous learning, and the ability to bring their best selves to work. As the premier wine and spirits distributor, Southern Glazer’s isn't just one of Forbes’ Top Private Companies; it's a family-owned business with deep roots dating back to 1933.

The reputation of Southern Glazer’s is well-established, and it's no surprise that we are regularly recognized for our culture. Southern Glazer’s has been recognized by Newsweek as one of America’s Greatest Workplaces for Inclusion and Diversity, as well as for Women and Parents and Families. These accolades speak volumes about our commitment to creating a supportive and inclusive culture of belonging for all employees.

As a full-time employee, you can choose from a wide-ranging menu of our Top Shelf Benefits, including comprehensive medical and prescription drug coverage, dental and vision plans, tax-saving Flexible Spending Accounts, disability coverage, life insurance plans, and a 401(k) plan. We also offer tuition assistance, a wellness program, parental leave, vacation accrual, paid sick leave, and more.

By joining Southern Glazer’s, you would be part of a team that values excellence, innovation, and community. This is more than just a job – it's an opportunity to build the future of beverage distribution and grow with a company that truly cares about its people.

Overview

The AI/ML Engineer is responsible for designing, building, and deploying machine learning models and AI systems to transform data into actionable insights. The AI/ML Engineer ensures that models developed by data scientists are scalable and seamlessly integrated into production environments, where they are monitored for data and infrastructure drift. Collaboration with Data Scientists, Software Developers, Engineers, and Domain Architects is essential for the AI/ML Engineer to gather requirements and integrate AI solutions into existing systems, creating a cohesive technological ecosystem.

Primary Responsibilities


 * Design and develop LLM-powered chatbots and agents that integrate with business systems and workflows.
 * Fine-tune or prompt-engineer foundation models (e.g., OpenAI, Anthropic, Databricks MosaicML) for enterprise use cases.
 * Build retrieval-augmented generation (RAG) pipelines and vector databases for domain-specific knowledge integration.
 * Develop data ingestion and orchestration pipelines using Databricks, Python, or Spark for model input/output.
 * Implement evaluation frameworks for chatbot quality, hallucination detection, and model performance tracking.
 * Collaborate with backend and data engineering teams to deploy AI models as APIs or microservices in production.
 * Ensure security, compliance, and ethical AI standards across all deployments.
 * Experiment with multi-agent workflows and contextual memory for autonomous task execution.
 * Contribute to the organization’s AI engineering playbook, ensuring scalable and reusable design patterns.
   
   

Additional Primary Responsibilities


 * Deploy machine learning models into production environments and ensure models are scalable and able to handle real-time data processing.
 * Monitor model performance and accuracy over time and update modes with new data when available and as requirements change.
 * Debug and troubleshoot issues with model performance and/or deployment.
 * Ensure AI models adhere to ethical guidelines and regulatory standards and address issues related to bias, fairness and transparency in AI systems.
 * Develop and optimize algorithms to enable machines to perform tasks aligned with business objectives.
 * Handle data preprocessing and feature engineering.
   
   

Minimum Qualifications


 * Bachelor’s or Master’s in Computer Science, Data Science, Engineering, or related field.
 * 3+ years of experience in AI/ML engineering, with proven experience in LLM or chatbot development.
 * Strong proficiency in Python (LangChain, or similar frameworks).
 * Experience with Databricks, Azure ML, AWS SageMaker, or equivalent platforms.
 * Hands-on experience with OpenAI API, Anthropic Claude, Hugging Face Transformers, or MosaicML.
 * Familiarity with vector databases.
 * Solid understanding of prompt engineering, RAG, model fine-tuning, and evaluation metrics.
 * Proficiency in SQL and data pipeline development.
 * Strong understanding of MLOps, CI/CD pipelines, and API deployment practices.
 * Excellent communication and collaboration skills with cross-functional teams.
 * Experience building enterprise-grade AI assistants or autonomous agent frameworks.
 * Familiarity with multi-agent orchestration and tools integration (e.g., MCP, LangGraph, CrewAI).
 * Exposure to supply chain, planning, or analytics use cases.
   
   

Physical Demands


 * Physical demands include a considerable amount of time sitting and typing/keyboarding, using a computer (e.g., keyboard, mouse, and monitor), or adding machine
 * Physical demands with activity or condition may include walking, bending, reaching, standing, squatting, and stooping
 * May require occasional lifting/lowering, pushing, carrying, or pulling up to 20lbs
   
   

EEO Statement

Southern Glazer's Wine and Spirits, an Affirmative Action/EEO employer, prohibits discrimination and harassment of any type and provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. SGWS complies with all federal, state and local laws concerning consideration of a qualified applicant's arrest and/or criminal conviction records. Southern Glazer's Wine and Spirits provides competitive compensation based on estimated performance level consistent with the past relevant experience, knowledge, skills, abilities and education of employees. Unless otherwise expressly stated, any pay ranges posted here are estimates from outside of Southern Glazer's Wine and Spirits and do not reflect Southern Glazer's pay bands or ranges.

If you have any questions or concerns about whether this posting complies/adheres with local pay transparency requirements, please contact the SGWS talent acquisition team at NationalTA@sgws.com

\","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Beverage Manufacturing, Food and Beverage Services, and Freight and Package Transportation","","","","6821","https://www.linkedin.com/jobs/view/ai-ml-engineer-supply-chain-at-southern-glazer-s-wine-spirits-4338865250?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr Manager, Data Science & AI Engineering","Plano, TX","4 days ago","2025-11-28","https://www.linkedin.com/jobs/view/sr-manager-data-science-ai-engineering-at-yum%21-brands-4299915185?trk=public_jobs_topcard-title","Yum! Brands","https://www.linkedin.com/company/yum-brands?trk=public_jobs_topcard-org-name","Yum Crave AI is seeking a Senior Manager, Data Science & AI Engineering to lead and scale our hybrid team of Data Scientists and AI Engineers across traditional ML and next-generation AI systems. This individual will oversee workstreams that span forecasting, personalization, experimentation, and intelligent agent development using both structured data and foundation models (LLMs, VLMs, etc.)

The ideal candidate is an experienced technical leader who thrives at the intersection of applied data science and LLM-driven development, and who can coach teams, collaborate cross-functionally, and communicate complex ideas clearly to technical and executive audiences.

Key Responsibilities



 * Team Leadership & Coaching:
   
    * Lead and mentor a team of Data Scientists and AI Engineers across multiple domains and products.
    * Provide technical and career development guidance; foster a collaborative, high-trust culture.
    * Drive standards for experimentation, evaluation, reproducibility, and model performance.
      

 * Technical Strategy & Execution:
   
    * Shape end-to-end ML and AI strategy across core DS use cases (forecasting, pricing, recommendation) and emerging LLM/VLM applications.
    * Guide architectural choices around model selection, evaluation design, and deployment workflows.
    * Provide oversight on LLM fine-tuning, prompt design, ASR/embedding adaptation, and production readiness.
      

 * Communication & Collaboration:
   
    * Act as a key interface between technical contributors and business/product stakeholders.
    * Distill analytical output and AI system behavior into clear presentations, dashboards, or executive summaries.
    * Partner with Product, Engineering, TPM, and Ops to align team output with company priorities.
      
      

Required Qualifications



 * 8+ years of experience in Data Science, Machine Learning, or AI Engineering.
 * Experience leading and coaching high-performing technical teams.
 * Hands-on expertise in both traditional ML (regression, classification, forecasting) and modern AI techniques (LLMs, RAG, embeddings, multimodal models).
 * Strong communication skills with the ability to influence senior leadership and simplify complex topics.
   
   
   

Preferred Qualifications



 * Experience building or scaling hybrid DS+AI teams in enterprise environments.
 * Familiarity with LangChain, HuggingFace, OpenAI, Pinecone, or vector-based ML architectures.
 * Exposure to business domains such as QSR, retail, personalization, or intelligent automation.
   
   
   

Salary Range: $165,700 - $226,800 annually + bonus eligibility. This is the expected salary range for this position. Ultimately, in determining pay, we'll consider the successful candidate’s location, experience, and other job-related factors.

The Yum! Brands story is simple. We have the four distinctive, relevant and easy global brands – KFC, Pizza Hut, Taco Bell and The Habit Burger Grill -- born from the hopes and dreams, ambitions and grit of passionate entrepreneurs. And we want more of this to create our future!

As the world’s largest restaurant company we have a clear and compelling mission: to build the world’s most love, trusted and fastest-growing restaurant brands. The key and not-so-secret ingredient in our recipe for growth is our unrivaled talent and culture, which fuels our results.

We’re looking for talented, motivated, visionary and team-oriented leaders to join us as we elevate and personalize the customer experience across our 48,000 restaurants, operating in 145 countries and territories around the world!

We put pizza, chicken and tacos in the hands of customers through customized ordering, unique delivery approaches, app experiences, and click and collect services and consumer data analytics creating unique customer dining experiences – and we are only getting started.

Employees may work for a single brand and potentially grow to support all company-owned brands depending on their role. Regardless of where they work, as a company opening an average of 8 restaurants a day worldwide, the growth opportunities are endless. Taco Bell has been named of the 10 Most Innovative Companies in the World by Fast Company; Pizza Hut delivers more pizzas than any other pizza company in the world and KFC’s still use its 75-year-old finger lickin’ good recipe including secret herbs and spices to hand-bread its chicken every day.

Yum! and its brands have offices in Chicago, IL, Louisville KY, Irvine, CA, Plano, TX and other markets around the world. We don’t just say we are a great place to work – our commitments to the world and our employees show it. Yum! has been named to the Dow Jones Sustainability North America Index and ranked among the top 100 Best Corporate Citizens by Corporate Responsibility Magazine in addition to being named to the Bloomberg Gender-Equality Index. Our employees work in an environment where the value of “believe in all people” is lived every day, enjoying benefits including but not limited to: 4 weeks’ vacation PLUS holidays, sick leave and 2 paid days to volunteer at the cause of their choice and a dollar-for-dollar matching gift program; generous parental leave; competitive benefits including medical, dental, vision and life insurance as well as a 6% 401k match – all encompassed in Yum!’s world-famous recognition culture.","121 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Restaurants","$165,700.00/yr - $226,800.00/yr","","","3409","https://yum.ongig.com/jobs/digital/plano-tx-united-states/sr-manager-data-science-ai-engineering/4186?utm_source=linkedin&amp;utm_medium=referral&amp;utm_campaign=jobboard&amp;group=1583","EXTERNAL",""
"Data Engineer","Dublin, OH","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/data-engineer-at-iqventures-4337032876?trk=public_jobs_topcard-title","IQVentures","https://www.linkedin.com/company/iqventures?trk=public_jobs_topcard-org-name","Data Engineer




The Data Engineer is a technical leader and hands-on developer responsible for designing, building, and optimizing data pipelines and infrastructure to support analytics and reporting. This role will serve as the lead developer on strategic data initiatives, ensuring scalable, high-performance solutions are delivered effectively and efficiently.




The ideal candidate is self-directed, thrives in a fast-paced project environment, and is comfortable making technical decisions and architectural recommendations. The ideal candidate has prior experience in modern data platforms, most notable Databricks and the “lakehouse” architecture. They will work closely with cross-functional teams, including business stakeholders, data analysts, and engineering teams, to develop data solutions that align with enterprise strategies and business goals.

Experience in the financial industry is a plus, particularly in designing secure and compliant data solutions.




Responsibilities:

 * Design, build, and maintain scalable ETL/ELT pipelines for structured and unstructured data.
 * Optimize data storage, retrieval, and processing for performance, security, and cost-efficiency.
 * Ensure data integrity and governance by implementing robust validation, monitoring, and compliance processes.
 * Consume and analyze data from the data pipeline to infer, predict and recommend actionable insight, which will inform operational and strategic decision making to produce better results.
 * Empower departments and internal consumers with metrics and business intelligence to operate and direct our business, better serving our end customers.
 * Determine technical and behavioral requirements, identify strategies as solutions, and section solutions based on resource constraints.
 * Work with the business, process owners, and IT team members to design solutions for data and advanced analytics solutions.
 * Perform data modeling and prepare data in databases for analysis and reporting through various analytics tools.
 * Play a technical specialist role in championing data as a corporate asset.
 * Provide technical expertise in collaborating with project and other IT teams, internal and external to the company.
 * Contribute to and maintain system data standards.
 * Research and recommend innovative, and where possible automated approaches for system data administration tasks. Identify approaches that leverage our resources and provide economies of scale.
 * Engineer system that balances and meets performance, scalability, recoverability (including backup design), maintainability, security, high availability requirements and objectives.




Skills:

 * Databricks and related – SQL, Python, PySpark, Delta Live Tables, Data pipelines, AWS S3 object storage, Parquet/Columnar file formats, AWS Glue.
 * Systems Analysis - The application of systems analysis techniques and procedures, including consulting with users, to determine hardware, software, platform, or system functional specifications.
 * Time Management - Managing one's own time and the time of others.
 * Active Listening - Giving full attention to what other people are saying, taking time to understand the points being made, asking questions as appropriate, and not interrupting at inappropriate times.
 * Critical Thinking - Using logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions or approaches to problems.
 * Active Learning - Understanding the implications of new information for both current and future problem-solving and decision-making.
 * Writing - Communicating effectively in writing as appropriate for the needs of the audience.
 * Speaking - Talking to others to convey information effectively.
 * Instructing - Teaching others how to do something.
 * Service Orientation - Actively looking for ways to help people.
 * Complex Problem Solving - Identifying complex problems and reviewing related information to develop and evaluate options and implement solutions.
 * Troubleshooting - Determining causes of operating errors and deciding what to do about it.
 * Judgment and Decision Making - Considering the relative costs and benefits of potential actions to choose the most appropriate one.




Experience and Education:

 * High School Diploma (or GED or High School Equivalence Certificate).
 * Associate degree or equivalent training and certification.
 * 5+ years of experience in data engineering including SQL, data warehousing, cloud-based data platforms.
 * Databricks experience.
 * 2+ years Project Lead or Supervisory experience preferred.
 * Must be legally authorized to work in the United States. We are unable to sponsor or take over sponsorship at this time.","Over 200 applicants","Full-time","Entry level","Information Technology","Financial Services","","","","10417531","https://www.linkedin.com/jobs/view/data-engineer-at-iqventures-4337032876?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Analyst Specialist","Arlington, VA","2 weeks ago","2025-11-17","https://www.linkedin.com/jobs/view/data-analyst-specialist-at-accenture-federal-services-4336633034?trk=public_jobs_topcard-title","Accenture Federal Services","https://www.linkedin.com/company/accenturefederalservices?trk=public_jobs_topcard-org-name","At Accenture Federal Services, nothing matters more than helping the US federal government make the nation stronger and safer and life better for people. Our 13,000+ people are united in a shared purpose to pursue the limitless potential of technology and ingenuity for clients across defense, national security, public safety, civilian, and military health organizations.

Join Accenture Federal Services, a technology company and part of global Accenture, to do work that matters in a collaborative and caring community, where you feel like you belong and are empowered to grow, learn and thrive through hands-on experience, certifications, industry training and more.

Join us to drive positive, lasting change that moves missions and the government forward!

As a Data Analyst Specialist on the Innovation and Automation team, you will serve as an internal consultant, applying your analytical expertise to our own engineering and operational processes. Your mission is to use data to find, quantify, and track opportunities for innovation and automation. You will analyze data from our CI/CD pipelines, system logs, code repositories, and project management tools to uncover bottlenecks, identify repetitive tasks, and measure the impact of the automation solutions our team builds. This is a hands-on role for an analyst who wants to use their skills to make our technical teams faster, more efficient, and more reliable.

Responsibilities:


 * Analyze operational and engineering data (e.g., CI/CD logs, application performance metrics, data pipeline runtimes, Jira data) to identify trends, inefficiencies, and opportunities for automation.
 * Develop and maintain a suite of dashboards and reports in tools like Tableau or Power BI to visualize key performance indicators (KPIs) for engineering efficiency, platform health, and delivery velocity.
 * Partner with the Automation Lead and engineers to provide a data-driven basis for prioritizing new automation initiatives.
 * Perform ""before and after"" analysis to quantify the impact of automation, such as reduced deployment times, decreased error rates, or improved system performance.
 * Translate complex technical data into clear, actionable insights and present findings and recommendations to engineering leadership.
 * Act as a subject matter expert on measuring and monitoring the health and performance of technical systems and development lifecycles.
 * Automate your own analytical workflows using Python, SQL, and other scripting tools to create scalable and repeatable analyses.
   
   

Required Qualifications:


 * 5+ years of experience in a data analyst or business intelligence role
 * Expert-level proficiency in SQL for complex querying and data manipulation
 * Strong scripting skills in Python or R for data analysis and automation
 * Advanced skills in a data visualization tool such as Tableau, Power BI, or similar
 * Demonstrated experience analyzing complex datasets to identify actionable insights
 * Excellent problem-solving skills and the ability to translate ambiguous questions into concrete analytical tasks
   
   

Preferred Qualifications:


 * Experience analyzing DevOps, CI/CD, or software development lifecycle metrics (e.g., cycle time, lead time, deployment frequency)
 * Familiarity with querying and analyzing data from tools like GitLab, Jenkins, Jira, or observability platforms (e.g., Grafana, Datadog)
 * Experience working in a cloud environment (AWS, Azure)
 * Experience working in a high-security DoD or Intelligence Community environment
 * Strong communication skills with a proven ability to present technical findings to both technical and non-technical audiences
   
   

Security Clearance:


 * Active TS or TS/SCI clearance
   
   

As required by local law, Accenture Federal Services provides reasonable ranges of compensation for hired roles based on labor costs in the states of California, Colorado, Hawaii, Illinois, Maryland, Massachusetts, Minnesota, New Jersey, New York, Washington, Vermont, the District of Columbia, and the city of Cleveland. The base pay range for this position in these locations is shown below. Compensation for roles at Accenture Federal Services varies depending on a wide array of factors, including but not limited to office location, role, skill set, and level of experience. Accenture Federal Services offers a wide variety of benefits. You can find more information on benefits here. We accept applications on an on-going basis and there is no fixed deadline to apply.

The pay range for the states of California, Colorado, Hawaii, Illinois, Maryland, Massachusetts, Minnesota, New Jersey, New York, Washington, Vermont, the District of Columbia, and the city of Cleveland is:

$93,400—$176,200 USD

What We Believe

As a company wholly dedicated to serving the US federal government, we bring together the best talent to help reinvent how federal agencies operate and deliver greater value for their mission and the American people. We have an unwavering commitment to creating a culture in which all our people are respected, feel a sense of belonging, and have equal opportunity. As a business imperative, every person at Accenture Federal Services has the responsibility to create and sustain a culture where everyone feels welcomed and included. This is grounded in our core values and our experience that hiring and developing great people who reflect different perspectives, experiences, and backgrounds is key to driving innovation and delivering the results that our clients and the country count on.

Equal Employment Opportunity Statement

We believe that no one should be discriminated against because of their differences. All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law. Our rich diversity makes us more innovative, more competitive, and more creative, which helps us better serve our clients and our communities. For details, view a copy of the Accenture Federal Services Equal Opportunity Policy Statement.

Accenture Federal Services is an Equal Employment Opportunity employer. Additionally, as an Affirmative Action Employer for Veterans and Individuals with Disabilities, Accenture Federal Services is committed to providing veteran employment opportunities to our service men and women.

Requesting An Accommodation

Accenture Federal Services is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture Federal Services and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you are being considered for employment opportunities with Accenture Federal Services and need an accommodation for a disability or religious observance during the interview process or for the job you are interviewing for, please speak with your recruiter.

Other Employment Statements

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.

Candidates who are currently employed by a client of Accenture Federal Services or an affiliated Accenture business may not be eligible for consideration.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.

California requires additional notifications for applicants and employees. If you are a California resident, live in or plan to work from Los Angeles County upon being hired for this position, please click here for additional important information.

","170 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","","","","25030011","https://www.linkedin.com/jobs/view/data-analyst-specialist-at-accenture-federal-services-4336633034?trk=public_jobs_topcard-title","EASY_APPLY",""
"Product Engineer, Applied AI","New York, NY","4 days ago","2025-11-28","https://www.linkedin.com/jobs/view/product-engineer-applied-ai-at-pocus-4339259926?trk=public_jobs_topcard-title","Pocus","https://www.linkedin.com/company/pocus?trk=public_jobs_topcard-org-name","Pocus exists to supercharge GTM teams. We make every rep a 10x seller. With Pocus, organizations can have fewer, better reps to drive increased pipeline and revenue.

How? We’ve created the world’s most powerful, AI-native prospecting platform.

Pocus influences nearly half a billion in pipeline per quarter for our customers. We’re trusted by high growth companies like Asana, Monday, Canva, and Miro where Pocus powers up to 50% of their pipeline and eliminates 10+ hrs of work per rep per week.

Pocus has hundreds of always-on AI agents doing the manual, tedious work of researching & prospecting so that reps can do what they do best: sell. With Pocus AI agents working for them, rep’s days are simplified. Reps get alerts when compelling events happen, account plans are generated by AI, and agents recommend who to reach out to with the next best action. We’re fortunate to be backed by First Round, Coatue, and execs like CEO Zoom, CPO Adobe, CRO OpenAI, who are helping us usher in this future of sales.

The Pocus team is full of humble overachievers that like to move quickly (we call it shiperate), own our work, give customers superpowers, and create magic for our team… all while having a ton of fun. Join us on this next phase of growth!

About The Role

Pocus is powered by a custom-built agentic AI platform designed to help users ingest, reason over, and take action on structured and semi-structured data—whether it’s public or private. As an Applied AI Engineer, you’ll work at the intersection of cutting-edge AI and robust systems, helping to design and build intelligent agents that deeply understand data and drive workflows end-to-end.

What you’ll do

As an Applied AI Engineer at Pocus, you’ll help scale the AI infrastructure that powers our entire product experience. Our stack is built on AWS, with services written in TypeScript and connected through GraphQL. We leverage tools like Clickhouse, Presto, Temporal, and large language models (LLMs) as core building blocks—and default to managed services wherever possible to keep velocity high.

In this role, you will


 * Build agentic AI systems end-to-end: Architect and implement intelligent agents that extract insights from fragmented data sources and power real-world workflows.
 * Engineer an extensible AI platform: This includes:
    * A flexible data ingestion layer that connects to warehouses, databases, CRMs, public datasets, and crawlers.
    * A semantic enrichment and transformation engine, leveraging LLMs and tool-use to reason about and contextualize data.
    * A query engine that enables low-latency filtering and aggregation of enriched entities.
    * A workflow orchestration layer that lets users trigger actions in tools like Slack, Outreach, and CRMs via APIs or webhooks.

 * Prototype, iterate, and ship quickly: You'll have deep autonomy to test ideas, own systems, and ship features that impact customers directly.
 * Prioritize security and reliability: Handle sensitive customer data with best-in-class security practices and a strong foundation of reliability.
 * Elevate the engineering bar: We value clean abstractions, fast feedback loops, thoughtful testing, and excellent developer tooling.
   
   

What you bring

We’re still early and moving fast—ideal teammates thrive with autonomy, ambiguity, and high impact. You might be a fit if you:


 * Have 3+ years of experience building production-ready distributed systems and 1+ years of experience with production grade AI applications
 * Have worked with data-rich systems and are comfortable reasoning across messy and fragmented datasets
 * Are excited by LLMs, tool-use, and applied reasoning, and have built or experimented with intelligent agent workflows
 * Have a strong bias for action, and enjoy collaborating in small, nimble teams
 * Think in systems, debug across stacks, and don’t hesitate to dive deep when needed
 * Hold a high bar for simplicity, reliability, and product-minded engineering
 * Regularly use tools like Copilot, Cursor, GPTs, etc. to boost productivity and explore new ideas
   
   

Compensation & Benefits

This base salary for this role is $120,000 to $240,000. Compensation also includes equity and numerous perks and benefits (listed below).

Job level and actual compensation will be decided based on factors including, but not limited to, individual qualifications objectively assessed during the interview process (including skills and prior relevant experience, potential impact, and scope of role) and market demands. The listed range is a guideline, and the range for this role may be modified.

Perks and benefits:


 * Best in class medical, dental, and vision plans through our PEO
 * A monthly wellness stipend to help support you in your health goals
 * 401K through Guideline to help you invest in your future
 * Access to mentorship programs through First Round Capital for personal growth and development
 * 10 company holidays and discretionary vacation with a baseline requirement of 2 weeks / year. We work hard but don’t want you to burn out!
 * In person offices in NY / SF or a work from home stipend to help you set up your home office
   
   

DE&I: At Pocus, we’re looking for people who are humble overachievers with an ownership mentality and a love for building. If this sounds like you, we encourage you to apply, even if your skills don’t perfectly match our job descriptions (especially if you’re making a career change or are insanely passionate about AI and the next wave of sales intelligence!). At Pocus, we welcome your diverse backgrounds and celebrate different perspectives that challenge the status quo. We will never discriminate on the basis of religion, color, gender identity, disability, marital status or any other characteristics protected by law.

","49 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","$120,000.00/yr - $240,000.00/yr","","","74109577","https://www.linkedin.com/jobs/view/product-engineer-applied-ai-at-pocus-4339259926?trk=public_jobs_topcard-title","EASY_APPLY",""
"Staff Data Scientist","San Francisco Bay Area","22 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/staff-data-scientist-at-quantix-search-4340363077?trk=public_jobs_topcard-title","Quantix Search","https://www.linkedin.com/company/quantix-search?trk=public_jobs_topcard-org-name","Staff Data Scientist | San Francisco | $250K–$300K + Equity




We’re partnering with one of the fastest-growing AI companies in the world to hire a Staff Data Scientist. Backed by over $230M from top-tier investors and already valued at over $1B, they’ve secured customers that include some of the most recognizable names in tech. Their AI platform powers millions of daily interactions and is quickly becoming the enterprise standard for conversational AI.




In this role, you’ll bring rigorous analytics and experimentation leadership that directly shapes product strategy and company performance.




What you’ll do:

 * Drive deep-dive analyses on user behavior, product performance, and growth drivers
 * Design and interpret A/B tests to measure product impact at scale
 * Build scalable data models, pipelines, and dashboards for company-wide use
 * Partner with Product and Engineering to embed experimentation best practices
 * Evaluate ML models, ensuring business relevance, performance, and trade-off clarity




What we’re looking for:

 * 5+ years in data science or product analytics at scale (consumer or marketplace preferred)
 * Advanced SQL and Python skills, with strong foundations in statistics and experimental design
 * Proven record of designing, running, and analyzing large-scale experiments
 * Ability to analyze and reason about ML models (classification, recommendation, LLMs)
 * Strong communicator with a track record of influencing cross-functional teams




If you're excited by the sound of this challenge- apply today and we'll be in touch.","113 applicants","Full-time","Mid-Senior level","Information Technology","IT System Custom Software Development","$250,000.00/yr - $300,000.00/yr","Greg Evans","https://www.linkedin.com/in/greg-evans-80838765","104750436","https://www.linkedin.com/jobs/view/staff-data-scientist-at-quantix-search-4340363077?trk=public_jobs_topcard-title","EASY_APPLY",""
"Applied AI Engineer","San Francisco, CA","2 weeks ago","2025-11-18","https://www.linkedin.com/jobs/view/applied-ai-engineer-at-serval-4336736292?trk=public_jobs_topcard-title","Serval","https://www.linkedin.com/company/getserval?trk=public_jobs_topcard-org-name","Who We Are

At Serval, we're building the AI platform for IT teams. Our goal is to take on legacy players like ServiceNow, a $230+ bn company, by building the platform for AI agents to resolve IT issues instead of humans.

Serval “automates the automation,” using a natural language-to-code workflow builder and AI agents that discover and deliver automations for tedious IT workflows.

Our mission is to free IT departments from the #helpdesk channel by creating the simplest way to automate employee onboarding/offboarding, software access management, and the long tail of employee requests. Long term, our vision extends to developing a universal workflow automation platform for all business functions.

Serval was founded by product and engineering leaders from Verkada and is backed by industry-leading investors like First Round, General Catalyst, Alt Capital, and Box Group.

Role Overview

As an Applied AI Engineer at Serval, you’ll help build the intelligence behind our platform - the foundational AI agents that reason, act, and automate complex IT workflows. Your work will apply cutting-edge models and techniques in creative, real-world ways to convert repetitive IT processes into intelligent automation.

Key Responsibilities


 * Design, build, and deploy AI-powered features from the ground up.
 * Develop and optimize Serval’s applied AI systems — from model selection and fine-tuning to inference and evaluation pipelines.
 * Integrate AI capabilities into production environments, ensuring reliability, scalability, and performance.
 * Collaborate across engineering and product to bring new customer experiences to life.
 * Continuously evaluate model performance and improve results based on data and user feedback.
 * Help establish AI engineering best practices and raise the technical bar across the team.
   
   

Requirements


 * Experience as a software engineer or machine learning engineer with a focus on applied AI.
 * Proven experience developing and deploying production-grade AI systems, ideally leveraging large language models or foundation models.
 * Experience with prompt engineering, fine-tuning, or evaluation techniques for LLMs.
 * Comfort working with APIs, data pipelines, and cloud environments (AWS, GCP, or similar).
 * Deep appreciation for delivering high-quality user experiences, not just high-performing models.
 * Excellent communication skills and ability to thrive in a fast-paced, collaborative startup environment.
 * Degree in Computer Science or a related technical field.
   
   

Nice to Have


 * Experience building AI-native applications or tools that use LLMs in production.
 * Familiarity with our stack: Go, gRPC, React, TypeScript, Kubernetes, AWS, and Terraform.
 * Early-stage startup experience or a track record of zero-to-one product development.
 * Experience with retrieval-augmented generation (RAG), vector databases, or orchestration frameworks.
   
   

What we offer


 * Impact: Be a key player in shaping the success of our product and company.
 * Growth: Build a fundamentally new AI product offering with the support of our experienced team and investors. Grow rapidly with the company.
 * Culture: Join a culture that values innovation, ownership, accountability, and fun.
 * Compensation: Top of market salary, equity, and a comprehensive benefits package.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","","","","101771821","https://jobs.ashbyhq.com/Serval/2bfaede4-22b2-43b2-a14c-f45e5f398624/application?utm_source=oMxPwOllGK","EXTERNAL",""
"AI Engineer with Databricks","King of Prussia, PA","2 weeks ago","2025-11-12","https://www.linkedin.com/jobs/view/ai-engineer-with-databricks-at-swits-digital-private-limited-4335735414?trk=public_jobs_topcard-title","SWITS DIGITAL Private Limited","https://in.linkedin.com/company/switsdigital?trk=public_jobs_topcard-org-name","Job Description: AI Engineer with Databricks

Location: King of Prussia PA, (Only Locals No relocation) full onsite

We are seeking a highly skilled AI Engineer with proven experience in developing, deploying, and optimizing AI models using the Databricks AI platform. The ideal candidate will have a strong background in machine learning, distributed data processing, and will be a champion of Databricks platform.

Responsibilities


 * Generative AI: Experience of LLM-based solutions (LlamaIndex, LangChain, RAG pipelines, or similar frameworks). Ability to integrate GenAI and Agentic AI into business workflows.
 * Design and implement end-to-end Generative AI solutions on Databricks, leveraging Unity Catalog, MLflow, Delta Lake, and Vector Search
 * Design, build, and deploy large-scale AI/ML models using the Databricks environment.
 * Implement data validation, lineage, and monitoring using Delta Live Tables and Unity Catalog.
 * Leverage Databricks’ data engineering workflows for feature engineering, model training, and evaluation.
 * Optimize training pipelines for efficiency, scalability, and accuracy.
 * Integrate AI models into production systems using APIs and microservices.
 * Build reusable ML pipelines using Databricks Repos, MLflow, and Feature Store.
 * Implement robust testing, monitoring, and retraining protocols for deployed models.
 * Ensure adherence to compliance, security, and performance standards.
 * Stay updated on advancements in AI frameworks, distributed computing, and Databricks platform updates.
   
   

Required Skills And Qualifications


 * Bachelor’s or Master’s degree in Computer Science, Data Science, or related field.
 * Certified Databricks Certified Generative AI Engineer
 * Proven experience developing AI solutions on Databricks.
 * Strong knowledge of Python, PySpark, MLflow, Spark and Databricks Notebooks.
 * Strong understanding and knowlege of Databricks platform features such as Unity Catalog, DLT, MosaicAI, Data Assets Bundles, etc.
 * Experience with Transformer-based models, generative AI, and Databricks pipelines.
 * Proficiency in integrating AI models with cloud-native architectures (AWS, Azure, or GCP).
 * Solid understanding of MLOps practices, Data Assets bundles (CI/CD), and containerization (Docker, Kubernetes) on Databricks Platform.
 * Familiarity with vector databases, embeddings, and retrieval-augmented generation (RAG).
 * Strong problem-solving, analytical thinking, and communication skills.","Be among the first 25 applicants","Full-time","Entry level","Engineering and Information Technology","IT Services and IT Consulting","","","","105290645","https://www.linkedin.com/jobs/view/ai-engineer-with-databricks-at-swits-digital-private-limited-4335735414?trk=public_jobs_topcard-title","EASY_APPLY",""
"Python Risk Model Developer (SQL & Unix)","New York, United States","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/python-risk-model-developer-sql-unix-at-capgemini-4339023290?trk=public_jobs_topcard-title","Capgemini","https://fr.linkedin.com/company/capgemini?trk=public_jobs_topcard-org-name","Choosing Capgemini means choosing a company where you will be empowered to shape your career in the way you’d like, where you’ll be supported and inspired by a collaborative community of colleagues around the world, and where you’ll be able to reimagine what’s possible. Join us and help the world’s leading organizations unlock the value of technology and build a more sustainable, more inclusive world.

Job Location: NY

Works in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.1. Applies scientific methods to analyse and solve software engineering problems.2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.

Job Responsibilities

As a successful candidate you will be given an opportunity to acquire and develop knowledge from related fields:

Collaborate with stakeholders throughout the organization to develop project plans of delivering objects and timelines of model development and implementation.

Develop risk models in Python/R used by risk teams for regulatory stress testing submission and company risk management. Design and build the execution workflow of models to forecast Balance Sheet, Fee Revenues, Macroeconomic Factors,

Expense and calculate risk metrics under various stress scenarios, sensitivity & attribution analysis.

Coordinate with different functional teams to implement models and coordinate coding, testing, implementation and documentation of financial models.

Develop processes and tools to monitor and analyze model performance to ensure the expected application performance levels are achieved. Also, apply various statistical and analytical tests for validating models and results.

Develop presentation decks using visual analytics tools and techniques. (JupyterHub/Python)

Apply data mining, data modelling and machine learning techniques to analyze large financial datasets and enhance the model performance.

Required Skills

Master/MBA/PhD's Degree in a quantitative field (computer science, financial engineering, mathematics, data science or engineering)

Experience using one or more programming languages (Python, R, C++, Java, Matlab, etc.) and manipulating data using SQL and Pandas

Excellent written and verbal communication skills for coordination across teams

Understanding of design, development and implementation of mathematical, financial risk and ML models

Relevant work experience in a related field based on education level

Knowledge of advanced statistical techniques and concepts (regression, time series analysis, statistical tests, etc.)

Life at Capgemini

Capgemini Supports All Aspects Of Your Well-being Throughout The Changing Stages Of Your Life And Career. For Eligible Employees, We Offer

Flexible work

Healthcare including dental, vision, mental health, and well-being programs

Financial well-being programs such as 401(k) and Employee Share Ownership Plan

Paid time off and paid holidays

Paid parental leave

Family building benefits like adoption assistance, surrogacy, and cryopreservation

Social well-being benefits like subsidized back-up child/elder care and tutoring

Mentoring, coaching and learning programs

Employee Resource Groups nd Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.

Capgemini is committed to providing reasonable accommodations du

Disaster Relief

The base compensation range for this role in the posted location is:

$110841 to $145000

Capgemini provides compensation range information in accordance with applicable national, state, provincial, and local pay transparency laws. The base compensation range listed for this position reflects the minimum and maximum target compensation Capgemini, in good faith, believes it may pay for the role at the time of this posting. This range may be subject to change as permitted by law.

The actual compensation offered to any candidate may fall outside of the posted range and will be determined based on multiple factors legally permitted in the applicable jurisdiction.

These may include, but are not limited to: Geographic location, Education and qualifications, Certifications and licenses, Relevant experience and skills, Seniority and performance, Market and business consideration, Internal pay equity.

It is not typical for candidates to be hired at or near the top of the posted compensation range.

In addition to base salary, this role may be eligible for additional compensation such as variable incentives, bonuses, or commissions, depending on the position and applicable laws.

Benefits

Capgemini offers a comprehensive, non-negotiable benefits package to all regular, full-time employees. In the U.S. and Canada, available benefits are determined by local policy and eligibility and may include:


 * Paid time off based on employee grade (A-F), defined by policy: Vacation: 12-25 days, depending on grade, Company paid holidays, Personal Days, Sick Leave
 * Medical, dental, and vision coverage (or provincial healthcare coordination in Canada)
 * Retirement savings plans (e.g., 401(k) in the U.S., RRSP in Canada)
 * Life and disability insurance
 * Employee assistance programs
 * Other benefits as provided by local policy and eligibility
   
   

Important Notice: Compensation (including bonuses, commissions, or other forms of incentive pay) is not considered earned, vested, or payable until it becomes due under the terms of applicable plans or agreements and is subject to Capgemini’s discretion, consistent with applicable laws. The Company reserves the right to amend or withdraw compensation programs at any time, within the limits of applicable legislation.

Disclaimers

Capgemini is an Equal Opportunity Employer encouraging inclusion in the workplace. Capgemini also participates in the Partnership Accreditation in Indigenous Relations (PAIR) program which supports meaningful engagement with Indigenous communities across Canada by promoting fairness, accessibility, inclusion and respect. We value the rich cultural heritage and contributions of Indigenous Peoples and actively work to create a welcoming and respectful environment. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.

This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodation does not pose an undue hardship. Capgemini is committed to providing reasonable accommodation during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.

Please be aware that Capgemini may capture your image (video or screenshot) during the interview process and that image may be used for verification, including during the hiring and onboarding process.

Click the following link for more information on your rights as an Applicant in the United States. http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law

Capgemini is a global business and technology transformation partner, helping organizations to accelerate their dual transition to a digital and sustainable world, while creating tangible impact for enterprises and society. It is a responsible and diverse group of 340,000 team members in more than 50 countries. With its strong over 55-year heritage, Capgemini is trusted by its clients to unlock the value of technology to address the entire breadth of their business needs. It delivers end-to-end services and solutions leveraging strengths from strategy and design to engineering, all fueled by its market leading capabilities in AI, generative AI, cloud and data, combined with its deep industry expertise and partner ecosystem.","Be among the first 25 applicants","Full-time","Mid-Senior level","General Business, Management, and Business Development","IT Services and IT Consulting","$110,841.00/yr - $145,000.00/yr","","","157240","https://www.capgemini.com/jobs/366067-en_US_SAPBTP/Python-Risk-Model-Developer-%28SQL-&-Unix%29","EXTERNAL",""
"Senior Data Engineer","Parsippany, NJ","16 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/senior-data-engineer-at-dowc-4340305296?trk=public_jobs_topcard-title","DOWC","https://www.linkedin.com/company/dowc?trk=public_jobs_topcard-org-name","Job description:

**This position is fully on-site in Parsippany, NJ and candidates must reside local to the area. Kindly do not apply if you need hybrid or remote at this time. Please read the full job description before applying.**




About Us

Dealer Owned Warranty Company LLC is a leading provider of F&I (Finance and Insurance) partnership services in the automotive industry, offering a full suite of obligor and administrator services, top-of-the-line products, technology, and training. We understand the importance of leveraging process and technology in the F&I industry to drive revenue and ensure success. Our goal is to provide visibility, transparency, and the tools needed for our partners to build their wealth and achieve their goals. All of our positions are fully on-site in Parsippany, NJ.




Job Summary

The Data Engineer leads the design, development, and maintenance of scalable and secure data architecture, pipelines, and systems to support the company’s data-driven initiatives. This role not only ensures the integrity, performance, and delivery of data solutions but also guides the broader data engineering team, mentors junior engineers, and drives innovation and best practices. The Senior Data Engineer collaborates cross-functionally to align data solutions with strategic business goals and plays a critical role in shaping the company’s data infrastructure roadmap.




Duties/Responsibilities:

Data Architecture, Pipeline Development, and Automation

 * Design and build robust, scalable, and efficient ETL pipelines that support complex data workflows and meet evolving business needs.
 * Lead the automation of data ingestion from diverse sources (databases, APIs, cloud services) and ensure system reliability and failover readiness.
 * Oversee the optimization of data storage, processing, and retrieval for performance, cost-efficiency, and scalability.

Process Improvement and Technical Leadership

 * Identify, evaluate, and implement improvements to legacy systems, ensuring alignment with current and future business demands.
 * Research, recommend, and introduce advanced tools, frameworks, and technologies to enhance the data platform.
 * Provide technical leadership to the data engineering team, including mentoring, code reviews, and enforcing engineering best practices.

Data Governance, Integrity, and Quality

 * Ensure end-to-end data quality and integrity by establishing and enforcing robust validation, monitoring, and testing protocols.
 * Collaborate with cross-functional stakeholders to translate business requirements into well-defined data models and transformations.
 * Proactively identify and resolve data inconsistencies, gaps, and errors across systems.

Cross-functional Collaboration

 * Partner closely with data analysts, data scientists, product managers, and business leaders to deliver data products that enable analytics, reporting, and advanced modeling.
 * Work with DevOps, software engineering, and IT teams to ensure seamless integration of data systems with enterprise platforms.
 * Drive the creation of self-service data tools, dashboards, and reporting solutions that empower business teams.

Documentation, Knowledge Sharing, and Strategy

 * Develop and maintain comprehensive documentation for data models, pipelines, processes, and system architecture.
 * Share knowledge and lead training efforts to upskill the team and promote a data-driven culture.
 * Contribute to the long-term data strategy, including architecture roadmaps, data governance policies, and compliance initiatives.

Other Responsibilities

 * Perform any other duties assigned by the discretion of management.




Required Skills & Experience:

 * Minimum of 7-10+ years of data engineering experience is required.
 * Bachelor's Degree in Data Engineering, Computer Science, Data Analytics or related field is required. Master's Degree preferred.
 * MUST have excellent communication skills both written and verbal in English. Must be able to present data to leadership and collaborate with team members.
 * Strong technical coding capabilities.
 * Advanced proficiency with SQL, Python, and ETL development are required.
 * Python proficiency is required. Must be seen on resume.
 * Strong experience with data modeling, data warehousing, and database technologies (e.g. PostgreSQL, Snowflake, Redshift).
 * Experience with cloud data platforms (AWS or Azure) and cloud-native data engineering tools.
 * Solid understanding of data architecture patterns (batch, streaming, event-driven) and best practices.
 * Proven ability to optimize data workflows, troubleshoot complex issues, and ensure high system performance.
 * Strong project management capabilities and ability to work independently.
 * Excellent communication skills, with the ability to explain complex technical concepts to non-technical stakeholders.
 * Must be able to pass a technical coding assessment.




Physical Requirements

 * Prolonged periods of sitting at a desk and working on a computer
 * Must be able to lift up to 15 pounds




Come join our growing team here in Parsippany! As NJ's Best Places to Work Honoree for three years in a row, we offer:

 * Competitive compensation
 * Medical, Dental, Vision, 401k matching, Life Insurance, medical expense card
 * PTO and Sick Time
 * Corporate events, team and culture building activities, employee awards and recognition, company trips and more!




DOWC is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected Veteran status, sexual orientation, gender identity, gender expression, genetic information, or any other characteristic protected by law. Applicants who require accommodation to participate in the job application process may contact us for assistance.","163 applicants","Full-time","Mid-Senior level","Engineering","Insurance and Financial Services","$125,000.00/yr - $145,000.00/yr","","","11750875","https://www.linkedin.com/jobs/view/senior-data-engineer-at-dowc-4340305296?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)"
"Data Integration Engineer","Bethesda, MD","1 week ago","2025-11-24","https://www.linkedin.com/jobs/view/data-integration-engineer-at-swarmint-llc-4338726218?trk=public_jobs_topcard-title","SwarmInt LLC","https://www.linkedin.com/company/swarmint?trk=public_jobs_topcard-org-name","About Us:
SwarmInt is a defense AI startup developing cutting-edge computer vision and edge AI capabilities for military expeditionary forces. We strive to develop operator-in-the-loop solutions for warfighters with active contracts supporting the Department of Defense and Intelligence Community.

Job Description:
We need a Data Integration Engineer to build robust pipelines for a large-scale enterprise data solution supporting our Intelligence Community customer. You'll architect data flows that move petabytes of information from diverse sources into unified intelligence platforms. This role requires regular on-site work at customer facilities in Bethesda, Maryland, including work in classified facilities (SCIF).

Responsibilities:

 * Design and implement data pipelines integrating diverse sources
 * Build real-time streaming architectures for data ingestion and processing
 * Develop ETL/ELT workflows for transforming and standardizing multi-source data
 * Create data connectors for military and government data formats and protocols
 * Implement data quality monitoring, validation, and anomaly detection
 * Build APIs and services for efficient data access and distribution
 * Architect data flows across distributed systems
 * Optimize pipelines for performance, reliability, and fault tolerance in challenging network conditions
 * Orchestrate complex workflows and manage data dependencies
 * Document data schemas, lineage, and integration architecture
 * Deploy and manage data infrastructure using containerized deployments
 * Collaborate with AI/ML teams to prepare and deliver data for training and inference

Required Qualifications:

 * Bachelor's degree in Computer Science, Data Engineering, or related field
 * 8-12 years experience building data pipelines and integration systems
 * Experience with Elasticsearch or similar search technologies
 * Strong programming skills with experience in data processing
 * Experience with data pipeline orchestration and workflow management
 * Proficiency with databases and data modeling
 * Understanding of streaming data concepts and architectures
 * Experience with APIs and data serialization
 * Strong experience with containerization technologies (Docker)
 * Active TS/SCI with Single Scope (CI) Polygraph Required (Do not apply unless you have this)
 * U.S. Citizenship required
 * Ability to work on-site in Bethesda, Maryland 2-4 days/week including at classified facilities

Preferred Qualifications:

 * Experience with video streaming protocols and real-time data feeds
 * Knowledge of geospatial data formats and processing
 * Familiarity with defense data standards and military protocols
 * Experience with distributed streaming platforms
 * Proficiency with workflow orchestration frameworks
 * Experience with time-series databases and analytics
 * Knowledge of data transformation tools and frameworks
 * Understanding of ML data pipelines and feature engineering
 * Knowledge of message queuing and pub/sub systems
 * Experience with infrastructure automation tools
 * Knowledge of government data systems and security requirements (NIST 800-171, CMMC)
 * Experience in air-gapped or restricted environments
 * Experience with enterprise-scale data solutions at petabyte scale

Benefits:

 * Competitive salary (~$180K based on experience)
 * Annual performance bonus
 * 401k with competitive company match
 * Comprehensive health, dental, and vision insurance
 * Clearance retention bonuses
 * Work on challenging data integration problems at petabyte scale
 * Direct impact on intelligence capabilities for national security
 * Collaborative team environment with strong technical leadership
 * Professional development budget
 * Work on cutting-edge intelligence data platforms","Be among the first 25 applicants","Full-time","Mid-Senior level","Information Technology","Internet Publishing","","","","94151073","https://www.linkedin.com/jobs/view/data-integration-engineer-at-swarmint-llc-4338726218?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Analyst","Seattle, WA","7 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-analyst-at-desc-downtown-emergency-service-center-4348065192?trk=public_jobs_topcard-title","DESC (Downtown Emergency Service Center)","https://www.linkedin.com/company/downtown-emergency-service-center?trk=public_jobs_topcard-org-name","Job Type

Full-time

Description

Days Off: Saturday, Sunday

Shift: Office Day

Insurance Benefits: Dental, Life, Long-term Disability, Medical

Other Benefits: Employee Assistance Program (EAP), Flexible Spending Account (FSA), ORCA card subsidy, Paid Time Off (34 days per year), Retirement Plan

About DESC:

DESC (Downtown Emergency Service Center) is a nonprofit organization working to help people with the complex needs of homelessness, substance use disorders, and serious mental illness achieve their highest potential for health and well-being through comprehensive services, treatment, and housing. Our vision is a community where no person is abandoned, ignored, or experiencing homelessness.

As the region's leading provider of services to multiply disabled adults who have experienced chronic homelessness, DESC serves almost 3,000 people each day. Our integrated service model is designed to help people secure and maintain appropriate, safe and affordable housing. DESC is recognized nationally and regionally as an innovator in developing solutions to homelessness.

JOB DEFINITION:

The Foundational Community Supports (FCS) Data Analyst is a member of a multi-disciplinary team that will support DESC’s mission by using data queries, creating reports, and providing administrative services for programs leveraging the 1115 Waiver. Considerable attention and skills are needed in the areas of data analytics, presentation, and problem solving. The FCS Data Analyst will work closely with the Senior Manager of Policy and Program Analytics to ensure programs leveraging Medicaid Waiver dollars are complying with all applicable laws, regulations and contract requirements.

MAJOR DUTIES AND RESPONSIBILITIES:


 * Use data sources to perform validation and quality control checks to track performance and compliance in identified areas.
 * Assist with the collection of data and analysis requested by FCS third party administrator, Wellpoint.
 * Use SQL to access data and write reports to query information from databases.
 * Assist staff with client enrollment and communication of benefit status information.
 * Identify and create process improvements and workflow automation to increase program performance.
 * Collaborate with the Housing and Quality and Information Management Departments and other DESC partners to scope, design, and validate recurring and ad hoc reports.
 * Document project details and maintain report specifications that clearly describe how the report works, and work with end-users to ensure usage and usability.
 * Serves as a subject matter expert for department managers on documentation standards that comply with regulatory requirements.
 * Research, audit, and investigate proper payment of claims.
 * Assist in various quality assurance activities, including but not limited to fidelity audits.
 * Serve as a liaison between Wellpoint, King County, HCA, and DESC on all administrative matters.
 * Comply with all agency policies and procedures, relevant Washington Administrative Code, RCWs, and HIPAA Privacy Rules.
 * Attend and participate in relevant team meetings, agency sponsored trainings and all-staff meetings.
 * Other duties as assigned.
   
   

Requirements

MINIMUM QUALIFICATIONS:


 * Bachelor’s or associate degree, or 2 years of highly relevant paid work experience
 * 2 years’ experience in data analytics and financial accounting
 * Strong computer skills, including using word processors, analyzing Excel spreadsheets, and writing SQL queries.
 * Strong oral and written communication skills and ability to work effectively with staff from various backgrounds and disciplines.
 * Ability to organize and coordinate work efficiently; prioritize workload, work under pressure with tight timelines and changing priorities.
 * Ability to work independently with minimum supervision, and act on own initiative, within agency procedural guidelines.
 * Initiative and creativity in problem solving and system development.
 * A willingness to be flexible and work cooperatively with co-workers to accomplish all responsibilities of the team.
 * Subscribe to philosophy of cooperation and continuity across programs, and of consideration and respect for clients.
 * Experience handling confidential and proprietary information, including healthcare information
   
   

PREFERRED QUALIFICATIONS:


 * Experience working in social services with people experiencing homelessness, mental health conditions, and/or substance use disorders
 * Bachelor's degree in computer science, accounting, data analytics, healthcare management, analytical science, engineering, or related field or equivalent experience: advanced degree a plus.
 * 4 years highly relevant paid work experience.
 * Experience working in administration/coordination in a human services, housing or health care setting.
 * Experience with a formal programming language, such as Python, or R, PHP
   
   

PHYSICAL DEMANDS:

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. While performing the duties of this job, the employee will be required sit for long periods of time, communicate with other employees by talking and hearing, and to operate computer systems. Specific vision abilities required by the job include close vision, distance vision, color vision, peripheral vision, depth perception, and the ability to adjust focus.

EQUAL OPPORTUNITY EMPLOYER:

DESC is committed to diversity in the workplace, and promotes equal employment opportunities for all staff members and applicants. The Agency will not discriminate against any employee or applicant for employment on the basis of race, creed, color, sex, gender, sexual orientation, age, national origin, caste, marital status, or the presence of any sensory, mental or physical disability in any employment practice, unless based on a bona fide occupational qualification. Minorities and veterans are encouraged to apply.

Salary Description

$86,680.32 - $98,070.72","105 applicants","Full-time","Entry level","Information Technology","Mental Health Care","$86,680.32/yr - $98,070.72/yr","","","1265972","https://recruiting.paylocity.com/Recruiting/Jobs/Details/3746887?source=LinkedIn","EXTERNAL",""
"Research Engineer","New York, NY","3 weeks ago","2025-11-06","https://www.linkedin.com/jobs/view/research-engineer-at-datalab-4334426517?trk=public_jobs_topcard-title","Datalab","https://www.linkedin.com/company/datalabto?trk=public_jobs_topcard-org-name","Company Description

At Datalab, we train state-of-the-art language models that read documents with human-level accuracy and power the next generation of AI products, workflows, and research.




Our models - Chandra, Surya, and Marker - have become the backbone of document intelligence, with more than 50,000 GitHub stars and adoption across top tier 1 AI research labs, Fortune 500 enterprises, and government agencies.




We've grown to 7-figure ARR with ~7x growth in 2025, driven by a lean, senior team that operates with high autonomy and deep technical ownership.




Backed by founding members of OpenAI, FAIR, and Hugging Face. We move fast, ship often, and we're hiring builders who do the same.




Role Description

We’re looking for a Research Engineer to work across our open-source repos, inference API, and model training stack. You’ll operate at the intersection of applied research and engineering — shaping the models that power real-world document intelligence systems used by enterprises and developers globally.




You’ll be training and evaluating new model architectures, integrating them into production, and shipping updates across our open-source ecosystem. You’ll also help close the loop with users — investigating issues, improving benchmarks, and turning real feedback into better model performance.




Our team focuses on training small, efficient models that outperform much larger LLMs on domain-specific tasks (like OCR, structured extraction, and math recognition). We move fast, prioritize practical results, and build tools that are open, reproducible, and built to last.




Day to day, you will:

 * Train and evaluate models: Train task-specific models (OCR, layout, text recognition, extraction). Explore architectures and training strategies to optimize task performance.
 * Optimize inference: Profile and accelerate model inference across different hardware setups (H100s, L40s, CPUs).
 * Contribute to open source: Ship features and improvements to our core open-source repos, including model APIs, data loaders, evaluation scripts, and benchmark tooling.
 * Build and maintain datasets: Source, design, and clean datasets for supervised and synthetic training; create reproducible pipelines for data versioning and evaluation.
 * Experiment and benchmark: Run ablations, track metrics, and publish findings that inform model design and internal research direction.
 * Engage with users and partners: Occasionally join calls or Slack threads to help customers evaluate, deploy, and extend models.




Ideal Candidate

You’ve shipped models that made it into production. You understand how to balance exploration with delivery, and how to turn research insights into products people actually use. You work autonomously and thrive in unstructured environments, but you’re also a strong collaborator — you communicate clearly, document your work, and elevate the people around you.

 * 3+ years experience training, fine-tuning, and evaluating LLMs
 * Trained at least one production-grade model or system used in real-world applications
 * Deep expertise in PyTorch and Python, with strong fundamentals in deep learning (optimization, evaluation, architecture design)
 * Comfortable with data engineering, benchmarking, and performance profiling across hardware setups




Bonus points if you:

 * Have experience with OCR, document AI, or structured extraction
 * Have published work — whether that’s a paper, a benchmark report, or a deep technical blog post
 * Have been a major contributor to open-source projects, especially in ML, vision, or NLP
 * Enjoy writing about your work and sharing learnings with the community


","193 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","","","","106354891","https://www.linkedin.com/jobs/view/research-engineer-at-datalab-4334426517?trk=public_jobs_topcard-title","EASY_APPLY",""
"Machine Learning Engineer","San Francisco Bay Area","1 week ago","2025-11-23","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-ikuto-4338635971?trk=public_jobs_topcard-title","Ikuto","https://uk.linkedin.com/company/ikuto-group-ltd?trk=public_jobs_topcard-org-name","Machine Learning Engineer – Applied AI Systems

San Francisco, CA – On-site

$170k–$250k + equity




A venture-backed AI company is expanding its engineering group and looking for a Machine Learning Engineer to help push forward a new generation of decision-support products used in complex, data-heavy environments.




The team builds systems that analyse large, unstructured datasets and surface insights that help organisations make high-stakes choices more consistently. You’ll join a small group of engineers and researchers working on applied ML problems that combine pattern recognition, anomaly detection, language modelling and real-time data interpretation.




This is a hands-on engineering role where you’ll prototype, train, evaluate and productionise models that directly shape the product experience.




What you’ll work on

 * Designing and implementing ML pipelines for processing a wide variety of semi-structured inputs.
 * Training and adapting large language models to handle classification, extraction and reasoning tasks.
 * Developing methods to identify irregularities, inconsistencies and unusual patterns within customer-supplied data.
 * Improving the performance, latency and reliability of deployed models at scale.
 * Collaborating with software engineers to integrate new capabilities into customer-facing features.
 * Exploring new approaches in multimodal modelling, retrieval-augmented generation and adaptive learning systems.




Who you might be

 * Someone with professional experience in ML engineering, data science, applied research or similar.
 * Confident programming in Python and fluent with at least one modern deep learning toolkit.
 * Comfortable working with messy, real-world data rather than clean academic datasets.
 * Experience with information extraction, language models, anomaly detection or data quality modelling is valuable.
 * Interested in joining a company where the ML team has genuine influence over product direction.
 * Enjoys experimentation, iteration and solving problems that don’t have an obvious starting point.

(No strict requirement on years — strength of experience matters more than time served.)




Why this is different

 * You’ll work on technically challenging problems where accuracy genuinely matters.
 * The company is scaling quickly and investing heavily in expanding its AI group.
 * You’ll collaborate closely with product and engineering leadership, not sit in a research silo.
 * The environment is fast-moving, with opportunities to own projects end-to-end.
 * Generous salary, equity and benefits package.




Location & Work Style

 * On-site in San Francisco to support a highly collaborative engineering culture.
 * Hybrid flexibility may be available for senior hires already living in the Bay Area.

","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Information Technology & Services and Software Development","$200,000.00/yr - $300,000.00/yr","David Stephens","https://uk.linkedin.com/in/davidstephensikuto","71180304","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-ikuto-4338635971?trk=public_jobs_topcard-title","EASY_APPLY",""
"Software Engineer (Data Platform)","Cambridge, MA","2 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/software-engineer-data-platform-at-the-recruiting-guy-4321957511?trk=public_jobs_topcard-title","The Recruiting Guy","https://www.linkedin.com/company/the-recruitingguy?trk=public_jobs_topcard-org-name","Note: This position is open to remote applicants based in the US only.

Job Title: Software Engineer (Data Platform)

Location: Remote. United States ONLY.

Employment Type: Salaried W2 Full-Time.

Salary: $125,000 - $200,000

About The Company

We represent a rapidly growing data company in NYC that’s redefining how real-world assets are represented and traded on public blockchains. Their platform serves investors, issuers, and financial institutions by providing reliable analytics, market intelligence, and transparent data on tokenized assets across the globe.

They’re trusted by leading players in finance and blockchain for their accuracy, scale, and forward-thinking approach to digital asset infrastructure. It’s an exciting opportunity to join a team that’s helping shape the future of real-world asset tokenization and build technology that’s changing how the financial world connects.

Responsibilities


 * Build and scale core data systems and APIs that serve product-level analytics
 * Collaborate with application engineers to ensure clean data flow between backend systems and end-user features
 * Develop and optimize data pipelines using PySpark and Databricks
 * Work closely with the lead data engineer on system architecture and data infrastructure design
 * Participate in system design discussions focused on scalability, performance, and maintainability
 * Contribute to the full software development lifecycle, from design through deployment
 * Support product and engineering teams by turning raw data into usable insights
   
   

Ideal Background


 * 4 to 5+ years of software engineering experience, preferably focused on large-scale data systems
 * Strong proficiency in Python and experience with PySpark
 * Experience with distributed frameworks such as Apache Spark, Beam, Flink, or Kafka Streams
 * Proven ability to design, build, and maintain production-grade data pipelines and APIs
 * Background in computer science, computer engineering, applied mathematics, or a related field (top 50 university or equivalent rigor preferred)
 * Experience working on data-driven products rather than internal BI or reporting systems
 * Strong communication skills and the ability to explain technical tradeoffs clearly
 * High attention to detail, ownership mindset, and a passion for building high-quality systems
   
   

Nice to Have


 * Experience in fintech, blockchain, or other data-intensive environments
 * Hands-on experience with Databricks or real-time streaming data systems
 * Demonstrated curiosity and craftsmanship through side projects or open-source work
   
   

Skills: beam,apache spark,software engineering,api,flink,python,kafka streams","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Human Resources Services","$125,000.00/yr - $200,000.00/yr","","","105823297","https://www.linkedin.com/jobs/view/software-engineer-data-platform-at-the-recruiting-guy-4321957511?trk=public_jobs_topcard-title","EASY_APPLY",""
"Big Data Platform Engineer","Charlotte, NC","2 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/big-data-platform-engineer-at-veracity-software-inc-4339934275?trk=public_jobs_topcard-title","Veracity Software Inc","https://www.linkedin.com/company/veracitysoftwareinc?trk=public_jobs_topcard-org-name","Job Title: Big Data Platform Engineer

Duration: 12 Months

Location: Charlotte, NC - Hybrid Role

Job Summary:

We are seeking a highly skilled and motivated Tools Administration & Engineering Specialist to join our Data private cloud. This role involves working closely with other technical staff to manage, support, and engineer platform tools across various big data and cloud environments including Cloudera Data Platform (CDP), Hortonworks, and OpenShift Container Platform (OCP).

Key Responsibilities:


 * Administer and support tools on the Data private cloud , Including CDP, HWX, MapR.
 * Install, configure, and maintain data analytical and virtualization tools such as Dremio, JupyterHub and AtScale, across multiple clusters.
 * Develop proof-of-concept solutions leveraging CDP and OCP technologies.
 * Deploy tools and troubleshoot issues, perform root cause analysis, and remediate vulnerabilities.
 * Act as a technical subject matter expert, supporting programming staff during development, testing, and implementation phases.
 * Develop automation scripts for configuration and maintenance of data virtualization tools.
 * Lead complex platform design, coding, and testing efforts.
 * Drive advanced modeling, simulation, and analysis initiatives.
 * Maintain comprehensive documentation of Hadoop cluster configurations, processes, and procedures.
 * Generate reports on cluster usage, performance metrics, and capacity utilization.
 * Work closely with data engineers, data scientists, and other stakeholders to understand their requirements and provide necessary support.
 * Collaborate with IT infrastructure teams for integrating Dremio Tool, Hadoop clusters with existing systems and services.
   
   

Required Skills & Experience:


 * Strong experience with big data platforms: MapR, Hortonworks, Cloudera Data Platform.
 * Hands-on expertise with data virtualization tools: Dremio, JupyterHub, AtScale.
 * Proficiency in deploying and managing tools in cloud and containerized environments (CDP, OCP).
 * Solid understanding of platform engineering, automation scripting, and DevOps practices.
 * Proven ability to troubleshoot complex issues and perform root cause analysis.
 * Experience in leading technical efforts and mentoring team members.
   
   

Preferred Qualifications:


 * Certifications in Cloudera, OpenShift, or related technologies.
 * Experience with enterprise-level data lake architectures and governance.","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","11137552","https://www.linkedin.com/jobs/view/big-data-platform-engineer-at-veracity-software-inc-4339934275?trk=public_jobs_topcard-title","EASY_APPLY",""
"Software Engineer (Data Platform)","Boston, MA","2 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/software-engineer-data-platform-at-the-recruiting-guy-4321857727?trk=public_jobs_topcard-title","The Recruiting Guy","https://www.linkedin.com/company/the-recruitingguy?trk=public_jobs_topcard-org-name","Note: This position is open to remote applicants based in the US only.

Job Title: Software Engineer (Data Platform)

Location: Remote. United States ONLY.

Employment Type: Salaried W2 Full-Time.

Salary: $125,000 - $200,000

About The Company

We represent a rapidly growing data company in NYC that’s redefining how real-world assets are represented and traded on public blockchains. Their platform serves investors, issuers, and financial institutions by providing reliable analytics, market intelligence, and transparent data on tokenized assets across the globe.

They’re trusted by leading players in finance and blockchain for their accuracy, scale, and forward-thinking approach to digital asset infrastructure. It’s an exciting opportunity to join a team that’s helping shape the future of real-world asset tokenization and build technology that’s changing how the financial world connects.

Responsibilities


 * Build and scale core data systems and APIs that serve product-level analytics
 * Collaborate with application engineers to ensure clean data flow between backend systems and end-user features
 * Develop and optimize data pipelines using PySpark and Databricks
 * Work closely with the lead data engineer on system architecture and data infrastructure design
 * Participate in system design discussions focused on scalability, performance, and maintainability
 * Contribute to the full software development lifecycle, from design through deployment
 * Support product and engineering teams by turning raw data into usable insights
   
   

Ideal Background


 * 4 to 5+ years of software engineering experience, preferably focused on large-scale data systems
 * Strong proficiency in Python and experience with PySpark
 * Experience with distributed frameworks such as Apache Spark, Beam, Flink, or Kafka Streams
 * Proven ability to design, build, and maintain production-grade data pipelines and APIs
 * Background in computer science, computer engineering, applied mathematics, or a related field (top 50 university or equivalent rigor preferred)
 * Experience working on data-driven products rather than internal BI or reporting systems
 * Strong communication skills and the ability to explain technical tradeoffs clearly
 * High attention to detail, ownership mindset, and a passion for building high-quality systems
   
   

Nice to Have


 * Experience in fintech, blockchain, or other data-intensive environments
 * Hands-on experience with Databricks or real-time streaming data systems
 * Demonstrated curiosity and craftsmanship through side projects or open-source work
   
   

Skills: beam,apache spark,software engineering,api,flink,python,kafka streams","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Human Resources Services","$125,000.00/yr - $200,000.00/yr","","","105823297","https://www.linkedin.com/jobs/view/software-engineer-data-platform-at-the-recruiting-guy-4321857727?trk=public_jobs_topcard-title","EASY_APPLY",""
"Machine Learning Engineer","Dallas, TX","1 month ago","2025-10-18","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-tiger-analytics-4335782158?trk=public_jobs_topcard-title","Tiger Analytics","https://www.linkedin.com/company/tiger-analytics?trk=public_jobs_topcard-org-name","Tiger Analytics is an advanced analytics consulting firm. We are the trusted analytics partner for several Fortune 100 companies, enabling them to generate business value from data. Our consultants bring deep expertise in Data Science, Machine Learning, and AI. Our business value and leadership have been recognized by various market research firms, including Forrester and Gartner.

Are you a Machine Learning Engineer with expertise in Google Cloud Platform (GCP) and Vertex AI? We are looking for two talented professionals to join our team in a fully remote, onshore capacity. If you thrive in building and deploying scalable AI solutions, this role is for you!

What You'll Do:


 * Collaborate with cross-functional teams to design and deploy ML models.
 * Develop reusable, scalable code for AI/ML applications.
 * Leverage GCP services to build end-to-end machine learning pipelines.
 * Optimize models for performance and scalability using Vertex AI
   
   

Requirements

Key Requirements:


 * Google Cloud Platform (GCP) Experience: Strong proficiency in GCP services, including data engineering and machine learning tools.
 * Google Vertex AI Expertise: Hands-on experience with model training, deployment, and optimization using Vertex AI.
 * Model Development & Deployment: Proven ability to design, build, and productionize machine learning models.
 * API Development: Skilled in developing robust APIs for seamless integrations.
 * Python Programming with CI/CD: Experience in Python-based applications and implementing CI/CD pipelines.
   
   

Why Join Us?


 * Work remotely while contributing to cutting-edge projects.
 * Collaborate with a dynamic team passionate about AI/ML innovation.
 * Opportunity to work with the latest Google Cloud technologies.
   
   

Ready to take the next step? Apply now and be part of a team that's shaping the future of AI!

Benefits

Significant career development opportunities exist as the company grows. The position offers a unique opportunity to be part of a small, fast-growing, challenging and entrepreneurial environment, with a high degree of individual responsibility.","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","2010798","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-tiger-analytics-4335782158?trk=public_jobs_topcard-title","EASY_APPLY",""
"Software Engineer (Data Platform)","Seattle, WA","2 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/software-engineer-data-platform-at-the-recruiting-guy-4321917612?trk=public_jobs_topcard-title","The Recruiting Guy","https://www.linkedin.com/company/the-recruitingguy?trk=public_jobs_topcard-org-name","Note: This position is open to remote applicants based in the US only.

Job Title: Software Engineer (Data Platform)

Location: Remote. United States ONLY.

Employment Type: Salaried W2 Full-Time.

Salary: $125,000 - $200,000

About The Company

We represent a rapidly growing data company in NYC that’s redefining how real-world assets are represented and traded on public blockchains. Their platform serves investors, issuers, and financial institutions by providing reliable analytics, market intelligence, and transparent data on tokenized assets across the globe.

They’re trusted by leading players in finance and blockchain for their accuracy, scale, and forward-thinking approach to digital asset infrastructure. It’s an exciting opportunity to join a team that’s helping shape the future of real-world asset tokenization and build technology that’s changing how the financial world connects.

Responsibilities


 * Build and scale core data systems and APIs that serve product-level analytics
 * Collaborate with application engineers to ensure clean data flow between backend systems and end-user features
 * Develop and optimize data pipelines using PySpark and Databricks
 * Work closely with the lead data engineer on system architecture and data infrastructure design
 * Participate in system design discussions focused on scalability, performance, and maintainability
 * Contribute to the full software development lifecycle, from design through deployment
 * Support product and engineering teams by turning raw data into usable insights
   
   

Ideal Background


 * 4 to 5+ years of software engineering experience, preferably focused on large-scale data systems
 * Strong proficiency in Python and experience with PySpark
 * Experience with distributed frameworks such as Apache Spark, Beam, Flink, or Kafka Streams
 * Proven ability to design, build, and maintain production-grade data pipelines and APIs
 * Background in computer science, computer engineering, applied mathematics, or a related field (top 50 university or equivalent rigor preferred)
 * Experience working on data-driven products rather than internal BI or reporting systems
 * Strong communication skills and the ability to explain technical tradeoffs clearly
 * High attention to detail, ownership mindset, and a passion for building high-quality systems
   
   

Nice to Have


 * Experience in fintech, blockchain, or other data-intensive environments
 * Hands-on experience with Databricks or real-time streaming data systems
 * Demonstrated curiosity and craftsmanship through side projects or open-source work
   
   

Skills: beam,apache spark,software engineering,api,flink,python,kafka streams","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Human Resources Services","$125,000.00/yr - $200,000.00/yr","","","105823297","https://www.linkedin.com/jobs/view/software-engineer-data-platform-at-the-recruiting-guy-4321917612?trk=public_jobs_topcard-title","EASY_APPLY",""
"FBI Special Agent: Data Science & Intelligence Expertise","Bellevue, WA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/fbi-special-agent-data-science-intelligence-expertise-at-federal-bureau-of-investigation-fbi-4338206292?trk=public_jobs_topcard-title","Federal Bureau of Investigation (FBI)","https://www.linkedin.com/company/fbi?trk=public_jobs_topcard-org-name","JOB DESCRIPTION




The position advertised has been exempted from the federal civilian hiring freeze.




As an FBI special agent with data engineering and big data experience, you'll directly impact national security. By harnessing your background to transition into federal law enforcement, you can help shape the Bureau’s approach to safeguarding our nation. At the FBI, you will have the opportunity to channel your data science, cloud infrastructure, or IoT systems expertise to protect our nation from cyberattacks, terrorism, fraud, and evolving threats. From conducting high-stakes investigations with your proficiency in advanced statistical modeling and data governance to leveraging your depth of knowledge in predictive modeling to identify trends and prevent criminal activity, your technical skills are essential to investigating crimes that threaten public safety. Your transition from a specialized career to a special agent role will be transformative as you employ your expertise to tackle national security challenges in innovative ways. Every day brings new challenges that demand your adaptability and resilience, but you’re not alone in this journey. The Bureau matches your dedication with a commitment to professional growth, a supportive work environment, and a robust benefits package that prioritizes you. Set yourself apart. Apply Today.




HOW TO APPLY




STEP 1: Click on the “Apply” button to be directed to the FBIJobs Careers website.




STEP 2: Click the “Start” button to begin. You will be prompted to either sign in to continue or register with FBIJobs if you don’t already have an account.




STEP 3: Follow the step-by-step process to submit your interest. You will be guided through each step. You must complete all sections of the form AND ALL REQUIRED DOCUMENTS MUST BE ATTACHED to successfully submit your interest.




 1. Your resume, specifically noting relevant work experience and associated start and end dates. Please note your resume MUST NOT exceed two (2) pages.
 2. Other supporting documents:

 * College transcripts, if qualifying based on education or if there is a positive education requirement.
 * Veterans: DD 214; Disabled Veterans: DD 214, SF-15, and VA letter dated 1991 or later.




Please see instructions on the site for attaching documents.




SALARY LEVEL




Pay level for this position:

 * $99,461.00–$128,329.00




Salary is commensurate with base, locality, and availability pay.




MAJOR DUTIES

 * Plan and conduct investigations of potential violations of federal laws, cybersecurity, and public safety.
 * Exercise judgment, resourcefulness, and versatility in meeting investigative demands.
 * Create and maintain effective liaison relationships with federal, state, local, tribal, territorial, and international law enforcement agencies.
 * Maintain a level of physical fitness to ensure the readiness required to perform law enforcement duties.




KEY REQUIREMENTS

 * Must be a U.S. citizen.
 * Must be able to obtain a Top Secret Sensitive Compartmented Information (SCI) Clearance.
 * Must be willing to travel as required.
 * Must meet the FBI’s Employment Eligibility requirements.
 * Must have a master's degree or higher from a U.S. accredited college or university.




The FBI is an Equal Opportunity Employer, and all qualified applicants will receive consideration for this vacancy. Unless explicitly authorized by law, selection will be made without regard to, and there will be no discrimination because of, color, race, religion, national origin, marital status, parental status, physical or mental disability, genetic information, age (40 or over), sex, pregnancy and related conditions, or on the basis of personal favoritism, or any other nonmerit factors.","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering","Higher Education, Software Development, and IT Services and IT Consulting","$99,461.00/yr - $128,329.00/yr","","","6408","https://www.linkedin.com/jobs/view/fbi-special-agent-data-science-intelligence-expertise-at-federal-bureau-of-investigation-fbi-4338206292?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","San Francisco, CA","1 week ago","2025-11-24","https://www.linkedin.com/jobs/view/data-engineer-at-air-apps-4347465796?trk=public_jobs_topcard-title","Air Apps","https://www.linkedin.com/company/airapps?trk=public_jobs_topcard-org-name","About Air Apps

At Air Apps, we believe in thinking bigger—and moving faster. We’re a family-founded company on a mission to create the world’s first AI-powered Personal & Entrepreneurial Resource Planner (PRP), and we need your passion and ambition to help us change how people plan, work, and live. Born in Lisbon, Portugal in 2018—and now with offices in both Lisbon and San Francisco—we’ve remained self-funded while reaching over 100 million downloads worldwide.

Our long-term focus drives us to challenge the status quo every day, pushing the boundaries of AI-driven solutions that truly make a difference. Here, you’ll be a creative force, shaping products that empower people across the globe.

Join us on this journey to redefine resource management—and change lives along the way.

The Role

As a Data Engineer at Air Apps, you will be responsible for designing, building, and optimizing data pipelines, data warehouses, and data lakes to ensure efficient data processing and analytics. You will work closely with data analysts, scientists, and software engineers to create scalable and reliable data infrastructure that supports business intelligence and machine learning initiatives.

This role requires expertise in data architecture, ETL processes, and cloud-based data solutions to handle large volumes of structured and unstructured data.

Responsibilities


 * Design, build, and maintain scalable data pipelines and ETL workflows to support analytics and reporting.
 * Develop and optimize data warehouses and data lakes using cloud platforms such as AWS, Google Cloud, or Azure.
 * Implement real-time and batch data processing solutions for various business needs.
 * Work with structured and unstructured data, ensuring proper data modeling and storage strategies.
 * Ensure data reliability, consistency, and scalability through best practices in architecture and engineering.
 * Collaborate with data analysts, scientists, and software engineers to enable efficient data access and analysis.
 * Automate data ingestion, transformation, and validation processes to improve data quality.
 * Monitor and optimize query performance and data processing efficiency.
 * Implement security, compliance, and governance standards for data storage and access control.
 * Stay up to date with emerging data engineering trends, tools, and technologies.
   
   

Requirements


 * Around 4+ years of experience in data engineering, software engineering, or database management.
 * Proficiency in SQL, Python, or Scala for data processing and automation.
 * Hands-on experience with cloud-based data solutions (AWS Redshift, Google BigQuery, Azure Synapse, Snowflake).
 * Experience building ETL pipelines with tools such as Apache Airflow, dbt, Talend, or Fivetran.
 * Strong understanding of data modeling, schema design, and database optimization.
 * Experience with big data frameworks (Apache Spark, Hadoop, Kafka, Flink) is a plus.
 * Familiarity with orchestration tools, containerization (Docker, Kubernetes), and CI/CD workflows.
 * Knowledge of data security, governance, and compliance (GDPR, CCPA, SOC 2).
 * Strong problem-solving and debugging skills with the ability to handle large-scale data challenges.
 * Experience working in fast-paced, data-driven environments with cross-functional teams.
   
   

What benefits are we offering?


 * Apple hardware ecosystem for work.
 * Annual Bonus.
 * Medical Insurance (including vision & dental).
 * Disability insurance - short and long-term.
 * 401k up to 4% contribution.
 * Air Conference – an opportunity to meet the team, collaborate, and grow together.
 * Transportation budget
 * Free meals at the hub
 * Gym membership
   
   

Diversity & Inclusion

At Air Apps, we are committed to fostering a diverse, inclusive, and equitable workplace. We enthusiastically welcome applicants from all backgrounds, experiences, and perspectives. We celebrate diversity in all its forms and believe that varied voices and experiences make us stronger.

Application Disclaimer

At Air Apps, we value transparency and integrity in our hiring process. Applicants must submit their own work without any AI-generated assistance. Any use of AI in application materials, assessments, or interviews will result in disqualification.","Over 200 applicants","Full-time","Entry level","Information Technology","Technology, Information and Internet","","","","11482067","https://jobs.ashbyhq.com/airapps/4927a40b-d1aa-41e9-a14e-49483969d80c?src=LinkedIn","EXTERNAL",""
"Head of PT Data Engineering","Oceanside, CA","1 week ago","2025-11-22","https://www.linkedin.com/jobs/view/head-of-pt-data-engineering-at-roche-4293225032?trk=public_jobs_topcard-title","Roche","https://ch.linkedin.com/company/roche?trk=public_jobs_topcard-org-name","At Roche you can show up as yourself, embraced for the unique qualities you bring. Our culture encourages personal expression, open dialogue, and genuine connections, where you are valued, accepted and respected for who you are, allowing you to thrive both personally and professionally. This is how we aim to prevent, stop and cure diseases and ensure everyone has access to healthcare today and for generations to come. Join Roche, where every voice matters.

The Position

The Pharma Technical Operations (PT) department is establishing the One PT Data Office to serve as the strategic center for data governance, strategy, and enablement across the entire global PT network. This team is at the heart of our digital transformation, responsible for architecting and leading a central data office to unlock the full potential of PT’s data assets.

The Head of PT Data Engineering will be instrumental in building the robust data backbone that powers PT's digital transformation and data driven decision making. Reporting into the One PT Data Office, this critical role is accountable for leading a cutting-edge internal and external global data engineering team. You will define the strategy, evolve the data platforms and processes, and oversee the delivery of scalable, high-quality data products to enable advanced analytics, AI initiatives, and critical business processes across Pharma Technical Operations. You will lead a critical team of internal and external data engineers, fostering a culture of technical excellence, innovation, and continuous delivery. This pivotal role requires a visionary leader to build and manage the foundational data infrastructure, pipelines, and platforms that enable the seamless flow of high-quality, FAIR data from diverse sources to data consumers, ensuring compliance, scalability, and future readiness for PT's ambitious digital agenda.

The Opportunity


 * Provide strategic leadership and vision for PT's global data engineering capabilities, defining the roadmap for data ingestion, transformation, storage, and consumption architectures
 * Accountable for the design, development, and evolution of scalable, robust, and cost-effective data platforms (e.g., data lakes, data warehouses, streaming platforms) that support PT's advanced analytics, AI/ML, and data product needs
 * Define and implement best practices, standards, and guidelines for data modeling, ETL/ELT processes, data quality, and data pipeline orchestration across the PT landscape
 * Actively monitor and integrate cutting-edge industry trends, emerging data engineering technologies, and cloud-native solutions to continually optimize PT's data infrastructure in close collaboration with IT
 * Build, mentor, mobilize, and empower a high-performing, global team of internal and external data engineers, fostering a culture of technical excellence, innovation, and agile delivery
 * Accountable for the end-to-end delivery and operational excellence of critical data pipelines, ensuring timely, accurate, and reliable data availability for PT's business processes and analytical use cases
 * Ensure data infrastructure and pipelines adhere to strict quality, security, and compliance standards (e.g., GxP, data integrity, data privacy), collaborating closely with Data Governance and Cybersecurity teams
 * Drive the automation and optimization of data engineering workflows to enhance efficiency, reduce manual effort, and improve data freshness
   
   

Who You Are


 * 12+ years of progressive experience in data engineering, data platform architecture, or related roles within a complex, global enterprise, preferably in life sciences/pharma and 7+ years of senior leadership experience, specifically building, developing, and leading large, global teams of data engineers
 * Proven track record of successfully designing, implementing, and scaling robust data pipelines and cloud-based data platforms (AWS, Azure, GCP data services) for advanced analytics and AI/ML
 * Expert-level knowledge of modern data architectures, ETL/ELT, data orchestration, and data quality management
 * Strong understanding of GxP, data integrity, and data privacy regulations in a manufacturing context
 * Exceptional strategic thinking, communication, and influencing skills to lead and align diverse stakeholders globally
 * Bachelor's degree in a relevant technical field required; Master's or advanced certifications are highly advantageous
   
   

Ready for the next step? We look forward to hearing from you. Apply now to discover this exciting opportunity!

Who we are

A healthier future drives us to innovate. Together, more than 100’000 employees across the globe are dedicated to advance science, ensuring everyone has access to healthcare today and for generations to come. Our efforts result in more than 26 million people treated with our medicines and over 30 billion tests conducted using our Diagnostics products. We empower each other to explore new possibilities, foster creativity, and keep our ambitions high, so we can deliver life-changing healthcare solutions that make a global impact.

Let’s build a healthier future, together.

Roche is an Equal Opportunity Employer.

Roche is an equal opportunity employer and strictly prohibits unlawful discrimination based upon an individual's race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, mental/physical disability, medical condition, marital status, veteran status, or any other characteristic protected by law.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Pharmaceutical Manufacturing, Biotechnology Research, and Medical Equipment Manufacturing","","","","1602","https://www.linkedin.com/jobs/view/head-of-pt-data-engineering-at-roche-4293225032?trk=public_jobs_topcard-title","EASY_APPLY",""
"Bioinformatics Engineer","San Francisco Bay Area","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/bioinformatics-engineer-at-metric-bio-4334339317?trk=public_jobs_topcard-title","Metric Bio","https://www.linkedin.com/company/metric-bio?trk=public_jobs_topcard-org-name","Bioinformatics Engineer | Onsite, San Francisco




Join a team of engineers and scientists building the cloud infrastructure transforming modern biotech R&D. Their platform enables researchers to store, analyze, and collaborate on complex biological data seamlessly; bridging wet-lab discovery with computational insight to accelerate breakthroughs in drug development, genomics, and synthetic biology.




The team is seeking a Bioinformatics Engineer to collaborate directly with customers, migrate and scale their computational workflows, and design robust, reproducible systems that advance the future of data-driven biology.




You’ll thrive here if you’re a scientifically fluent engineer who bridges experimentation and computation; someone who works independently, communicates clearly, and takes ownership from concept to delivery.




Key Responsibilities

 * Partner with scientists to understand experimental goals and translate them into scalable, cloud-based workflows.
 * Build and maintain reproducible bioinformatics pipelines using Nextflow, Snakemake, or similar frameworks.
 * Analyze and visualize complex datasets in Python and R, turning results into actionable insights.
 * Diagnose and resolve workflow, data, and infrastructure issues to ensure reliable performance.
 * Collaborate with product and engineering teams to improve platform capabilities and streamline bioinformatics tooling.
 * Rapidly learn and integrate emerging techniques such as spatial ATAC-seq or single-nucleus RNA-seq.
 * Approach problems critically; understanding the biological questions, experimental design, and tradeoffs between methods.




Qualifications

 * Strong foundation in statistics, linear algebra, and algorithmic reasoning with understanding of bioinformatics methods.
 * Proven experience building and maintaining sequencing or multi-omics data pipelines.
 * Proficiency in Python, R, and workflow orchestration tools such as Nextflow, Snakemake.
 * Familiarity with machine learning or LLM-based approaches for biological analysis is a plus.
 * Solid grasp of software engineering practices including testing, documentation, and version control.
 * Excellent communicator with the ability to interface across scientific and engineering teams.
 * Curious, adaptable, and eager to learn new computational and biological domains.




If all this sounds like you, I'd love to introduce you to the team directly.

","Over 200 applicants","Full-time","Mid-Senior level","Engineering and Science","Biotechnology Research","","Saul Hernandez 🌵","https://www.linkedin.com/in/saulhjr","101789238","https://www.linkedin.com/jobs/view/bioinformatics-engineer-at-metric-bio-4334339317?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI Engineer","Austin, TX","1 month ago","2025-10-09","https://www.linkedin.com/jobs/view/ai-engineer-at-gyde-4333778887?trk=public_jobs_topcard-title","Gyde","https://www.linkedin.com/company/gydeinc?trk=public_jobs_topcard-org-name","About Us


 * Insurance brokers sit at the intersection of care, cost, and access — yet remain one of the most underleveraged assets in the $5T healthcare value chain. They guide millions of Americans through plan selection, coverage questions, and care navigation, yet still rely on spreadsheets, manual workflows, and outdated tools that limit their growth and impact.
 * Gyde is reimagining this. We’re building the first AI-native insurance brokerage platform—a system that learns from every client interaction to automate operations, power intelligent voice and chat experiences, and predict the right coverage and products for every individual or business.
 * Our approach combines acquisition and AI: we acquire traditional brokerages and transform them into next-generation, data-driven organizations. Through Gyde’s platform, agencies run more efficiently, serve clients more personally, and scale faster than ever before.
 * Join us if you’re excited to:
    * Redefine how millions of people access and understand their healthcare coverage, by building systems that turn unstructured data, human conversations, and fragmented processes into intelligence.
    * Build AI systems that improve how people access healthcare
    * Design production-grade voice, chat, and predictive models for a highly regulated domain
    * Launch technologies that augment human judgment and make complex decisions transparent and scalable
    * Help reinvent an entire industry from the inside out

 * We’re creating the future of brokerage — where every interaction, insight, and decision is powered by intelligence.
 * Our founding team boasts pedigrees from Oscar, Stripe, and Spark. Lightspeed led Gyde’s Seed financing, with participation from Virtue and Crystal Venture Partners, and angels from Oscar, Uber, and more.
   

Role Summary

You will lead the development and delivery of key applications within Gyde’s AI-native brokerage platform—encompassing voice, chat, personalization, and real-time analytics—to drive growth, automation, and insights across acquired agencies. You’ll partner with our COO on AI-driven workflows, and Product on roadmap prioritization.

Key Responsibilities


 * Build AI-driven applications. Develop applications that use LLMs, voice, and chat to automate broker workflows, unlock revenue growth opportunities, and improve member engagement.
 * Ship quality products fast and compliantly. Build tools and infrastructure with a focus on security, reliability, and HIPAA compliance.
 * Integrate with third-party systems. Connect to platforms like AgencyBloc, Sunfire, HealthSherpa, and Ideon to streamline agent and member experiences.
 * Design for scale. Contribute to a modular, multi-tenant architecture that supports tens of agencies and millions of members on our platform, as well as key capabilities that enable agent growth, carrier contracting, commission processing, and reporting.
 * Collaborate across functions. Partner with Ops, Value Creation, and Data teams to translate real-world brokerage problems into elegant, scalable engineering solutions.
   
   

What You Bring And Who You Are


 * Strong product sense, fluent in user needs, and an ability to build with empathy for both agents and end consumers (we’ll be in agency offices frequently!).
 * A passion for building on the frontier of AI, and, ideally, experience building AI applications.
 * A high degree of ownership, urgency, and pragmatism. You thrive in ambiguity and take pride in tackling challenging tasks effectively.
 * You will only work with world-class talent, and you are both highly team-oriented and competitive.
 * Bachelor’s or advanced degree in CS, Engineering, AI/ML, or equivalent.
 * 3+ years of engineering leadership, and 1+ years building AI/ML products at scale
 * Familiarity with health insurance distribution, healthcare, financial services, and HIPAA compliance is preferred but not required.
   
   

What We Offer

Gyde offers a competitive benefits package to all employees.


 * Top of the market compensation
 * Flexible (Unlimited) Paid Time Off
 * Remote, or Hybrid Work in Austin or NYC
 * Medical, Dental, and Vision benefits for you and your family
 * Retirement Plan (e.g., 401K)
 * Parental Leave","29 applicants","Full-time","Entry level","Engineering","Construction, Software Development, and IT Services and IT Consulting","","","","109051250","https://www.linkedin.com/jobs/view/ai-engineer-at-gyde-4333778887?trk=public_jobs_topcard-title","EASY_APPLY",""
"Software Engineer II, Data Engineering & Infrastructure","Pittsburgh, PA","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/software-engineer-ii-data-engineering-infrastructure-at-aurora-4301603144?trk=public_jobs_topcard-title","Aurora","https://www.linkedin.com/company/auroradriver?trk=public_jobs_topcard-org-name","Who We Are

Aurora’s mission is to deliver the benefits of self-driving technology safely, quickly, and broadly.

The Aurora Driver will create a new era in mobility and logistics, one that will bring a safer, more efficient, and more accessible future to everyone.

At Aurora, you will tackle massively complex problems alongside other passionate, intelligent individuals, growing as an expert while expanding your knowledge. For the latest news from Aurora, visit aurora.tech or follow us on LinkedIn.

Aurora hires talented people with diverse backgrounds who are ready to help build a transportation ecosystem that will make our roads safer, get crucial goods where they need to go, and make mobility more efficient and accessible for all. We are seeking a talented and experienced Software Engineer to join our data engineering and infrastructure team. In this role, you will be a key contributor to the design, development, and maintenance of our data platform, building the scalable and reliable systems that enable our organization to leverage data for insights and product innovation. You will work on the core data lake and data warehouse ecosystem infrastructure, data pipelines, and tools that process data at massive scale, ensuring it is accessible, high-quality, and secure.

In this role, you will


 * Design, build, and maintain robust and scalable data pipelines and ETL/ELT processes to ingest, transform, and load data from various sources into our data warehouse.
 * Develop and manage data infrastructure components using AWS cloud services and infrastructure-as-code tools like Terraform.
 * Collaborate with data scientists, analysts, autonomy engineering teams and product teams to understand their data needs and build solutions that meet their requirements.
 * Optimize data processing systems for performance, reliability, and cost-efficiency.
 * Implement monitoring, alerting, and logging for data pipelines and infrastructure to ensure operational stability.
 * Champion best practices in data governance, data quality, and security.
   
   

Required Qualifications


 * Bachelor’s degree in Computer Science, Engineering, or a related field, or equivalent practical experience.
 * 3+ years of professional experience in software engineering, with a focus on data-related projects.
 * Proficiency in at least one programming language commonly used for data engineering (e.g., Python, Go or C++).
 * Solid experience with big data processing frameworks like Apache Spark, Flink, Kinesis Data Stream, or similar technologies.
 * Hands-on experience with cloud platforms (AWS, GCP, or Azure) and their data services (e.g., S3, Redshift, BigQuery, Glue).
 * Strong knowledge of SQL and experience working with relational and NoSQL databases.
 * Intermediate knowledge of data analytics infrastructure, including data transformation tools such as DBT and visualization frameworks and tools
 * Experience with building and managing data pipelines using an orchestrator like Apache Airflow.
 * Able to systematically approach open-ended questions to identify pragmatic data solutions that scale
 * Able to work effectively in a highly cross-functional, fast-moving and high-stakes environment
 * Proven ability to communicate technical, data-driven solutions to both technical and non-technical audiences across stakeholders
   
   

Desirable Qualifications


 * Experience with data warehousing solutions like Snowflake or data lake architectures.
 * Familiarity with modern data stack tools and practices.
 * A passion for building elegant, scalable, and maintainable systems.
 * Experience using Amazon Web Services (AWS) tools
   
   

The base salary wage range for this position is $139,000 - $223,000 per year. Aurora’s pay ranges are determined by role, level, and location. Within the range, the successful candidate’s starting base pay will be determined based on factors including job-related skills, experience, qualifications, relevant education or training, and market conditions. These ranges may be modified in the future. The successful candidate will also be eligible for an annual bonus, equity compensation, and benefits.

#Entry-Level

Working at Aurora

At Aurora, we bring together extraordinarily talented and experienced people united by the strength of our values. We operate with integrity, set outrageous goals, and build a culture where we win together — all without any jerks. Our Careers page provides insight into what it is like to work at Aurora, and you can find all the latest updates in our Newsroom.

Commitment to inclusion

Aurora considers candidates without regard to their race, color, religion, national origin, age, sex, gender, gender identity, gender expression, sexual orientation, marital status, pregnancy status, parent or caregiver status, ancestry, political affiliation, veteran and/or military status, physical or mental disability, or any other status protected by federal or state law. Aurora considers qualified applicants with criminal histories, consistent with applicable federal, state, and local law. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at careersiteaccommodations@aurora.tech.

For California applicants, information collected and processed as part of your application and any job applications you choose to submit is subject to Aurora’s California Employment Privacy Policy.

","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","$139,000.00/yr - $223,000.00/yr","","","17973173","https://aurora.tech/jobs/8172107002?gh_src=b6049de52us","EXTERNAL",""
"Data Engineer - Senior","Atlanta, GA","2 weeks ago","2025-11-14","https://www.linkedin.com/jobs/view/data-engineer-senior-at-women-of-the-vine-spirits-4336152150?trk=public_jobs_topcard-title","Women of the Vine & Spirits","https://www.linkedin.com/company/women-of-the-vine?trk=public_jobs_topcard-org-name","Company

Republic National Distributing Company

Location

Atlanta, GA

Other

Other

Apply

Republic National Distributing Company (RNDC) is a family-owned business with roots extending before Prohibition that has evolved into one of the nation's largest wine and spirits wholesalers. Our success is grounded in our core values of Family, Service, Accountability, Honesty, and Professionalism. We offer a vibrant, inclusive culture and workplace experience for individuals who want a career that makes them feel accomplished and engaged. RNDC values the health and well-being of our associates, inside and outside the office, offering dynamic health and wellness benefits that supply exceptional care and value. RNDC is geared toward growing our footprint and our people. Join our team of energetic professionals who believe in many happy hours and are experts in our craft.

Summary

The Senior Data Engineer manages and organises RNDC's enterprise data. They will translate requirements and designs into functional data pipelines while ensuring the continued quality and completeness of the information. Senior Data Engineers will combine raw information from different sources to create consistent and machine-readable datasets that are easy to analyze and support company initiatives. They will support other Data Engineers and Data Analysts on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They will also implement methods to improve data reliability and quality, improve data visibility and reduce effort through automation.

In this role, you will


 * Contribute on a team of data engineers through design, demand delivery, code reviews, release management, implementation, presentations, and meetings.
 * Mentor fellow data engineers and contribute to ongoing process improvements for the team
 * Evaluate business needs and objectives and align architecture/designs with business requirements
 * Build the data pipelines required for the optimal extraction, transformation, integration and loading of raw data from a wide variety of data sources
 * Assemble large, complex data sets and model our data in a way that meets functional / non-functional business requirements
 * Create data tools for analytics team members that assist them in generating innovative industry insights that provide our business a competitive advantage
 * Implement data tagging mechanisms and metadata management so data is accurately classified and visible to the organization
 * Build processes to help identify and improve data quality, consistency and effectiveness
 * Ensure our data is managed in a way that it conforms to all information privacy and protection policies
 * Use agile software development processes to iteratively make improvements to our data management systems
   
   

What you bring to RNDC

Bachelor's/Tech School degree in Computer Science, Information Systems, Engineering or equivalent and/or commensurate years of real-world experience in software engineering.

4+ years of relevant experience in data management

3+ years in data engineering with detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT

Experience with performance analysis and optimization

Experience in data acquisition, transformation and storage design using design principles, patterns and best practices

What's in it for you


 * 401(k) with company matching
 * Medical, dental and vision benefits*
 * Generous paid time off program - work your way up to 5 weeks of PTO a year with the ability to carryover unused PTO
 * Paid volunteer time
 * Paid parental leave
 * Paid caregiver leave
 * Fertility benefits
 * Paid training
 * Company paid life insurance, short-term disability, and company-paid holidays
 * Associate resource groups, and diversity, equity, and inclusion programs available for all associates
 * Participation in these programs are subject to applicable wait periods and all plan and program terms and eligibility
   
   

COVID-19 Considerations

We follow CDC Guidelines and have a fun and safe environment for our teams.

Bonus if you bring


 * Data engineering certification is a plus
 * Previous experience in the Wine and Spirits industry
   
   

Republic National Distributing Company and National Distributing Company are Equal Opportunity/Affirmative Action employers. It is our policy not to discriminate against any Employee or Applicant. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex, age, status as a protected veteran, among other things, or status as a qualified individual with disability. This policy of nondiscrimination in employment includes but is not limited to: recruitment, hiring, placement, promotion, transfer, employment advertising or solicitations, compensation, layoff or termination of employment.

RNDC is committed to providing reasonable accommodation to people with disabilities throughout the job application and interview process, to the point of undue hardship. If you require an accommodation during the application or interview process, pleaseclick here.

Nearest Major Market: Atlanta

Apply","111 applicants","Full-time","Mid-Senior level","Information Technology","Food and Beverage Services","","","","2768518","https://jobs.womenofthevine.com/jobs/f2ed5a7b-b080-477c-bd9f-90ee083544a6","EXTERNAL",""
"Data Analyst","Miami, FL","2 weeks ago","2025-11-17","https://www.linkedin.com/jobs/view/data-analyst-at-oneimaging-4336704097?trk=public_jobs_topcard-title","OneImaging","https://www.linkedin.com/company/oneimagingradiology?trk=public_jobs_topcard-org-name","Radiology is the second most used healthcare service, used by over 51% of the workforce annually. Despite the critical role of radiology in healthcare, the process for undergoing a medical imaging exam has remained unchanged for decades. OneImaging is solving this with a concierge approach and a premium-quality radiology network of over 4,000 vetted providers across 48 states, which also reduces imaging costs by 60-80%. Our solution helps patients and families access essential radiology services at fair prices and without surprise bills, all while delivering immediate savings and ROI for employers and payers on every exam.

What you'll do:


 * Partner with operations, data, engineering, and product teams to address complex business challenges through data-first analytical strategies and solutions
 * Build, maintain, and optimize scalable dashboards, automated reports, and self-service tools for teams across OneImaging
 * Champion the adoption and integration of data tooling within company workflows, educating and uplifting team proficiency in modern solutions and innovative thinking
 * Communicate complex insights clearly to technical and non-technical stakeholders, influencing decisions and business outcomes
 * Continuously explore and experiment with emerging technologies and automation methods to advance the team's analytics offerings
   
   

About you:


 * 7+ years of experience in analytics, operations, product, engineering, or related fields—ideally within deadline focused tech environments or consulting
 * Bachelor's degree in a quantitative discipline such as Computer Science, Data Science, Statistics, Mathematics, Operations Research, or equivalent practical experience
 * Advanced proficiency in SQL for data analysis and automation
 * Proven experience building and deploying scalable data products and productizing dashboards using BI tools (e.g., Tableau, Looker, Power BI, etc.)
 * Solid understanding of statistical analysis with practical application to real-world business problems
 * Demonstrated ability to independently manage analytics projects end-to-end, from problem definition to business adoption and impact measurement
 * Hands-on experience with Business Intelligence products development, deployment, and/or integration
 * Rudimentary Python coding knowledge for ad-hoc data processing
   
   

The base salary range for this position is $70,000 - $100,000. Individual compensation will depend on various factors, including qualifications, skills, experience, location, and applicable laws. In addition to base salary, this role is eligible to participate in our equity incentive and competitive benefits plans.

Fraud and Security Notice:

Please be aware of recent job scam attempts. Our team uses the oneimaging.com email domain exclusively. If you have been contacted by someone claiming to be a OneImaging recruiter or a hiring manager from a different domain about a potential job, please report it to law enforcement here and to candidateprotection@oneimaging.com.

Equal Employment Opportunity:

OneImaging is proud to be an Equal Employment Opportunity employer and values diversity in the workplace. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views, or other applicable legally protected characteristics.

OneImaging is committed to providing accommodations for qualified individuals with disabilities in our recruiting process. If you need assistance or an accommodation due to a disability, you may contact us at talent@oneimaging.com.","Over 200 applicants","Full-time","Entry level","Information Technology","Hospitals and Health Care","$70,000.00/yr - $100,000.00/yr","","","81970209","https://www.linkedin.com/jobs/view/data-analyst-at-oneimaging-4336704097?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer II","Scottsdale, AZ","9 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-engineer-ii-at-willscot-4325261438?trk=public_jobs_topcard-title","WillScot","https://www.linkedin.com/company/willscot?trk=public_jobs_topcard-org-name","At WillScot (NASDAQ WSC), our 4000+ people are at the heart of everything we do. In addition to providing industry-leading pay and benefits, we provide opportunities for development and upward mobility, while investing in the communities we serve. We are the undisputed leader in providing innovative ﬂexible workspace and portable storage solutions, serving an incredible range of customers across all industries from 240+ locations across the United States, Canada, and Mexico.

Our values are our foundation. We constantly strive to diversify our teams to ensure we have the best and brightest talent. We’re deeply committed to creating an inclusive and equitable workplace where each person can contribute while being their authentic self. For more about WillScot and who we are, click here. Build your future with us!

About The Job

The Data Engineer is responsible for the maintaining, improving, and building database solutions to support business operations and analytics. The Data Engineer works with the business and Business Intelligence team to translate business requirements into data and analytics solutions, optimize data pipeline performance, and troubleshoot any issues.

What You'll Be Doing


 * Work directly with members of the business to gather business and functional requirements and turn these into technical designs. Develop and optimize SQL. Based solutions on cloud platforms such as Snowflake.
 * Assemble medium to large data sets that meet functional / non-functional business requirements
 * Build automated data pipelines in accordance with internal policies and procedures
 * Perform unit testing, integration testing, and change management activities to ensure quality
 * Monitor data pipeline jobs and perform break-fix and root cause analysis on any identified defects
 * Build analytics tools that utilize the data pipeline to provide actionable insights
 * Keep our data secure
 * Work with data and analytics experts to strive for greater functionality in our data systems
   
   

Education And Qualifications

Required Education and Experience:


 * Bachelor’s Degree in Computer Science, Data Engineering or related field required.
 * Minimum five years of experience in data engineering or similar role.
 * Strong functional knowledge of SAP ERP modules including SD, MM PP, FI-CO, etc. required.
 * Strong working expertise in SQL working with relational databases, query authoring 9SQL) as well as working familiarity with a variety of database technologies preferred.
 * Strong experience using the following: Relational SQL and NoSQL databases, including SQL Server, Snowflake, Could-based ETL tools, object-oriented/object function scripting languages including Python, Java, C++, Scala, etc. and cloud-bases SaaS applications including Salesforce, Success Factors an Hyperion.
   
   

Required Skills And Abilities


 * Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
 * Strong analytical skills related to working with unstructured datasets.
 * Ability to build processes supporting data transformation, data structures, metadata, dependency and workload management.
 * Successful history of manipulating, processing ad extracting value from large, disconnected datasets.
 * Strong communication and organizational skills.
 * Experience supporting and working with cross functional teams in a dynamic environment.
   
   

Work Environment


 * This is an in office role; not hybrid.
   
   

Physical Requirements


 * Ability to sit, stand, walk, etc., for office environment; ability to be on phones majority of business day
   
   

Disclaimer: This posting describes the general nature and level of work performed and does not represent an exhaustive list of responsibilities, duties, or skills required. Collaboration and teamwork drive our success. Team members may be required to perform duties outside normal responsibilities from time to time as needed.

All regular WillScot Holdings Corp. positions offer generous benefits including medical, dental, vision, disability and life insurance, paid time off, Company holidays, tuition reimbursement, and 401(k) with match. Most positions also have variable pay opportunities including commission or bonus, performance rewards, or incentive programs. More information about benefits may be found here.

WillScot provides equal employment opportunities to employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

WillScot embraces diversity and is committed to equal opportunity in all aspects of employment, including recruiting, hiring, promotion, termination, leaves of absence, compensation, and training. We are focused on building teams that include a variety of backgrounds, lived experiences, and skills. The more inclusive we are, the stronger we will be!","101 applicants","Full-time","Entry level","Information Technology","Construction","","","","22302","https://careers.willscot.com/job/Scottsdale-Data-Engineer-II-AZ-85257/1346399800/?mode=job&iis=LinkedInSlots&iisn=LinkedInSlots","EXTERNAL",""
"BI (Analytics) Engineer","New York, NY","4 days ago","2025-11-28","https://www.linkedin.com/jobs/view/bi-analytics-engineer-at-candid-health-4339189351?trk=public_jobs_topcard-title","Candid Health","https://www.linkedin.com/company/candid-health?trk=public_jobs_topcard-org-name","The Role

At Candid Health, we’re searching for an Analytics Engineer to bridge Analytics Engineering, Business Intelligence, and Data Analysis. As a key strategic investment for the company and product, you will be responsible for the data modeling and pipelines that enable our downstream data products. You will work closely with stakeholders across the business and play a foundational role in scaling the data team. Candid Health is positioned to unlock transformative technology for healthcare providers and the BI Engineer will play a critical role in that effort.

What You’ll Do


 * Own Data Modeling as a Practice: Build and deliver critical reporting, analytics, and data models for varying use cases. You will be the standardbearer for operational excellence in our efforts to extrapolate data for meaningful outcomes
 * Set the Foundation for Future Data Work: We have ambitious plans to leverage data as a key component to our long term product strategy. This role will improve and scale our data infrastructure, enabling future ML and AI products
 * Implement New Processes and Systems for Data Collection and Analysis: Deep dive with engineers to understand complex production data. Ensure that tooling and visualization platforms are accurate and available
   
   

Who You Are


 * You have Bachelors degree in Math, Science, Engineering, or another data intensive field of study such as Library Science
 * You have 4+ years of experience working in a Data Science, Data Analytics, or Data Engineering at a high growth startup or scaled technical organization
 * You have experience working with data models, data pipelines and performing analysis
 * You have hands on experience working with common data warehouses such as Snowflake, BigQuery, or Redshift
 * Enthusiasm for data modeling; hopefully you have opinions on slow changing dimensions
 * You have a strong understanding of SQL and have used it in complex data environments
 * You have well-developed opinions on modern data engineering and an ability to bring others up to speed
 * You thrive in ambiguity and enjoy tackling complex tasks that have significant impact on the business at large
 * You’re a clear and concise communicator; you enjoy the challenge of explaining complicated ideas in simple terms, both in-person and in writing.
 * Experience or exposure with the broader set of technologies in our ecosystem: Google Cloud Platform (BigQuery), Metabase, Terraform, Python, DBT.
   
   

Pay Transparency

The estimated starting annual salary range for this position is $135,000 to $180,000 USD. The listed range is a guideline from Pave data, and the actual base salary may be modified based on factors including job-related skills, experience/qualifications, interview performance, market data, etc. Total compensation for this position may also include equity, sales incentives (for sales roles), and employee benefits. Given Candid Health’s funding and size, we heavily value the potential upside from equity in our compensation package. Further note that Candid Health has minimal hierarchy and titles, but has broad ranges of experience represented within roles

","87 applicants","Full-time","Entry level","Information Technology","Hospitals and Health Care","$135,000.00/yr - $180,000.00/yr","","","70448411","https://www.joincandidhealth.com/careers?ashby_jid=3b76459e-9521-4687-84a8-117b5b98a410&utm_source=mvzxgrd3O0","EXTERNAL",""
"Data Engineer","McLean, VA","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/data-engineer-at-bespoke-technologies-inc-4338420297?trk=public_jobs_topcard-title","Bespoke Technologies, Inc.","https://www.linkedin.com/company/bespoketechinc?trk=public_jobs_topcard-org-name","BT-166 – Data Engineer

Location: McLean (fully on-site, no remote option)


 * MUST HAVE A POLY CLEARANCE TO APPLY. Those who do not have a Poly clearance will not be considered.**
   
   

Bespoke Technologies is seeking a Data Engineer who will provide highly technical and in-depth data engineering support.

Key Must Haves


 * The candidate MUST have experience with data engineering, to include designing and building data infrastructure, developing data pipelines, transforming and preparing data, ensuring data quality and security, and monitoring and optimizing systems.
 * The candidate MUST have extensive experience with Python and AWS.
 * Experience with SQL, multi-data source queries with database technologies (PostgreSQL, MySQL, RDS, etc.), NiFi, Git, Elasticsearch, Kibana, Jupyter Notebooks, NLP, AI, and any data visualization tools (Tableau, Kibana, Qlik, etc.) are desired.
   
   

Required Skills And Demonstrated Experience


 * Demonstrated experience with data engineering, to include designing and building data infrastructure, developing data pipelines, transforming/preparing data, ensuring data quality and security, and monitoring/optimizing systems.
 * Demonstrated experience with data management and integration, including designing and operating robust data layers for application development across local and cloud or web data sources.
 * Demonstrated work experience programming with Python
 * Demonstrated experience building scalable ETL and ELT workflows for reporting and analytics.
 * Demonstrated experience with general Linux computing and advanced bash scripting
 * Demonstrated experience with SQL.
 * Demonstrated experience constructing complex multi-data source queries with database technologies such as PostgreSQL, MySQL, Neo4J or RDS
 * Demonstrated experience processing data sources containing structured or unstructured data
 * Demonstrated experience developing data pipelines with NiFi to bring data into a central environment
 * Demonstrated experience delivering results to stakeholders through written documentation and oral briefings
 * Demonstrated experience using code repositories such as Git
 * Demonstrated experience using Elastic and Kibana technologies
 * Demonstrated experience working with multiple stakeholders
 * Demonstrated experience documenting such artifacts as code, Python packages and methodologies
 * Demonstrated experience using Jupyter Notebooks
 * Demonstrated experience with machine learning techniques including natural language processing
 * Demonstrated experience explaining complex technical issues to more junior data scientists, in graphical, verbal, or written formats
 * Demonstrated experience developing tested, reusable and reproducible work
 * Work or educational background in one or more of the following areas: mathematics, statistics, hard sciences (e.g. Physics, Computational Biology, Astronomy, Neuroscience, etc.) computer science, data science, or business analytics
   
   

Desired Skills And Demonstrated Experience


 * Demonstrated experience with cloud services, such as AWS, as well as cloud data technologies and architecture.
 * Demonstrated experience using big data processing tools such as Apache Spark or Trino
 * Demonstrated experience with machine learning algorithms
 * Demonstrated experience with using container frameworks such as Docker or Kubernetes
 * Demonstrated experience with using data visualizations tools such as Tableau, Kibana or Apache Superset
 * Demonstrated experience creating learning objectives and creating teaching curriculum in technical or scientific fields","31 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","","","","71291624","https://www.linkedin.com/jobs/view/data-engineer-at-bespoke-technologies-inc-4338420297?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Product Analyst","Chicago, IL","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/data-product-analyst-at-farmer-s-fridge-4336192135?trk=public_jobs_topcard-title","Farmer's Fridge","https://www.linkedin.com/company/farmer's-fridge?trk=public_jobs_topcard-org-name","Farmer’s Fridge makes fruits and vegetables accessible and approachable for everyone. We offer a variety of fresh, healthy, ready-to-eat meals and snacks through our fresh food vending machines, wholesale partners, and our office pantry solution — providing chef-curated meals to customers within seconds. Today, we operate a network of Fridges and partner with clients nationwide in high-foot-traffic areas, such as airports, hospitals, universities, and large office buildings — where there is limited accessibility to fresh, healthy, grab-n-go options.

We care deeply about what we’re creating and aspire to make sure our customers feel that through every touchpoint. This shows up in many ways across the business. We are committed to prioritizing food safety, we are passionate about product quality, we value our employees, we champion the best idea no matter where it comes from, and we’re committed to making an overall positive impact as we scale.

About This Role

Farmer’s Fridge is entering a period of rapid growth, and we are looking for a a motivated Data Product Analyst with strong technical skills and business acumen to help turn millions of potential data points into models and actionable insights that can drive product improvements, make our customer acquisition more efficient, improve our customer retention rates, and drive operating efficiencies on our production and logistics teams.

What You’ll Do…


 * Execute data and analytics projects based on clearly defined requirements and priorities set by the Data team.
 * Coordinate with analytics, engineering, and business partners to gather requirements, clarify scope, and ensure smooth handoff between teams.
 * Support data governance efforts by helping enforce data quality standards, definitions, and documentation ownership.
 * Translate technical inputs into clear, simple communication for non-technical partners (e.g., summarizing changes, impacts, or requirements).
 * Manage project timelines, blockers, and communication across multiple initiatives.
 * Assist with A/B tests and experiments by supporting setup, tracking, and documentation.
 * Document data processes, definitions, and project learnings to build transparency and self-service capabilities.
 * Provide input and feedback on the data roadmap, tools, and infrastructure needs based on project execution experience.
   
   

Who You Are…


 * 3-5 years of experience in data product coordination, analytics operations, or a related project execution role.
 * Strong communication and organizational skills. Able to work effectively with both technical and non-technical stakeholders.
 * Experience supporting or coordinating data or analytics projects.
 * Working knowledge of SQL, Python, and BI tools such as Tableau.
 * Familiarity with using AI Tools in your day-to-day workflow.
 * Understanding of A/B testing and experimental design.
 * A process-oriented mindset. Someone who can bring structure, clarity, and follow-through to complex initiatives.
 * Curiosity, humility, and a collaborative spirit.
   
   

The base salary range for this role is $90,000 - $100,000. The base pay offered will be determined by factors such as experience, skills, training, certifications, education, and any applicable minimum wage requirements.

In addition to base salary, this position is eligible for company performance-based bonuses and equity.

We Provide a Comprehensive Benefits Package, Including


 * Medical, dental, and vision insurance (multiple plans available)
 * 401(k) with immediate employer match vesting
 * Paid time off (including vacation, sick leave, and holidays)
 * Paid sabbatical after 5 years of service
 * Employee discounts
 * Employee Assistance Program (EAP)
   
   

Benefits At Farmer's Fridge

In This Together - We stay connected, whether in person or virtually. We encourage business transparency through monthly town hall meetings and weekly financial updates. We set out to make the best product on the market, and we believe we’ve done it. We value your input in the new menu creation process. From regular tasting panels, where employees provide new menu feedback.

Happier Workdays - Each day at work should fill you with joy. We're a fun and passionate group, and we don't take ourselves too seriously. Bring your unique self to work, dress comfortably, and always feel free to share your thoughts and opinions. We encourage curiosity; there's no hierarchy here when we're all swapping ideas.

Never run on empty - Daily Farmer's Fridge meal and office snacks are just some of the offerings to make sure you aren't distracted by a growling stomach. Recharge with our paid sabbatical program after five years of service.

Innovate & Elevate - We're all teachers and learners. You'll grow and help grow the company through cross-functional collaboration, open access to leadership, and regular business updates. You have a direct impact on the company’s bottom line. You can also impact your bottom line by participating in our 401(k) plan that includes a company match with immediate vesting.

Farmer’s Fridge Diversity Statement

""Don’t meet every single requirement? Studies have shown that women and people of color are less likely to apply for jobs unless they meet every single qualification. At Farmer’s Fridge, we are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.”

Farmer’s Fridge is an equal-opportunity employer. We are committed to providing equal employment opportunity in all employment practices, including hiring, without regard to race, color, religion, national origin, sex, gender identity, sexual orientation, age, disability status, veteran status, or any other characteristic protected by federal, state or local law. View our disclosures related to External Agencies and Applicants below: https://www.farmersfridge.com/careerdisclosures","Over 200 applicants","Full-time","Mid-Senior level","Analyst and Product Management","Food & Beverages, Food and Beverage Manufacturing, and Technology, Information and Media","$90,000.00/yr - $100,000.00/yr","","","3521364","https://www.linkedin.com/jobs/view/data-product-analyst-at-farmer-s-fridge-4336192135?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Paid maternity leave
Paid paternity leave
Commuter benefits
Disability insurance"
"Staff Product Data Scientist","San Francisco, CA","8 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/staff-product-data-scientist-at-slack-4340188610?trk=public_jobs_topcard-title","Slack","https://www.linkedin.com/company/tiny-spec-inc?trk=public_jobs_topcard-org-name","To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.

Job Category

Data

Job Details

About Salesforce

Salesforce is the #1 AI CRM, where humans with agents drive customer success together. Here, ambition meets action. Tech meets trust. And innovation isn’t a buzzword — it’s a way of life. The world of work as we know it is changing and we're looking for Trailblazers who are passionate about bettering business and the world through AI, driving innovation, and keeping Salesforce's core values at the heart of it all.

Ready to level-up your career at the company leading workforce transformation in the agentic era? You’re in the right place! Agentforce is the future of AI, and you are the future of Salesforce.

Applications will be accepted until 11/11/2025.

We are looking for a seasoned Data Science expert to help build a world-class data science and analytics platform that supports and scales data-driven product decision-making.

As a Staff Product Data Scientist, you will work closely with cross-functional partners to proactively define the product landscape, derive insights from data, communicate key findings to product executives, and directly contribute to product strategy building and implementation. You’ll partner with Product, Design, and Engineering (PDE) to contribute directly to product development—shaping what we build, how we measure success, and when/how we iterate and improve.

At Slack, we foster a positive, diverse, and supportive culture. We look for people who are curious, bold, and eager to improve every day. Our team values being smart, humble, hardworking, and above all, collaborative.

What you will be doing


 * Apply advanced data science techniques to analyze Slack product usage patterns, identifying what’s working, what’s not, and opportunities for improvement.
 * Conduct evidence-based evaluations to determine key drivers of Slack’s product growth.
 * Define and report key success metrics, effectively communicating insights to Slack and Salesforce leadership to enable executive level decision making and follow-ups.
 * Synthesize insights across different product areas and business outcomes, identifying correlations and causal relationships that drive success.
 * Serve as a domain expert in product data science, guiding best practices and advancing data science methodologies and operations.
 * Champion evidence-based decision-making, making data and insights accessible and scalable for stakeholders at all levels.
   
   

What you should have


 * 5+ years of experience in data science or quantitative analysis, preferably in technology product development or enterprise software.
 * A related technical degree required.
 * Expertise in at least one programming language for data science (e.g., Python, R).
 * Experience working with large-scale data technologies (e.g., Spark, Presto, Hive, Hadoop). Expertise in Apache Airflow is a strong plus.
 * Strong communication skills. Able to translate complex technical results into clear, actionable insights.
 * Cross-functional collaboration and influencing skills, with a track record of impacting decisions at both strategic and executional levels.
 * Experience designing and implementing advanced data models with scalability and efficiency.
 * Experienced in applying advanced quant measurement techniques in a product development environment.
   
   

Unleash Your Potential

When you join Salesforce, you’ll be limitless in all areas of your life. Our benefits and resources support you to find balance and be your best, and our AI agents accelerate your impact so you can do your best. Together, we’ll bring the power of Agentforce to organizations of all sizes and deliver amazing experiences that customers love. Apply today to not only shape the future — but to redefine what’s possible — for yourself, for AI, and the world.

Accommodations

If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.

Posting Statement

Salesforce is an equal opportunity employer and maintains a policy of non-discrimination with all employees and applicants for employment. What does that mean exactly? It means that at Salesforce, we believe in equality for all. And we believe we can lead the path to equality in part by creating a workplace that’s inclusive, and free from discrimination. Know your rights: workplace discrimination is illegal. Any employee or potential employee will be assessed on the basis of merit, competence and qualifications – without regard to race, religion, color, national origin, sex, sexual orientation, gender expression or identity, transgender status, age, disability, veteran or marital status, political viewpoint, or other classifications protected by law. This policy applies to current and prospective employees, no matter where they are in their Salesforce employment journey. It also applies to recruiting, hiring, job assignment, compensation, promotion, benefits, training, assessment of job performance, discipline, termination, and everything in between. Recruiting, hiring, and promotion decisions at Salesforce are fair and based on merit. The same goes for compensation, benefits, promotions, transfers, reduction in workforce, recall, training, and education.

In the United States, compensation offered will be determined by factors such as location, job level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, and benefits. Salesforce offers a variety of benefits to help you live well including: time off programs, medical, dental, vision, mental health support, paid parental leave, life and disability insurance, 401(k), and an employee stock purchasing program. More details about company benefits can be found at the following link: https://www.salesforcebenefits.com.Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.

For New York-based roles, the base salary hiring range for this position is $200,800 to $276,100.

For Washington-based roles, the base salary hiring range for this position is $184,000 to $253,000.

For California-based roles, the base salary hiring range for this position is $200,800 to $276,100.","Be among the first 25 applicants","Full-time","Mid-Senior level","Research, Analyst, and Engineering","Technology, Information and Internet","$184,000.00/yr - $276,100.00/yr","","","1612748","https://www.linkedin.com/jobs/view/staff-product-data-scientist-at-slack-4340188610?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI/ML Engineer","San Francisco, CA","1 week ago","2025-11-24","https://www.linkedin.com/jobs/view/ai-ml-engineer-at-air-apps-4347435495?trk=public_jobs_topcard-title","Air Apps","https://www.linkedin.com/company/airapps?trk=public_jobs_topcard-org-name","About Air Apps

At Air Apps, we believe in thinking bigger—and moving faster. We’re a family-founded company on a mission to create the world’s first AI-powered Personal & Entrepreneurial Resource Planner (PRP), and we need your passion and ambition to help us change how people plan, work, and live. Born in Lisbon, Portugal in 2018—and now with offices in both Lisbon and San Francisco—we’ve remained self-funded while reaching over 100 million downloads worldwide.

Our long-term focus drives us to challenge the status quo every day, pushing the boundaries of AI-driven solutions that truly make a difference. Here, you’ll be a creative force, shaping products that empower people across the globe.

Join us on this journey to redefine resource management—and change lives along the way.

The Role

As an AI/ML Engineer, you will play a crucial role in designing, developing, and optimizing machine learning models to power our mobile applications. You will work closely with product managers, engineers, and designers to create intelligent, data-driven features that enhance user experiences. Your expertise in artificial intelligence and deep learning will help us innovate and stay ahead in the mobile app industry.

Please note that this post serves the purpose of enhancing our talent pool while we prepare to launch the official job. As soon as it gets posted we will get in touch with you.

Responsibilities


 * Develop, train, and optimize machine learning models for various mobile app features.
 * Research and implement state-of-the-art AI techniques to improve user engagement and app performance.
 * Collaborate with cross-functional teams to integrate AI-driven solutions into our applications.
 * Design and maintain scalable ML pipelines, ensuring efficient model deployment and monitoring.
 * Analyze large datasets to derive insights and drive data-driven decision-making.
 * Stay updated with the latest AI trends and best practices, incorporating them into our development processes.
 * Optimize AI models for mobile environments to ensure high performance and low latency.
   
   

Requirements


 * Around 3+ years of experience in AI/ML development, preferably in mobile applications.
 * Proficiency in Python, TensorFlow, PyTorch, or other ML frameworks.
 * Experience with deep learning, NLP, computer vision, and statistical modeling.
 * Familiarity with cloud-based ML services (AWS, Google Cloud, or Azure).
 * Strong understanding of data structures, algorithms, and software engineering best practices.
 * Experience in deploying and maintaining ML models in production.
 * Ability to work collaboratively in a remote team environment.
 * Strong problem-solving skills and a passion for innovation.
   
   

What benefits do we offer?


 * Apple hardware ecosystem for work.
 * Annual Bonus.
 * Medical Insurance (including vision & dental).
 * Disability insurance - short and long-term.
 * 401k up to 4% contribution.
 * Air Conference – an opportunity to meet the team, collaborate, and grow together.
 * Transportation budget
 * Free meals at the hub
 * Gym membership
   
   

Diversity & Inclusion

At Air Apps, we are committed to fostering a diverse, inclusive, and equitable workplace. We enthusiastically welcome applicants from all backgrounds, experiences, and perspectives. We celebrate diversity in all its forms and believe that varied voices and experiences make us stronger.

Application Disclaimer

At Air Apps, we value transparency and integrity in our hiring process. Applicants must submit their own work without any AI-generated assistance. Any use of AI in application materials, assessments, or interviews will result in disqualification.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Technology, Information and Internet","","","","11482067","https://www.linkedin.com/jobs/view/ai-ml-engineer-at-air-apps-4347435495?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Analytics Manager","New York, NY","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/data-analytics-manager-at-the-walt-disney-company-4323528159?trk=public_jobs_topcard-title","The Walt Disney Company","https://www.linkedin.com/company/the-walt-disney-company?trk=public_jobs_topcard-org-name","Working with the Executive Director of Polling, Elections, and Data Analytics, and the Washington Bureau, the Manager of Data Analytics will develop editorial content and analytical tools to support and enhance ABC News’ coverage of public opinion and elections. This role brings together data science, survey analysis, data visualization, software engineering, and reporting to provide innovative coverage of polls and elections.

Responsibilities


 * Develop analytical tools such as polling averages, election race ratings, county vote benchmarks, and other election metrics and tools.
 * Create editorial content based on polling, analytical tools, and election data.
 * Explore unique angles in storytelling by writing compelling news stories using ABC News’ polling data and polls conducted by outside sources.
 * Help ensure that all ABC News platforms are presenting polling and election data with appropriate context.
 * Work with the Decision Desk in the design, implementation and testing of statistical models for making election projections and assisting in election analysis.
 * Conduct analyses of early voting using voter files and related data.
 * Assist the Director of Polling in overseeing the team that analyzes the exit poll on election nights for reporting across ABC News’ platforms.
 * Vet polls and social science studies from outside sources for the news division and provide guidance on reportability and newsworthiness.
   
   

Qualifications


 * 10+ years of experience in data journalism, data analytics, and public opinion research including 5+ years in a newsroom and/or television environment.
 * A deep knowledge of and interest in data journalism and public opinion research as it relates to news and storytelling.
 * Experience with computer programming languages and database management (e.g., Python, SQL, and C++).
 * A strong communicator with the ability to translate polling and other data into clear, engaging news stories including data visualizations.
 * Experience with advanced statistical analysis, modeling, statistical software, (e.g., R, STAN, SPSS, STATA).
 * Experience working with data visualization software (e.g., Datawrapper, Tableau, Power BI).
 * A solid background in survey research methodology.
 * Experience working with and analyzing voter registration files, election returns and Census data.
 * Must be well-organized and able to handle multiple projects and news stories simultaneously.
 * Able to work in a fast-paced, high-pressure environment and consistently meet very tight deadlines.
 * Able to work at night and on weekends during election season and during breaking news events.
 * Must have strong collaboration skills and demonstrated ability to work across various teams.
 * Exceptional attention to detail and commitment to accuracy and high standards.
 * A solid background and interest in U.S. electoral politics.
   
   

Required Education


 * BA or BS from a 4-year accredited college or university
   
   

Preferred Education


 * Master’s degree or PhD
   
   

The hiring range for this position in New York, NY is $145,100 to $199,400 per year and in Washington D.C. is $138,400 to $190,300 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","103 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Entertainment Providers","$138,400.00/yr - $199,400.00/yr","","","1292","https://www.linkedin.com/jobs/view/data-analytics-manager-at-the-walt-disney-company-4323528159?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","McLean, VA","18 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-engineer-at-ccs-global-tech-4340344596?trk=public_jobs_topcard-title","CCS Global Tech","https://www.linkedin.com/company/california-creative-solutions-ccs-?trk=public_jobs_topcard-org-name"," * MUST HAVE active Top Secret Clearance
 * Degree in Computer Science, Data Engineering, or a related field is preferred; however, candidates with a strong mix of education and hands-on experience are encouraged to apply.
 * 5+ years of experience in data engineering or backend systems development.
 * Expertise in Python and frameworks such as R, Pandas, SQLAlchemy, PySpark, and RESTful API design.
 * Proficient in writing and optimizing SQL queries and working with relational and non-relational databases (e.g., PostgreSQL, MongoDB, Redis).
 * Familiarity with CI/CD workflows and Git.
 * Experience creating, developing, testing, and sustaining databases.
 * Experience with data conversion, migration, and conditioning.
 * MUST HAVE Security+

","128 applicants","Full-time","Mid-Senior level","Engineering","IT Services and IT Consulting","","Darpan Sahai","https://www.linkedin.com/in/darpan-sahai","344299","https://www.linkedin.com/jobs/view/data-engineer-at-ccs-global-tech-4340344596?trk=public_jobs_topcard-title","EASY_APPLY",""
"Lead - Business Analytics","San Mateo, CA","1 week ago","2025-11-25","https://www.linkedin.com/jobs/view/lead-business-analytics-at-freshworks-4338856513?trk=public_jobs_topcard-title","Freshworks","https://www.linkedin.com/company/freshworks-inc?trk=public_jobs_topcard-org-name","Organizations everywhere struggle under the crushing costs and complexities of ""solutions"" that promise to simplify their lives. To create a better experience for their customers and employees. To help them grow. Software is a choice that can make or break a business. Create better or worse experiences. Propel or throttle growth. Business software has become a blocker instead of ways to get work done.



There's another option. Freshworks. With a fresh vision for how the world works.



At Freshworks, we build uncomplicated service software that delivers exceptional customer and employee experiences. Our enterprise-grade solutions are powerful, yet easy to use, and quick to deliver results. Our people-first approach to AI eliminates friction, making employees more effective and organizations more productive. Over 72,000 companies, including Bridgestone, New Balance, Nucor, S&P Global, and Sony Music, trust Freshworks' customer experience (CX) and employee experience (EX) software to fuel customer loyalty and service efficiency. And, over 4,500 Freshworks employees make this possible, all around the world.



Fresh vision. Real impact. Come build it with us.





Job Description



Overview



We are looking for a highly analytical Lead, Business Analytics to focus on data-driven insights for the go-to-market organization. The ideal candidate will have strong experience in data analytics and performance measurement, alongside expertise in collaboration with cross-functional teams, including marketing, sales, product, and finance. A strong background in B2B SaaS metrics, statistical modeling, and data visualization is essential for success in this role.



Job Description



 * Provide actionable insights to senior leadership by analyzing key GTM metrics, identifying market trends, customer behavior, and opportunities to refine go-to-market strategies.
 * Manage data pipelines and collaborate with data engineering teams to ensure accurate data collection and integration across platforms.
 * Design, implement, and manage structured processes within the GTM Ops team to maintain high levels of data quality and accuracy.
 * Effectively manage stakeholder communication on the insights & metrics developed.
 * Collaborate closely with sales, marketing, product, and finance teams to translate data insights into actionable events and ensure cohesive execution across channels.
 * Continue to push stakeholders to think big in developing or re-design current BI applications that can create transformational business impact.
 * Understand Business Storylines as tied to Goals, OKRs and business outcomes.
   
   

Qualifications


 * 7+ years of experience in sales / marketing analytics or a related field
 * Bachelor’s / Master’s degree in Business Analytics, Data Science, Statistics, or a related field
 * Expertise in developing metrics, performance measurement, data modeling, and reporting
 * Proficiency with analytics tools such as Google Analytics, SQL, Tableau, PowerBI, or other BI platforms
 * Good understanding of marketing automation and CRM platforms (e.g., Marketo, HubSpot, Salesforce)
 * Excellent interpersonal skills and ability to drive consensus with internal and external stakeholders
   
   

Additional Information



The annual base salary range for this position is $127,400 - $183,080. This role is also eligible for a target bonus.



Compensation is based on a variety of factors including but not limited to location, experience, job-related skills, and level. Bonus/equity may be available. Freshworks offers multiple options for dental, medical, vision, disability and life insurances. Equity + ESPP, flexible PTO, flexible spending, commuter benefits and wellness benefits are also offered. Freshworks also offers adoption and parental leave benefits.



At Freshworks, we have fostered an environment that enables everyone to find their true potential, purpose, and passion, welcoming colleagues of all backgrounds, genders, sexual orientations, religions, and ethnicities. We are committed to providing equal opportunity and believe that diversity in the workplace creates a more vibrant, richer environment that boosts the goals of our employees, communities, and business. Fresh vision. Real impact. Come build it with us.

","71 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","$127,400.00/yr - $183,080.00/yr","","","1377014","https://www.linkedin.com/jobs/view/lead-business-analytics-at-freshworks-4338856513?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Database Administrator","Columbia, MD","17 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/senior-database-administrator-at-sparksoft-corporation-4340395015?trk=public_jobs_topcard-title","Sparksoft Corporation","https://www.linkedin.com/company/sparksoft-corporation?trk=public_jobs_topcard-org-name","Join us at Sparksoft, where we're not just another tech company—we're a catalyst for change. Our mission isn't just to offer IT solutions; it's to revolutionize the way you work. Here, passion isn't just a buzzword; it's the fuel behind groundbreaking ideas and transformative technologies. We serve a wide range of government clients, delivering impact that's felt across the nation.

Our true strength lies in our people. They're the problem-solvers and innovators consistently delivering extraordinary outcomes. With Sparksoft, you're not stepping into a routine job; you're joining a team committed to innovation and excellence. Our innovation extends beyond just delivering projects. Through our specialized Innovation Centers, we continuously refine our methods, ensuring we remain industry leaders.

We are Sparksoft!

Roles and Responsibilities


 * Manage user access for support teams and service accounts.
 * Support PEGA application on Oracle in AWS (EC2/RDS).
 * Coordinate upgrades, patches, troubleshooting, and Data Guard replication.
 * Optimize Oracle performance and support future app development.
 * Lead Oracle to PostgreSQL migration projects end-to-end: schema conversion, data migration, performance tuning, validation, and cutover planning.
 * Administer and tune PostgreSQL (RDS, Aurora) and Snowflake databases for high availability and scalability.
 * Support ETL/data replication across Oracle, PostgreSQL, and Snowflake.
 * Ensure data integrity, security, and compliance across platforms.
 * Collaborate with cross-functional teams to define data needs, reporting requirements, and workflow optimization.
   
   

Required Skills


 * Strong Oracle skills (Data Guard, replication, failover, AWS EC2/RDS).
 * Proven hands-on expertise in Oracle to PostgreSQL migration using tools such as AWS DMS, ora2pg, pgloader.
 * Hands-on PostgreSQL administration (replication, indexing, query tuning, partitioning).
 * Experience with Snowflake administration (RBAC, warehouse sizing, query optimization, ETL integration).
 * SQL expertise across Oracle PL/SQL, PostgreSQL PL/pgSQL, and Snowflake SQL.
 * Experience with ETL pipelines and AWS databases (Athena, RDS, Aurora).
 * Knowledge of Power BI Gateway integration for Oracle/PostgreSQL/Snowflake.
 * Strong problem-solving, communication, and teamwork skills.
 * Candidates must be able to obtain and maintain a Public Trust clearance.
 * Candidates must have lived in the United States 3 out of the past 5 years.
   
   

Preferred Experience


 * Experience with PEGA, CMS, ACA Marketplace databases.
 * Healthcare industry background.
 * Agile/Scrum methodology.
 * Familiarity with modern ETL/data integration tools (Informatica, Talend, dbt, Airflow).
   
   

Education & Certification


 * 8+ years database administration experience.
 * BS in Computer Science, Engineering, or related field.
   
   

WHAT WE OFFER:

At Sparksoft, we know that people do their best work when they feel supported, inspired, and connected. That's why we've built a workplace that balances comprehensive benefits with a culture of collaboration and innovation. From flexible time off to professional growth opportunities, we're committed to helping you thrive both inside and outside of work. When you join Sparksoft, you'll enjoy:


 * Competitive compensation and a 401(k) with employer contributions to help you plan for the future
 * Flexible paid time off and hybrid ways of working that support true work-life balance
 * Comprehensive health coverage—including medical, dental, vision, life, and disability insurance
 * A curated in-office experience designed to foster community, team connections, and innovation
 * Opportunities to give back through Sparksoft Cares, including annual company-wide fundraising events
 * Training and development programs that build new skills and prepare you for leadership roles
 * A collaborative, transparent, and fun culture—recognized as a Great Place to Work®
   
   

Accessibility and Accommodations: Sparksoft Corporation is committed to providing equal employment opportunities to all individuals. If you require accommodations during the application or interview process, please contact us at Sparksoft.Accommodations@sparksoftcorp.com or call 410-424-7700. Requests are reviewed and fulfilled on a case-by-case basis.

Security Notice: Your privacy and data security are important to us. Sparksoft Corporation will never request sensitive personal information via email. If you receive any suspicious communication claiming to be from Sparksoft, please report it immediately to our security team at abuse@sparksoftcorp.com.

Artificial Intelligence (AI) Policy: While Sparksoft recognizes the value of artificial intelligence in the workplace, our hiring process is designed to assess each candidate's individual skills, judgment, and problem-solving abilities. To maintain the integrity of this process, the use of AI tools at any stage of the application or interview is strictly prohibited. Violations of this policy may result in disqualification from consideration.","27 applicants","Full-time","Mid-Senior level","Information Technology","IT Services and IT Consulting","","","","1528487","https://www.linkedin.com/jobs/view/senior-database-administrator-at-sparksoft-corporation-4340395015?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist","Raleigh-Durham-Chapel Hill Area","1 month ago","2025-10-27","https://www.linkedin.com/jobs/view/data-scientist-at-sea-cliff-consulting-4332334201?trk=public_jobs_topcard-title","Sea Cliff Consulting","https://www.linkedin.com/company/seacliffconsulting?trk=public_jobs_topcard-org-name","Why Sea Cliff Consulting:

Sea Cliff Consulting is a business analytics consulting firm specializing in supply chain planning, revenue management, accounting, and finance. We partner with midmarket and multi-national organizations to solve complex business challenges through rigorous analytical methods and strategic insights. Our client base spans from Global 10 to Fortune 500 companies across multiple industries. Since our inception, Sea Cliff has maintained consistent growth through our commitment to delivering measurable business value and our expertise in advanced analytics.




About the Role:

Sea Cliff Consulting is seeking a Data Scientist to join our analytics team. This position offers the opportunity to apply advanced machine learning and optimization techniques to address complex business challenges for enterprise clients across manufacturing, supply chain, and corporate finance domains. As a Data Scientist, you will work at the intersection of statistical modeling, optimization, and business strategy, developing predictive models and prescriptive solutions that deliver measurable business impact.




You will collaborate directly with clients to translate business challenges into analytical frameworks, build sophisticated machine learning models, and develop optimization solutions that enhance operational efficiency and financial performance. Your work will span demand forecasting in Sales & Operations Planning (S&OP) processes, production schedule optimization, and predictive maintenance models using sensor data.




Your responsibilities will include:

 * Developing machine learning models for predictive analytics, including classification, regression, clustering, and time series forecasting applications
 * Building optimization models, primarily using mixed-integer programming (MIP/MILP), to solve complex business problems in supply chain and operations
 * Designing and implementing demand forecasting models for S&OP processes using advanced statistical and time series techniques
 * Developing predictive models for manufacturing operations, including OEE (Overall Equipment Effectiveness) optimization, and quality prediction
 * Creating capacity planning and operations planning models to optimize resource allocation and production scheduling
 * Conducting advanced statistical analysis and developing regression models for various business applications
 * Collaborating with cross-functional teams to translate business requirements into analytical solutions
 * Communicating complex analytical findings to both technical and non-technical stakeholders through compelling visualizations and presentations
 * 0-20% Travel




Qualifications

Required:

 * Advanced degree in Data Science, Statistics, Industrial Engineering, Computer Science, Physics, Applied Mathematics, or related quantitative field
 * 3-5 years of experience applying machine learning and optimization techniques to real-world business problems
 * Proficiency in Python with experience in key libraries including scikit-learn, pandas, and NumPy
 * Experience with mixed-integer programming (MIP/MILP) and optimization solvers such as Gurobi, CPLEX, or GLPK
 * Familiarity with statistical modeling and regression analysis techniques (linear, logistic, multivariate)
 * Strong understanding of machine learning algorithms and their practical applications
 * Proficiency in SQL and experience working with large-scale databases
 * Excellent analytical and problem-solving skills with attention to detail
 * Strong communication skills with ability to explain technical concepts to non-technical audiences

Preferred:

 * Background in supply chain analytics, specifically in demand planning & forecasting, capacity & production planning, manufacturing operations, or corporate finance
 * Experience developing machine learning models for manufacturing environments, particularly sensor-based predictive models for OEE optimization, quality prediction, or predictive maintenance
 * Proficiency in R and/or SAS, or C++ is a plus
 * Experience with at least one of Databricks, SageMaker or Azure ML
 * Previous consulting experience or client-facing roles




Company Benefits:

 * Paid time off
 * Competitive base salary with bonus
 * HSA with employer contributions
 * Medical, Dental, Vision, and Life Insurance
 * 401(k) plan with 5% company match




Ready to Make a Difference? Apply Today!

Join us in driving business success and shaping the future of advanced analytics. Apply now and be part of a dynamic team dedicated to excellence in consulting services. Let's embark on this journey together!




Sea Cliff Consulting is an Equal Opportunity Employer. All qualified candidates will receive consideration for employment without regard to race, color, creed, religion, age, gender, national origin, disability, sexual orientation, US Veteran status, or any other factor protected by law.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Business Consulting and Services","","","","65309831","https://www.linkedin.com/jobs/view/data-scientist-at-sea-cliff-consulting-4332334201?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Solutions Analyst","Brooklyn, NY","2 days ago","2025-11-29","https://www.linkedin.com/jobs/view/data-solutions-analyst-at-ninedot-energy-4339867090?trk=public_jobs_topcard-title","NineDot Energy","https://www.linkedin.com/company/ninedotenergy?trk=public_jobs_topcard-org-name","FLSA Classification: Exempt

Salary Range: $120,000 - $130,000 plus bonus and incentive stock options

Reports to: Director, Data & Technology

Location: Brooklyn, NY (Hybrid)

About The Company:

NineDot's name derives from the classic mathematical puzzle for sparking out-of-the-box solutions. As a leading community-scale, clean energy developer with a growing portfolio of projects across a range of technologies, NineDot Energy is creating innovative energy solutions that support a more resilient electric grid, deliver economic savings, address environmental justice and reduce carbon emissions. We plan to develop, build and operate more than 400 MW of clean energy systems by 2026 that will strengthen the local power grid infrastructure and provide clean, reliable and resilient power to tens of thousands of New York households and businesses. This is all in support of New York State's mission to achieve 100% clean energy by 2040.

With the backing of Manulife Investment Management and The Carlyle Group - two of the world's leading infrastructure investors - NineDot is continuing to expand its core battery energy storage pipeline, deliver enhanced products and services, explore new regions and consider potential acquisitions all to advance the decarbonization of New York's grid. This is an exciting opportunity to build a platform from the ground-up with a world-class team of developers and innovators. NineDot is committed to building a company that exemplifies diversity, equity and inclusion values in its team culture, as well as business practices and community engagement.

Job Summary

Our Data & Technology team is looking to hire a Data Solutions Analyst to strengthen our team's ability to design, structure, and optimize data across NineDot. This role bridges technical programming and user-centered solution design — combining database structuring and automation with the ability to build intuitive, scalable systems in Airtable and related tools.

The ideal candidate will have a solid foundation in SQL and Python, along with hands-on experience building data structures, automations, and scripts in Airtable. This role is highly collaborative, supporting internal teams by gathering requirements, creating efficient data models, and ensuring our systems seamlessly integrate with the data warehouse and business intelligence tools.

Responsibilities


 * Partner with internal stakeholders to gather requirements, understand workflows, and translate business needs into structured, reliable data solutions.
 * Design, build, and maintain Airtable bases and interfaces, ensuring they are scalable, intuitive, and optimized for cross-team use.
 * Develop and refine Airtable automations and scripts to support business users' daily work.
 * Develop requirements for integrations with external systems (e.g., Procore, SAP, contracting tools).
 * Write and maintain Python and SQL scripts to clean and , transform datasets into order to send marts-level data into a BI Tool.
 * Identify opportunities to streamline processes and automate workflows, balancing front-end usability with backend reliability.
 * Document data structures, logic, and workflows to ensure clarity and knowledge sharing across teams.
 * Collaborate with technical teammates to review code, troubleshoot issues, and improve data integrations as needed.
 * Perform other duties as assigned.
   
   

Core Competencies:


 * Collaborates - Building partnerships and working collaboratively with others to meet shared objectives.
 * Drives Results - Constantly achieving results, even under tough circumstances.
 * Interpersonal Savvy - Relating openly and comfortably with diverse groups of people.
 * Manages Ambiguity - Operating effectively, even when things are not certain or the way forward is not clear.
 * Nimble Learning - Actively learning through experimentation when tackling new problems, using both success and failures as learning fodder
 * Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals.
 * Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications.
   
   

Required Education and Experience


 * 3+ years of experience in data structuring, solutions engineering, or related roles (e.g., data analyst, product developer).
 * Proven experience building and managing Airtable bases, including automations, table design, and scripting both within Airtable and via the Airtable API.
 * Strong understanding of data structuring, modeling, and optimization principles.
 * Proficiency in Python and SQL for building and maintaining data pipelines.
 * Experience with data transformation tools such as dbt or SQLMesh.
 * Ability to approach data problems analytically, with a background in Math, Data Science, Economics, Computer Science, or related fields (CS degree not required).
 * Demonstrated ability to translate complex data problems into practical solutions for non-technical users.
 * Excellent communication and problem-solving skills, with a balance of technical and user-facing capabilities.
   
   

Preferred Experience


 * Broader experience with database systems and integrations beyond Airtable.
 * Familiarity with workflow automation tools, APIs, and system integrations.
 * Experience collaborating with data engineers or software developers to review and maintain code quality.
 * Understanding of data architecture to support BI tools and analytics pipelines.
   
   

Reasonable accommodations may be made to enable individuals with disabilities to perform these essential functions.

At NineDot Energy, we believe diverse perspectives drive innovation and are the foundation of our success. As such, we do not discriminate on the basis of race, color, national origin, religion, gender expression, gender identity, age, or any other status of an individual or that individual's associates or relatives that is protected under applicable federal, state, or local law.

If you're passionate about this role but don't meet every qualification listed, we still encourage you to apply. You may be the right candidate for this or other opportunities with us. We're committed to building a team that reflects a broad range of experiences, backgrounds, and skills.

NineDot Employee benefits include but are not limited to:


 * Medical, dental and vision coverage
 * 5% employer match on your 401k retirement account
 * 20 paid vacation days off, plus 7 sick days, 9 federal holidays and 3 personal floating holidays
 * 12 weeks of 100% paid parental leave for both the primary and secondary caregiver within the first year of birth or adoption
 * Wellness initiatives including a $1,000 stipend
 * 16 volunteer hours plus two planned company-wide volunteer outings per year","69 applicants","Full-time","Mid-Senior level","Information Technology","Services for Renewable Energy","$120,000.00/yr - $130,000.00/yr","","","10876146","https://grnh.se/txxbng1t5us","EXTERNAL",""
"GEN AI LLM Data Scientist","Raritan, NJ","1 month ago","2025-10-27","https://www.linkedin.com/jobs/view/gen-ai-llm-data-scientist-at-the-dignify-solutions-llc-4341985668?trk=public_jobs_topcard-title","The Dignify Solutions, LLC","https://www.linkedin.com/company/dignify-solutions?trk=public_jobs_topcard-org-name"," * Must have 12+ years of experience working in Data science, Machine learning and especially NLP technologies.
 * Exposure to various LLM technologies and solid understanding of Transformer Encoder Networks.
 * Able to apply deep learning and generative modeling techniques to develop LLM solutions in the field of Artificial Intelligence.
 * Utilize your extensive knowledge and expertise in machine learning (Client) with a focus on generative models, including but not limited to generative adversarial networks (GANs), variational autoencoders (VAEs), and transformer-based architectures.
 * Solid understanding of Model development, model serving, training/re-training techniques in a data sparse environment.
 * Very good understanding of Prompt engineering techniques in developing Instruction based LLMs.
 * Must be able to design and implement state-of-the-art generative models for natural language processing (NLP) tasks such as text generation, text completion, language translation, and document summarization.
 * Work with SAs and collaborate with cross-functional teams to identify business requirements and deliver solutions that meet the customer needs.
 * Passionate to learn and stay updated with the latest advancements in generative AI and LLM.
 * Nice to have -contributions to the research community through publications, presentations, and participation in relevant conferences or workshops.
 * Evaluate and preprocess large-scale datasets, ensuring data quality and integrity, and develop data pipelines for training and evaluation of generative models.
 * Ability to articulate to business stakeholders on the hallucination effects and various model behavioral analysis techniques followed.
 * Exposure to developing Guardrails for LLMs both with open source and cloud native models.
 * Collaborate with software engineers to deploy and optimize generative models in production environments, considering factors such as scalability, efficiency, and real-time performance.
 * Nice to have- provide guidance to junior data scientists, sharing expertise and knowledge in generative AI and LLM, and contribute to the overall growth and success of the data science team.","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","75031133","https://www.linkedin.com/jobs/view/gen-ai-llm-data-scientist-at-the-dignify-solutions-llc-4341985668?trk=public_jobs_topcard-title","EASY_APPLY",""
"Artificial Intelligence Engineer","Seattle, WA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/artificial-intelligence-engineer-at-meeboss-4339141723?trk=public_jobs_topcard-title","MeeBoss","https://www.linkedin.com/company/meeboss?trk=public_jobs_topcard-org-name","About Nimbus AI

Nimbus AI is building the fastest way for companies to create, train, and resell branded conversational and workflow AI agents. Our platform automates data capture, optimization, and deployment, making it simple for teams to turn conversations and workflows into continuously improving, revenue-generating products.




The Role

We’re looking for a Head of AI Product who thrives in a fast-moving, high-ownership environment. You’ll help shape Nimbus’s core platform—expanding how users capture data, train models, and deploy automated agents at scale.




This is a hands-on, high-impact role: part product strategist, part operator, and part builder. You’ll work across customer feedback, internal teams, and go-to-market to ensure Nimbus evolves into the most powerful self-learning, white-label AI platform on the market.




What You’ll Do

 * Own the core product roadmap — focusing on data capture, training workflows, and agent automation.
 * Partner with engineering and design to define, ship, and iterate on high-leverage features.
 * Drive platform extensibility — enabling partners and customers to embed, customize, and resell agents.
 * Optimize onboarding and training loops to make data capture and model improvement frictionless.
 * Translate insights into action by setting KPIs, tracking adoption, and iterating based on real usage data.
 * Bridge customer needs with technical realities, ensuring that what we build directly drives business outcomes.




What We’re Looking For

 * 3–5+ years of product experience in SaaS or platform environments.
 * Strong understanding of AI, data, or automation-driven products (LLMs, conversational AI, or workflow tools).
 * Experience with partner or platform ecosystems (APIs, integrations, white-label products).
 * Ability to create compelling product narratives—both visually and strategically.
 * Technically conversant: comfortable working with APIs, webhooks, and developer-facing tools.
 * Builder’s mindset: you move fast, embrace ambiguity, and balance vision with execution.




Why Nimbus AI?

 * Be at the forefront of agentic AI—helping companies automate and scale knowledge workflows.
 * Join a small, ambitious team where your fingerprints shape the product and the company.
 * Every week is different: prototype new data loops, improve training pipelines, or co-create with users.
 * We’re growing fast—and you’ll grow with us.




About MeeBoss:

MeeBoss unleashes the potential in people, teams, and organizations. We’re revolutionizing online recruiting with a mission to streamline hiring, connecting job seekers and employers faster, smarter, and more human than ever.

With real two-way communication, MeeBoss brings the human touch early, allowing both sides to quickly assess fit, swap feedback, and move the hiring journey forward, fast. Our mobile-first experience delivers top-quality candidate matches and instant chat with job-ready talent, helping businesses and job seekers connect anytime, anywhere.

At MeeBoss, we also collaborate closely with our clients to design optimal organizational structures, roles, and responsibilities, building stronger foundations for success. All postings we share are carried out with the prior consent and partnership of our clients.","Over 200 applicants","Full-time","Mid-Senior level","Engineering, Management, and Product Management","Technology, Information and Internet","","","","105035463","https://www.linkedin.com/jobs/view/artificial-intelligence-engineer-at-meeboss-4339141723?trk=public_jobs_topcard-title","EASY_APPLY","401(k)
Medical insurance"
"Operations Data Analyst","Chicago, IL","2 weeks ago","2025-11-12","https://www.linkedin.com/jobs/view/operations-data-analyst-at-selby-jennings-4335815293?trk=public_jobs_topcard-title","Selby Jennings","https://uk.linkedin.com/company/selby-jennings?trk=public_jobs_topcard-org-name","About the Role



As an Operations Data Analyst, you'll be the first line of defense for ensuring smooth operations across multiple data pipelines. You'll monitor system health, validate data integrity, and provide actionable insights that keep our processes reliable and efficient.



What You'll Do


 * Track live operational data and system performance across multiple pipelines.
 * Use SQL for light analysis to confirm data accuracy, detect anomalies, and support decision-making.
 * Design and maintain dashboards and automated alerts to monitor key metrics.
 * Troubleshoot operational issues, document findings, and escalate to engineering when needed.
 * Partner with engineering and product teams to enhance observability and streamline processes.
   
   

Required Skills


 * Strong SQL skills and experience with relational databases.
 * Ability to create dashboards and visualizations (e.g., Datadog, Looker, Metabase, Grafana).
 * Keen attention to detail and pattern recognition in data.
 * Clear written communication for reporting and collaboration.
 * Comfortable working in a fast-paced technical environment.
   
   

Nice to Have


 * Basic scripting knowledge (Python, Bash) for simple automation.
 * Familiarity with monitoring tools (Datadog, Prometheus).
 * Understanding of ETL pipelines or event-driven systems.
 * Exposure to distributed systems or blockchain environments.
 * Previous experience in operations, reliability, or trading-related roles.","Over 200 applicants","Full-time","Mid-Senior level","Analyst","Financial Services","$100,000.00/yr - $125,000.00/yr","Abbey Milligan","https://www.linkedin.com/in/abbey-milligan-836093166","106584","https://www.linkedin.com/jobs/view/operations-data-analyst-at-selby-jennings-4335815293?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer II","Bellevue, WA","2 weeks ago","2025-11-17","https://www.linkedin.com/jobs/view/data-engineer-ii-at-chewy-4336722505?trk=public_jobs_topcard-title","Chewy","https://www.linkedin.com/company/chewy-com?trk=public_jobs_topcard-org-name","Our Opportunity: At Chewy, we’re on a mission to become the most trusted and convenient destination for pet parents everywhere. The Data Platform team in the Marketing Sciences Organization sits at the intersection of data, marketing, and innovation — helping us understand our customers, personalize their experiences, and measure the impact of every interaction.

We’re looking for a Data Engineer II who is passionate about building data ecosystems that unlock insights and fuel smarter decisions. This is more than a data engineer role — it’s an opportunity to shape how Chewy thinks about marketing data at scale and to help drive the future of customer engagement.

Key Responsibilities


 * Design, implement, and improve the analytics platform
 * Implement and simplify self-service data query and analysis capabilities of the BI platform
 * Develop and improve the current BI architecture, emphasizing data security, data quality and timeliness, scalability, and extensibility
 * Deploy and use various big data technologies and run pilots to design low latency data architectures at scale
 * Collaborate with business analysts, data scientists, product managers, software development engineers, and other BI teams to develop, implement, and validate KPIs, statistical analyses, data profiling, prediction, forecasting, clustering, and machine learning algorithms
 * Partner with other BI and analytics teams to build and verify hypotheses to improve the discovery experience
   
   

Basic Qualifications


 * Bachelor’s degree in Computer Science or related field or 3+ years relevant experience
 * Current permanent U.S. work authorization is required
 * Expert level skills writing and optimizing complex SQL
 * Knowledge of data warehousing concepts.
 * Experience in data mining, profiling, and analysis
 * Experience with complex data modelling, ETL design, and using large databases in a business environment
 * Proficiency with Linux command line and systems administration
 * Experience with languages like Python, Ruby, Java, or similar language
 * Experience with Big Data technologies such as Hive/Spark.
 * Proven ability to develop unconventional solutions; Sees opportunities to innovate and leads the way
 * Excellent verbal and written communication; Proven interpersonal skills and ability to convey key insights from complex analyses in summarized business terms; Ability to effectively communicate with technical teams
 * Ability to work with shifting deadlines in a fast-paced environment
   
   

Preferred Qualifications


 * Authoritative in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies
 * Experience with building data pipelines and applications to stream and process datasets at low latencies.
 * Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
 * Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.
 * Knowledge of Engineering and Operational Excellence using standard methodologies.
   
   

The specific salary offered to a candidate may be influenced by a variety of factors including but not limited to the candidate’s relevant experience, education, and work location. In addition, this position is eligible for 401k and a new hire and annual equity grant.

We offer different types of insurance and benefits, such as medical/Rx, vision, dental, life, disability, hospital indemnity, critical illness, and accident. We offer parental leave, family services benefits, backup dependent care, flexible spending accounts, telemedicine, pet adoption reimbursement, employee assistance program, and many discounts including 10% off pet insurance and 20% off at Chewy.com.

Exempt salary team members have unlimited PTO, subject to manager approval. Team members will receive six paid holidays per year. Team members may be eligible for paid sick and family leave in compliance with applicable state and local regulations.

Base Salary Range

$113,000—$180,500 USD

Chewy is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, ancestry, national origin, gender, citizenship, marital status, religion, age, disability, gender identity, results of genetic testing, veteran status, as well as any other legally-protected characteristic. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here.

To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.","Over 200 applicants","Full-time","Entry level","Information Technology","Retail","$113,000.00/yr - $180,500.00/yr","","","2433416","https://careers.chewy.com/us/en/job/CHINUS7392143EXTERNALENUS/Data-Engineer-II?utm_source=linkedin&utm_medium=phenom-feeds?gh_src=o8ua3y1","EXTERNAL",""
"Senior Data Engineer/ Data Engineering Architect [32710]","San Jose, CA","20 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/senior-data-engineer-data-engineering-architect-32710-at-stealth-startup-4348161587?trk=public_jobs_topcard-title","Stealth Startup","https://www.linkedin.com/company/stealth-startupsssss?trk=public_jobs_topcard-org-name","Benefits:

 * 401(k)
 * 401(k) matching
 * Dental insurance
 * Health insurance
 * Paid time off
 * Vision insurance
 * Wellness resources







Responsibilities




 * Design robust and scalable data system architecture to collect, process, and store large volumes of data from IoT devices.
 * Design and build data systems that support real-time, customer facing data applications, ensuring data integrity and efficient retrieval processes.
 * Design and build a data validation framework to guarantee the accuracy and consistency of data across all stages of the pipeline, ensuring reliable insights and decision-making.
 * Implement data architectures to continuously improve AI models through automated feedback loops and data collection processes.
 * Optimize data processing workflows for AIoT tasks.
 * Collaborate with product owners to translate data requirements into actionable data engineering solutions.
 * Collaborate with other engineers, product owners to solve challenging problems.
 * Evangelize software engineering best practices and lead by example.







Qualifications




 * Bachelor's degree in Computer Science, Data Science, Engineering, or a related field.
 * 5+ years of proven experience in data engineering, with a strong focus on data warehousing and data system architecture.
 * Expertise in design and build IoT data systems.
 * Expertise in architecting that power high-volume consumer application.
 * Expertise in big data and streaming technologies (Python, Java, Kafka, Spark,Spark Streaming).
 * Expertise in moderen database technology (MongoDB, ElasticSearch, StarRocks, S3, Snowflake, Bigquery etc).
 * Experience with data annotation tools and processes for machine learning datasets.
 * Familiarity with MLOps practices and tools for managing AI model lifecycles.
 * Knowledge about deploying systems into a production Cloud Native Environment (AWS or similar).
 * Experience in Java Spring Framework is a plus
 * Experience with video data handling and image processing is a plus

","Over 200 applicants","Full-time","Mid-Senior level","Engineering","Technology, Information and Internet","","","","18225241","https://www.linkedin.com/jobs/view/senior-data-engineer-data-engineering-architect-32710-at-stealth-startup-4348161587?trk=public_jobs_topcard-title","EASY_APPLY",""
"GEN AI LLM Data Scientist","Raritan, NJ","1 month ago","2025-10-27","https://www.linkedin.com/jobs/view/gen-ai-llm-data-scientist-at-the-dignify-solutions-llc-4347015640?trk=public_jobs_topcard-title","The Dignify Solutions, LLC","https://www.linkedin.com/company/dignify-solutions?trk=public_jobs_topcard-org-name"," * Must have 12+ years of experience working in Data science, Machine learning and especially NLP technologies.
 * Exposure to various LLM technologies and solid understanding of Transformer Encoder Networks.
 * Able to apply deep learning and generative modeling techniques to develop LLM solutions in the field of Artificial Intelligence.
 * Utilize your extensive knowledge and expertise in machine learning (Client) with a focus on generative models, including but not limited to generative adversarial networks (GANs), variational autoencoders (VAEs), and transformer-based architectures.
 * Solid understanding of Model development, model serving, training/re-training techniques in a data sparse environment.
 * Very good understanding of Prompt engineering techniques in developing Instruction based LLMs.
 * Must be able to design and implement state-of-the-art generative models for natural language processing (NLP) tasks such as text generation, text completion, language translation, and document summarization.
 * Work with SAs and collaborate with cross-functional teams to identify business requirements and deliver solutions that meet the customer needs.
 * Passionate to learn and stay updated with the latest advancements in generative AI and LLM.
 * Nice to have -contributions to the research community through publications, presentations, and participation in relevant conferences or workshops.
 * Evaluate and preprocess large-scale datasets, ensuring data quality and integrity, and develop data pipelines for training and evaluation of generative models.
 * Ability to articulate to business stakeholders on the hallucination effects and various model behavioral analysis techniques followed.
 * Exposure to developing Guardrails for LLMs both with open source and cloud native models.
 * Collaborate with software engineers to deploy and optimize generative models in production environments, considering factors such as scalability, efficiency, and real-time performance.
 * Nice to have- provide guidance to junior data scientists, sharing expertise and knowledge in generative AI and LLM, and contribute to the overall growth and success of the data science team.","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","75031133","https://www.linkedin.com/jobs/view/gen-ai-llm-data-scientist-at-the-dignify-solutions-llc-4347015640?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer - III: 25-07122","San Francisco, CA","10 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-engineer-iii-25-07122-at-akraya-inc-4348173630?trk=public_jobs_topcard-title","Akraya, Inc.","https://www.linkedin.com/company/akraya-inc?trk=public_jobs_topcard-org-name","Primary Skills: Python-Expert, PySpark-Advanced, Databricks-Intermediate, ETL BigData-Advanced, Cloud Warehousing-Intermediate

Contract Type: W2 Only

Duration: 12+ Months

Location: San Francisco, CA ()

Pay Range: $80 - $90 per hour on W2

#LP

Job Summary

This role requires the candidate to be a Permanent Resident or US citizen due to specific job requirements.

We are seeking a seasoned Data Engineer to play a pivotal role in collecting, parsing, managing, analyzing, and converting large datasets into actionable insights. The role involves creating scalable, repeatable, and secure data pipelines across multiple platforms to cater to diverse user needs. The ideal candidate should have a solid background in computer science, with extensive experience in data tools and technologies, and a knack for leveraging data to drive business decisions.

Key Responsibilities


 * Design, develop, and maintain robust and efficient data pipelines to transform, catalog, and deliver high-quality data.
 * Participate actively in Agile processes and deliver high-quality data products and services following Safe Agile Practices.
 * Proactively identify and resolve issues with data pipelines and analytical data stores.
 * Deploy monitoring, alerting, and auto-remediation for data pipelines and stores to ensure reliability.
 * Collaborate with cross-functional teams to meet their data needs, employing a security-first and automation strategy.
   
   

Must-Have Skills:


 * Proficiency in Python and PySpark.
 * Experience with cloud data warehouses (RedShift, Snowflake).
 * Strong understanding of ETL and Big Data processes.
 * Looking for a 8 to 12 plus years of experience
   
   

Domain/Industry Experience:


 * Previous data engineering experience, particularly in AWS environments, is essential for this role. Experience in Agile environments and familiarity with data security regulations applicable to Protected Individuals will be advantageous.
   
   

ABOUT AKRAYA

Akraya is an award-winning IT staffing firm consistently recognized for our commitment to excellence and a thriving work environment. Most recently, we were recognized Inc's Best Workplaces 2024 and Silicon Valley's Best Places to Work by the San Francisco Business Journal (2024) and Glassdoor's Best Places to Work (2023 & 2022)!

Industry Leaders in IT Staffing

As staffing solutions providers for Fortune 100 companies, Akraya's industry recognitions solidify our leadership position in the IT staffing space. We don't just connect you with great jobs, we connect you with a workplace that inspires!

Join Akraya Today!

Let us lead you to your dream career and experience the Akraya difference. Browse our open positions and join our team!

","37 applicants","Full-time","Mid-Senior level","Information Technology","IT Services and IT Consulting","$80.00/hr - $90.00/hr","","","41771","https://www.linkedin.com/jobs/view/data-engineer-iii-25-07122-at-akraya-inc-4348173630?trk=public_jobs_topcard-title","EASY_APPLY",""
"Full Stack AI Engineer","Charlotte, NC","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/full-stack-ai-engineer-at-vertex-service-partners-4339001458?trk=public_jobs_topcard-title","Vertex Service Partners","https://www.linkedin.com/company/vertexservicepartners?trk=public_jobs_topcard-org-name","About Us

Vertex Service Partners is a home improvement services company focused on residential roofing and other exterior services across the United States. Backed by Alpine Investors, a top-decile private equity fund with $4.0 billion of committed capital, Vertex is building a best-in-class national platform. Our company is built on our core values—servant leadership, unwavering character, a growth mindset, persistence, empowerment, pace, and fun—and guided by three pillars: being the Employer of Choice, Partner of Choice, and Contractor of Choice. We offer transformative support in operations, marketing, training, talent, finance, and technology, all while preserving the autonomy of local brands.

Location: Hybrid (Charlotte, NC + Remote)

Job Type: Full-time

FLSA: Exempt, Salary

Reports to: VP of Technology

About Vertex Service Partners

Vertex Service Partners is a residential home improvement services company focused on roofing and other exterior services across the United States. Backed by Alpine Investors, a top-decile private equity fund with $4.0 billion of committed capital, Vertex is building a best-in-class national platform.

Position Summary

We are seeking a Full Stack AI Engineer who combines strong software engineering fundamentals with applied AI creativity. This role plays a foundational part in shaping Vertex’s AI and automation strategy—architecting, building, and deploying intelligent tools that transform how our businesses operate.

You will own full-stack development of AI-driven internal tools, partner directly with operators and business units, and help build Vertex’s internal culture of AI adoption. This role requires high ownership, strong execution, and a passion for building practical, real-world AI solutions.

Key Responsibilities

Build AI-Powered Internal Tools


 * Design, prototype, and deploy full-stack applications using FastAPI/Django and React/Next.js.
 * Develop AI features including chat assistants, retrieval workflows, summarization, and workflow automation.
 * Integrate APIs and data systems including OpenAI, LangChain, ServiceTitan, and Snowflake.
   
   



Architect and Scale Vertex’s AI Foundations


 * Establish scalable patterns for APIs, cloud deployments, CI/CD, and front-end frameworks.
 * Implement reliable pipelines for retrieval-augmented generation (RAG), prompt management, vector storage, and model orchestration.
 * Build reusable libraries and architectural components to accelerate future AI initiatives.
   
   

Automate Operational Workflows


 * Identify manual workflows across operations, sales, finance, and field teams; replace them with AI-enabled tools and automation.
 * Partner with FP&A, Data Engineering, and Operations to ensure data is modeled effectively to support automations.
 * Build intuitive interfaces and solutions designed for non-technical internal users.
   
   

Drive AI Culture Across the Organization


 * Lead workshops, demos, and internal sessions on how to use AI tools effectively.
 * Build self-service templates and guided workflows to help business users adopt AI independently.
 * Create documentation and best practices for AI tooling across the organization.
   
   



Cross-Functional Collaboration


 * Work closely with the VP of Technology and executive leadership to prioritize AI opportunities.
 * Translate ambiguous business problems into prototypes and production-ready solutions.
 * Communicate complex technical concepts clearly and simply to non-technical teams.
   
   

Qualifications


 * 4–7+ years of professional experience in software engineering with modern web frameworks.
 * Proficiency in Python and TypeScript; experience with FastAPI/Django and React/Next.js.
 * Hands-on experience with LLMs, RAG systems, vector databases, and prompt engineering.
 * Familiarity with Snowflake or similar data warehouse technologies.
 * Experience building and deploying applications in a cloud environment (Azure preferred).
 * Strong ownership mindset with the ability to iterate quickly and deliver high-quality tools.
 * Ability to translate complex operational or business problems into simple, elegant solutions.
 * Excellent communication skills and comfort working directly with non-technical business users.
   
   

Benefits

Full-time employees are eligible to participate in the following benefits:


 * Health, Dental, and Vision Insurance
 * 401(k) with company match
 * Paid Time Off
 * Retirement Plan
 * Opportunities for growth and on-the-job training
   
   

Vertex Service Partners is an equal opportunity employer and does not discriminate based on race, color, religion, sex, national origin, political affiliation, sexual orientation, marital status, disability, age, military service, or any other protected class. If you need a reasonable accommodation due to a disability, please contact Human Resources with your request and contact information. Applicant Privacy Policy

Why Join Us?

At Vertex Service Partners, we take pride in our people, our work, and our commitment to integrity. If you're looking for a company where you can grow professionally while making a real impact, we’d love to hear from you!

Apply Today!

Benefits:

Full-time employees are eligible to participate in the following benefits:


 * Health, Dental, and Vision Insurance
 * 401(k) with company match
 * Company sponsored Life and AD&D coverage
 * Paid Time Off
 * Opportunities for growth and on-the-job training
   
   

Why Join Us?


 * Build Something Big – Shape processes for a rapidly growing organization.
 * Growth-Oriented Culture – Work in a dynamic, people-first environment.
 * Make an Impact Across Regions – Partner with business leaders to drive meaningful change.
   
   

Apply Today!

Vertex Service Partners is an equal opportunity employer and does not discriminate based on race, color, religion, sex, national origin, political affiliation, sexual orientation, marital status, disability, age, military service, or any other protected class. If you need a reasonable accommodation due to a disability, please contact Human Resources with your request and contact information. Applicant Privacy Policy","Be among the first 25 applicants","Full-time","Entry level","Engineering and Information Technology","Consumer Services","","","","96291807","https://www.linkedin.com/jobs/view/full-stack-ai-engineer-at-vertex-service-partners-4339001458?trk=public_jobs_topcard-title","EASY_APPLY",""
"Computer/Data Science (3699)","West Mifflin, PA","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/computer-data-science-3699-at-navarro-research-and-engineering-4337792632?trk=public_jobs_topcard-title","Navarro Research and Engineering","https://www.linkedin.com/company/navarro-research-and-engineering?trk=public_jobs_topcard-org-name","Navarro Research and Engineering is recruiting a Computer/Data Science in West Mifflin, PA. An active DOE L Clearance or DOD equivalent is required to be considered for this position.

Navarro Research & Engineering is an award-winning federal contractor dedicated to partnering with clients to advance clean energy and deliver effective solutions for complex challenges in the nuclear and environmental fields. Joining Navarro means being a part of an exceptional team committed to quality and safety while also looking for innovative strategies to create value for the client's success. Headquartered in Oak Ridge, Tennessee, Navarro has active programs in place across the nation for DOE/NNSA, NASA, and the Department of Defense.

This position will support the design, development, maintenance, and implementation of artificial intelligence into the Reactor Servicing Directorate. The Al will be developed using retrieval augmented generation and established Large Language Models to allow for enhanced information retrieval and the creation of detailed safety documents and operational procedures based on existing information. This project is built on an already established computer model that has been created.

Required Knowledge, Skills, and Abilities


 * Computer coding using python
 * Experience with retrieval augmented generation (RAG) and word processing compatibility
 * Strong Natural Language Processing (NLP) knowledge
 * Skills with language models, clustering, vectorization/embedding, tokenization, prompt engineering, and temperature optimization
 * Plotly Dash front end development
 * Project packaging and large-scale deployment

Desired Knowledge, Skills, and Abilities


 * General Al implementation experience to consider large Al applications
 * Open WebUI
 * Haystack
 * Data logging
 * Testing
 * Asynchronous programming
 * Neural Networks, deep learning, transformers
 * Collaboration and teamwork - Containerization (OpenShift/Kubernetes)
   
   
   

Requirements


 * Bachelor's degree in a related field- engineering, computer science, or IT related.
 * 5-10 years of experience.
 * An active DOE L Clearance or DOD Top Secret Clearance

 * 3+ years experience in NLP

Due to the nature of the government contract requirements and/or clearances requirements, US citizenship is required.

Navarro is an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, race, religion, color, national origin, age, disability, veteran's status or any classification protected by applicable state or local law.

EEO Employer/Vet/Disabled



Benefits


 * Health Care Plan (Medical, Dental & Vision)
 * Retirement Plan (401k, IRA)
 * Life Insurance (Basic, Voluntary & AD&D)
 * Paid Time Off (Vacation & Public Holidays)
 * Short Term & Long Term Disability","Be among the first 25 applicants","Full-time","Entry level","Information Technology","Non-profit Organizations and Primary and Secondary Education","","","","1252897","https://www.linkedin.com/jobs/view/computer-data-science-3699-at-navarro-research-and-engineering-4337792632?trk=public_jobs_topcard-title","EASY_APPLY",""
"Strategic Data Scientist","Columbus, OH","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/strategic-data-scientist-at-covermymeds-4338951793?trk=public_jobs_topcard-title","CoverMyMeds","https://www.linkedin.com/company/covermymeds?trk=public_jobs_topcard-org-name","McKesson is an impact-driven, Fortune 10 company that touches virtually every aspect of healthcare. We are known for delivering insights, products, and services that make quality care more accessible and affordable. Here, we focus on the health, happiness, and well-being of you and those we serve – we care.

What you do at McKesson matters. We foster a culture where you can grow, make an impact, and are empowered to bring new ideas. Together, we thrive as we shape the future of health for patients, our communities, and our people. If you want to be part of tomorrow’s health today, we want to hear from you.

Customer-Focused Strategic Data Scientist

What You'll Do

The Strategic Data Scientist at CoverMyMeds makes a meaningful contribution to the success of our company. This role is broadly responsible for value proposition refinement and supports key customers by providing world-class analytics and insight into our vast store of live data, turning insights and model predictions into program and product recommendations.

This position collaborates extensively with business units and channels across the company and supports the business goals of external clients.

Our ideal candidate is curious, thrives in a constantly changing environment and adeptly conveys complex analytical findings to non-technical audiences and actionable insights. Examples of tasks to be performed within the role:


 * Serve as the lead analytics point of contact for specific Biopharma customers.
 * Frequently develops data and storytelling to help anticipate and meet the strategic needs of a customer and Customer Success Team (CST).
 * Develop trusted advisor relationships with key accounts, customer stakeholders and executive sponsors.
 * Work closely with Commercial Customer Success Team (CST) members and external clients, demonstrating the value of CMM products through data narratives.
 * Analytics work will consist of deep dives into program performance and health of the current portfolio.
 * Perform in-depth analyses to identify opportunities which can lead to recommendations to improve overall profitability, value or strategic use of our products and make recommendations to improve overall profitability and value.
 * Responsibilities will include using and identifying patient, product and network models to interpret data, creating ad-hoc reports, data visualizations, and modifying and updating standard reports when applicable
 * Lead new data-driven insight presentations with customers.
 * Use creative means to proactively identify areas of improvement to enhance product value for clients.
 * Use standard formulas and methods, perform basic and advanced statistical evaluations and analysis of product data in all stages including collection, analysis, and reporting.
 * Monitor portfolio programs to support continuous quality improvement efforts using performance metric development and monitoring, and effectively communicate to this to stakeholders via strategic business reviews, scheduled meetings or where require appropriate escalation.
 * Lead data-driven insight presentations with clients
 * Use creative means to proactively identify areas of improvement to enhance product value for clients.
 * Perform in-depth analysis to identify key business risks and opportunities and make recommendations to improve overall profitability and value.
 * Become a subject matter expert (SME) on CoverMyMeds products and programs and the pharmaceutical industry.
 * Work on high-profile customer accounts in collaboration with account management teams.
   
   

Minimum Qualifications


 * Bachelor’s degree in Data Science, Statistics, Computer Science, Engineering, Public Health Information, Bioinformatics, or a related quantitative field, or equivalent practical experience
   
   

Skills You’ll Need


 * BA/BS required in Data Science, Statistics, Computer Science, Engineering, Public Health Information, Bioinformatics, or equivalent quantitative field.
 * 3-5 years of experience in a BI role in healthcare/Pharma industry
 * Understanding of data science methodologies including decision trees, multivariate analysis, segmentation modeling, factor analysis, regression analysis, forecasting, machine learning, etc.
 * Experience with statistical software experience (PYTHON, R, MATLAB, SAS, etc.) is a plus
 * Curious problem solver by nature; able to quickly make sense of complex data issues.
 * Driven, self-motivated, team player adept at working in environment with competing priorities.
 * Experience with data mining, analysis, and providing insights.
 * Adept at creating queries, writing reports, and presenting findings.
 * Intermediate to Advanced proficiency in SQL.
 * Intermediate to Advanced proficiency in data visualization tools e.g., Excel, Tableau, Power BI etc.
 * Able to communicate and manage expectations.
 * Excellent communication and presentation skills including to senior leadership and C-Suite external stakeholders; able to “think on your feet” and respond to questions where the answer is not known or not straightforward. (able to provide complex analysis in layman’s terms – at varying levels of audience, from peer set to C-suite).
   
   

Preferred Skills


 * Pharmacy or Financial transaction adjudication experience
 * Industry Expertise – Specifically in Insurance, Pharmaceutical, or Healthcare.
 * Curiosity - A naturally curious mindset with a drive to dig deeper into data and uncover the “why.”
 * Collaboration – Key success factors in this role include leading without direct authority, building relationships across multiple functions, and listening to input and perspectives from across the organization, customers, and industry stakeholders.
 * Passion - The candidate should have a passion for improving US healthcare and a desire to join a team that focuses every day on enabling healthier lives through the work that we do.
   
   

We are proud to offer a competitive compensation package at McKesson as part of our Total Rewards. This is determined by several factors, including performance, experience and skills, equity, regular job market evaluations, and geographical markets. The pay range shown below is aligned with McKesson's pay philosophy, and pay will always be compliant with any applicable regulations. In addition to base pay, other compensation, such as an annual bonus or long-term incentive opportunities may be offered. For more information regarding benefits at McKesson, please click here.

Our Base Pay Range for this position

$104,600 - $174,400

McKesson is an Equal Opportunity Employer

McKesson provides equal employment opportunities to applicants and employees and is committed to a diverse and inclusive environment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, age or genetic information. For additional information on McKesson’s full Equal Employment Opportunity policies, visit our Equal Employment Opportunity page.

Join us at McKesson!","91 applicants","Full-time","Entry level","Engineering and Information Technology","IT Services and IT Consulting","$104,600.00/yr - $174,400.00/yr","","","1741261","https://ad.doubleclick.net/ddm/clk/530879206;338758318;v?https://mckesson.wd3.myworkdayjobs.com/en-US/CoverMyMeds_External_Careers/job/USA-OH-Columbus/Strategic-Data-Scientist_JR0138798?utm_source=linkedin.com&utm_medium=job_posting&utm_campaign=Enterprise&utm_content=&utm_term=338758318&ss=paid","EXTERNAL",""
"Senior Analytics Engineer","San Francisco, CA","1 month ago","2025-10-30","https://www.linkedin.com/jobs/view/senior-analytics-engineer-at-descript-4333221051?trk=public_jobs_topcard-title","Descript","https://www.linkedin.com/company/descript?trk=public_jobs_topcard-org-name","Our vision is to build the next generation platform to enable easy and fast creation of audio and video content powered by cutting-edge AI. Building a revolutionary way to record, transcribe, edit, and mix spoken audio and video comes with a series of unique challenges and requires solving hard and complex problems.

As an early member on the data team, you will build out our data foundation across product and marketing. If you are curious, excited about working cross-functionally, and motivated by having a huge impact on the business, this role could be a good fit for you!

What You'll Do


 * Design, develop, and optimize robust data models to facilitate seamless reporting, analysis, and experimentation for marketing, product, and finance teams.
 * Spearhead the creation of advanced marketing pipelines, ensuring data flows efficiently and accurately to support customer segmentation, campaign optimization, and ROI analysis.
 * Collaborate closely with cross-functional teams to refine metrics and build intuitive dashboards that empower stakeholders with actionable insights.
 * Standardize, monitor, and document data assets, ensuring data integrity and consistency throughout our analytics infrastructure.
   
   

What You Bring


 * 7+ years of experience in Analytics Engineering, Data Engineering, or Data Analytics
 * Proficiency in SQL, Python, and dbt
 * Strong communication skills and the ability to translate business needs into tractable work items
 * Extensive experience with prosumer and/or enterprise SaaS products
 * Curiosity, savviness to navigate in a dynamic environment, and a growth mindset
   
   

The base salary range for this role is $170,000- $208,000/year. Final offer amounts will carefully consider multiple factors, including prior experience, expertise, location, and may vary from the amount above.

About Descript

Descript is building a simple, intuitive, fully-powered editing tool for video and audio — an editing tool built for the age of AI. We are a team of 150 and the backing of some of the world's greatest investors (OpenAI, Andreessen Horowitz, Redpoint Ventures, Spark Capital).

Descript is the special company that's in possession of both product market fit and the raw materials (passionate user community, great product, large market) for growth, but is still early enough that each new employee has a measurable influence on the direction of the company.

Benefits include a generous healthcare package, 401k matching program, catered lunches, and flexible vacation time. Our headquarters are located in the Mission District of San Francisco, CA. We're hiring for a mix of remote roles and hybrid roles. For those who are remote, we have a handful of opportunities throughout the year for in person collaboration. For our hybrid roles, we're flexible, and you're an adult—we don't expect or mandate that you're in the office every day. We do believe there are valuable and serendipitous moments of discovery and collaboration that come from working together in person.

Descript is an equal opportunity workplace—we are dedicated to equal employment opportunities regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. We believe in actively building a team rich in diverse backgrounds, experiences, and opinions to better allow our employees, products, and community to thrive.","158 applicants","Full-time","Mid-Senior level","Information Technology","Software Development","$170,000.00/yr - $208,000.00/yr","","","18383806","https://grnh.se/txlmsy4s3us","EXTERNAL",""
"Senior Data Analyst, Business Analytics (AI)","San Francisco, CA","3 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/senior-data-analyst-business-analytics-ai-at-cisco-4335461048?trk=public_jobs_topcard-title","Cisco","https://www.linkedin.com/company/cisco?trk=public_jobs_topcard-org-name","Sr Data Analyst, Business Analytics We believe that when passionate people can spend less time struggling with technology, they can spend more time on what matters - like teaching children, running businesses, keeping airports safe, and connecting disaster victims with relief. That’s the real power of simplicity. Cisco Meraki is the leader in cloud-managed IT, thanks to our creative, inclusive, fearless team that is driven to simplify technology so the world can simply work! Cisco Meraki is revolutionizing how IT administrators manage their infrastructure by providing simple and secure cloud-managed solutions! With a large install base of customers and rich, multi-dimensional data sets, the potential for data analytics to improve business performance for our customers and our own business is enormous. The Data Science team is a growing group that works closely with executives and leaders across the company to support the development and alignment of our business strategy. As a Senior Data Analyst in this group, you will develop cross-functional relationships and bring rigorous quantitative methods to bear on product data to drive near- and longer-term impact. This role requires a blend of strategic thinking and hands-on technical skills to ensure that projects are not only conceptualized effectively but also executed to completion with high quality. We are expanding our capabilities to leverage artificial intelligence (AI) to solve complex data challenges, uncover hidden insights, and accelerate data‑driven decision‑making. As part of this evolution, you will play a key role in identifying opportunities where AI can enhance analytics, automate processes, and improve organizational efficiency, effectively doubling down on efforts to embed AI into our workflows and optimize business outcomes. What will you do:


 * Collaborate Across Teams: Partner with PM and Engineering leaders to define key metrics for monitoring and understanding product performance and the customer experience
 * Drive AI-Enhanced Analytics: Leverage AI-powered analytics tools (such as Snowflake Cortex and similar platforms) to build intelligent reports, surface hidden patterns, generate automated insights, and proactively recommend actions for product and operational improvements.
 * Champion AI Adoption: Maintain a growth mindset around AI, constantly learn and experiment with new AI technologies, frameworks, and methodologies. Lead initiatives to adopt and scale AI tools within the analytics function.
 * Develop Next-Generation Dashboards: Create compelling, intuitive, and automated dashboards for PM, Engineering, and Executives, utilizing AI to enhance visualization, automate discovery, and deliver actionable intelligence
 * Identify High-Value AI Use Cases: Independently uncover opportunities to apply AI, such as trend detection, anomaly detection, forecasting, and natural language summarization—to improve operational processes and inform business strategy.
 * Partner on Data Integration: Work with data infrastructure teams to support Cisco data integration into the Meraki ecosystem, ensuring AI and analytics tools are optimized for evolving business needs. What skills you possess:
 * 5+ years of proven ability in an analytical role or equivalent combination of graduate degree and work experience.
 * Demonstrated experience with AI-powered analytics and automation tools (experience with Snowflake Cortex, AWS AI/ML services, or similar platforms is highly desirable).
 * Proven ability to work with dashboarding and visualization platforms, with hands‑on use of AI‑powered analytics features to enhance visualizations, automate routine insights.
 * Hands-on proficiency with SQL and Python; experience with cloud data platforms (Snowflake, AWS, GCP) is a plus.
 * Practical experience applying AI techniques (e.g., trend detection, anomaly detection, forecasting, natural language processing/summarization) to support business analysis and decision-making.
 * Outstanding critical thinking and problem-solving ability with superb attention to detail and accuracy
 * Bachelor’s degree in a quantitative major, such as Computer Science, Mathematics, Statistics, Physics, Engineering, etc Who you are:
 * You have a real passion for analytics and desire for continuous learning
 * You have strong organizational skills; able to keep track of multiple complicated priorities without losing details
 * You are eager to take ownership of projects
 * You remain curious and with an appetite to understand all the components of your work We encourage you to drop us a line even if you don’t have all the points above. That's a lot of different areas of responsibility! We will help you pick them up because we believe that great engineers come from diverse backgrounds. At Cisco Meraki, we’re challenging the status quo with the power of diversity, inclusion, and collaboration. When we connect different perspectives, we can imagine new possibilities, inspire innovation, and release the full potential of our people. We’re building an employee experience that includes appreciation, belonging, growth, and purpose for everyone. Cisco is an Affirmative Action and Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, national origin, genetic information, age, disability, veteran status, or any other legally protected basis. Cisco will consider for employment, on a case by case basis, qualified applicants with arrest and conviction records.
   
   

Why Cisco?

At Cisco, we’re revolutionizing how data and infrastructure connect and protect organizations in the AI era – and beyond. We’ve been innovating fearlessly for 40 years to create solutions that power how humans and technology work together across the physical and digital worlds. These solutions provide customers with unparalleled security, visibility, and insights across the entire digital footprint.

Fueled by the depth and breadth of our technology, we experiment and create meaningful solutions. Add to that our worldwide network of doers and experts, and you’ll see that the opportunities to grow and build are limitless. We work as a team, collaborating with empathy to make really big things happen on a global scale. Because our solutions are everywhere, our impact is everywhere.

We are Cisco, and our power starts with you.

Message to applicants applying to work in the U.S. and/or Canada:

The starting salary range posted for this position is $165,000.00 to $241,400.00 and reflects the projected salary range for new hires in this position in U.S. and/or Canada locations, not including incentive compensation*, equity, or benefits.

Individual pay is determined by the candidate's hiring location, market conditions, job-related skillset, experience, qualifications, education, certifications, and/or training. The full salary range for certain locations is listed below. For locations not listed below, the recruiter can share more details about compensation for the role in your location during the hiring process.

U.S. employees are offered benefits, subject to Cisco’s plan eligibility rules, which include medical, dental and vision insurance, a 401(k) plan with a Cisco matching contribution, paid parental leave, short and long-term disability coverage, and basic life insurance. Please see the Cisco careers site to discover more benefits and perks. Employees may be eligible to receive grants of Cisco restricted stock units, which vest following continued employment with Cisco for defined periods of time.

U.S. employees are eligible for paid time away as described below, subject to Cisco’s policies:


 * 10 paid holidays per full calendar year, plus 1 floating holiday for non-exempt employees
 * 1 paid day off for employee’s birthday, paid year-end holiday shutdown, and 4 paid days off for personal wellness determined by Cisco
 * Non-exempt employees** receive 16 days of paid vacation time per full calendar year, accrued at rate of 4.92 hours per pay period for full-time employees
 * Exempt employees participate in Cisco’s flexible vacation time off program, which has no defined limit on how much vacation time eligible employees may use (subject to availability and some business limitations)
 * 80 hours of sick time off provided on hire date and each January 1st thereafter, and up to 80 hours of unused sick time carried forward from one calendar year to the next
 * Additional paid time away may be requested to deal with critical or emergency issues for family members
 * Optional 10 paid days per full calendar year to volunteer
   
   

For non-sales roles, employees are also eligible to earn annual bonuses subject to Cisco’s policies.

Employees On Sales Plans Earn Performance-based Incentive Pay On Top Of Their Base Salary, Which Is Split Between Quota And Non-quota Components, Subject To The Applicable Cisco Plan. For Quota-based Incentive Pay, Cisco Typically Pays As Follows


 * .75% of incentive target for each 1% of revenue attainment up to 50% of quota;
 * 1.5% of incentive target for each 1% of attainment between 50% and 75%;
 * 1% of incentive target for each 1% of attainment between 75% and 100%; and
 * Once performance exceeds 100% attainment, incentive rates are at or above 1% for each 1% of attainment with no cap on incentive compensation.
   
   

For non-quota-based sales performance elements such as strategic sales objectives, Cisco may pay 0% up to 125% of target. Cisco sales plans do not have a minimum threshold of performance for sales incentive compensation to be paid.

The applicable full salary ranges for this position, by specific state, are listed below:

New York City Metro Area

$165,000.00 - $277,600.00

Non-Metro New York State & Washington State

$146,700.00 - $247,000.00


 * For quota-based sales roles on Cisco’s sales plan, the ranges provided in this posting include base pay and sales target incentive compensation combined.
 * Employees in Illinois, whether exempt or non-exempt, will participate in a unique time off program to meet local requirements.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Software Development","$165,000.00/yr - $241,400.00/yr","","","1063","https://careers.cisco.com/global/en/job/CISCISGLOBAL1449744EXTERNALENGLOBAL/Senior-Data-Analyst-Business-Analytics-AI?utm_source=linkedin&utm_medium=phenom-feeds","EXTERNAL",""
"Data Scientist","San Francisco, CA","1 week ago","2025-11-22","https://www.linkedin.com/jobs/view/data-scientist-at-sierra-business-solution-4338573138?trk=public_jobs_topcard-title","Sierra Business Solution","https://www.linkedin.com/company/sierrabusiness?trk=public_jobs_topcard-org-name","About Us


 * At Sierra, we’re creating a platform to help businesses build better, more human customer experiences with AI. We are primarily an in-person company based in San Francisco, with growing offices in Atlanta, New York, London, and Singapore.
 * We are guided by a set of values that are at the core of our actions and define our culture: Trust, Customer Obsession, Craftsmanship, Intensity, and Family. These values are the foundation of our work, and we are committed to upholding them in everything we do.
 * Our co-founders are Bret Taylor and Clay Bavor. Bret currently serves as Board Chair of OpenAI. Previously, he was co-CEO of Salesforce (which had acquired the company he founded, Quip) and CTO of Facebook. Bret was also one of Google's earliest product managers and co-creator of Google Maps. Before founding Sierra, Clay spent 18 years at Google, where he most recently led Google Labs. Earlier, he started and led Google’s AR/VR effort, Project Starline, and Google Lens. Before that, Clay led the product and design teams for Google Workspace.
   
   

What You'll Do

Sierra has built a strong data foundation—now we're looking to grow our Data Science team to unlock its full potential. You’ll play a foundational role in driving data strategy, leveraging rich customer interaction data to improve user engagement and product experience. Partnering with engineering, research, and product teams, you’ll develop predictive models, build experimentation capabilities, and embed data-driven decision-making across the company. This is a unique opportunity to shape Sierra’s data future and make a lasting impact on AI-powered customer interactions.


 * Conduct deep-dive analyses of customer data to identify trends, patterns, and actionable insights for improving the customer experience and product strategies.
 * Develop and deploy machine learning models to analyze customer engagement and optimize experiences across chat, agent interactions, and product usage.
 * Collaborate with product, engineering, and research teams to inform product strategy and execution, build excellent experiences, and experiment rapidly.
 * Partner with the data platform team to ensure robust data pipelines and a scalable infrastructure for conducting advanced analytics.
   
   

What You'll Bring


 * Proven Experience: Extensive experience in data science and analytics, with background leading projects from ideation to launch.
 * Curiosity & Customer-centricity: Passion for deeply understanding user needs and finding the right solutions from first principles.
 * Adaptability and Resilience: Comfort working in a fast-paced startup environment, able to adapt to changing priorities and handle ambiguity with grace.
 * Technical proficiency: Strong proficiency in statistical analysis, machine learning, and data mining techniques using tools such as Python, R, SQL, and cloud-based platforms (e.g., AWS, GCP).
 * Strong analytic skills: Experience with large-scale data analysis, and working with structured and unstructured data (including customer interaction data, chat logs, and user behavior data).
 * Experimentation expertise: Ability to build and evaluate models for experimentation and causal inference, with a clear understanding of designing and analyzing A/B tests.
 * Excellent communication: Strong written and verbal communication skills, with the ability to present complex technical results to non-technical stakeholders.
 * Great Collaboration: Ability to partner closely with product, engineering, and leadership to help bring ideas to life.
   
   

Even better...


 * Experience working with large language models (LLMs), conversational AI, or agent-based systems.
 * Familiarity with building or improving data platforms for advanced analytics.
 * Exposure to product analytics or customer experience research in a SaaS or consumer-facing tech company.
   
   

Our values


 * Trust: We build trust with our customers with our accountability, empathy, quality, and responsiveness. We build trust in AI by making it more accessible, safe, and useful. We build trust with each other by showing up for each other professionally and personally, creating an environment that enables all of us to do our best work.
 * Customer Obsession: We deeply understand our customers’ business goals and relentlessly focus on driving outcomes, not just technical milestones. Everyone at the company knows and spends time with our customers. When our customer is having an issue, we drop everything and fix it.
 * Craftsmanship: We get the details right, from the words on the page to the system architecture. We have good taste. When we notice something isn’t right, we take the time to fix it. We are proud of the products we produce. We continuously self-reflect to continuously self-improve.
 * Intensity: We know we don’t have the luxury of patience. We play to win. We care about our product being the best, and when it isn’t, we fix it. When we fail, we talk about it openly and without blame so we succeed the next time.
 * Family: We know that balance and intensity are compatible, and we model it in our actions and processes. We are the best technology company for parents. We support and respect each other and celebrate each other’s personal and professional achievements.
   
   

What We Offer

We want our benefits to reflect our values and offer the following to full-time employees:


 * Flexible (Unlimited) Paid Time Off
 * Medical, Dental, and Vision benefits for you and your family
 * Life Insurance and Disability Benefits
 * Retirement Plan (e.g., 401K, pension) with Sierra match
 * Parental Leave
 * Fertility and family building benefits through Carrot
 * Lunch, as well as delicious snacks and coffee to keep you energized
 * Discretionary Benefit Stipend giving people the ability to spend where it matters most
 * Free alphorn lessons
   
   

These benefits are further detailed in Sierra's policies and are subject to change at any time, consistent with the terms of any applicable compensation or benefits plans. Eligible full-time employees can participate in Sierra's equity plans subject to the terms of the applicable plans and policies.

Be you, with us

We're working to bring the transformative power of AI to every organization in the world. To do so, it is important to us that the diversity of our employees represents the diversity of our customers. We believe that our work and culture are better when we encourage, support, and respect different skills and experiences represented within our team. We encourage you to apply even if your experience doesn't precisely match the job description. We strive to evaluate all applicants consistently without regard to race, color, religion, gender, national origin, age, disability, veteran status, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class.","162 applicants","Full-time","Entry level","Engineering and Information Technology","IT Services and IT Consulting","","","","33245639","https://www.adzuna.com/details/5508487195?v=7938A4026B4A2CF717FACA35326753AF868E1E76&ccd=38897cc5f206873d1b9dc2660b5637e6&r=20758277&frd=28fa273d735dd7570a17829007238858&utm_source=linkedin7&utm_medium=organic&chnlid=1931&title=Data%20Scientist&a=e","EXTERNAL",""
"Senior Data Engineer","San Jose, CA","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/senior-data-engineer-at-adobe-4324841531?trk=public_jobs_topcard-title","Adobe","https://www.linkedin.com/company/adobe?trk=public_jobs_topcard-org-name","Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

The Opportunity

We are seeking a passionate Data Engineer who can operate at the intersection of data processing and machine learning to derive intelligence from enterprise content and help build the data backbone of brand-aware generative AI. In this role, you will design and implement data foundations that ingest and enrich structured, unstructured, and multimodal brand assets, creating a scalable and retrievable brand intelligence platform. Your work will directly help enterprises create content at scale while preserving brand identity.

As part of the brand AI services team, you’ll ensure generative models reliably access timely, relevant data—driving better reasoning, personalization, and consistency across key Adobe surfaces (GenStudio for Performance Marketers, Workfront, AEM).

What You'll Do


 * Build scalable ingestion pipelines for brand information and creative assets, ensuring freshness, reliability, and versioning.
 * Integrate and leverage systems and models from our machine learning and data science partner teams.
 * Design and maintain brand-aware data models, ontologies, and multi-modal graphs to support context linking and rich retrievals.
 * Implement hybrid storage and retrieval strategies across vector databases, graph databases, and search engines, optimizing for precision and latency.
 * Develop metadata enrichment pipelines to enhance semantic search, personalization, and optimization for RAG-based conversational systems.
 * Ensure data quality and observability by monitoring metrics for accuracy, coverage, and timeliness; build monitoring systems to track ingestion and retrieval health.
 * Collaborate with product, ML, and information retrieval teams to align data infrastructure with creative workflows.
 * Optimize pipelines using distributed/streaming systems for scale and speed.
   
   

What You Need To Succeed


 * 4+ years of software development experience with 1+ year in data engineering, search relevance, or large-scale systems for conversational experiences.
 * Expertise in building reliable and innovative ETL pipelines for heterogeneous data.
 * Experience with distributed data frameworks (Spark, Flink) and streaming platforms (Kafka).
 * Proficiency in Python (preferred) or Java/Scala, with strong CS fundamentals.
 * Experience with cloud platforms (Azure, AWS, or GCP) and containerization/orchestration (Docker, Kubernetes).
 * Familiarity with modern search systems (Elastic, Vespa) and graph databases (Neo4j, TigerGraph).
 * Understanding of ML data pipelines and MLOps standards for monitoring and continuous improvement
 * Self-starter who thrives in zero-to-one environments and can make informed tradeoffs.
   
   

Preferred Qualifications


 * Background in information retrieval, NLP, or cognitive computing.
 * Experience developing, optimizing, and deploying data processing with Apache Spark/Dask/Ray.
 * Experience with ontologies, knowledge graphs, or semantic enrichment pipelines.
 * Degree in Computer Science, Information Systems, or related field.
   
   

Our compensation reflects the cost of labor across several  U.S. geographic markets, and we pay differently based on those defined markets. The U.S. pay range for this position is $133,900 -- $242,000 annually. Pay within this range varies by work location and may also depend on job-related knowledge, skills, and experience. Your recruiter can share more about the specific salary range for the job location during the hiring process.

At Adobe, for sales roles starting salaries are expressed as total target compensation (TTC = base + commission), and short-term incentives are in the form of sales commission plans. Non-sales roles starting salaries are expressed as base salary and short-term incentives are in the form of the Annual Incentive Plan (AIP).

In addition, certain roles may be eligible for long-term incentives in the form of a new hire equity award.

State-Specific Notices:

California:

Fair Chance Ordinances

Adobe will consider qualified applicants with arrest or conviction records for employment in accordance with state and local laws and “fair chance” ordinances.

Colorado:

Application Window Notice

If this role is open to hiring in Colorado (as listed on the job posting), the application window will remain open until at least the date and time stated above in Pacific Time, in compliance with Colorado pay transparency regulations. If this role does not have Colorado listed as a hiring location, no specific application window applies, and the posting may close at any time based on hiring needs.

Massachusetts:

Massachusetts Legal Notice

It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.

Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.

Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Advertising Services, IT Services and IT Consulting, and Software Development","$133,900.00/yr - $242,000.00/yr","","","1480","https://www.linkedin.com/jobs/view/senior-data-engineer-at-adobe-4324841531?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","New York City Metropolitan Area","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/data-engineer-at-alexander-chapman-4337038112?trk=public_jobs_topcard-title","Alexander Chapman","https://uk.linkedin.com/company/alexander-chapman?trk=public_jobs_topcard-org-name","🚀 Hiring: Data Engineer | NYC | Modern Stack | High-Impact Finance




A fast-growing investment firm in New York City is looking for a Data Engineer (5–7 years) to own and scale their modern data infrastructure. This is a high-impact role where your work directly shapes reporting, analytics, and strategic decision-making across the organization.




What You’ll Do:

• Build and maintain scalable pipelines using Snowflake, DBT, FiveTran/Hevo

• Design clean, reliable data models powering BI dashboards (PowerBI, Sigma, Tableau)

• Automate workflows with Azure Logic Apps & Power Automate

• Implement CI/CD best practices for data workflows

• Drive data governance, quality, and security standards

• Partner with cross-functional teams to standardize data and ensure strong QA/QC




What We’re Looking For:

• 5–7 years of experience in data engineering (finance industry experience is a plus)

• Strong hands-on skills with modern data stack tools

• Experience with data modeling, data governance, and workflow automation

• Solid understanding of cloud platforms (Azure, AWS, or GCP)

• Strong communication and collaboration skills




Why This Role Stands Out:

You’ll join a collaborative, high-performing team operating at the intersection of data, finance, and strategy. This is the kind of environment where great engineers can deeply influence architecture, drive standards, and help scale a sophisticated data ecosystem.




📍 Location: New York City (hybrid)

💼 Level: Mid–Senior","Over 200 applicants","Full-time","Mid-Senior level","Engineering and Finance","Financial Services and Investment Management","","Jonida Carkaxhiu","https://www.linkedin.com/in/jonida-carkaxhiu-355186248","10978719","https://www.linkedin.com/jobs/view/data-engineer-at-alexander-chapman-4337038112?trk=public_jobs_topcard-title","EASY_APPLY","Vision insurance
Medical insurance
Dental insurance
401(k)"
"Data Scientist, People","Los Angeles, CA","2 weeks ago","2025-11-15","https://www.linkedin.com/jobs/view/data-scientist-people-at-doordash-4340823464?trk=public_jobs_topcard-title","DoorDash","https://www.linkedin.com/company/doordash?trk=public_jobs_topcard-org-name","About The Team

The People Data Science team is part of DoorDash’s People Intelligence organization, a multidisciplinary group that combines data science, business intelligence, analytics engineering, and data engineering to power our people decisions with trusted, scalable insights. Together, we enable DoorDash to unlock the full potential of our talent and drive measurable improvements in organizational effectiveness.

As the advanced analytics arm of People Intelligence, the People Data Science team applies statistical modeling, machine learning, and AI-driven analysis to uncover trends and patterns across the employee lifecycle — from hiring to engagement to retention. By transforming people data into meaningful insights, we help DoorDash foster a thriving, high-performing workforce and make data-informed decisions that elevate the employee experience and organizational impact.

About The Role

As a Data Scientist on the People Team at DoorDash, you will shape the future of people analytics by building and deploying AI and LLM-based models that deliver insights from both quantitative and qualitative employee data. You’ll design intelligent systems and agents that leverage large-scale employee experience, performance, and organizational data — integrating structured and unstructured signals to uncover trends that inform talent strategy and business outcomes.

This role blends deep expertise in statistical modeling, natural language processing, and applied machine learning with a strong understanding of people analytics and business context. You’ll collaborate with data engineers, applied scientists, and People Business Partners to develop scalable insight-generation systems that help leaders make more informed, data-backed decisions.

You're Excited About This Opportunity Because You Will...


 * Build AI-powered people analytics tools — develop LLM- or agent-based systems that summarize employee sentiment, extract insights from qualitative feedback, and surface trends in quantitative data.
 * Apply advanced statistical and ML techniques to understand drivers of engagement, retention, and performance.
 * Design, test, and deploy scalable models and pipelines that analyze large volumes of survey, feedback, and HR data.
 * Collaborate cross-functionally with People, Engineering, and Product partners to design AI solutions that support business strategy and improve the employee experience.
 * Translate data into action — tell compelling stories with data that shape leadership decisions and organizational priorities.
 * Explore cutting-edge GenAI and NLP approaches — from embeddings and topic modeling to fine-tuning LLMs for people analytics applications.
 * Contribute to the evolution of People Data Science at DoorDash — shaping our approach to scalable, AI-driven insights for the future of work.
   
   

We’re Excited About You Because You Have...


 * Master’s or Ph.D. in Data Science, Computer Science, Statistics, Applied Mathematics, Economics, Industrial-Organizational Psychology (quantitative track), or a related field.
 * 3+ years of experience applying data science methods to real-world problems (1–2+ years in People Analytics preferred).
 * Proficiency in Python and SQL, with experience using ML and NLP libraries (e.g., scikit-learn, statsmodels).
 * Proven experience building or applying large language models (LLMs) and NLP-based systems for text summarization, sentiment analysis, or insight extraction.
 * Strong foundation in statistical modeling, causal inference, and experimental design (e.g., regression, clustering, A/B testing, time-series).
 * Experience designing and scaling data pipelines using Snowflake, dbt, Databricks.
 * Familiarity with LLM orchestration tools (e.g., LangChain, LlamaIndex, or similar frameworks) and vector databases (e.g., Postgres with pgvector).
 * Ability to distill complex analyses into actionable insights through clear communication, visualization, and storytelling.
 * Experience creating data visualizations and dashboards using tools such as Sigma, Tableau, or Looker to communicate insights effectively.
 * Passion for building AI solutions that empower people leaders and improve organizational decision-making through ethical and responsible applications of data science.
   
   

Nice-to-have


 * Experience building or contributing to AI analytics assistants or chatbots that enable natural language access to insights.
 * Experience with data science python packages such as PyTorch, TensorFlow, and Hugging Face Transformers.
 * Experience in survey analytics, employee engagement research, or text analytics using large-scale feedback data.
 * Familiarity with HRIS systems (e.g., Workday) and core workforce metrics such as attrition and engagement.
 * Exposure to fine-tuning foundation models and evaluating LLM performance for reliability and bias.
 * Experience with graph databases (e.g., Neo4j) for modeling organizational networks.
 * Background in applied behavioral science, organizational research, or people analytics experimentation.
   
   

Notice to Applicants for Jobs Located in NYC or Remote Jobs Associated With Office in NYC Only

We use Covey as part of our hiring and/or promotional process for jobs in NYC and certain features may qualify it as an AEDT in NYC. As part of the hiring and/or promotion process, we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound from August 21, 2023, through December 21, 2023, and resumed using Covey Scout for Inbound again on June 29, 2024.

The Covey tool has been reviewed by an independent auditor. Results of the audit may be viewed here: Covey

Compensation

The successful candidate’s starting pay will fall within the pay range listed below and is determined based on job-related factors including, but not limited to, skills, experience, qualifications, work location, and market conditions. Base salary is localized according to an employee’s work location. Ranges are market-dependent and may be modified in the future.

In addition to base salary, the compensation for this role includes opportunities for equity grants. Talk to your recruiter for more information.

DoorDash cares about you and your overall well-being. That’s why we offer a comprehensive benefits package to all regular employees, which includes a 401(k) plan with employer matching, 16 weeks of paid parental leave, wellness benefits, commuter benefits match, paid time off and paid sick leave in compliance with applicable laws (e.g. Colorado Healthy Families and Workplaces Act). DoorDash also offers medical, dental, and vision benefits, 11 paid holidays, disability and basic life insurance, family-forming assistance, and a mental health program, among others.

To learn more about our benefits, visit our careers page here.

See Below For Paid Time Off Details


 * For salaried roles: flexible paid time off/vacation, plus 80 hours of paid sick time per year.
 * For hourly roles: vacation accrued at about 1 hour for every 25.97 hours worked (e.g. about 6.7 hours/month if working 40 hours/week; about 3.4 hours/month if working 20 hours/week), and paid sick time accrued at 1 hour for every 30 hours worked (e.g. about 5.8 hours/month if working 40 hours/week; about 2.9 hours/month if working 20 hours/week).
   
   

The national base pay range for this position within the United States, including Illinois and Colorado.

$124,100—$182,500 USD

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

Our Commitment to Diversity and Inclusion

We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on “protected categories,” we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.

Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.

If you need any accommodations, please inform your recruiting contact upon initial connection.","188 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","","","","3205573","https://www.linkedin.com/jobs/view/data-scientist-people-at-doordash-4340823464?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Riverside, CA","5 days ago","2025-11-27","https://www.linkedin.com/jobs/view/data-engineer-at-caci-international-inc-4339362474?trk=public_jobs_topcard-title","CACI International Inc","https://www.linkedin.com/company/caci-international-inc?trk=public_jobs_topcard-org-name","Job Category: Information Technology

Time Type: Full time

Minimum Clearance Required to Start: Secret

Employee Type: Regular

Percentage of Travel Required: Up to 10%

Type of Travel: Continental US

* * *

The Opportunity

CACI is actively seeking a Data Engineer to support Naval Surface Warfare Center (NSWC) Corona. As a Data Engineer you will support one of the departments within NSWC Corona and provide expertise in support of multiple technical projects with a variety of stakeholders/sponsors.

Responsibilities


 * Design, develop, and maintain data pipelines. Using a variety of data engineering tools.
 * Work in a team environment.
 * Create and execute queries into various databases including SQL Server and Oracle DB in order to find relevant and curate relative data.
 * Create and train various Large Language models (LLMs) and other Machine Learning Models.
 * Develop and work with Machine Learning and Natural Language Processing systems and integrate with existing products.
 * Work with technical leads and project managers on architecting data engineering solutions.
 * Researching and staying up to date with the latest ETL tools, AI/Machine Learning Models, and Data Science applications.
 * Analyze large data sets to derive insights, analyze trends, and create predictive models.
 * Maintain code repositories and follow change management protocols.
 * Collaborate with Team Members across multiple projects.
 * Provide recommendations for process development and improvement.
 * Communicate findings effectively through data visualization techniques such as charts, graphs, and dashboards.
   
   

Qualifications

Required:


 * Relevant Degree or US Navy equivalent work experience.
 * 3-5 years of experience statistical analysis.
 * Strong verbal and written communication capabilities.
 * Code/Programming Language Fluency in Python, SQL, and knowledge of frameworks such as PyTorch, Tensorflow, and Keras.
 * Experience with AI & Machine Learning.
   
   

Desired


 * Knowledge of the Navy and Navy Organization.
 * Knowledge of Data Science, Big Data and its applications.
 * Knowledge of data COTS tools.
 * Experience with using Cloud native tools.
 * Experience with soft ware development process.
   
   

________________________________________________________________________________________

What You Can Expect

A culture of integrity.

At CACI, we place character and innovation at the center of everything we do. As a valued team member, you’ll be part of a high-performing group dedicated to our customer’s missions and driven by a higher purpose – to ensure the safety of our nation.

An environment of trust.

CACI values the unique contributions that every employee brings to our company and our customers - every day. You’ll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality.

A focus on continuous growth.

Together, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground — in your career and in our legacy.

Your potential is limitless. So is ours.

Learn more about CACI here.

________________________________________________________________________________________

Pay Range: There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here.

Since this position can be worked in more than one location, the range shown is the national average for the position.

The Proposed Salary Range For This Position Is

$63,300-$129,700

CACI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, age, national origin, disability, status as a protected veteran, or any other protected characteristic.","121 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","$63,300.00/yr - $129,700.00/yr","","","3672","https://careers.caci.com/global/en/job/CACIGLOBAL319974EXTERNALENGLOBAL/Data-Engineer?utm_source=linkedin&utm_medium=phenom-feeds","EXTERNAL",""
"Analytics Director","San Jose, CA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/analytics-director-at-fractal-4323576190?trk=public_jobs_topcard-title","Fractal","https://www.linkedin.com/company/fractal-analytics?trk=public_jobs_topcard-org-name","Analytics Director




Fractal is a strategic AI partner to Fortune 500 companies with a vision to power every human decision in the enterprise. Fractal is building a world where individual choices, freedom, and diversity are the greatest assets. An ecosystem where human imagination is at the heart of every decision. Where no possibility is written off, only challenged to get better. We believe that a true Fractalite is the one who empowers imagination with intelligence. Fractal has been featured as a Great Place to Work by The Economic Times in partnership with the Great Place to Work® Institute and recognized as a ‘Cool Vendor’ and a ‘Vendor to Watch’ by Gartner.




Please visit Fractal | Intelligence for Imagination for more information about Fractal.




Position Overview:

Fractal is seeking an experienced and highly influential Analytics Director. This is a client facing role where you will be a key strategic partner to clients across multiple functional areas ex. Marketing, engineering, analytics & user experience, using data to shape the future of our client’s products & services.




You will be responsible for defining and analyzing metrics that measure success, conducting deep-dive analyses to uncover critical insights and opportunities, and driving a culture of data-informed decision-making. You shall also play the role of a strategic AI & Analytics advisor to the clients, a role in which you would help bring the best of thinking on AI, Engineering and Design to our client’s workstreams and help identify solutions to the problems.




The ideal candidate is a master of their craft, possessing deep technical skills combined with strong business acumen, ability to translate complex data into a compelling narrative that inspires action and drives product strategy, and the operational expertise to run a globally distributed delivery team.




Role & Responsibilities:

 * Delivery Excellence - Guide team to ensure implementation of delivery best practices
 * Client Management: Liaise between the clients & Fractal team, for gathering analytics requirements and managing the quality of delivery
 * Business overview - Help the team understand business context and map the analysis back to business problem
 * Storyboarding & Problem Solving - Lead in problem solving for all projects, ensure first principles thinking is applied
 * Standardization - Implement usage of standard template for all analysis (Excel, Presentations, dashboards), project plan, dashboard development docs etc.
 * Accuracy - Be accountable for the correctness of output
 * Timeliness - Ensure timely completion of projects with regular updates, and escalations / recommendations if timelines are going to be missed.
 * Communication - Coach and guide the team to share summarized observations and insights
 * Documentation - Ensure the preparation of analysis documents, BRDs, scoping documentation, presentation decks, code check-ins, consistent code formatting, etc.




 * Consulting excellence: Co-own business/ success with the client
 * Outside in perspective: Bring outside in perspective to projects being delivered (ex. Impact of AI on Content creation, Impact on AI on Product growth)
 * Business ownership: Showcase end to end ownership of client’s business problem, showcase thinking beyond immediate focus areas for the client
 * AED Led solutioning: Expand footprint by bringing in AI, Design and Engineering workstream to the pod
 * AI - Leverage ML / AI / Gen AI based solution approaches to elevate the quality of solutions
 * Engineering - Help the team adopt engineering best practices around data design, pipeline design, code quality, code check-in etc.
 * Design - Leverage design thinking and behavioral science based approaches
 * Productivity & Utilization - Strategically partner to increase the productivity of the team
 * Improve processes, anticipate requirements, and develop and implement solutions
 * Ensure appropriate utilization of team member’s time across teams to maximize productivity
 * Manage weekly / monthly workstack by allocating projects, developing and monitoring the implementation of project plans, and optimizing bandwidth across the team
 * Team Management - Performance management and Engagement
 * Collect regular performance feedback and be responsible for the training and coaching of the team based on the performance feedback provided
 * Ensure each feedback is acknowledged, and a remedial plan recommended and actioned if areas of improvement are flagged
 * Ensure high engagement to maximize retention
 * Business Continuity - Ensure business continuity in case of unforeseen circumstances
 * Facilitate analytics continuity by planning, managing and communicating leaves, backups during leaves, and exit / onboarding transitions with no/minimal impact on operations.
 * Create onboarding documents for new hires that enlist the process to get their access enabled and complete their KT within 3-5weeks from joining.
 * Periodic Updates - Provide regular updates on progress, future plan, blockers, risks etc
 * Create and update documents that tracks weekly / bi-weekly/ monthly updates for the projects delivered and share with key stakeholders on regular basis
 * Share weekly documented updates to client stakeholders over an email
 * Growth enablement-
 * Ensure project work is marketable using case studies & demos (where applicable) such that each project / workstream should have a case study
 * Lead development of new solutions through POVs during QBRs and other mediums




Qualifications & Experience:

 * Minimum 10 years hands on experience in running data analytics projects, project management, client relationship management & people management within AI/Data Analytics services industry
 * Hands on experience with SQL, Python, Tableau and other similar industry leading data and analytics resources
 * Strong analytical/ logical thinking skills and clarity of thought
 * Clear & articulate communication with senior executives
 * Enable and demonstrate innovative thinking and inspire innovative action
 * Exhibit a commitment to be a team player with a flexible “can do” attitude and strong interpersonal skills; be a Self-Starter; Very proactive; Takes accountability and ownership
 * Possess cross-cultural/geographical sensitivities
 * Minimum 5 years of experience working in TMT data and analytics consulting, understands data landscape and value creation through consulting services for TMT
 * Have experience working with any of large TMT companies
 * Education: Bachelors / Master’s degree in Engineering, Business, Economics/ Statistics or equivalent




Nice to have:

 * Embed Artificial Intelligence & Machine Learning in all projects & proposals
 * Cross-learn and collaborate to demo solutions to other clients
 * Design mock-ups for the solutions – visualizations/solution approaches
 * Share status updates every week in a standard format; Share minutes of meetings with clients & offshore team after every meeting
 * Raise flags to clients in case of failure to meet dependencies




Pay:

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions, including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Fractal, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is: $132,000 - $180,000. In addition, you may be eligible for a discretionary bonus for the current performance period.




Benefits:

As a full-time employee of the company or as an hourly employee working more than 30 hours per week, you will be eligible to participate in the health, dental, vision, life insurance, and disability plans in accordance with the plan documents, which may be amended from time to time. You will be eligible for benefits on the first day of employment with the Company. In addition, you are eligible to participate in the Company 401(k) Plan after 30 days of employment, in accordance with the applicable plan terms. The Company provides for 11 paid holidays and 12 weeks of Parental Leave. We also follow a “free time” PTO policy, allowing you the flexibility to take the time needed for either sick time or vacation.




Fractal provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.","37 applicants","Full-time","Mid-Senior level","Project Management, Management, and Information Technology","IT Services and IT Consulting","$132,000.00/yr - $180,000.00/yr","","","26945","https://www.linkedin.com/jobs/view/analytics-director-at-fractal-4323576190?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Paid maternity leave
Paid paternity leave
Disability insurance
Commuter benefits
Child care support"
"Data Engineer","Herndon, VA","3 weeks ago","2025-11-07","https://www.linkedin.com/jobs/view/data-engineer-at-bespoke-technologies-inc-4332962451?trk=public_jobs_topcard-title","Bespoke Technologies, Inc.","https://www.linkedin.com/company/bespoketechinc?trk=public_jobs_topcard-org-name","BT-151 – Data Engineer

Skill Level: Mid

Location: Chantilly/Herndon


 * MUST HAVE AN ACTIVE TS OR TS/SCI CLEARANCE TO APPLY. Those without an active security clearance will not be considered.**
   
   

Role Description

As a Data Engineer on the Data Catalog and Governance team, you will be the technical engineer that brings our governance policies to life. You will be responsible for the hands-on development and maintenance of the systems that connect our data sources to our enterprise data catalog. Working under the guidance of senior technical and program leadership, you will build the data pipelines and integrations necessary to automate the collection of metadata and lineage. This is an implementation-focused role for a skilled engineer who enjoys solving technical challenges and wants to apply their skills to build a foundation of trust and transparency in data.


 * Develop, maintain, and enhance data pipelines that automatically harvest metadata from various data sources (e.g., databases, data lakes, APIs) and ingest it into the enterprise data catalog (e.g., Collibra).
 * Implement custom integrations using the data catalog's APIs and SDKs to connect with platforms like Databricks, Snowflake, and S3.
 * Work with senior engineers and analysts to implement technical data quality rules and monitoring solutions within data pipelines.
 * Support the technical administration and operational health of the data catalog platform, troubleshooting ingestion issues and ensuring system stability.
 * Write and maintain clear, concise documentation for the data pipelines and integrations you build.
 * Collaborate with data source owners and other engineering teams to ensure successful metadata extraction and lineage tracing.
 * Contribute to the scripting and automation of recurring data governance tasks.
   
   

Required Qualifications


 * 4-7 years of hands-on experience in a data engineering role.
 * Strong programming proficiency in Python and advanced SQL.
 * Experience building and maintaining data pipelines and ETL/ELT processes.
 * Hands-on experience working with REST APIs to integrate different systems.
 * Experience with cloud data platforms (e.g., Databricks, Snowflake, AWS S3, Azure Data Lake).
 * A foundational understanding of metadata management and data governance concepts.
   
   

Preferred Qualifications


 * Hands-on experience developing integrations for an enterprise data catalog platform (e.g., Collibra, Alation).
 * Experience with workflow orchestration tools (e.g., Airflow, Prefect).
 * Familiarity with Infrastructure-as-Code (e.g., Terraform).
 * Exposure to streaming data technologies (e.g., Kafka).","71 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","","","","71291624","https://www.linkedin.com/jobs/view/data-engineer-at-bespoke-technologies-inc-4332962451?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr. Software Engineer","San Francisco, CA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/sr-software-engineer-at-6sense-4339041571?trk=public_jobs_topcard-title","6sense","https://www.linkedin.com/company/6sense?trk=public_jobs_topcard-org-name","Our Mission:

6sense is on a mission to revolutionize how B2B organizations create revenue by predicting customers most likely to buy and recommending the best course of action to engage anonymous buying teams. 6sense Revenue AI is the only sales and marketing platform to unlock the ability to create, manage and convert high-quality pipeline to revenue.

Our People:

People are the heart and soul of 6sense. We serve with passion and purpose. We live by our Being 6sense values of Accountability, Growth Mindset, Integrity, Fun and One Team. Every 6sensor plays a part in deﬁning the future of our industry-leading technology. 6sense is a place where difference-makers roll up their sleeves, take risks, act with integrity, and measure success by the value we create for our customers.

We want 6sense to be the best chapter of your career.

About The Role

You are a Software Engineer, who is passionate about writing beautiful code and building great products. You have an intuitive sense of the right tools and frameworks to

use to solve a given problem. You are not afraid to traverse the entire spectrum of the development process from writing code and testing to deploying and managing your

systems in production. You are smart, but know that there is no substitute for hard work.

You have good communication skills, a ‘can-do’ entrepreneurial attitude, and a team-oriented mindset.

Key Responsibilities

Develop backend & data engineering framework for 6sense’s revenue AI, marketing and analytics products

Work on complex problems related to scalability, performance & big data

Write performant REST APIs for both internal and external consumption

Build robust, high-volume, large data set production applications. Collaborate with Product and Architect to solve complex problems

Support QA and DevOps teams with test frameworks and automation

Mentors junior engineers and provides technical guidance to the team

Required Qualifications And Must-have Skills

BS/MS in Computer Science, or related field

5+ years of relevant technical experience

Solid foundation in computer science, with strong competencies in data structures, algorithms, and software design.

Experience with software design and development, with knowledge of UNIX/Linux.

Strong coding skills and hands-on experience in Java on Spring Boot, Python on Django, Golang, and an OO framework.

Basic AWS experience or any other cloud platforms like GCP, Azure, etc.

Exposure and experience working with Kubernetes.

Knowledge in SQL or Non-SQL, direct work experience on MySQL and/or Hive.

Working experience of SingleStore(memsql) DB is a huge plus.

Work with teams and being able to multi-task on multiple products and projects.

Excellent communication skills, both written and oral.

Experience with test-driven development, continuous integration, and continuous deployment processes

Nice To Have Skills

Experience with DevOps i.e. rolling out and managing development, build, and production environments

Experience with CI/CD, tools like Jenkins, Bazel, DevOps for build.

Exposure to application security

Familiar with Node.js

SQL, Non-SQL performance tuning

Exposure to design patterns, aspect-oriented programming is a huge Interpersonal Attributes

You can work independently as well as part of a team

You take ownership of projects and drive them to a conclusion

You’re a good communicator and are capable of not just doing the work, but teaching others and explaining the “why” behind complicated technical decisions

You can present your architecture and designs to cross teams

You aren’t afraid to roll up your sleeves: This role will evolve, and we’ll want you to evolve with it!

Our Benefits:

Full-time employees can take advantage of health coverage, paid parental leave, generous paid time-off and holidays, quarterly self-care days off, and stock options. We’ll make sure you have the equipment and support you need to work and connect with your teams, at home or in one of our oﬃces.

We have a growth mindset culture that is represented in all that we do, from onboarding through to numerous learning and development initiatives including access to our LinkedIn Learning platform. Employee well-being is also top of mind for us. We host quarterly wellness education sessions to encourage self care and personal growth. From wellness days to ERG-hosted events, we celebrate and energize all 6sense employees and their backgrounds.

Equal Opportunity Employer:

6sense is an Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to jobs@6sense.com.

We are aware of recruiting impersonation attempts that are not affiliated with 6sense in any way. All email communications from 6sense will originate from the @6sense.com domain. We will not initially contact you via text message and will never request payments. If you are uncertain whether you have been contacted by an official 6sense employee, reach out to jobs@6sense.com","Over 200 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Software Development","","","","3677944","https://www.linkedin.com/jobs/view/sr-software-engineer-at-6sense-4339041571?trk=public_jobs_topcard-title","EASY_APPLY",""
"GEN AI LLM Data Scientist","Raritan, NJ","1 month ago","2025-10-27","https://www.linkedin.com/jobs/view/gen-ai-llm-data-scientist-at-the-dignify-solutions-llc-4341865726?trk=public_jobs_topcard-title","The Dignify Solutions, LLC","https://www.linkedin.com/company/dignify-solutions?trk=public_jobs_topcard-org-name"," * Must have 12+ years of experience working in Data science, Machine learning and especially NLP technologies.
 * Exposure to various LLM technologies and solid understanding of Transformer Encoder Networks.
 * Able to apply deep learning and generative modeling techniques to develop LLM solutions in the field of Artificial Intelligence.
 * Utilize your extensive knowledge and expertise in machine learning (Client) with a focus on generative models, including but not limited to generative adversarial networks (GANs), variational autoencoders (VAEs), and transformer-based architectures.
 * Solid understanding of Model development, model serving, training/re-training techniques in a data sparse environment.
 * Very good understanding of Prompt engineering techniques in developing Instruction based LLMs.
 * Must be able to design and implement state-of-the-art generative models for natural language processing (NLP) tasks such as text generation, text completion, language translation, and document summarization.
 * Work with SAs and collaborate with cross-functional teams to identify business requirements and deliver solutions that meet the customer needs.
 * Passionate to learn and stay updated with the latest advancements in generative AI and LLM.
 * Evaluate and preprocess large-scale datasets, ensuring data quality and integrity, and develop data pipelines for training and evaluation of generative models.
 * Nice to have- provide guidance to junior data scientists, sharing expertise and knowledge in generative AI and LLM, and contribute to the overall growth and success of the data science team.","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","75031133","https://www.linkedin.com/jobs/view/gen-ai-llm-data-scientist-at-the-dignify-solutions-llc-4341865726?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Springfield, VA","1 month ago","2025-10-31","https://www.linkedin.com/jobs/view/data-engineer-at-d2-consulting-4333406178?trk=public_jobs_topcard-title","D2 Consulting","https://www.linkedin.com/company/d2-consulting-llc?trk=public_jobs_topcard-org-name"," * ACTIVE TS/SCI SECURITY CLEARANCE REQUIRED**
   
   

The Data Engineer supports mission-critical data engineering and analytics operations within a classified federal environment, focusing on maintaining and enhancing an Enterprise Data Warehouse (EDW) built on Data Vault 2.0 principles. This position ensures the secure ingestion, transformation, and presentation of corporate data containing Personally Identifiable Information (PII) within a TS/SCI network enclave.

The engineer will develop and maintain automated data pipelines from enterprise business systems, implement best practices for secure data handling, and ensure compliance with all applicable DoD and IC data protection policies. The role requires strong technical skills in data integration, automation, and AWS-based data services, combined with deep experience supporting federal systems.

Key Responsibilities


 * Provide adaptive maintenance and development support for the organization’s Enterprise Data Warehouse in a classified TS/SCI environment with PII overlays
 * Design, implement, and optimize ETL/ELT processes using SQL Server Integration Services (SSIS), T-SQL, and Python to automate data ingest and transformation from multiple corporate systems.
 * Develop and sustain automated data pipelines from enterprise applications including PeopleSoft, Momentum, Prism, and Service Plus, ensuring end-to-end data integrity and retention within the classified data warehouse.
 * Implement AWS-native tools (e.g., Lambda, Glue) to enhance automation and scalability of data ingestion and transformation processes.
 * Leverage PowerShell scripting and Visual Studio for automation, environment configuration, and integration workflows.
 * Utilize SharePoint and Nintex workflows to design secure, user-friendly interfaces for presentation of backend SQL database outputs to government and contractor stakeholders.
 * Support data governance, compliance, and security audits in coordination with information assurance and system security officers (ISSOs) to maintain alignment with DoD and IC directives.
 * Develop and maintain technical documentation, including Standard Operating Procedures (SOPs), system design documentation, and data lineage tracking.
 * Provide technical expertise during requirements analysis, solution design, and integration testing phases of ongoing modernization efforts.
   
   

Required Qualifications


 * Minimum of 4 years of experience performing adaptive maintenance and development of an Enterprise Data Warehouse (EDW) in a TS/SCI environment with PII data.
 * At least 4 years of experience with the following tools and technologies:
    * Development Tools: SQL Server Integration Services (SSIS), Visual Studio
    * Programming Languages: Python, PowerShell, T-SQL

 * Demonstrated experience integrating and automating data ingests from PeopleSoft, Momentum, Prism, and Service Plus into a data warehouse.
 * Hands-on experience developing automated data pipelines using AWS services (e.g., Lambda, Glue) in support of secure data ingestion and retention.
 * Experience with SharePoint and Nintex workflows for front-end presentation of SQL-based datasets.
 * Bachelor’s Degree in Computer Science, Information Technology, or related field;
    * In lieu of degree: an additional 8 years of relevant experience.
      

Desired Qualifications


 * Data Vault 2.0 Certified Practitioner (DV 2.0 Certification).
 * Master’s Degree in Computer Science, Information Technology, or a related discipline.
 * Experience working on DoD or Intelligence Community (IC) data warehouse programs.
 * Familiarity with DoD Cloud Computing Security Requirements Guide (SRG) and NIST 800-53 controls.
   
   

Core Competencies


 * Strong understanding of data warehousing principles, data modeling, and ETL automation.
 * Demonstrated expertise with data security, PII protection, and classified system compliance.
 * Excellent problem-solving, debugging, and performance optimization skills.
 * Proven ability to operate effectively in cross-functional government–contractor teams.
 * Clear and concise technical communication and documentation skills.
   
   

Position Impact

This role directly contributes to the federal agency’s mission assurance by ensuring the secure, reliable, and automated integration of enterprise data sources within a classified environment. The Data Scientist enables mission stakeholders to leverage accurate, timely, and compliant data for strategic analysis and operational decision-making.

Additional Information


 * All your information will be kept confidential according to EEO guidelines.
 * Compensation is unique to each candidate and relative to the skills and experience they bring to the position. This does not guarantee a specific salary as compensation is based upon multiple factors such as education, experience, certifications, and other requirements, and may fall outside of the above-stated range.
 * Highlights of our benefits include Health/Dental/Vision, 401(k) match, Accrued PTO, STD/LTD/Life Insurance, Referral Bonuses, professional development reimbursement, and more!
   
   

D2 Consulting is committed to a merit-based recruitment process and encourages applications from all qualified individuals. As a Veteran-Owned Small Business, we particularly welcome applications from veterans who have the requisite skills and experience. Job applicants that are interested in one of our openings and may require a reasonable accommodation to participate in the job application or interview process, should contact us to request an accommodation.","Be among the first 25 applicants","Full-time","Entry level","Information Technology and Engineering","Construction, Software Development, and IT Services and IT Consulting","","","","11095898","https://www.linkedin.com/jobs/view/data-engineer-at-d2-consulting-4333406178?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Analyst (AI)","Newark, OH","4 weeks ago","2025-11-04","https://www.linkedin.com/jobs/view/data-analyst-ai-at-licking-county-chamber-of-commerce-4334034618?trk=public_jobs_topcard-title","Licking County Chamber of Commerce","https://www.linkedin.com/company/licking-county-chamber-of-commerce?trk=public_jobs_topcard-org-name","Posted: 10/12/2025

Information Technology

The Energy Cooperative, headquartered in Newark, Ohio, serves over 72,000 electric, natural gas and propane members throughout east-central Ohio. As a non-profit cooperative, we are member-owned and controlled by the members we serve. We are committed to serving our members safe, high quality energy services at a reasonable price. We believe in our employees and strive to provide fair, honest and equal treatment with a commitment to training, education, and opportunity for advancement in a safe and secure environment.

At The Energy Cooperative, we take pride in offering competitive benefits and want our employees to have what they need to be their best.

Here’s a glimpse of the programs we offer our employees:


 * Medical, Dental, and Vision Insurance
 * Life and Accidental Death & Dismemberment Insurance
 * Supplemental Life Insurance Programs for Employee, Spouse and Children
 * Disability Insurance
 * Flexible Spending Account (FSA)
 * Paid Time-Off (PTO)
 * Paid Holidays
 * Traditional 401(k) and Roth 401(k)
 * Retirement Pension Plan
 * Education Assistance
 * Employee Assistance Program
   
   

We are currently looking to fill the position of Data Analyst (AI) based at our Newark, OH Headquarters. This exempt position is responsible for leading the cooperative’s efforts in leveraging artificial intelligence (AI), machine learning (ML) and advanced data analytics to support and improve efficiencies of the cooperative. The AI Data Analyst works across departments to collect and analyze data, build predictive models, and deliver actionable insights through dashboards and reports.

Essential Duties And Responsibilities


 * Under the direction of the CIO, develop and execute the cooperative’s AI strategy aligned with the cooperative’s board goals and strategic plans.
 * Serve as the cooperative’s subject matter expert in AI and data-driven technologies.
 * Analyze a variety of data to uncover trends, inefficiencies, and opportunities for improvement.
 * Develop and apply AI/ML models to support predictive maintenance, load forecasting, outage management, and member engagement.
 * Collaborate with engineering and operations teams to integrate AI into grid modernization and smart infrastructure initiatives.
 * Create intuitive dashboards and reports to communicate insights to both technical and non-technical stakeholders.
 * Ensure data quality, security, and compliance with cooperative and regulatory standards.
 * Conduct document reviews to extract, validate, and analyze data from internal reports, regulatory filings, and technical documentation.
 * Stay informed on emerging AI technologies and their potential applications in the utility industry.
 * Provide technical support and training to staff on the use of analytics tools and dashboards.
 * Perform other related work in addition to other duties as may be assigned.
   
   

Qualifications: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skills and/or abilities necessary. Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions.


 * Experience and Education: Bachelor’s degree in Data Science, Computer Science, Engineering, or a related field, or an equivalent combination of education, experience and training. Minimum of 3 years of experience in data analytics, business intelligence, or AI/ML development (utility or energy sector experience preferred). Hands on experience in SQL, Python/R, and AI/ML frameworks (TensorFlow, PyTorch, or Scikit-learn, etc.). Strong understanding of statistical analysis, machine learning, and data visualization tools (e.g., Power BI, Tableau). Familiarity with utility data systems (e.g., SCADA, AMI, GIS, OMS) is a plus. Experience with energy forecasting, grid analytics, or DER (Distributed Energy Resources) modeling. Knowledge of cloud platforms (Azure, AWS) and MLOps practices.
 * Certificates, Licenses and Training: Valid Ohio Driver’s License. Must have the ability to attend meetings and/or training seminars when requested. Has the functional and technical knowledge and skills to do the job at a high level of accomplishment and professionalism.
 * Language and Interpersonal Skills: Excellent communication, analytical, and organizational skills. Ability to explain technical findings to non-technical staff. Is a good listener and actively engages in conversations to clearly understand others’ messages and intent. Is easy to approach and talk to and spends the extra effort to put others at ease.
 * Other Skills and Abilities: Thorough understanding of Cooperative’s goals and objectives. Displays high standards of ethical conduct and is widely trusted and viewed as a direct and truthful person. Remains calm under pressure and does not become defensive or irritated when times are tough. Knows personal strengths, weaknesses, opportunities and limits and is open to criticism and is not defensive.
   
   

Physical Demands and Work Environment: The physical demands described below are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions.


 * Work is primarily performed in an office environment where climate and noise levels are controlled. Occasional travel for training and to and from various office locations occurs.
 * The physical demands of this position include sitting, standing, walking, climbing stairs, lifting, and/or carrying light loads, talking, hearing, visual acuteness, and mental and emotional demands. Requires repetitive motions with hands and fingers such as working on a keyboard.
 * Must be available to work during non-working hours, which may include weekends and holidays.
 * This position is subject to pre-employment physical and substance abuse testing and may be subject to random testing in accordance with the Cooperative’s substance abuse policy.
   
   

The Energy Cooperative


 * 1500 Granville Road Newark OH 43055
 * (800) 255-6815
 * Send Email
 * Visit Website
   
   

Business Directory News Releases Events Calendar Job Postings Join The Chamber

Share

Print Email Facebook Twitter LinkedIn

Tell a Friend","Be among the first 25 applicants","Full-time","Entry level","Information Technology","Non-profit Organizations","","","","1351894","https://members.lickingcountychamber.com/jobs/info/information-technology-data-analyst-ai-6803","EXTERNAL",""
"Data Engineer","San Francisco, CA","5 days ago","2025-11-27","https://www.linkedin.com/jobs/view/data-engineer-at-replit-4339202666?trk=public_jobs_topcard-title","Replit","https://www.linkedin.com/company/repl-it?trk=public_jobs_topcard-org-name","Replit is the agentic software creation platform that enables anyone to build applications using natural language. With millions of users worldwide and over 500,000 business users, Replit is democratizing software development by removing traditional barriers to application creation.

About the role:

As a Data Engineer, your job is to facilitate data analytics and measurement at scale at Replit. You'll work with product and business teams to help build data pipelines and transformations to enable us to understand and measure product usage. You'll also work to make our data scientists and analysts -- and the business decisions that depend on them-- more powerful and efficient.

You will:


 * Design, build, and maintain scalable data pipelines that power analytics and data-driven decision-making across Replit (e.g. tracking Repl deployments, AI agent usage, etc.)
 * Develop ETL/ELT workflows using modern data stack tools and transform raw data into clean, reliable datasets that enable self-service analytics.
 * Partner with teams across the company to understand data needs, deliver robust solutions, and implement data quality monitoring to ensure accuracy and reliability.
   
   

Examples of what you could do:


 * Build unified data models combining product usage, billing, and customer data to enable cohort analysis and retention tracking.
 * Design real-time pipelines that surface key metrics and automated data quality checks to catch inconsistencies before they impact downstream users.
 * Create dimensional models that enable flexible analysis of user behavior, feature adoption, and conversion funnels.
   
   

Required skills and experience:


 * 5+ years of experience building production data pipelines with strong SQL skills and experience designing data models.
 * Experience with modern data transformation tools (dbt preferred), proficiency in Python, and hands-on experience with cloud data warehouses (BigQuery, Snowflake, Redshift).
 * Understanding of data warehouse design principles and ability to communicate effectively with both technical and non-technical stakeholders.
   
   

Preferred Qualifications:


 * Experience with modern data stack tools (dbt, Fivetran, Segment, HEX, Databricks, Amplitude) and background in high-growth SaaS or PLG companies.
 * Familiarity with event-based analytics platforms, data visualization tools, and software engineering best practices.
   
   

Bonus Points:


 * Experience with real-time data processing, reverse ETL tools, or developer tools and collaborative coding environments.
 * Knowledge of data governance frameworks or machine learning pipelines and feature engineering.
   
   

This is a full-time role that can be held from our Foster City, CA office. The role has an in-office requirement of Monday, Wednesday, and Friday.

Full-Time Employee Benefits Include:

💰 Competitive Salary & Equity

💹 401(k) Program

⚕️ Health, Dental, Vision and Life Insurance

🩼 Short Term and Long Term Disability

🚼 Paid Parental, Medical, Caregiver Leave

🚗 Commuter Benefits

📱 Monthly Wellness Stipend

🧑‍💻 Autonoumous Work Environement

🖥 In Office Set-Up Reimbursement

🏝 Flexible Time Off (FTO) + Holidays

🚀 Quarterly Team Gatherings

☕ In Office Amenities

Want to learn more about what we are up to?


 * Meet the Replit Agent
 * Replit: Make an app for that
 * Replit Blog
 * Amjad TED Talk
   
   

Interviewing + Culture at Replit


 * Operating Principles
 * Reasons not to work at Replit
   
   

To achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.

Compensation Range: $160K - $325K

","Over 200 applicants","Full-time","Entry level","Information Technology","Software Development","$160,000.00/yr - $325,000.00/yr","","","18542592","https://jobs.ashbyhq.com/replit/74270340-cb76-4071-a089-6d39881afddc/application?utm_source=1Zx6V2PngV","EXTERNAL",""
"BI (Analytics) Engineer","Denver, CO","4 days ago","2025-11-28","https://www.linkedin.com/jobs/view/bi-analytics-engineer-at-candid-health-4339339177?trk=public_jobs_topcard-title","Candid Health","https://www.linkedin.com/company/candid-health?trk=public_jobs_topcard-org-name","The Role

At Candid Health, we’re searching for an Analytics Engineer to bridge Analytics Engineering, Business Intelligence, and Data Analysis. As a key strategic investment for the company and product, you will be responsible for the data modeling and pipelines that enable our downstream data products. You will work closely with stakeholders across the business and play a foundational role in scaling the data team. Candid Health is positioned to unlock transformative technology for healthcare providers and the BI Engineer will play a critical role in that effort.

What You’ll Do


 * Own Data Modeling as a Practice: Build and deliver critical reporting, analytics, and data models for varying use cases. You will be the standardbearer for operational excellence in our efforts to extrapolate data for meaningful outcomes
 * Set the Foundation for Future Data Work: We have ambitious plans to leverage data as a key component to our long term product strategy. This role will improve and scale our data infrastructure, enabling future ML and AI products
 * Implement New Processes and Systems for Data Collection and Analysis: Deep dive with engineers to understand complex production data. Ensure that tooling and visualization platforms are accurate and available
   
   

Who You Are


 * You have Bachelors degree in Math, Science, Engineering, or another data intensive field of study such as Library Science
 * You have 4+ years of experience working in a Data Science, Data Analytics, or Data Engineering at a high growth startup or scaled technical organization
 * You have experience working with data models, data pipelines and performing analysis
 * You have hands on experience working with common data warehouses such as Snowflake, BigQuery, or Redshift
 * Enthusiasm for data modeling; hopefully you have opinions on slow changing dimensions
 * You have a strong understanding of SQL and have used it in complex data environments
 * You have well-developed opinions on modern data engineering and an ability to bring others up to speed
 * You thrive in ambiguity and enjoy tackling complex tasks that have significant impact on the business at large
 * You’re a clear and concise communicator; you enjoy the challenge of explaining complicated ideas in simple terms, both in-person and in writing.
 * Experience or exposure with the broader set of technologies in our ecosystem: Google Cloud Platform (BigQuery), Metabase, Terraform, Python, DBT.
   
   

Pay Transparency

The estimated starting annual salary range for this position is $135,000 to $180,000 USD. The listed range is a guideline from Pave data, and the actual base salary may be modified based on factors including job-related skills, experience/qualifications, interview performance, market data, etc. Total compensation for this position may also include equity, sales incentives (for sales roles), and employee benefits. Given Candid Health’s funding and size, we heavily value the potential upside from equity in our compensation package. Further note that Candid Health has minimal hierarchy and titles, but has broad ranges of experience represented within roles

","70 applicants","Full-time","Entry level","Information Technology","Hospitals and Health Care","$135,000.00/yr - $180,000.00/yr","","","70448411","https://www.joincandidhealth.com/careers?ashby_jid=3b76459e-9521-4687-84a8-117b5b98a410&utm_source=mvzxgrd3O0","EXTERNAL",""
"Risk Developer (C#) – Tier 1 Systematic Hedge Fund – Excellent Compensation + Benefits","New York, United States","16 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/risk-developer-c%23-%E2%80%93-tier-1-systematic-hedge-fund-%E2%80%93-excellent-compensation-%2B-benefits-at-mondrian-alpha-4339542941?trk=public_jobs_topcard-title","Mondrian Alpha","https://uk.linkedin.com/company/mondrian-alpha?trk=public_jobs_topcard-org-name","I’m working with a leading systematic hedge fund in New York that is seeking an elite C# Developer to join its Risk Development team.




This is a front-footed technical role in one of the most business-critical engineering groups in the firm – focused on designing and scaling cutting-edge risk systems that power real-time and historical analytics for PMs, risk officers, and senior leadership.




As part of this team, you’ll be building foundational components to support stress testing, equity factor models, VaR, risk decomposition, and analytics tooling. You’ll also contribute to scaling the firm’s large-scale data systems and driving modernization efforts across risk technology.




You'll work in a highly technical environment using Python and have the opportunity to contribute to high-performance architecture, cloud-based data platforms (AWS, Snowflake, Redshift), and streaming technologies (Kafka).




Responsibilities

 * Design and build scalable systems for risk analytics, stress testing, VaR, and multi-factor risk modeling across asset classes.
 * Develop and maintain high-performance services in an OOP language, with strong focus on clean architecture and modular design.
 * Own the full lifecycle of solutions from conception to deployment, including data storage, transformation, analysis, and visualisation.
 * Collaborate with risk managers, PMs, and other engineering teams to deliver production-grade risk tools and analytics.
 * Drive innovation within risk infrastructure, leveraging modern technologies to modernize data processing and enhance system resiliency.
 * Provide Level 3 production support for global users and continuously iterate based on business feedback.




Requirements

 * Expertise in Software development, with deep understanding of software design principles and system architecture.
 * Strong experience with relational databases and data modelling for large-scale analytical applications.
 * Background in risk technology or quantitative engineering within the financial services industry.
 * Excellent written and verbal communication skills; able to translate technical ideas into actionable business value.
 * Proven track record of ownership and delivery in high-performance, high-stakes environments.




My client anticipates to pay a strong performer upwards of $400k year 1 total compensation package. As well as a market-leading compensation package, they offer exceptional benefits including a top-tier healthcare package, fully subsidised qualifications plus breakfast and lunch paid for each day.




To apply, either respond to this advert or send your CV directly to sasha.duquesne@mondrian-alpha.com","42 applicants","Full-time","Mid-Senior level","Finance, Engineering, and Information Technology","Investment Management, Investment Banking, and Banking","","","","1908485","https://www.linkedin.com/jobs/view/risk-developer-c%23-%E2%80%93-tier-1-systematic-hedge-fund-%E2%80%93-excellent-compensation-%2B-benefits-at-mondrian-alpha-4339542941?trk=public_jobs_topcard-title","EASY_APPLY",""
"Business Intelligence Analyst","Port Washington, NY","2 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/business-intelligence-analyst-at-dashing-diva-4335564374?trk=public_jobs_topcard-title","Dashing Diva","https://www.linkedin.com/company/dashing-diva?trk=public_jobs_topcard-org-name","About the Role:

Dashing Diva is seeking a highly analytical, detail-oriented Business Intelligence Analyst to drive data-informed decision-making across our organization. This individual will play a key role in transforming complex data into actionable insights by partnering with internal teams across Sales, Marketing, Ecommerce, Operations, and Finance to deliver intuitive, stakeholder-ready dashboards and analyses that enable strategic business decisions.




What You Will Do:

 * Design, develop, and maintain interactive dashboards and reports using Apache Superset (or similar BI tools) that provide clear, actionable insights to stakeholders at all levels
 * Partner with cross-functional teams to understand business requirements and translate them into effective analytical solutions that drive growth and operational efficiency
 * Conduct deep-dive analyses on customer behavior, product performance, and market trends to uncover opportunities for business optimization
 * Create and maintain automated reporting processes to ensure consistent, timely delivery of key metrics and KPIs across retail, ecommerce, and wholesale channels
 * Present findings and recommendations to leadership using compelling data visualization and storytelling techniques
 * Monitor and analyze performance metrics for both digital and retail channels, identifying trends and anomalies that require attention
 * Collaborate with data engineering teams to optimize data pipelines and ensure data quality, accessibility, and reliability
 * Support the Sales and Marketing teams with campaign performance analysis, customer segmentation, and ROI measurement
 * Develop and document best practices for dashboard design and data visualization across the organization
 * Proactively identify opportunities to leverage data for strategic advantage and operational improvements




What We’re Looking For:

 * Bachelor's degree in Business Analytics, Data Science, Statistics, Computer Science, Economics, or other technical fields
 * 2-5 years of experience in business intelligence, data analysis, or related analytical role
 * Strong SQL skills with ability to write complex queries for data extraction and analysis
 * Proven expertise in creating user-friendly, visually compelling dashboards using BI tools (Apache Superset preferred; experience with Tableau, Power BI, Looker, or similar tools acceptable)
 * Demonstrated business intuition with the ability to translate data findings into strategic recommendations
 * Excellence in data visualization principles and best practices for dashboard design
 * Experience working directly with business stakeholders to gather requirements and deliver solutions
 * Strong analytical and problem-solving skills with meticulous attention to detail
 * Excellent written and verbal communication skills with ability to explain complex concepts to non-technical audiences
 * Proficiency in Microsoft Office (Excel, PowerPoint, Outlook); familiarity with project management tools
 * A passion for the beauty industry and a proactive, data-driven mindset




Bonus Points If You Have:

 * Experience with Python or R for advanced analytics and automation
 * Familiarity with cloud data platforms (AWS, Google Cloud Platform, or Azure)
 * Knowledge of retail, ecommerce, or beauty industry metrics and KPIs
 * Experience with Snowflake, BigQuery, or similar cloud data warehouses
 * Proficiency with dbt (data build tool) for data transformation
 * Experience with eRetail analytics platforms (e.g., Amazon Brand Analytics, Walmart Luminate)




You’ll love working at Dashing Diva because:

 * Great work environment to grow and learn new skills
 * We are collaborative and work closely with each other
 * We give everyone a chance to be creative and value input and feedback
 * In-office catered breakfast, lunches, and team lunches, team outings, and team-building activities
 * Perks: Health benefits (Medical, dental, vision, AD&D, Life), 401(k) matching, PTOs, Company holidays, Summer Fridays & more!




About Dashing Diva:

We see nails as a canvas for self-expression and an opportunity to let your personality shine. Whether rocking a French manicure or show-stopping stilettoes, all Divas are uniquely fabulous. We celebrate differences, the mold breakers, the trendsetters, and the risk-takers. These bold beauties are what inspired us to step out of the conventional salons and instead provide you options for your home to make even your manicurist jealous. Our mission is to create accessible, easy to use, at home products that fuel creativity of nail enthusiasts and manicure mavens alike. It’s all powered by one purpose – empowering you to “Own Your Diva” and wear it proudly from your fingers to your toes.","Over 200 applicants","Full-time","Mid-Senior level","Business Development, Information Technology, and Analyst","Personal Care Product Manufacturing","$85,000.00/yr - $105,000.00/yr","","","490595","https://www.linkedin.com/jobs/view/business-intelligence-analyst-at-dashing-diva-4335564374?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Paid maternity leave
Commuter benefits"
"Software Engineer, Payments","San Francisco Bay Area","6 days ago","2025-11-26","https://www.linkedin.com/jobs/view/software-engineer-payments-at-discord-4324449161?trk=public_jobs_topcard-title","Discord","https://www.linkedin.com/company/discord?trk=public_jobs_topcard-org-name","Discord is used by over 200 million people every month for many different reasons, but there’s one thing that nearly everyone does on our platform: play video games. Over 90% of our users play games, spending a combined 1.5 billion hours playing thousands of unique titles on Discord each month. Discord plays a uniquely important role in the future of gaming. We are focused on making it easier and more fun for people to talk and hang out before, during, and after playing games.

Come build the future of Discord’s business with us! We are looking for an impact-focused Software Engineer to join our world-class Revenue group as we accelerate Discord’s growth by enabling sophisticated payments experiences. These product lines allow us to grow our business while keeping Discord’s core functionality free. To learn more about Discord Engineering, take a look at our engineering blog!

What You'll Be Doing


 * Work with other fullstack engineers to build the checkout and payments capabilities that support Discord’s existing business lines, and enable new revenue streams across Web, Android, and iOS
 * Own problems end to end — through defining technical specifications, implementing changes, and launch.
 * Partner with Product, Design, CX, Data Science, and feature teams across the company to evolve Discord’s commerce platform and expand its capabilities
 * Provide feature teams with tools and platform support needed to spin up new monetization products
 * Improve the reliability, observability, and stability of Discord’s commerce systems
   
   

What You Should Have


 * 3+ years of software engineering experience. We primarily work in the backend (Python), but we also do some frontend work (React, Typescript). You have a background with a similar emphasis on fullstack development
 * A growth mindset. You view mistakes as learning opportunities and build upon your successes. You challenge yourself and those around you to continuously improve
 * Product and platform sense. You maintain a high degree of empathy for both your internal and external users, and seek feedback from them about your work.
 * Domain experience in the payments: You’d worked on or worked adjacent to and are familiar with checkout flows, payment processor integrations, global payment methods and localized pricing, discounts and trials systems
   
   

The US base salary range for this full-time position is $160,000 to $180,000 + equity + benefits. Our salary ranges are determined by role and level. Within the range, individual pay is determined by additional factors, including job-related skills, experience, and relevant education or training. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include equity, or benefits.

Candidates must reside in or be willing to relocate to the San Francisco Bay Area (Alameda, Contra Costa, Marin, Napa, San Francisco, San Mateo, Santa Clara, Solano, and Sonoma counties). Relocation assistance may be available. For this role, there is no formal requirement to work from the office.

Why Discord?

Discord plays a uniquely important role in the future of gaming. We're a multiplatform, multigenerational and multiplayer platform that helps people deepen their friendships around games and shared interests. We believe games give us a way to have fun with our favorite people, whether listening to music together or grinding in competitive matches for diamond rank. Join us in our mission! Your future is just a click away!

Discord is committed to inclusion and providing reasonable accommodations during the interview process. We want you to feel set up for success, so if you are in need of reasonable accommodations, please let your recruiter know.

Please see our Applicant and Candidate Privacy Policy for details regarding Discord’s collection and usage of personal information relating to the application and recruitment process by clicking HERE.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","$160,000.00/yr - $180,000.00/yr","","","3765675","https://www.linkedin.com/jobs/view/software-engineer-payments-at-discord-4324449161?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Software Engineer, Data Engineering","Menlo Park, CA","23 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/senior-software-engineer-data-engineering-at-robinhood-4283624877?trk=public_jobs_topcard-title","Robinhood","https://www.linkedin.com/company/robinhood?trk=public_jobs_topcard-org-name","Join us in building the future of finance.

Our mission is to democratize finance for all. An estimated $124 trillion of assets will be inherited by younger generations in the next two decades. The largest transfer of wealth in human history. If you’re ready to be at the epicenter of this historic cultural and financial shift, keep reading.

About the team + role

We are building an elite team, applying frontier technologies to the world’s biggest financial problems. We’re looking for bold thinkers. Sharp problem-solvers. Builders who are wired to make an impact. Robinhood isn’t a place for complacency, it’s where ambitious people do the best work of their careers. We’re a high-performing, fast-moving team with ethics at the center of everything we do. Expectations are high, and so are the rewards.

Robinhood is a metrics driven company and data is foundational to all key decisions from growth strategy to product optimization to our day-to-day operations. We are looking for a Senior Data Engineer to build and maintain foundational datasets that will allow us to reliably and efficiently power decision making at Robinhood. These datasets include application events, database snapshots, and the derived datasets that describe and track Robinhood's key metrics across all products. You’ll partner closely with engineers, data scientists and business teams to power analytics, experimentation, and machine learning use cases. We are a fast-paced team in a fast growing company and this is a unique opportunity to help lay the foundation for reliable, impactful, data-driven decisions across the company for years to come.

The role is located in the office location(s) listed on this job description which will align with our in-office working environment. Please connect with your recruiter for more information regarding our in-office philosophy and expectations.

What You’ll Do


 * Help define and build key datasets across all Robinhood product areas. Lead the evolution of these datasets as use cases grow.
 * Build scalable data pipelines using Python, Spark and Airflow to move data from different applications into our data lake.
 * Partner with upstream engineering teams to enhance data generation patterns.
 * Partner with data consumers across Robinhood to understand consumption patterns and design intuitive data models.
 * Ideate and contribute to shared data engineering tooling and standards.
 * Define and promote data engineering best practices across the company.
   
   

What You Bring


 * 5+ years of professional experience building end-to-end data pipelines
 * Hands-on software engineering experience, with the ability to write production-level code in Python for user-facing applications, services, or systems (not just data scripting or automation).
 * Expert at building and maintaining large-scale data pipelines using open source frameworks (Spark, Flink, etc)
 * Strong SQL (Presto, Spark SQL, etc) skills.
 * Experience solving problems across the data stack (Data Infrastructure, Analytics and Visualization platforms)
 * Expert collaborator with the ability to democratize data through actionable insights and solutions.
   
   

What We Offer


 * Market competitive and pay equity-focused compensation structure
 * 100% paid health insurance for employees with 90% coverage for dependents
 * Annual lifestyle wallet for personal wellness, learning and development, and more!
 * Lifetime maximum benefit for family forming and fertility benefits
 * Dedicated mental health support for employees and eligible dependents
 * Generous time away including company holidays, paid time off, sick time, parental leave, and more!
 * Lively office environment with catered meals, fully stocked kitchens, and geo-specific commuter benefits
   
   

In addition to the base pay range listed below, this role is also eligible for bonus opportunities + equity + benefits.

Base pay for the successful applicant will depend on a variety of job-related factors, which may include education, training, experience, location, business needs, or market demands. The expected base pay range for this role is based on the location where the work will be performed and is aligned to one of 3 compensation zones. For other locations not listed, compensation can be discussed with your recruiter during the interview process.

Base Pay Range

Zone 1 (Menlo Park, CA; New York, NY; Bellevue, WA; Washington, DC)

$187,000—$198,000 USD

Zone 2 (Denver, CO; Westlake, TX; Chicago, IL)

$165,000—$174,600 USD

Zone 3 (Lake Mary, FL; Clearwater, FL; Gainesville, FL)

$146,000—$154,800 USD

Click here to learn more about our Total Rewards, which vary by region and entity.

If our mission energizes you and you’re ready to build the future of finance, we look forward to seeing your application.

Robinhood provides equal opportunity for all applicants, offers reasonable accommodations upon request, and complies with applicable equal employment and privacy laws. Inclusion is built into how we hire and work—welcoming different backgrounds, perspectives, and experiences so everyone can do their best. Please review the Privacy Policy for your country of application.","Over 200 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Financial Services","","","","3254263","https://boards.greenhouse.io/robinhood/jobs/4738660?t=gh_src%3D&gh_jid=4738660&gh_src=ed898e781us&source=LinkedIn","EXTERNAL",""
"Quantitative Developer","New York, United States","3 weeks ago","2025-11-05","https://www.linkedin.com/jobs/view/quantitative-developer-at-impax-recruitment-4334305917?trk=public_jobs_topcard-title","Impax Recruitment","https://uk.linkedin.com/company/impaxrecruitment?trk=public_jobs_topcard-org-name","Compensation

This role offers a total compensation package of up to $500,000




Responsibilities

 * Build, optimize, and maintain real-time trading systems that deliver exceptional speed, reliability, and scalability.
 * Partner closely with quantitative researchers to create and refine research infrastructure, including simulation and backtesting frameworks.
 * Develop robust ETL workflows to handle and transform massive volumes of financial data with efficiency and accuracy.

Required Qualifications

 * Degree in Computer Science, Mathematics, Statistics, Engineering, or a closely related field (advanced degrees welcome).
 * Deep experience with C++ and Python, with a strong grasp of system architecture and trade-offs between performance, resilience, and uptime.
 * Genuine interest in financial markets, electronic trading, and quantitative research.
 * Proven background in data engineering and database management comfortable working with large datasets using Python and SQL.

Preferred Experience

 * Exposure to cloud environments (AWS, GCP, or Azure).
 * Familiarity with GPU programming is advantageous.
 * Understanding of algorithmic trading concepts or quantitative strategy development.

","104 applicants","Full-time","Mid-Senior level","Finance","Blockchain Services, Financial Services, and Software Development","","Arsen Mataj","https://www.linkedin.com/in/arsenmataj","71772415","https://www.linkedin.com/jobs/view/quantitative-developer-at-impax-recruitment-4334305917?trk=public_jobs_topcard-title","EASY_APPLY",""
"Software Data Engineer","Bowie, MD","2 days ago","2025-11-30","https://www.linkedin.com/jobs/view/software-data-engineer-at-complexcare-solutions-4339867887?trk=public_jobs_topcard-title","ComplexCare Solutions","https://www.linkedin.com/company/complex-care-solutions?trk=public_jobs_topcard-org-name","Overview: The Software Data Engineer is responsible for contributing to data analytics, data operations, and software product development across the organization. They will support existing data operations such as data refresh ETL, data structure development, and troubleshooting of data issues. They will be a leader in the development of new products using data centric DevOps concepts and approaches to inform requirements and creation of APIs to support software development. They will work across a variety of products and projects as needed and engage with a variety of data types. This position requires significant independent contributions working closely with the rest of the team.

Duties and Responsibilities:


 * Take a collaborative role with the application support team to triage production problems, determine faults and provide fixes in a timely fashion, particularly with high priority items.
 * Work with the software engineering team to test and validate application upgrades.
 * Work with the infrastructure engineering team to test and validate system patches and production availability.
 * Work with Command Center to initiate, manage, and remediate production incidents.
 * Liaise with Operations, Networks and Database teams to resolve application issues.
 * Help develop new processes and procedures to improve departmental efficiency and evangelize across the team.
 * Research customer data related questions and provide mapping between requirements and data points.
 * Responsible for customer data releases which includes working with customers, data packaging, validation, and documentation.
 * Able to compare, contrast, and validate work with keen attention to detail.
 * Develop predictive and other classification methods thorough understanding of healthcare specific data sets such as CMS LDS files, 837 and 835 EDI specifications.
 * Develop APIs to allow for interaction with data sets from customer facing tools.
 * Perform data updates on a routine basis to keep product data sets current.
 * Work and communicate in a cross-functional geographically dispersed team environment comprised of software engineers and product managers.
 * Ensure compliance to company procedures when making changes and implementing code.
 * Maintain compliance with ComplexCare Solutions policies, procedures and mission statement.
 * Adhere to all confidentiality and HIPAA requirements as outlined within ComplexCare Solutions Operating Policies and Procedures in all ways and at all times with respect to any aspect of the data handled or services rendered in the undertaking of the position; and
 * Fulfill those responsibilities and/or duties that may be reasonably provided by Inovalon for the purpose of achieving operational and financial success of the Employer.
   
   

Job Requirements:


 * Minimum of 3 years of related professional experience
 * Strong ability to develop SQL queries for complex data analysis
 * Experience working with Python or other programming languages to develop scripts and APIs
 * Experience working with and implementing Commercial Cloud database tools (AWS, Azure, etc.)
 * Hands-on experience with Databricks on Azure
 * Demonstrates a growth mindset, seeks feedback, and focuses on continuous development
 * Ability to learn quickly and independently
 * Experience with HIPAA and working with PHI
 * Strong communication skills for interacting with internal and external customers
 * Excellent proficiency in Microsoft Office (Word, Excel, Outlook)
 * Ability to work under pressure, meet deadlines, and handle multiple priorities
 * Ability to work independently and complete tasks following standard practices
 * Experience working with DevOps tools in a cloud environment
 * Experience handling large datasets of varying complexity and formats
 * Strong understanding of the context and environment in which data products are developed and used
   
   

Education:


 * Bachelor's degree in computer science, software engineering, or related field; and
 * Databricks Certified Engineer preferred.
   
   

Physical Demands and Work Environment:


 * Sedentary work (i.e., sitting for long periods of time);
 * Exerting up to 10 pounds of force occasionally and/or negligible amount of force;
 * Frequently or constantly to lift, carry push, pull or otherwise move objects and repetitive motions;
 * Subject to inside environmental conditions; and
 * Travel for this position will include less than 10%, typically for training and collaboration purposes.
   
   

ComplexCare Solutions Offers a Competitive Salary and Benefits Package

In addition to the base compensation, this position may be eligible for performance-based incentives.

The actual base pay offered may vary depending on multiple factors including, but not limited to, job-related knowledge/skills, experience, business needs, geographical location, and internal equity. At ComplexCare Solutions, it is not typical for an individual to be hired at or near the top end of the range for their role, and compensation decisions are dependent upon the facts and circumstances of each position and candidate.

Base Compensation Range

$88,300—$132,500 USD

Studies have shown that women and people of color are less likely to apply for jobs unless they believe they meet every one of the qualifications listed in a job description. If you don't meet every qualification listed but are excited about our mission and the work described, we encourage you to apply regardless. ComplexCare Solutions is most interested in finding the best candidate for the job and you may be just the right person for this or other roles.

By embracing diversity, equity and inclusion we enhance our work environment and drive business success. ComplexCare Solutions strives to reflect the diversity of the communities where we operate and of our clients and everyone whom we serve. We endeavor to create a culture of inclusion in which our associates feel empowered to bring their full, authentic selves to work and pursue their professional goals in an equitable setting. We understand that by fostering this type of culture, and welcoming different perspectives, we generate innovation and growth.

ComplexCare Solutions is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirement.

The Company maintains a drug free work environment for all of its associates, which includes employees, contractors and vendors. It is unlawful for associates to manufacture, sell, distribute, dispense, possess or use any controlled substance or marijuana in the workplace and doing so will result in disciplinary action, up to and including termination of employment or the contracted relationship.

To review the legal requirements, including all labor law posters, please visit this link","123 applicants","Full-time","Entry level","Information Technology","Hospitals and Health Care","$88,300.00/yr - $132,500.00/yr","","","1056962","https://www.linkedin.com/jobs/view/software-data-engineer-at-complexcare-solutions-4339867887?trk=public_jobs_topcard-title","EASY_APPLY",""
"Scientist II","New York, NY","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/scientist-ii-at-uber-4336826362?trk=public_jobs_topcard-title","Uber","https://www.linkedin.com/company/uber-com?trk=public_jobs_topcard-org-name","About The Role

Scientists at Uber use data to analyze, improve and automate all aspects of Uber's core rideshare and delivery products. You will be joining the Rider Pricing and Incentives team, which owns our automated real-time pricing and incentives algorithms and platform. You will work on analyzing data that help design the models that maintain reliability and improve the efficiency of Uber's Mobility marketplace.

We are looking for experienced candidates with a passion for analyzing data and solving new and difficult problems with data. In this role, you will be able to use your strong quantitative skills in the fields of economics, machine learning, and/or operations research to improve the Uber rider experience as well as the overall marketplace performance.

What The Candidate Will Need / Bonus Points

---- What the Candidate Will Do ----


 * Use data to understand product performance and to identify improvement opportunities.
 * Build statistical, optimization, and machine learning models for a range of applications in the pricing and incentives algorithms space.
 * Design and execute product experiments and interpret the results to draw detailed and actionable conclusions.
 * Present findings to senior management to inform business decisions.
 * Collaborate with cross-functional teams across disciplines such as product, engineering, operations, and marketing to drive system development end-to-end from ideation to productionization
   
   

Basic Qualifications


 * Ph.D., M.S., or Bachelors degree in Statistics, Economics, Machine Learning, Operations Research, or other quantitative fields.
 * 2+ years of experience as an Applied or Data Scientist or equivalent (can be also as part of Ph.D training).
 * Knowledge of underlying mathematical foundations of statistics, machine learning, optimization, economics, and analytics.
 * Experience in experimental design and analysis.
 * Experience with exploratory data analysis, statistical analysis and testing, and model development.
 * Ability to use Python to work efficiently at scale with large data sets.
 * Proficiency in SQL.
   
   

Preferred Qualifications


 * 2+ years of industry experience.
 * Experience in algorithm development and prototyping.
 * Experience in pricing optimization.
 * Experience with productionizing algorithms for real-time systems.
 * Well-honed communication and presentation skills.
   
   

For New York, NY-based roles: The base salary range for this role is USD$155,000 per year - USD$172,000 per year. For San Francisco, CA-based roles: The base salary range for this role is USD$155,000 per year - USD$172,000 per year. For Seattle, WA-based roles: The base salary range for this role is USD$155,000 per year - USD$172,000 per year. For Sunnyvale, CA-based roles: The base salary range for this role is USD$155,000 per year - USD$172,000 per year. For all US locations, you will be eligible to participate in Uber's bonus program, and may be offered an equity award & other types of comp. You will also be eligible for various benefits. More details can be found at the following link https://www.uber.com/careers/benefits., For New York, NY-based roles: The base salary range for this role is USD$155,000 per year - USD$172,000 per year. For San Francisco, CA-based roles: The base salary range for this role is USD$155,000 per year - USD$172,000 per year. For Seattle, WA-based roles: The base salary range for this role is USD$155,000 per year - USD$172,000 per year. For Sunnyvale, CA-based roles: The base salary range for this role is USD$155,000 per year - USD$172,000 per year. For all US locations, you will be eligible to participate in Uber's bonus program, and may be offered an equity award & other types of comp. You will also be eligible for various benefits. More details can be found at the following link https://www.uber.com/careers/benefits.","111 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Internet Marketplace Platforms","$155,000.00/yr - $172,000.00/yr","","","1815218","https://tnl2.jometer.com/v2/job?jz=5wqzs4d63e6827610f845500c569287774d98KIAGUCAAAABQ&iis=Job%20Board%20-%20Recruitment%20Marketing&iisn=LinkedIn","EXTERNAL",""
"Business Intelligence Data Engineer","New York City Metropolitan Area","3 weeks ago","2025-11-10","https://www.linkedin.com/jobs/view/business-intelligence-data-engineer-at-effy-jewelry-4335335365?trk=public_jobs_topcard-title","Effy Jewelry","https://www.linkedin.com/company/effy-jewelry?trk=public_jobs_topcard-org-name","Title: Business Intelligence Data Engineer

Reporting to: Business Intelligence Manager

Location: New York, NY (Onsite)

Salary: $100,000 - $110,000




About Us

Effy Jewelry is a family-owned and operated business that has been crafting exquisite jewelry for over four decades. Founded by Effy Hematian, the brand has become synonymous with innovative design, superior craftsmanship, and unparalleled quality.




With a focus on innovation and creativity, Effy Jewelry has become a global leader in the fine jewelry industry. Its pieces can be found in major retailers and department stores worldwide, as well as over 150 land and cruise-based stores. Effy is also a major name in the Maritime & Cruise industry, providing exclusive onboard retail experiences including trunk shows and VIP events.




Job Summary

We are seeking an experienced Data Engineer/BI Engineer to support our data-driven initiatives in cruise retail focusing on revenue analytics. You will be responsible for building & maintaining data infrastructures and financial dashboards that power key insights across sales performance, customer demographics, and inventory management.




This role is a full-time, onsite position based at our NYC Headquarters. The selected candidate will be required to work onsite five days per week.




Essential Job Functions

 * Design, develop, and maintain scalable data pipelines to process and transform large volumes of retail data from multiple sources (POS systems, e-commerce platforms, ERP, CRM, etc.).
 * Develop and maintain data lakes, data warehouses, and marts (e.g., Snowflake, BigQuery).
 * Integrate data from proprietary systems to refine semantic layers optimized for data-driven strategies
 * Optimize data workflows and automate recurring data tasks to improve operational efficiency.
 * Design, build, and manage financial dashboards using tools such as Power BI, Tableau, Looker; monitor report usage & collect feedback for continuous improvement.
 * Maintain clear documentation of data pipelines, schemas, and data governance processes.
 * Stay current with emerging technologies and recommend tools that fit retail-specific needs.




Qualifications

 * Bachelor’s degree in Computer Science, Engineering, Information Systems, Analytics or a related field.
 * 3+ years of experience in data engineering, preferably in a retail or e-commerce environment.
 * Strong programming skills in Python, SQL, and experience with distributed data systems.
 * Experience with cloud platforms (Dynamics, Azure) and modern data architecture (data lake/lakehouse); Experience working with large volumes of transactional and customer data.
 * Deep understanding of retail-specific metrics and financial datasets (sales, inventory, SKU, loyalty programs, etc.).
 * Must have current work authorization to work in the U.S.




Preferred Qualifications:

 * Experience with retail systems like Oracle Retail, Shopify, Dynamics.
 * Understanding of omnichannel data flows (online, in-store, mobile).
 * Exposure to machine learning pipelines or advanced analytics for recommendation engines and customer segmentation.




Competencies:

 * Business Intelligence Tools: Excel, Power BI, SQL, etc.
 * Strong communication skills with technical and non-technical stakeholders.
 * Analytical mindset with a problem-solving approach.
 * Ability to manage multiple priorities in a fast-paced retail environment.
 * Proactive, with attention to detail and a passion for data quality.







Effy Jewelry is committed to diversity in its workplace and is proud to offer equal employment opportunities to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, veteran status, or any other legally protected characteristic in the location in which the candidate is applying. Effy Jewelry applicants are assessed solely on their qualifications for the role, without regard to disability or need for accommodation.","Over 200 applicants","Full-time","Mid-Senior level","Finance and Analyst","Retail Luxury Goods and Jewelry","$100,000.00/yr - $110,000.00/yr","","","7578010","https://www.linkedin.com/jobs/view/business-intelligence-data-engineer-at-effy-jewelry-4335335365?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Commuter benefits"
"Database Administrator","Cincinnati, OH","2 weeks ago","2025-11-17","https://www.linkedin.com/jobs/view/database-administrator-at-agility-partners-4341313224?trk=public_jobs_topcard-title","Agility Partners","https://www.linkedin.com/company/agilitypartners?trk=public_jobs_topcard-org-name","Agility Partners is seeking a qualified Snowflake Database Administrator (DBA) to fill an open position with one of our clients.

This role will be responsible for maintaining, optimizing, and securing Snowflake environments to support large-scale data operations. The Snowflake DBA will collaborate across data engineering and analytics teams to ensure top performance, governance, and reliability of data systems in a cloud-based environment.




Responsibilities:

 * Analyze and optimize complex SQL queries and workloads for efficiency and cost management
 * Monitor and tune Snowflake compute resources for optimal performance
 * Manage user roles, access controls, and data masking policies to meet security standards
 * Maintain clean schemas and implement automated data archiving and metadata management




The Ideal Candidate:

 * Has proven experience as a Snowflake DBA or in a similar cloud data management role
 * Demonstrates strong proficiency in SQL and performance tuning
 * Understands Snowflake architecture, including warehouses, storage layers, and caching
 * Experienced with data security frameworks and compliance standards
 * Familiar with ETL/ELT tools and data integration frameworks
 * Possesses excellent problem-solving, communication, and documentation skills
 * Stays current with Snowflake updates and emerging data technologies




Reasons to Love It:

 * Opportunity to own and optimize a mission-critical Snowflake environment
 * Work cross-functionally with data engineers, analysts, and business leaders
 * Join a forward-thinking team leveraging cutting-edge cloud data technologies","136 applicants","Full-time","Mid-Senior level","Information Technology","IT Services and IT Consulting","","","","16167895","https://www.linkedin.com/jobs/view/database-administrator-at-agility-partners-4341313224?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)"
"AI Engineer - Casera","Seattle, WA","2 weeks ago","2025-11-12","https://www.linkedin.com/jobs/view/ai-engineer-casera-at-pioneer-square-labs-4340045782?trk=public_jobs_topcard-title","Pioneer Square Labs","https://www.linkedin.com/company/pioneer-square-labs?trk=public_jobs_topcard-org-name","AI / Data Engineer

About the Role

We're seeking a highly skilled AI/Data Engineer to design, build, and optimize data pipelines, machine learning infrastructure, and intelligent applications that turn complex data into actionable insights. You'll collaborate closely with data scientists, ML engineers, and software developers to deploy scalable, production-ready AI systems and ensure data quality, observability, and performance across the stack.

Key Responsibilities


 * Design and implement robust data ingestion and transformation pipelines (batch and streaming) using tools such as Airflow, Spark, Databricks, or AWS Glue.
 * Develop and maintain ETL/ELT workflows for structured and unstructured data from multiple sources (APIs, event streams, databases, third-party services).
 * Collaborate with data scientists to operationalize ML models, including feature engineering, model serving, and real-time inference pipelines.
 * Deploy, monitor, and maintain machine learning models using MLflow, SageMaker, Vertex AI, or similar frameworks.
 * Implement MLOps best practices, including CI/CD for model retraining, versioning, and testing.
 * Optimize performance and scalability of data storage solutions (e.g., Redshift, BigQuery, Snowflake, or Delta Lake).
 * Ensure data quality, lineage, and governance through monitoring, validation, and documentation.
 * Contribute to infrastructure-as-code (IaC) setups for reproducible deployments using Terraform, CDK, or CloudFormation.
 * Collaborate with cross-functional teams to support AI-driven analytics, dashboards, and decision intelligence applications.
   
   

Qualifications


 * Bachelor's or Master's degree in Computer Science, Data Engineering, or a related field.
 * 5+ years of experience in data engineering, ML engineering, or backend systems.
 * Strong programming skills in Python, SQL, Scala, Java or any OP languages.
 * Proficiency with cloud platforms (AWS, GCP, or Azure) and their data/AI services.
 * Experience with ML pipelines, including feature stores, model registries, and inference APIs.
 * Familiarity with containerization and orchestration (Docker, Kubernetes).
 * Solid understanding of data modeling, warehousing, and schema design.
 * Knowledge of modern AI frameworks (PyTorch, TensorFlow, scikit-learn) and vector databases (Pinecone, Weaviate, FAISS) is a plus.
 * Understanding of data privacy, security, and compliance (HIPAA, GDPR, SOC 2) preferred.
   
   

Nice to Have


 * Experience implementing LLM-powered systems (e.g., retrieval-augmented generation, embeddings, prompt optimization).
 * Knowledge of real-time analytics and event-driven architectures (Kafka, Kinesis, Pub/Sub).
 * Familiarity with observability stacks (Prometheus, Grafana, OpenTelemetry).
 * Contributions to open-source or AI research projects.
   
   

What We Offer


 * Opportunity to build scalable AI systems that drive measurable business impact.
 * Collaborative environment working alongside data scientists, ML researchers, and software engineers.
 * Flexible hybrid/remote work culture.
 * Competitive compensation, benefits, and growth opportunities.","165 applicants","Full-time","Entry level","Engineering and Information Technology","Technology, Information and Internet","","","","10218193","https://grnh.se/dav3k3r62us","EXTERNAL",""
"Engineering Data Analyst III","Charlotte, NC","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/engineering-data-analyst-iii-at-associate-staffing-4332878783?trk=public_jobs_topcard-title","Associate Staffing","https://www.linkedin.com/company/associate-staffing-llc?trk=public_jobs_topcard-org-name","Company Overview

Our client is looking to add an Engineering Data Analyst to their team. This is a hybrid position located in Charlotte, NC.

Essential Job Functions


 * Participate with a team of engineers focused on the analysis, visualization, and reporting of engineering data from telematics devices, wayside monitoring and other data systems
 * Lead telematics data analytics and utilization by collaborating with internal business units, external and industry partners
 * Develop methodology for documenting data templates for various types of data
 * Support engineers in component testing by delivering data analysis and ad-hoc reporting solutions
   
   

Minimum Qualifications


 * Bachelor’s Degree
 * 5 years of overall experience with data analysis for major software systems
 * Effective use of data analysis tools (SQL, Power BI, Tableau, etc.)
 * Experience and ability using advanced analytic tools to develop predictive models
 * Master’s degree relating to data science or equivalent – Preferred
 * Experience with AI and machine learning tools – Preferred
   
   

Equal Opportunity Employer

Associate Staffing is an Equal Opportunity Employer and does not discriminate against any employee or applicant for employment based on race, color, religion, sex, national origin, age, disability, veteran status, sexual orientation, gender identity, or any other protected status under applicable law. We are committed to creating a diverse and inclusive work environment and welcome applicants from all backgrounds to apply for open positions with our company.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Staffing and Recruiting","$77,000.00/yr - $110,000.00/yr","","","1798047","https://www.linkedin.com/jobs/view/engineering-data-analyst-iii-at-associate-staffing-4332878783?trk=public_jobs_topcard-title","EASY_APPLY",""
"Staff Product Data Scientist","Seattle, WA","8 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/staff-product-data-scientist-at-slack-4340718478?trk=public_jobs_topcard-title","Slack","https://www.linkedin.com/company/tiny-spec-inc?trk=public_jobs_topcard-org-name","To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.

Job Category

Data

Job Details

About Salesforce

Salesforce is the #1 AI CRM, where humans with agents drive customer success together. Here, ambition meets action. Tech meets trust. And innovation isn’t a buzzword — it’s a way of life. The world of work as we know it is changing and we're looking for Trailblazers who are passionate about bettering business and the world through AI, driving innovation, and keeping Salesforce's core values at the heart of it all.

Ready to level-up your career at the company leading workforce transformation in the agentic era? You’re in the right place! Agentforce is the future of AI, and you are the future of Salesforce.

Applications will be accepted until 11/11/2025.

We are looking for a seasoned Data Science expert to help build a world-class data science and analytics platform that supports and scales data-driven product decision-making.

As a Staff Product Data Scientist, you will work closely with cross-functional partners to proactively define the product landscape, derive insights from data, communicate key findings to product executives, and directly contribute to product strategy building and implementation. You’ll partner with Product, Design, and Engineering (PDE) to contribute directly to product development—shaping what we build, how we measure success, and when/how we iterate and improve.

At Slack, we foster a positive, diverse, and supportive culture. We look for people who are curious, bold, and eager to improve every day. Our team values being smart, humble, hardworking, and above all, collaborative.

What you will be doing


 * Apply advanced data science techniques to analyze Slack product usage patterns, identifying what’s working, what’s not, and opportunities for improvement.
 * Conduct evidence-based evaluations to determine key drivers of Slack’s product growth.
 * Define and report key success metrics, effectively communicating insights to Slack and Salesforce leadership to enable executive level decision making and follow-ups.
 * Synthesize insights across different product areas and business outcomes, identifying correlations and causal relationships that drive success.
 * Serve as a domain expert in product data science, guiding best practices and advancing data science methodologies and operations.
 * Champion evidence-based decision-making, making data and insights accessible and scalable for stakeholders at all levels.
   
   

What you should have


 * 5+ years of experience in data science or quantitative analysis, preferably in technology product development or enterprise software.
 * A related technical degree required.
 * Expertise in at least one programming language for data science (e.g., Python, R).
 * Experience working with large-scale data technologies (e.g., Spark, Presto, Hive, Hadoop). Expertise in Apache Airflow is a strong plus.
 * Strong communication skills. Able to translate complex technical results into clear, actionable insights.
 * Cross-functional collaboration and influencing skills, with a track record of impacting decisions at both strategic and executional levels.
 * Experience designing and implementing advanced data models with scalability and efficiency.
 * Experienced in applying advanced quant measurement techniques in a product development environment.
   
   

Unleash Your Potential

When you join Salesforce, you’ll be limitless in all areas of your life. Our benefits and resources support you to find balance and be your best, and our AI agents accelerate your impact so you can do your best. Together, we’ll bring the power of Agentforce to organizations of all sizes and deliver amazing experiences that customers love. Apply today to not only shape the future — but to redefine what’s possible — for yourself, for AI, and the world.

Accommodations

If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.

Posting Statement

Salesforce is an equal opportunity employer and maintains a policy of non-discrimination with all employees and applicants for employment. What does that mean exactly? It means that at Salesforce, we believe in equality for all. And we believe we can lead the path to equality in part by creating a workplace that’s inclusive, and free from discrimination. Know your rights: workplace discrimination is illegal. Any employee or potential employee will be assessed on the basis of merit, competence and qualifications – without regard to race, religion, color, national origin, sex, sexual orientation, gender expression or identity, transgender status, age, disability, veteran or marital status, political viewpoint, or other classifications protected by law. This policy applies to current and prospective employees, no matter where they are in their Salesforce employment journey. It also applies to recruiting, hiring, job assignment, compensation, promotion, benefits, training, assessment of job performance, discipline, termination, and everything in between. Recruiting, hiring, and promotion decisions at Salesforce are fair and based on merit. The same goes for compensation, benefits, promotions, transfers, reduction in workforce, recall, training, and education.

In the United States, compensation offered will be determined by factors such as location, job level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, and benefits. Salesforce offers a variety of benefits to help you live well including: time off programs, medical, dental, vision, mental health support, paid parental leave, life and disability insurance, 401(k), and an employee stock purchasing program. More details about company benefits can be found at the following link: https://www.salesforcebenefits.com.Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.

For New York-based roles, the base salary hiring range for this position is $200,800 to $276,100.

For Washington-based roles, the base salary hiring range for this position is $184,000 to $253,000.

For California-based roles, the base salary hiring range for this position is $200,800 to $276,100.","Be among the first 25 applicants","Full-time","Mid-Senior level","Research, Analyst, and Engineering","Technology, Information and Internet","$184,000.00/yr - $276,100.00/yr","","","1612748","https://www.linkedin.com/jobs/view/staff-product-data-scientist-at-slack-4340718478?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Software Engineer ($200k + Equity)","New York, NY","2 weeks ago","2025-11-13","https://www.linkedin.com/jobs/view/senior-software-engineer-%24200k-%2B-equity-at-akido-labs-4336024204?trk=public_jobs_topcard-title","Akido Labs","https://www.linkedin.com/company/akido-labs?trk=public_jobs_topcard-org-name","Akido builds AI-powered doctors. Akido is the first AI-native care provider, combining cutting-edge technology with a nationwide medical network to address America’s physician shortage and make exceptional healthcare universal. Its AI empowers doctors to deliver faster, more accurate, and more compassionate care.

Serving 500K+ patients across California, Rhode Island, and New York, Akido offers primary and specialty care in 26 specialties—from serving unhoused communities in Los Angeles to ride-share drivers in New York.

Founded in 2015 (YC W15), Akido is expanding its risk-bearing care models and scaling ScopeAI, its breakthrough clinical AI platform. Read more about Akido’s $60M Series B. More info at Akidolabs.com.

The Opportunity

Come work at Akido if you want to help build the future of medicine. In 2024, Akido achieved a historic milestone — conducting the first doctor visit run entirely by AI. We’re building tools that force multiply our doctors and unlock infinite access for our patients.

What makes Akido different is that we own and operate our own health system. That means the doctors using our software are our colleagues, not our customers’ employees. This deep integration between technology and clinical operations allows us to innovate faster than anyone else in healthcare, creating a feedback loop where ideas move from concept to clinical impact in record time.

What you will do:


 * Build and maintain RESTful and GraphQL APIs that serve as the backbone for front-end applications, including Akido Chart (our EMR) and Scope AI (our groundbreaking AI doctor).
 * Design scalable and secure backend services that integrate with clinical data systems, AI inference pipelines, and patient-facing interfaces.
 * Collaborate closely with product and design teams to translate user needs into elegant, maintainable, and high-performance software solutions.
 * Lead architecture discussions and make key decisions around system design, data modeling, and service reliability.
 * Mentor junior engineers and contribute to a culture of code quality, documentation, and continuous improvement.
 * Own projects end-to-end, from ideation to deployment and ongoing monitoring in production.
   
   

What you bring:


 * 7+ years of experience in software engineering, ideally with exposure to healthcare or complex data systems.
 * Deep experience building APIs and distributed systems using modern JS frameworks (e.g., Node.js).
 * Experience with front-end integration (React, Next.js, or similar) and cloud infrastructure (AWS, GCP).
 * Strong understanding of data modeling, performance optimization, and system architecture.
 * A team player who thrives in a fast-moving, mission-driven environment.
   
   

Benefits


 * Stock-options package
 * Health benefits include medical, dental and vision
 * 401K
 * Long-term disability
 * Unlimited PTO
 * Life insurance
 * Paid Leave Program
   
   

Salary range: $150,000 USD - $200,000 USD

Akido Labs, Inc. is an equal opportunity employer, and we encourage qualified applicants of every background, ability, and life experience to contact us about appropriate employment opportunities.","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering","Construction, Software Development, and IT Services and IT Consulting","$150,000.00/yr - $200,000.00/yr","","","9335675","https://www.linkedin.com/jobs/view/senior-software-engineer-%24200k-%2B-equity-at-akido-labs-4336024204?trk=public_jobs_topcard-title","EASY_APPLY",""
"Field Engineer - Advanced Manufacturing","El Paso, TX","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/field-engineer-advanced-manufacturing-at-tic-the-industrial-company-4324535143?trk=public_jobs_topcard-title","TIC - The Industrial Company","https://www.linkedin.com/company/tic-the-industrial-company?trk=public_jobs_topcard-org-name","Requisition ID: 178631

Job Level: Mid Level

Home District/Group: TIC Denver

Department: Field Operations

Market: Industrial

Employment Type: Full Time

Position Overview

As a Field/Office Engineer, you bring your big ideas, commitment to top quality and unwavering work ethic. In return, we offer huge career and travel opportunities and the satisfaction of building ""the next big thing"" from the ground up. There's a reason Kiewit attracts the best: we offer fast-paced excitement and fulfillment you won't find anywhere else. Our mission is to make a difference and we offer opportunities for you to make make a difference in our construction operations. Whether we’re boring tunnels through mountains, turning rivers into energy or building bridges that connect communities, we depend on our passionate, skilled, and safety-obsessed construction professionals to get it done right.

District Overview

TIC is a Kiewit Subsidiary that provides direct-hire construction services for industrial projects. TIC Denver has projects in Power, Industrial Manufacturing, Oil Gas Chemical, and Mining across the United States. Its projects range from small capital work up to major EPC projects. We are looking for people committed to the construction industry in an “open-shop” environment.

Location

This position will be based at one of our project sites across the U.S., with an office rotation at either our headquarters in Denver, CO or our area office in Lenexa, KS. Candidates must be open to relocating as needed.

One of the many things that makes our culture unique is that we go where the work is, which exposes your career to abundant opportunities. We relocate our teams based on the work that is available, combined with the development plans, skill sets and career goals of each team member. This means your Kiewit's adventure is custom-designed to meet our shared needs.

Responsibilities


 * Field Operations: Interpret drawings and specifications for field crews and craft, prepare work plans and work packages, order and schedule material deliveries
 * Office Engineering: Perform takeoffs from drawings, generating change orders reviewed by the Project Manager, provide field support and supervise subcontractor operations
 * Estimating: Review and analyze data relative to the project, complete plans and specification reviews for projects, assist with the preparation of a bid
   
   
   

Qualifications


 * Bachelor’s degree in Construction Management, Mechanical Engineering, Electrical Engineering, Civil Engineering, or a related field; Associate's degree in Construction Management also considered
 * Ability to travel and relocate as needed
 * Ability to freely access all points of a construction site in a wide-ranging climates and environments
 * Highly motivated, with a demonstrated passion for excellence and taking initiative
 * Strong work ethic, willing to do what it takes to get the job done right the first time
 * Demonstrated commitment to ethics and integrity
 * Passion for safety, with the ability to help us ensure that nobody gets hurt
 * Strong interpersonal, written, and verbal communication skills
 * Team player with the ability to work independently to meet deadlines, goals, and objectives
 * Strong organization, time management, and attention to detail
   
   
   

Other Requirements:


 * Regular, reliable attendance
 * Work productively and meet deadlines timely
 * Communicate and interact effectively and professionally with supervisors, employees, and others individually or in a team environment.
 * Perform work safely and effectively. Understand and follow oral and written instructions, including warning signs, equipment use, and other policies.
 * Work during normal operating hours to organize and complete work within given deadlines. Work overtime and weekends as required.
 * May work at various different locations and conditions may vary.
   
   
   

We offer our fulltime staff employees a comprehensive benefits package that’s among the best in our industry, including top-tier medical, dental and vision plans covering eligible employees and dependents, voluntary wellness and employee assistance programs, life insurance, disability, retirement plans with matching, and generous paid time off.

Equal Opportunity Employer, including disability and protected veteran status.","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Construction and Civil Engineering","","","","422503","https://www.linkedin.com/jobs/view/field-engineer-advanced-manufacturing-at-tic-the-industrial-company-4324535143?trk=public_jobs_topcard-title","EASY_APPLY",""
"Analytics Engineer - Weights & Biases","Livingston, NJ","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/analytics-engineer-weights-biases-at-weights-biases-4341452866?trk=public_jobs_topcard-title","Weights & Biases","https://www.linkedin.com/company/wandb?trk=public_jobs_topcard-org-name","CoreWeave, the AI Hyperscaler™, acquired Weights & Biases to create the most powerful end-to-end platform to develop, deploy, and iterate AI faster. Since 2017, CoreWeave has operated a growing footprint of data centers covering every region of the US and across Europe, and was ranked as one of the TIME100 most influential companies of 2024. By bringing together CoreWeave’s industry-leading cloud infrastructure with the best-in-class tools AI practitioners know and love from Weights & Biases, we’re setting a new standard for how AI is built, trained, and scaled.

The integration of our teams and technologies is accelerating our shared mission: to empower developers with the tools and infrastructure they need to push the boundaries of what AI can do. From experiment tracking and model optimization to high-performance training clusters, agent building, and inference at scale, we’re combining forces to serve the full AI lifecycle — all in one seamless platform.

Weights & Biases has long been trusted by over 1,500 organizations — including AstraZeneca, Canva, Cohere, OpenAI, Meta, Snowflake, Square,Toyota, and Wayve — to build better models, AI agents and applications. Now, as part of CoreWeave, that impact is amplified across a broader ecosystem of AI innovators, researchers, and enterprises.

As we unite under one vision, we’re looking for bold thinkers and agile builders who are excited to shape the future of AI alongside us. If you're passionate about solving complex problems at the intersection of software, hardware, and AI, there's never been a more exciting time to join our team.

What You’ll Do

The Data group at Weights & Biases works across the full range of data-related topics:


 * We help business partners set goals, make decisions, and understand the levers to achieve their goals.
 * We build reporting to keep the business attuned and aligned.
 * We build datasets and pipelines to support self-service analysis.
 * We train models to understand our customer growth, churn risk, and detect spam and abuse.
 * We’re exploring novel benchmarks and recs for model training.
 * We build and maintain a massive data platform to power it all.
   
   

About The Role

We’re hiring a Data Analytics Engineer who will focus primarily on analytics engineering while remaining a core member of the broader data platform team. You’ll be the dedicated owner of our dbt layer and related analytics infrastructure, driving operational excellence, cost/performance optimization, and self-service analytics at scale. You’ll partner closely with analysts, data scientists, and platform engineers to harden our foundations and enable better decision-making across the company.

Who You Are


 * Deep knowledge of data engineering and analytics engineering workflows at scale, with a track record of operational excellence
 * Expert with dbt (core or Cloud): model design, incremental strategies, macros/packages, testing, documentation, CI/CD
 * Strong SQL and warehouse design for BigQuery (partitioning, clustering, materializations, cost/perf tuning at multi-TB/PB scale)
 * Experience with orchestration (Dagster preferred; Airflow acceptable) and production-grade deployment practices
 * Familiar with data quality frameworks (e.g., dbt tests, Great Expectations, data contracts) and SLA/SLO design
 * Proficient in Python for orchestration, utilities, and light data tooling; Git-based workflows
 * Understanding of product telemetry, logging standards, and event modeling for web apps/SaaS
 * Excellent communication and documentation; able to align analysts, engineers, and stakeholders on semantics and standards
   
   

Preferred: (if applicable)


 * Hex (or similar BI) performance tuning and governance experience
 * Experience building semantic/metrics layers and catalogs (e.g., dbt exposures/semantics, OpenLineage, DataHub/Amundsen/Atlan)
 * Prior work migrating dbt Cloud → Dagster or similar orchestrator
 * Familiarity with AI/ML workflows and terminology
 * Terraform/infra-as-code exposure on GCP
 * Experience designing anomaly detection or rule-based alerting for KPIs
   
   

Why Us?

About

We work hard, have fun, and move fast! We’re in an exciting stage of hyper-growth that you will not want to miss out on. We’re not afraid of a little chaos, and we’re constantly learning. Our team cares deeply about how we build our product and how we work together, which is represented through our core values:


 * Be Curious at Your Core
 * Act Like an Owner
 * Empower Employees
 * Deliver Best-in-Class Client Experiences
 * Achieve More Together
   
   

We support and encourage an entrepreneurial outlook and independent thinking. We foster an environment that encourages collaboration and provides the opportunity to develop innovative solutions to complex problems. As we get set for takeoff, the growth opportunities within the organization are constantly expanding. You will be surrounded by some of the best talent in the industry, who will want to learn from you, too. Come join us!

The base salary range for this role is $139,000 to $204,000. The starting salary will be determined based on job-related knowledge, skills, experience, and market location. We strive for both market alignment and internal equity when determining compensation. In addition to base salary, our total rewards package includes a discretionary bonus, equity awards, and a comprehensive benefits program (all based on eligibility).

What We Offer

The range we’ve posted represents the typical compensation range for this role. To determine actual compensation, we review the market rate for each candidate which can include a variety of factors. These include qualifications, experience, interview performance, and location.

In addition to a competitive salary, we offer a variety of benefits to support your needs, including:


 * Medical, dental, and vision insurance - 100% paid for by CoreWeave
 * Company-paid Life Insurance
 * Voluntary supplemental life insurance
 * Short and long-term disability insurance
 * Flexible Spending Account
 * Health Savings Account
 * Tuition Reimbursement
 * Ability to Participate in Employee Stock Purchase Program (ESPP)
 * Mental Wellness Benefits through Spring Health
 * Family-Forming support provided by Carrot
 * Paid Parental Leave
 * Flexible, full-service childcare support with Kinside
 * 401(k) with a generous employer match
 * Flexible PTO
 * Catered lunch each day in our office and data center locations
 * A casual work environment
 * A work culture focused on innovative disruption
   
   

Our Workplace

While we prioritize a hybrid work environment, remote work may be considered for candidates located more than 30 miles from an office, based on role requirements for specialized skill sets. New hires will be invited to attend onboarding at one of our hubs within their first month. Teams also gather quarterly to support collaboration

California Consumer Privacy Act - California applicants only

CoreWeave is an equal opportunity employer, committed to fostering an inclusive and supportive workplace. All qualified applicants and candidates will receive consideration for employment without regard to race, color, religion, sex, disability, age, sexual orientation, gender identity, national origin, veteran status, or genetic information.

As part of this commitment and consistent with the Americans with Disabilities Act (ADA), CoreWeave will ensure that qualified applicants and candidates with disabilities are provided reasonable accommodations for the hiring process, unless such accommodation would cause an undue hardship. If reasonable accommodation is needed, please contact: careers@coreweave.com.

Export Control Compliance

This position requires access to export controlled information. To conform to U.S. Government export regulations applicable to that information, applicant must either be (A) a U.S. person, defined as a (i) U.S. citizen or national, (ii) U.S. lawful permanent resident (green card holder), (iii) refugee under 8 U.S.C.


 * 1157, or (iv) asylee under 8 U.S.C.
 * 1158, (B) eligible to access the export controlled information without a required export authorization, or (C) eligible and reasonably likely to obtain the required export authorization from the applicable U.S. government agency. CoreWeave may, for legitimate business reasons, decline to pursue any export licensing process.","86 applicants","Full-time","Entry level","Information Technology","Software Development","$139,000.00/yr - $204,000.00/yr","","","18593641","https://coreweave.com/careers/job?4610861006&board=weights_and_biases&gh_jid=4610861006","EXTERNAL",""
"IT Manager - Data Engineering","Diamond Bar, CA","2 weeks ago","2025-11-16","https://www.linkedin.com/jobs/view/it-manager-data-engineering-at-niagara-bottling-4166890033?trk=public_jobs_topcard-title","Niagara Bottling","https://www.linkedin.com/company/niagara-bottling?trk=public_jobs_topcard-org-name","At Niagara, we’re looking for Team Members who want to be part of achieving our mission to provide our customers the highest quality most affordable bottled water.

Consider Applying Here, If You Want To


 * Work in an entrepreneurial and dynamic environment with a chance to make an impact.
 * Develop lasting relationships with great people.
 * Have the opportunity to build a satisfying career.
   
   

We offer competitive compensation and benefits packages for our Team Members.

IT Manager - Data Engineering

As a key leader within our data and analytics function, the Advanced Analytics Manager plays a critical role in architecting and maintaining the data infrastructure that underpins enterprise analytics. This role leads a team of data engineers and analytics professionals, focusing on the design, implementation, and optimization of scalable, reliable, and secure data pipelines, especially for complex, high-volume sources such as IoT and sensor-based systems. Working cross-functionally with operations, IT, and business stakeholders, the Advanced Analytics Manager ensures that data from diverse sources, including real-time telemetry, manufacturing systems, and traditional enterprise platforms are efficiently ingested, transformed, and made accessible for analytical consumption. In addition, the role includes light but growing exposure to Generative AI use cases, such as document summarization, chat interfaces for data access, and large language model (LLM) integration—especially in scenarios that augment data accessibility and user experience across the organization. This position requires not only technical expertise but also strategic thinking and leadership skills to evolve data infrastructure, support analytics scalability, and drive a data-first culture. A proven ability to lead high-performing teams and deliver impactful solutions in dynamic, data-rich environments is essential for success.


 * Lead and manage a team of data engineers and analytics professionals, providing strategic direction, mentorship, and hands-on support to foster a collaborative, high-performing team environment focused on delivering impactful data solutions.
 * Establish clear objectives and key results (OKRs) for the team that align with the enterprise analytics and data strategy, ensuring close coordination with business goals and evolving priorities.
 * Conduct regular performance reviews, deliver constructive feedback, and champion continuous learning by identifying training, upskilling, and development opportunities for team members.
 * Partner with cross-functional teams, including business analysts, data scientists, IT, and key business stakeholders, to understand data requirements and deliver solutions that support business intelligence, operational reporting, and advanced analytics use cases.
 * Define and implement best practices in data engineering, covering data modeling, pipeline orchestration (ETL/ELT), data integration, and data quality, while ensuring reliable access to data from diverse sources such as databases, APIs, cloud platforms, and IoT systems.
 * Drive continuous improvement and innovation in data architecture and engineering techniques, with a focus on increasing scalability, performance, and reusability across the analytics ecosystem.
 * Oversee project planning and execution, balancing team capacity with priority management, delivery timelines, and quality standards to ensure successful outcomes for strategic and operational analytics initiatives.
 * Collaborate with cross-functional business and IT stakeholders to define and implement data and analytics strategies that support enterprise decision-making, ensuring data integrity, security, and governance across all analytical initiatives.
 * Provide technical leadership in data engineering and analytics infrastructure, leveraging modern cloud-native tools to enable high-performance data platforms that support BI, reporting, and advanced analytics.
 * Champion a culture of data innovation and continuous learning, encouraging the team to explore new data patterns, tooling, and architectural practices that improve scalability, reliability, and time-to-insight.
 * Oversee resource planning, vendor coordination, and budget management for the analytics engineering function, ensuring alignment with strategic priorities and operational efficiency.
 * Lead the design and implementation of high-volume, scalable data pipelines, models, and data marts across Data Lakes and Data Warehouses to support reporting, dashboarding, and analytics workloads.
 * Translate technical and project outcomes into business context through executive-ready presentations and analytics steering committee briefings, facilitating alignment and decision-making.
 * Demonstrate proficiency in Microsoft Azure Cloud (preferred) and/or Amazon Web Services, particularly within data engineering and analytics service ecosystems (e.g., Azure Data Factory, Synapse, Databricks, Redshift).
 * Build and manage DevOps pipelines for CI/CD and analytics solution deployment, ensuring consistency, automation, and compliance with change control standards.
 * Serve as a proactive leader who delivers on commitments and identifies opportunities for process improvement, team development, and organizational data literacy.
 * Coordinate and collaborate with onsite and offshore consultants to support scalable delivery and knowledge transfer across global analytics initiatives.
 * Maintain flexibility and responsiveness to evolving business needs; this job description may be adjusted to reflect emerging priorities or strategic direction.
   
   

Please note that this job description is not designed to contain a comprehensive list of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without prior notice.

Additionally, The Advanced Analytics Manager Is Expected To Demonstrate


 * Excellent communication, leadership and collaboration skills
 * Possesses solid project management skills
 * Advanced decision making and problem-solving skills
 * Ability to guide technical projects successfully from inception to completion
 * Experienced with Microsoft Word, Excel, PowerPoint, Visio and Outlook
 * Team Work - balances team and individual responsibilities; gives and welcomes feedback; contributes to building a positive team spirit; puts success of team above own interests; able to build morale and group commitments to goals and objectives
 * Adaptability - adapts to changes in the work environment; able to deal with frequent change, delays, or unexpected events
 * Planning/Organizing - uses time efficiently; plans for additional resources; sets goals and objectives; organizes or schedules other people and their tasks
 * Project Management - coordinates projects; communicates changes and progress; completes projects on time; budget management; manages project team activities
 * Oral Communication - speaks clearly and persuasively in positive or negative situations; listens and gets clarification; responds well to questions
 * Excellent team player
   
   

Work Experience


 * Required:
    * 7-10 years – Experience in data modeling, ETL processes, and data warehousing
    * 7-10 years – Experience in building and managing enterprise scale data pipelines
    * 5-7 years – Experience with cloud-based data platforms (e.g., AWS, Azure, GCP)
    * 5-7 years – Experience in DevOps, CI/CD pipelines
    * 5-7 years – Experience in Python/R, Spark/Kafka
    * 5-7 years – Experience with Azure Databricks/Data Factory or similar technology
    * 3-5 years – Experience in Team leadership and people management
    * 3-5 years – Experience in Project management
      
      

 * Preferred:
    * 10+ years – Experience in data modeling, ETL processes, and data warehousing
    * 5-7 years – Experience with cloud-based data platforms (e.g., AWS, Azure, GCP)
    * 5-7 years – Experience in DevOps, CI/CD pipelines
    * 5-7 years – Experience in Python/R, Spark/Kafka
    * 5-7 years – Experience with Azure Databricks/Data Factory or similar technology
    * 5-7 years – Experience in Team leadership and people management
    * 5-7 years – Experience in Project management
    * 0-2 year(s) – Experience with Large language Models and building Gen AI applications
      

Education


 * Minimum Required:
    * Bachelor's Degree in Computer Science or Engineering
      
      

 * Preferred:
    * Master's Degree in Computer Science or Engineering
      

Certification/License


 * Required: None Required
 * Preferred: Data Engineering/Cloud certifications/Gen AI
   
   

Typical Compensation Range

Pay Rate Type: Salary

$136,778.46 - $198,328.77 / Yearly

Bonus Target: 10% Annual

Benefits

https://careers.niagarawater.com/us/en/benefits


 * *Los Angeles County applicants only** Qualified applicants with arrest or conviction records will be considered for employment in accordance with the Los Angeles County Fair Chance Ordinance for Employers, the California Fair Chance Act, and any other applicable local and state laws.
   
   

Any employment agency, person or entity that submits a résumé into this career site or to a hiring manager does so with the understanding that the applicant's résumé will become the property of Niagara Bottling, LLC. Niagara Bottling, LLC will have the right to hire that applicant at its discretion without any fee owed to the submitting employment agency, person or entity.

Employment agencies that have fee agreements with Niagara Bottling, LLC and have been engaged on a search shall submit résumé to the designated Niagara Bottling, LLC recruiter or, upon authorization, submit résumé into this career site to be eligible for placement fees.

Niagara Plant Name

CORP-MAIN","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Food and Beverage Services","$136,778.45/yr - $198,328.77/yr","","","120859","https://careers.niagarawater.com/us/en/job/NBLLUSR45735EXTERNALENUS/IT-Manager-Data-Engineering?utm_source=linkedin&utm_medium=phenom-feeds","EXTERNAL",""
"Manager, Business Intelligence Engineering","Los Angeles, CA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/manager-business-intelligence-engineering-at-snap-inc-4337673045?trk=public_jobs_topcard-title","Snap Inc.","https://www.linkedin.com/company/snap-inc-co?trk=public_jobs_topcard-org-name","Snap Inc is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are Snapchat, a visual messaging app that enhances your relationships with friends, family, and the world; Lens Studio, an augmented reality platform that powers AR across Snapchat and other services; and its AR glasses, Spectacles.

The Data Science & Insights team seeks to leverage our massive data sets into actionable insights that deliver business value. As truth seekers and truth tellers, we relay what the data says without bias, even when inconvenient or difficult. We aim to improve decision-making quality and speed across the organization to enable a deeper understanding of our customers and products. We focus on efficient and effective analytic execution, positioning ourselves as the go-to experts with deep knowledge and expertise, constantly striving for better, faster insights from data.

We’re looking for a Manager, Business Intelligence Engineering to join Snap Inc!

What you’ll do:


 * Lead a team to establish foundational data and analytics capabilities for our ads platform and identify key insights around our ads platform.
 * Collaborate with Data Science, Product, and Engineering, and Business partners to design and build data tools/visualizations, operationalize metrics, conduct investigations, deliver actionable insights, and conduct in-depth product analysis.
 * Understand the challenges within our ads platform and help make decisions based on data driven insights by analyzing information from multiple sources in a logical and coherent data story
 * Build and maintain dashboards that communicate the performance of the various components of our ads platform with compelling data visualizations and consistency
 * Develop data pipelines that power our analytics data layer for analysis, reporting and dashboarding ensuring efficiency and reliability
 * Own the data model used to power our underlying data layer for monetization including the associated pipelines, data structures, and schemas
 * Maintain the key metric definitions and understand them at a deep level, offering recommendations for improvements and new metrics
 * Conduct exploratory and deep dive analysis to understand drivers of revenue performance and overall platform performance, developing actionable insights to Product and Engineering leadership
 * Own root-cause investigations starting from proactive identification of metric regressions to resolution including recommendations for long term product improvements
 * Proactively identify improvements to our platform or business that can be expected to drive increased revenue
   
   

Knowledge, Skills & Abilities:


 * Data driven and analytical mindset
 * Hands-on expertise with data warehousing tools and workflow automation
 * Comfortable with quantitative concepts
 * Strong attention to detail and organizational skills
 * Excellent verbal and written communication skills
 * Ability to work in an agile, dynamic environment
 * Ability to use tech to improve work-flows and create efficiencies
   
   

Minimum Qualifications:


 * BS/BA degree in Analytics, Statistics, Economics or other technical field or equivalent years of experience
 * 10+ years of post-Bachelor’s analytics experience; or a Master’s degree in a technical field + 9+ year of post-grad analytics experience; or a PhD in a related technical field + 6+ years of post-grad analytics experience
 * 1+ years relevant people management experience
   
   

Preferred Qualifications:


 * Advanced Degree in Analytics, Statistics, Economics, Computer Science or other technical field
 * Experience as a data scientist and/or managing a data team
 * Experience in the digital media space
 * A passion for Snapchat as a user and knowledge of our ad products
 * Proficiency in Looker, BigQuery, and Airflow
   
   

If you have a disability or special need that requires accommodation, please don’t be shy and provide us some information.

""Default Together"" Policy at Snap: At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office 4+ days per week.

At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets.

We are an Equal Opportunity Employer and will consider qualified applicants with criminal histories in a manner consistent with applicable law (by example, the requirements of the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, where applicable).

Our Benefits: Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid parental leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success!

Compensation

In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. The starting pay may be negotiable within the salary range for the position. These pay zones may be modified in the future.

Zone A (CA, WA, NYC):

The base salary range for this position is $209,000-$313,000 annually.

Zone B:

The base salary range for this position is $199,000-$297,000 annually.

Zone C:

The base salary range for this position is $178,000-$266,000 annually.

This position is eligible for equity in the form of RSUs.","71 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Software Development","$178,000.00/yr - $313,000.00/yr","","","15191764","https://wd1.myworkdaysite.com/en-US/recruiting/snapchat/snap/job/Los-Angeles-California/Manager\u002d\u002dBusiness-Intelligence-Engineering_R0043164-1?source=LinkedIn","EXTERNAL",""
"Data Engineer","Richmond, VA","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/data-engineer-at-brooksource-4341984028?trk=public_jobs_topcard-title","Brooksource","https://www.linkedin.com/company/brooksource?trk=public_jobs_topcard-org-name","Data Engineer – Distributed Energy Resources (DER)

Richmond, VA - Hybrid (1 week on - 1 week off)

12-month contract (Multiple Year Project)

$45-55/hr. depending on experience




We are hiring a Data Integration Engineer to join one of our Fortune 500 utilities partners in the Richmond area! In this role, you will support our client’s rapidly growing Distributed Energy Resources (DER) and Virtual Power Plant (VPP) initiatives. You will be responsible for integrating data across platforms such as Salesforce, GIS, SAP, Oracle, and Snowflake to build our client’s centralized asset tracking system for thermostats, EV chargers, solar assets, home batteries, and more.




In this role, you will map data, work with APIs, support Agile product squads, and help design system integrations that enable our client to manage customer energy assets and demand response programs at scale. This is a highly visible position on a brand-new product team with the chance to work on cutting-edge energy and utility modernization efforts. If you are interested, please apply!




MINIMUM QUALIFICATIONS:

 * 3–5 years of experience in system integration, data engineering, or data warehousing and Bachelor’s degree in Computer Science, Engineering, or related technical discipline.
 * Hands-on experience working with REST APIs and integrating enterprise systems.
 * Strong understanding of data structures, data types, and data mapping.
 * Familiarity with Snowflake or similar data warehousing platform.
 * Experience connecting data across platforms and/or integrating data from a variety of sources, i.e. SAP, Oracle, etc.
 * Ability to work independently and solve problems in a fast-paced Agile environment.
 * Excellent communication skills with the ability to collaborate across IT, business, engineering, and product teams.




RESPONSIBILITIES:

 * Integrate and map data across Salesforce, GIS, Snowflake, SAP, Oracle, and other enterprise systems
 * Link distributed energy asset data (EV chargers, thermostats, solar, home batteries, etc.) into a unified asset tracking database
 * Support API-first integrations: consuming, analyzing, and working with RESTful services
 * Participate in Agile ceremonies and work through user stories in Jira
 * Collaborate with product owners, BAs, data analysts, architects, and engineers to translate requirements into actionable technical tasks
 * Support architecture activities such as identifying data sources, formats, mappings, and integration patterns
 * Help design and optimize integration workflows across new and existing platforms
 * Work within newly formed Agile product squads focused on VPP/Asset Tracking and Customer Segmentation
 * Troubleshoot integration issues and identify long-term solutions
 * Contribute to building net-new systems and tools as the client expands DER offerings




NICE TO HAVES:

 * Experience with Salesforce.
 * Experience working with GIS systems or spatial data.
 * Understanding customer enrollment systems.
 * Jira experience.




WHAT’S IN IT FOR YOU…?

Joining our client provides you the opportunity to join a brand-new Agile product squad, work on high-impact energy modernization and DER initiatives, and gain exposure to new technologies and integration tools. This is a long-term contract with strong likelihood of extension in a stable industry and company.




Eight Eleven Group provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state, and local laws.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology and Engineering","Utilities and Energy Technology","$45.00/hr - $55.00/hr","Elise Kohnke","https://www.linkedin.com/in/elise-kohnke","18476","https://www.linkedin.com/jobs/view/data-engineer-at-brooksource-4341984028?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance"
"Senior Engineer - Data Analytics","Chevy Chase, MD","1 week ago","2025-11-24","https://www.linkedin.com/jobs/view/senior-engineer-data-analytics-at-geico-4324321172?trk=public_jobs_topcard-title","GEICO","https://www.linkedin.com/company/geico?trk=public_jobs_topcard-org-name","At GEICO, we offer a rewarding career where your ambitions are met with endless possibilities.

Every day we honor our iconic brand by offering quality coverage to millions of customers and being there when they need us most. We thrive through relentless innovation to exceed our customers’ expectations while making a real impact for our company through our shared purpose.

When you join our company, we want you to feel valued, supported and proud to work here. That’s why we offer The GEICO Pledge: Great Company, Great Culture, Great Rewards and Great Careers.

At GEICO, we offer a rewarding career where your ambitions are met with endless possibilities.

Every day we honor our iconic brand by offering quality coverage to millions of customers and being there when they need us most. We thrive through relentless innovation to exceed our customers’ expectations while making a real impact for our company through our shared purpose.

When you join our company, we want you to feel valued, supported and proud to work here. That’s why we offer The GEICO Pledge: Great Company, Great Culture, Great Rewards and Great Careers.

Position Summary

GEICO is seeking an experienced Senior Engineer with a passion for building high-performance, low maintenance, zero-downtime data solutions. You will help drive our insurance business transformation as we transition from a traditional IT model to a tech organization with engineering excellence as its mission. Within the Data Analytics and Vertical Engineering team, you will develop state-of-the-art data pipelines, models, and reports, transforming vast datasets that reach up to multiple terabytes in size, while championing innovation, best practices, and continuous learning.

Position Description

As a Senior Engineer, you will work to provide an excellent user experience for our internal stakeholders across the organization and maintain the highest standards of data and analytics engineering. Our team thrives and succeeds in delivering high quality data solutions in a hyper-growth environment where priorities shift quickly. The ideal candidate has broad and deep technical knowledge, typically ranging from data processing and pipeline development to dimensional data modeling and reporting.

Position Responsibilities

As a Senior Engineer, you will:


 * Scope, design, and build scalable, resilient distributed systems
 * Utilize programming languages like Python, SQL, and NoSQL databases, along with Apache Spark for data processing, dbt for data transformation, container orchestration services such as Docker and Kubernetes, and various Azure tools and services
 * Utilize your passion for data exploration to produce high quality reports with tools such as Power BI and Apache Superset to empower outstanding business decisions
 * Use your technical expertise to shape product definitions and drive towards optimal solutions
 * Lead in design sessions and code reviews with peers to elevate the quality of engineering across the organization
 * Engage in cross-functional collaboration throughout the entire development lifecycle
 * Manage data pipelines, ensuring consistent data availability
 * Mentor other engineers
 * Consistently share best practices and improve processes within and across teams
   
   

Qualifications


 * Advanced programming experience and big data experience within Python, SQL, dbt, Spark, Kafka, Git, Containerization (Docker and Kubernetes)
 * Advanced experience with Data Warehouses (Snowflake preferred), dimensional modeling, and analytics
 * Demonstrable knowledge of business intelligence tools (Power BI and Apache Superset preferred)
 * Experience with Apache Iceberg for managing large-scale tabular data in data lakes is a plus
 * Experience with orchestration tools such as Apache Airflow or similar technologies to automate and manage complex data pipelines
 * Experience architecting and designing new ETL and BI systems
 * Experience with supporting existing ETL and BI systems
 * Experience with CI/CD to ensure smooth and continuous integration and deployment of data solutions
 * Ability to balance the competing needs of multiple priorities and excel in a dynamic environment
 * Advanced understanding of DevOps concepts including Azure DevOps framework and tools
 * Knowledge of developer tooling across the data development life cycle (task management, source code, building, deployment, operations, real-time communication)
 * Understanding of microservices oriented architecture and REST APIs and GraphQL
 * Advanced understanding of data quality monitoring and automated testing
 * Strong problem-solving ability
 * Experience with Marketing, Product, Sales, Service, Customer, Associate, Billing, Agency, Claims, or Telematics data is preferred
   
   

Experience


 * 4+ years of professional data and/or analytics engineering, programming languages and developing with big data technologies
 * 3+ years of experience with data architecture and design
 * 3+ years of experience with AWS, GCP, Azure, or another cloud service
 * 3+ years of experience with ETL and/or BI tools
 * 2+ years of experience in Big-data tools like Spark and Databricks
   
   

Education


 * Bachelor’s degree in Computer Science, Information Systems, Data Science, Statistics, Data Analytics or equivalent education or work experience
   
   

Annual Salary

$75,000.00 - $230,000.00

The above annual salary range is a general guideline. Multiple factors are taken into consideration to arrive at the final hourly rate/ annual salary to be offered to the selected candidate. Factors include, but are not limited to, the scope and responsibilities of the role, the selected candidate’s work experience, education and training, the work location as well as market and business considerations.

GEICO will consider sponsoring a new qualified applicant for employment authorization for this position.

The GEICO Pledge

Great Company: At GEICO, we help our customers through life’s twists and turns. Our mission is to protect people when they need it most and we’re constantly evolving to stay ahead of their needs.

We’re an iconic brand that thrives on innovation, exceeding our customers’ expectations and enabling our collective success. From day one, you’ll take on exciting challenges that help you grow and collaborate with dynamic teams who want to make a positive impact on people’s lives.

Great Careers: We offer a career where you can learn, grow, and thrive through personalized development programs, created with your career – and your potential – in mind. You’ll have access to industry leading training, certification assistance, career mentorship and coaching with supportive leaders at all levels.

Great Culture: We foster an inclusive culture of shared success, rooted in integrity, a bias for action and a winning mindset. Grounded by our core values, we have an an established culture of caring, inclusion, and belonging, that values different perspectives. Our teams are led by dynamic, multi-faceted teams led by supportive leaders, driven by performance excellence and unified under a shared purpose.

As part of our culture, we also offer employee engagement and recognition programs that reward the positive impact our work makes on the lives of our customers.

Great Rewards: We offer compensation and benefits built to enhance your physical well-being, mental and emotional health and financial future.


 * Comprehensive Total Rewards program that offers personalized coverage tailor-made for you and your family’s overall well-being.
 * Financial benefits including market-competitive compensation; a 401K savings plan vested from day one that offers a 6% match; performance and recognition-based incentives; and tuition assistance.
 * Access to additional benefits like mental healthcare as well as fertility and adoption assistance.
 * Supports flexibility- We provide workplace flexibility as well as our GEICO Flex program, which offers the ability to work from anywhere in the US for up to four weeks per year.
   
   

The equal employment opportunity policy of the GEICO Companies provides for a fair and equal employment opportunity for all associates and job applicants regardless of race, color, religious creed, national origin, ancestry, age, gender, pregnancy, sexual orientation, gender identity, marital status, familial status, disability or genetic information, in compliance with applicable federal, state and local law. GEICO hires and promotes individuals solely on the basis of their qualifications for the job to be filled.

GEICO reasonably accommodates qualified individuals with disabilities to enable them to receive equal employment opportunity and/or perform the essential functions of the job, unless the accommodation would impose an undue hardship to the Company. This applies to all applicants and associates. GEICO also provides a work environment in which each associate is able to be productive and work to the best of their ability. We do not condone or tolerate an atmosphere of intimidation or harassment. We expect and require the cooperation of all associates in maintaining an atmosphere free from discrimination and harassment with mutual respect by and for all associates and applicants.","69 applicants","Full-time","Mid-Senior level","Information Technology","Insurance","$75,000.00/yr - $230,000.00/yr","","","157327","https://www.linkedin.com/jobs/view/senior-engineer-data-analytics-at-geico-4324321172?trk=public_jobs_topcard-title","EASY_APPLY",""
"Corporate Solutions Engineer","New York, NY","6 days ago","2025-11-26","https://www.linkedin.com/jobs/view/corporate-solutions-engineer-at-postman-4339134150?trk=public_jobs_topcard-title","Postman","https://www.linkedin.com/company/postman-platform?trk=public_jobs_topcard-org-name","Who Are We?

Postman is the world’s leading API platform, used by more than 40 million developers and 500,000 organizations, including 98% of the Fortune 500. Postman is helping developers and professionals across the globe build the API-first world by simplifying each step of the API lifecycle and streamlining collaboration—enabling users to create better APIs, faster.

The company is headquartered in San Francisco and has offices in Boston, New York, and Bangalore - where Postman was founded. Postman is privately held, with funding from Battery Ventures, BOND, Coatue, CRV, Insight Partners, and Nexus Venture Partners. Learn more at postman.com or connect with Postman on X via @getpostman.

P.S: We highly recommend reading The ""API-First World"" graphic novel to understand the bigger picture and our vision at Postman.

The Opportunity

With so many organizations using Postman, we are looking for an exceptional Corporate Solutions Engineer to join our team & help us support the growth of our customers in the corporate market. You will partner with our corporate sales team to promote an API-first development culture, nurture customer relationships, and guide Postman users in leveraging our platform to build their APIs most effectively. Ideally, we are looking for someone who lives & breathes APIs, has experience in corporate sales, is comfortable with JavaScript & is an expert Postman user already!

In addition to working with a product that customers already know and love, our sales, customer success, product, and engineering teams will support you well in this role.

What You’ll Do


 * Help drive sales by nurturing prospects & supporting customers in our corporate market
 * Conduct discovery, qualification, technical demos, & proof of value workshops with prospective customers looking to embrace Postman for their API lifecycle
 * Handle Postman technical questions or objections & provide solutions or workarounds to address customer needs
 * Produce reusable collateral that can be distributed to help our prospective customers understand how to adopt API-first practices with Postman.
 * Understand deeply our customer workflows today & how they can adopt API-first development best practices
 * Share customer feedback with appropriate teams & provide general customer advocacy
 * Remain up-to-date with the competitive landscape, current trends, & challenges in the API market
 * Create proof of concept integrations, tooling, & workflows as needed to support prospective customers
 * Maintain & develop customer sandbox environments & best practices for working with the product
 * Act as a technical intermediary between sales & other teams to best fit our customer needs
   
   

About You


 * 4+ years of corporate sales/solutions engineering experience
 * 3+ years of software development experience
 * 3+ API’s and Data platforms experience
 * Bachelor's degree in Computer Science, a related field, or relevant work experience
 * Ability to travel up to 25%
 * Loves teamwork & collaboration in a fast-paced environment
 * Customer-facing experience & comfortable engaging all levels of technologists, including individual developers, QA, product, & engineering leaders
 * Strong understanding of APIs, & experience with producing & consuming APIs across different domains
 * Strong knowledge of modern development methodologies & DevOps with an appreciation of the software development life cycle
 * Comfortable with the SaaS sales process & common security concerns of cloud services
 * Experience executing sales strategies & sales methodologies like MEDDIC, Challenger Sale, Command of the Message, etc.
 * Excellent listener who seeks to understand what a customer is trying to achieve rather than pre-supposing solutions
 * Familiar with typical developer tooling: IDEs, Git, CI/CD, monitoring services, microservices, containers, cloud computing services, etc.
 * Fast learner, excited & willing to learn new technology on an ongoing basis
 * Excellent communication skills (presentation, verbal & written)
   
   

The reasonably estimated OTE for this role is $145,000 - $175,000 plus a competitive equity package. Actual compensation is based on the candidate's skills, qualifications, and experience.

What Else?

In addition to Postman's pay-on-performance philosophy, and a flexible schedule working with a fun, collaborative team, Postman offers a comprehensive set of benefits, including full medical coverage, flexible PTO, wellness reimbursement, and a monthly lunch stipend. Along with that, our wellness programs will help you stay in the best of your physical and mental health. Our frequent and fascinating team-building events will keep you connected, while our donation-matching program can support the causes you care about. We’re building a long-term company with an inclusive culture where everyone can be the best version of themselves.

At Postman, we embrace a hybrid work model. For all roles based out of San Francisco Bay Area, Boston, Bangalore, Hyderabad, and New York, employees are expected to come into the office 3-days a week. We were thoughtful in our approach which is based on balancing flexibility and collaboration and grounded in feedback from our workforce, leadership team, and peers. The benefits of our hybrid office model will be shared knowledge, brainstorming sessions, communication, and building trust in-person that cannot be replicated via zoom.

Our Values

At Postman, we create with the same curiosity that we see in our users. We value transparency and honest communication about not only successes, but also failures. In our work, we focus on specific goals that add up to a larger vision. Our inclusive work culture ensures that everyone is valued equally as important pieces of our final product. We are dedicated to delivering the best products we can.

Equal opportunity

Postman is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. Postman does not accept unsolicited headhunter and agency resumes. Postman will not pay fees to any third-party agency or company that does not have a signed agreement with Postman.","35 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","","","","3795851","https://www.linkedin.com/jobs/view/corporate-solutions-engineer-at-postman-4339134150?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Science Associate","Des Moines, IA","3 weeks ago","2025-11-06","https://www.linkedin.com/jobs/view/data-science-associate-at-wellmark-blue-cross-and-blue-shield-4334552334?trk=public_jobs_topcard-title","Wellmark Blue Cross and Blue Shield","https://www.linkedin.com/company/wellmark?trk=public_jobs_topcard-org-name","Why Wellmark: We are a mutual insurance company owned by our policy holders across Iowa and South Dakota, and we’ve built our reputation on over 80 years’ worth of trust. We are not motivated by profits. We are motivated by the well-being of our friends, family, and neighbors–our members. If you’re passionate about joining an organization working hard to put its members first, to provide best-in-class service, and one that is committed to sustainability and innovation, consider applying today!

Why Wellmark Technology? Wellmark is building innovative, modern solutions using cutting edge technology. We are driving organizational transformation and business strategy by empowering our technology team to innovate new and elegant solutions to enhance the customer experience. Together, we are leaning into the future, owning the outcome, and driving organizational change to transform how we work.

Learn more about our unique benefit offerings here.

Want to know more? You can learn about life at Wellmark here.

Job Description

Responsible for extracting, integrating analyzing, and interpreting data from internal and external data sources, to develop intelligence packaging that draws conclusions and supports recommendations that will help to achieve business goals. Collaborate with team and key business stakeholders to ensure critical business objectives are met by following the analytics lifecycle within assigned domains. Work cross-functionally with business stakeholders to identify risk and provide solutions that drive data-enabled decisions.

Qualifications

Required:


 * For consideration, you must meet one of the following educational/technical requirements:
 * Bachelor’s degree in quantitative discipline such as statistics, mathematics, finance, accounting, computer science, engineering, or economics.
 * Less than 1-year hands-on experience with specific experience in data or statistical analysis, including data collection, joins, analysis, statistics and/or data presentation. Specific exposure with hands-on data analysis of databases and files using SQL dialects and statistical programming languages.
 * Strong formulas and data visualizations knowledge.
 * Exposure to business intelligence or analysis platforms.
 * Naturally curious and ability to drive business decisions and solutions.
 * Effective communication skills, both verbal and written, with the ability to present complex information.
 * Proactive, self-starter and can manage priorities through effective time management skills.
   
   

Preferred:


 * Master’s degree.
 * Experience working with unstructured data sets.
 * Experience developing project roadmaps and timelines.
   
   

Additional Information

Job Responsibilities


 * Participate in or conduct discovery sessions and stakeholder interactions to gain business understanding and identify business problem. Understand the project objectives and gather requirements to build a preliminary plan.
 * Research and gather appropriate data from various sources. Source, extract, assemble, collate, and consolidate data needs for the business.
 * Profile and prepare data for analysis.
 * Build and execute models to analyze business outcomes, using tables, graphs, and charts, as well as algorithms, forecasts, and trends.
 * Interpret results, identify key findings to quantify business value.
 * Develop a narrative to summarize and convey findings to stakeholders. Make recommendations based on findings.
 * Create, update, and maintain a production schedule for reporting and ensure reports and presentations are completed on schedule.
 * Manage multiple projects simultaneously and support corporate process improvement initiatives, meeting aggressive timeframes.
 * Collaborate with peers to identify reporting objectives and develop reports and analyses that meet their need and drive Wellmark’s value proposition for stakeholders.
 * Wrangle data from a wide variety of data sets and assemble into normalized and enriched data assets that enables new insights, solutions, and visualizations. Perform and document data profiling, quality assessment, source consolidation, aggregation, and other data manipulation efforts, to understand data formats, source systems, file sizes, etc.
 * Create, update, and maintain documentation and procedures for sourcing, analyzing, and preparing internal reporting and presentations. Ensure the highest quality and integrity of data sources.
 * Other duties as assigned.
   
   

An Equal Opportunity Employer

The policy of Wellmark Blue Cross Blue Shield is to recruit, hire, train and promote individuals in all job classifications without regard to race, color, religion, sex, national origin, age, veteran status, disability, sexual orientation, gender identity or any other characteristic protected by law.

Applicants requiring a reasonable accommodation due to a disability at any stage of the employment application process should contact us at careers@wellmark.com

Please inform us if you meet the definition of a ""Covered DoD official"".

At this time, Wellmark is not considering applicants for this position that require any type of immigration sponsorship (additional work authorization or permanent work authorization) now or in the future to work in the United States. This includes, but IS NOT LIMITED TO: F1-OPT, F1-CPT, H-1B, TN, L-1, J-1, etc. For additional information around work authorization needs please refer to the following resources:Nonimmigrant Workers and Green Card for Employment-Based Immigrants","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Software Development and IT Services and IT Consulting","","","","28499","https://jobs.smartrecruiters.com/WellmarkInc/744000091909369-data-science-associate?trid=2d92f286-613b-4daf-9dfa-6340ffbecf73","EXTERNAL",""
"Data Analyst with Pyspark and A/B Tesing","Sunnyvale, CA","19 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-analyst-with-pyspark-and-a-b-tesing-at-avance-consulting-4324958995?trk=public_jobs_topcard-title","Avance Consulting","https://uk.linkedin.com/company/avance-services?trk=public_jobs_topcard-org-name","Role:-Data Analyst with Pyspark & AB Testing

Location:-Sunnyvale, CA

Job Type:- Fulltime

Job Description:-







Job Description:-

Required Qualifications:

 * At least 4 years of experience in Information Technology
 * Proven years of applied experience in exploratory data analysis, devising, deploying and servicing statistical models
 * Strong hands-on experience with data mining and data visualization, Tableau, A/B Testing, SQL for developing and creating data pipelines to source and transform Data
 * Strong experience using Python, Advanced SQL and PySpark

Preferred Qualifications:

 * Advanced degree with Master’s or above in area of quantitative discipline such as Statistics, Applied Math, Operations Research, Computer Science, Engineering or Physics or a related field
 * Marketing domain background (Web analytics, click stream data analysis, and other KPI’s on marketing campaigns)
 * Knowledge of Machine Learning techniques

","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Staffing and Recruiting","","Shaik Arthi","https://in.linkedin.com/in/shaik-arthi-971477254","613812","https://www.linkedin.com/jobs/view/data-analyst-with-pyspark-and-a-b-tesing-at-avance-consulting-4324958995?trk=public_jobs_topcard-title","EASY_APPLY",""
"Member of Technical Staff, Data Engineering","New York, NY","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/member-of-technical-staff-data-engineering-at-cohere-4324862552?trk=public_jobs_topcard-title","Cohere","https://ca.linkedin.com/company/cohere-ai?trk=public_jobs_topcard-org-name","Who are we?

Our mission is to scale intelligence to serve humanity. We’re training and deploying frontier models for developers and enterprises who are building AI systems to power magical experiences like content generation, semantic search, RAG, and agents. We believe that our work is instrumental to the widespread adoption of AI.

We obsess over what we build. Each one of us is responsible for contributing to increasing the capabilities of our models and the value they drive for our customers. We like to work hard and move fast to do what’s best for our customers.

Cohere is a team of researchers, engineers, designers, and more, who are passionate about their craft. Each person is one of the best in the world at what they do. We believe that a diverse range of perspectives is a requirement for building great products.

Join us on our mission and shape the future!

Why this role?

As a Data Engineer specializing in pretraining data, you will play a pivotal role in developing the data pipeline that underpins Cohere’s advanced language models. Your responsibilities will encompass the end-to-end management of training data, including ingestion, cleaning, filtering, and optimization, as well as data modeling to ensure datasets are structured and formatted for optimal model performance. You will work with diverse data sources, such as web data, code data, and multilingual corpora, to ensure their quality, diversity, and reliability. By combining research and engineering, you will bridge the gap between raw data and cutting-edge AI models, directly contributing to improvements in critical training metrics like throughput and accelerator utilization.

Your work will be essential to Cohere’s mission of delivering efficient and reliable language understanding and generation capabilities, driving innovation in natural language processing. If you are passionate about transforming data into the foundation of AI systems, this role offers a unique opportunity to make a meaningful impact.

Please Note: We have offices in London, Paris, Toronto, San Francisco and New York but also embrace being remote-friendly! There are no restrictions on where you can be located for this role between EST and EU.

As a Member of Technical Staff, Data Engineering, you will:


 * Design and build scalable data pipelines to ingest, parse, filter, and optimize diverse web datasets.
 * Conduct data ablations to assess data quality and experiment with data mixtures to enhance model performance.
 * Develop robust data modeling techniques to ensure datasets are structured and formatted for optimal training efficiency.
 * Research and implement innovative data curation methods, leveraging Cohere’s infrastructure to drive advancements in natural language processing.
 * Collaborate with cross-functional teams, including researchers and engineers, to ensure data pipelines meet the demands of cutting-edge language models.
   
   

You May Be a Good Fit If You Have


 * Strong software engineering skills, with proficiency in Python and experience building data pipelines.
 * Familiarity with data processing frameworks such as Apache Spark, Apache Beam, Pandas, or similar tools.
 * Experience working with large-scale web datasets like CommonCrawl.
 * A passion for bridging research and engineering to solve complex data-related challenges in AI model training.
   
   

Bonus: paper at top-tier venues (such as NeurIPS, ICML, ICLR, AIStats, MLSys, JMLR, AAAI, Nature, COLING, ACL, EMNLP).

If some of the above doesn’t line up perfectly with your experience, we still encourage you to apply!

We value and celebrate diversity and strive to create an inclusive work environment for all. We welcome applicants from all backgrounds and are committed to providing equal opportunities. Should you require any accommodations during the recruitment process, please submit an Accommodations Request Form, and we will work together to meet your needs.

Full-Time Employees At Cohere Enjoy These Perks

🤝 An open and inclusive culture and work environment

🧑‍💻 Work closely with a team on the cutting edge of AI research

🍽 Weekly lunch stipend, in-office lunches & snacks

🦷 Full health and dental benefits, including a separate budget to take care of your mental health

🐣 100% Parental Leave top-up for up to 6 months

🎨 Personal enrichment benefits towards arts and culture, fitness and well-being, quality time, and workspace improvement

🏙 Remote-flexible, offices in Toronto, New York, San Francisco, London and Paris, as well as a co-working stipend

✈️ 6 weeks of vacation (30 working days!)","35 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Software Development","","","","24024765","https://jobs.ashbyhq.com/cohere/0885b39d-b2f8-44be-af4c-e533be2b34af?utm_source=jKNDxYPz51","EXTERNAL",""
"Data Scientist","Bentonville, AR","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/data-scientist-at-us-tech-solutions-4347620555?trk=public_jobs_topcard-title","US Tech Solutions","https://www.linkedin.com/company/us-tech-solutions?trk=public_jobs_topcard-org-name","Duration- Full Time




Description:

What you'll do...

 * Chance to work on financial data for complex problems/challenges.
 * Utilize LLMs/Genai systems and architectures to build and deploy state-of-the-art Genai systems.
 * Our team collaborates closely with Finance teams to enhance financial planning and strategic decision-making through cutting-edge data-driven solutions.
 * We specialize in a range of initiatives which provides actionable insights into trends and patterns and leveraging Generative AI (Genai) to produce concise, insightful summaries that empower decision-makers.
 * By integrating these innovative approaches, we strive to drive efficiency, accuracy, and impactful outcomes in financial operations.




About Team:

 * Our team works closely with our US stores and eCommerce business to better serve customers by empowering team members, stores, and merchants with technological innovation. From groceries and entertainment to sporting goods and crafts, Client U.S. offers an extensive selection that our customers value, whether they shop online at Client.com, through one of our mobile apps, or in-store.
 * Focus areas include customers, stores and employees, in-store service, merchant tools, merchant data science, and search and personalization.




What you'll do:

 * Lead high-caliber team to build large-scale Genai systems
 * Develop data science systems and tools for retail; e-commerce applications:
 * Leverage LLMS to summarize and build large scale applications
 * Establish cross-functional relationships to maintain win-win situation for the corporation
 * Collaborate with various product stake holders and business owners to formulate and productionize a solution




What you'll bring: Master's degree or PHD in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 7+ years' experience in the related field.




Must have qualifications...

 * Strong solution architecture mindset, with the ability to apply AI/ML technologies to solve complex business problems.
 * Experience with training and inference of large-scale AI models such as Large Language Models (LLMs), multimodal models, and reasoning models.
 * Knowledge of advanced model optimization techniques, including quantization, pruning, distillation, Low-Rank Adaptation (Lora), and Parameter-Efficient Fine-Tuning (PEFT) for cloud deployment.
 * Solid understanding of LLMs and Genai ecosystems, including GPT, Llama, Mistral, Claude, Gemini, AWS Sonnet, and related frameworks/tools.
 * Hands-on experience with RAG (Retrieval-Augmented Generation), AI agent development, and frameworks such as Lang Chain, Langgraph etc.,




Great to have...

 * Experience with Big Data processing and feature engineering using Spark
 * Experience with training machine learning models through Cloud Services including Google Cloud Platform and Microsoft Azure
 * Hands on experience of designing and training large DL models on GPU




Behavior qualifications...

 * Problem solver with can-do attitude, not afraid of facing new problems, technical challenges, delivery pressures
 * Ability to clearly define problems, models and constraints from informal and flexible business requirements
 * Tech leadership with teamwork spirit, quick adaptation to new environment
 * Form collaborative working environment.
 * Demonstrated ability to manage multiple cross-functional initiatives, balancing competing priorities and deadlines.
 * Comfortable working in ambiguous, rapidly changing environments, with strong problem-solving and adaptability.
 * Highly motivated to demystify emerging technologies and drive adoption across teams and stakeholders.




About US Tech Solutions:

US Tech Solutions is a global staff augmentation firm providing a wide range of talent on-demand and total workforce solutions. To know more about US Tech Solutions, please visit www.ustechsolutions.com.

US Tech Solutions is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Ensures effective and efficient operations through conducting operations analyses (i.e. operational effectiveness and capacity utilization), and recommends improvements.




Details

Job ID-25-53538","148 applicants","Full-time","Mid-Senior level","Information Technology","Retail","$120,000.00/yr - $200,000.00/yr","Tarun Kumar","https://www.linkedin.com/in/tarun-kumar-62561025b","27292","https://www.linkedin.com/jobs/view/data-scientist-at-us-tech-solutions-4347620555?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Strategy Lead","Newport Beach, CA","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/data-strategy-lead-at-pimco-4319383815?trk=public_jobs_topcard-title","PIMCO","https://www.linkedin.com/company/pimco?trk=public_jobs_topcard-org-name","PIMCO is a global leader in active fixed income with deep expertise across public and private markets. We invest our clients’ capital across a range of fixed income and credit opportunities, leveraging our decades of experience navigating complex debt markets. Our flexible capital base and deep relationships with issuers have helped us become one of the world’s largest providers of traditional and nontraditional solutions for companies that need financing and investors who seek strong risk-adjusted returns.

Since 1971, our people have shaped our organization through a high-performance inclusive culture, in which we celebrate diverse thinking. We invest in our people and strive to imprint our CORE values of Collaboration, Openness, Responsibility and Excellence. We believe each of us is here to help others succeed and this has led to PIMCO being recognized as an innovator, industry thought leader and trusted advisor to our clients.

Job Description

We are seeking a Data Strategy Lead for our Portfolio Management business to join us in our Newport Beach (preferred) or NYC office. This person will be part of our PM Analytics function and be responsible for shaping our technical vision for data management and production that underpins our research, analytical tools, dashboards and decision-support for our PM teams. You will oversee the creation of a comprehensive internal data catalog that will enable seamless discovery, access, and governance of high-quality market and analytical data. Your cross-team leadership will drive the development of scalable, reusable analytical frameworks - especially for financial time series analysis, while ensuring rigorous data quality and production workflow oversight.

Key Responsibilities


 * Data Catalog & Governance
    * Oversee the creation and management of a comprehensive internal data catalog, ensuring market and analytical data assets are easily discoverable and accessible.
    * Implement best practices for data quality and accuracy to support high-impact analytics and investment decisions.

 * Technical Leadership & Architecture
    * Partner with senior leaders across Technology, Analytics and PM to align data strategies with business objectives and firm-wide technology initiatives. Ensuring cost effective solutions.
    * Design and implement scalable data pipelines and production workflows for portfolio analytics, including reusable libraries for time series, financial modeling, risk, and performance analysis.
    * Integrate new data sources into production systems, ensuring seamless ingestion, transformation, and validation. Lead efforts to optimize data acquisition strategies, ensuring alignment with a low-cost, high-value approach that maximizes business impact.

 * Data Quality Control
    * Develop and enforce rigorous data quality controls, including automated validation, anomaly detection, reconciliation, and real-time monitoring for data integrity, latency, and completeness.
    * Lead root cause analysis and remediation for data quality issues, collaborating with technology and analytics teams.

 * Production Process Management
    * Partner with Technology to design end-to-end production data lifecycle, from acquisition to analytics and reporting, while implementing best practices for CI/CD, version control, and testing.
    * Ensure appropriate documentation and audit trails for all production data processes.

 * Analytics Innovation
    * Collaborate across PM groups and Analytics to provide thought leadership on leveraging AI/LLM and PIMCO data assets, to maximize business impact.
      

Requirements


 * Advanced degree in Data Science, Computer Science, Financial Engineering, or related quantitative field preferred.
 * Proven experience architecting and managing production data pipelines and analytics platforms in financial services or asset management.
 * Demonstrated ability to lead technical teams and collaborate across business and technology functions.
 * Programming in Python and experience with cloud-based data platforms and big data technologies such as AWS and Snowflake.
 * Expertise in time series analysis, financial modeling, quantitative analytics, and strong understanding of global markets (i.e., fixed income, commodities, equities, and derivatives).
 * Strong background in data query, search, monitoring, and root cause analysis.
   
   

PIMCO follows a total compensation approach when rewarding employees which includes a base salary and a discretionary bonus. Base salary is the fixed component of compensation that is determined by core job responsibilities, relevant experience, internal level, and market factors. The discretionary bonus is used to award performance and therefore is determined by company, business, team, and individual performance.

Salary Range: $ 205,000.00 - $ 305,000.00

Equal Employment Opportunity and Affirmative Action Statement

PIMCO recruits and hires qualified candidates without regard to race, national origin, ancestry, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), sexual orientation, gender (including gender identity and expression), age, military or veteran status, disability (physical or mental), any factor prohibited by law, and as such affirms in policy and practice to support and promote the concept of equal employment opportunity and affirmative action, in accordance with all applicable federal, state, provincial and municipal laws. The company also prohibits discrimination on other basis such as medical condition, or marital status under applicable laws.

Applicants with Disabilities

PIMCO is an Equal Employment Opportunity/Affirmative Action employer. We provide reasonable accommodation for qualified individuals with disabilities, including veterans, in job application procedures. If you have any difficulty using our online system due to a disability and you would like to request an accommodation, you may contact us at 949-720-7744 and leave a message. This is a dedicated line designed exclusively to assist job seekers with disabilities to apply online. Only messages left for this purpose will be considered. A response to your request may take up to two business days.","104 applicants","Full-time","Mid-Senior level","Information Technology","Investment Management","$205,000.00/yr - $305,000.00/yr","","","7970","https://pimco.wd1.myworkdayjobs.com/pimco-careers/job/Newport-Beach-CA-USA/Data-Strategy-Lead_R105778?source=linkedin","EXTERNAL",""
"Associate, Data Engineer","New York, NY","3 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/associate-data-engineer-at-cfsb-4340040609?trk=public_jobs_topcard-title","CFSB","https://www.linkedin.com/company/cfsb---community-federal-savings-bank?trk=public_jobs_topcard-org-name","Community Federal Savings Bank is a full-service payments, lending and banking provider that delivers global financial services through a personal approach. CFSB is seeking an Associate, Data Engineer, you will partner with talented architects, infrastructure engineers, machine learning engineers, data scientists and data analysts to improve may different products and services. You will analyze, design, develop, test, and perform ongoing maintenance to build high quality data pipelines that drive platform delivery. You will implement capabilities to solve sophisticated business problems, deploy innovative products, services, and experiences for our customers.

Responsibilities


 * Build and optimize data pipelines latest coding practices and industry standards, modern design patterns and architectural principles
 * Conduct complex data analysis and report on results, prepare data for prescriptive and predictive modeling, combine raw information from different sources Develop and maintain process and data documentation
 * Monitor and triage the data pipeline processes
 * Write unit, integration tests and functional automation, researching problems discovered by quality assurance or product support, developing solutions to address the problem
 * Apply a software development approach to data engineering problems (including testing, documentation, modularity and dry-ness, CI/CD workflow, etc.
   
   

Knowledge, Skills, And Abilities


 * Ability to use programming languages including but not limited to Python, SQL, Java, Shell scripting
 * Strong understanding with cloud computing platforms (e.g., AWS)
 * Experience with Data Visualization tools (Looker, Mode, Sigma, ThoughtSpot, etc.…) is a plus
 * Strong understanding of database security, backup, and recovery procedure
 * Strong communication and collaboration skills
 * Excellent problem-solving and troubleshooting skills
   
   

Education, Training, And Experience


 * Bachelor's degree in computer science, information technology, or a related field (or equivalent experience)
 * Minimum 4 years of experience required
 * Expert level experience as a Data Engineer with a focus on Snowflake, dbt cloud, SQL, Python, Shell scripting
   
   

Salary Range: $85K - $100K / year

""Base salary range does not include performance-based bonus and/or other benefits, where applicable. Actual base salary offer will vary based on skills and experience.""

About Community Federal Savings Bank (CFSB)

Community Federal Savings Bank (CFSB) is a federally chartered bank founded in 2001 and headquartered in New York City. CFSB has focused on providing superior service and added value to clients through as solid understanding of relationship banking. We offer a full range of services including loans, bill payments, card services, internet banking, and merchant processing.

We are an equal opportunity employer and do not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, disability, military and/or veteran status, or any other Federal or State legally-protected classes.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Financial Services","$85,000.00/yr - $100,000.00/yr","","","5296909","https://www.linkedin.com/jobs/view/associate-data-engineer-at-cfsb-4340040609?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Data Engineer","Washington, DC","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/senior-data-engineer-at-children-s-national-hospital-4339103276?trk=public_jobs_topcard-title","Children's National Hospital","https://www.linkedin.com/company/children's-national-medical-center?trk=public_jobs_topcard-org-name","The Senior Data Engineer is responsible for designing, developing, and operationalizing advanced cloud data pipelines to facilitate seamless data consumption for reports, advanced analytics, and AI initiatives. This role involves overseeing the entire data lifecycle, including data ingestion, transformation, validation, and quality assurance. The Senior Data Engineer ensures the optimization and orchestration of data pipelines to handle high-volume and high-performance requirements effectively. Additionally, this role leads efforts in Continuous Integration and Continuous Deployment (CI/CD), driving automation and deployment efficiency. The Senior Data Engineer collaborates with cross-functional teams to align data solutions with business needs, provide strategic insights, and mentor junior team members, all while upholding best practices and ensuring data integrity.

Minimum Education

Bachelor's Degree A Bachelor’s degree in a quantitative or business field (e.g., Statistics, Mathematics, Engineering, Computer Science). (Required)

Minimum Work Experience

6 years Requires deep functional knowledge with 6+ years of related experience or equivalent experience acquired through accomplishments of applicable knowledge, duties, scope and skill reflective of the level of this position. (Required)

Required Skills/Knowledge

Experience with big data; data processing and cloud technologies.

Strong experience diagnosing system issues, engaging in data validation, and providing quality assurance testing.

Experience with data manipulation; Data mining.

Experience working in production cloud infrastructure.

Experience with C# (programming language); Java (programming language); Programming concepts; Programming tools; Python (Programming Language); SQL (programming language).

Knowledge of Microsoft Azure; Databricks or equivalent.

Seeks to acquire knowledge in area of specialty.

Ability to identify basic problems and procedural irregularities, collect data, establish facts, and draw valid conclusions.

Ability to work independently.

Demonstrated analytical skills.

Demonstrated project management skills.

Demonstrates a high level of accuracy, even under pressure.

Demonstrates excellent judgment and decision-making skills.

Great verbal and written communication skills, communicate complex findings in a clear and understandable manner

Great facilitation ability to host sessions and elicit ideas from others, understanding their issues and encourage group participation

Attention to detail.

Communicate complex findings in a clear and understandable manner

Collaborate effectively with cross-functional teams

Adapt to changing priorities and thrive in a dynamic environment

Functional Accountabilities


 * Helps guide the design and implementation of complex data management procedures around data staging, data ingestion, data preparation, data provisioning, data destruction, (scripts, programs automation, assisted by automation etc.)
 * Provides guidance to data engineering in the design, development, implementation, testing, documentation, and preparation of large scale, high volume, high performance data structures for business intelligence analysts.
 * Designs, develops and maintains real time processing applications and real time data pipelines.
 * Ensure quality of technical solutions as data moves across environments.
 * Provides senior level knowledge and insight into the changing cloud data environment, data processing, data storage, and utilization requirements for the company and drives the team toward viable solutions.
 * Develops, constructs, tests, and maintains architectures using advanced programming languages and tools.
 * Drives ways to improve data reliability, efficiency, and quality and deploys a solution; use data to discover tasks that can be automated.
 * Performs other duties as assigned.
 * Complies with all policies and standards.
   
   

Organizational Accountabilities

Organizational Accountabilities (Staff)

Organizational Commitment/Identification


 * Anticipate and responds to customer needs; follows up until needs are met
   
   

Teamwork/Communication


 * Demonstrate collaborative and respectful behavior
 * Partner with all team members to achieve goals
 * Receptive to others’ ideas and opinions
   
   

Performance Improvement/Problem-solving


 * Contribute to a positive work environment
 * Demonstrate flexibility and willingness to change
 * Identify opportunities to improve clinical and administrative processes
 * Make appropriate decisions, using sound judgment
   
   

Cost Management/Financial Responsibility


 * Use resources efficiently
 * Search for less costly ways of doing things
   
   

Safety


 * Speak up when team members appear to exhibit unsafe behavior or performance
 * Continuously validate and verify information needed for decision making or documentation
 * Stop in the face of uncertainty and takes time to resolve the situation
 * Demonstrate accurate, clear and timely verbal and written communication
 * Actively promote safety for patients, families, visitors and co-workers
 * Attend carefully to important details - practicing Stop, Think, Act and Review in order to self-check behavior and performance
   
   

Primary Location

District of Columbia-Washington

Work Locations

Remote Work Location

Job

Information Technology

Organization

Miscellaneous

Position Status

R (Regular)

Shift

Day

Work Schedule

8:30-5

Job Posting

Nov 26, 2025, 1:39:10 AM

Full-Time Salary Range

109116.8","182 applicants","Full-time","Mid-Senior level","Information Technology","Hospitals and Health Care","$109,116.80/yr - $181,854.40/yr","","","11358","https://www.linkedin.com/jobs/view/senior-data-engineer-at-children-s-national-hospital-4339103276?trk=public_jobs_topcard-title","EASY_APPLY",""
"Head of Data","New York, NY","3 weeks ago","2025-11-06","https://www.linkedin.com/jobs/view/head-of-data-at-gyde-4334599872?trk=public_jobs_topcard-title","Gyde","https://www.linkedin.com/company/gydeinc?trk=public_jobs_topcard-org-name","About Us


 * Insurance brokers sit at the intersection of care, cost, and access — yet remain one of the most underleveraged assets in the $5T healthcare value chain. They guide millions of Americans through plan selection, coverage questions, and care navigation, yet still rely on spreadsheets, manual workflows, and outdated tools that limit their growth and impact.
 * Gyde is reimagining this. We’re building the first AI-native insurance brokerage platform—a system that learns from every client interaction to automate operations, power intelligent voice and chat experiences, and predict the right coverage and products for every individual or business.
 * Our approach combines acquisition and AI: we acquire traditional brokerages and transform them into next-generation, data-driven organizations. Through Gyde’s platform, agencies run more efficiently, serve clients more personally, and scale faster than ever before.
 * Join us if you’re excited to:
    * Redefine how millions of people access and understand their healthcare coverage, by building systems that turn unstructured data, human conversations, and fragmented processes into intelligence.
    * Build AI systems that improve how people access healthcare
    * Design production-grade voice, chat, and predictive models for a highly regulated domain
    * Launch technologies that augment human judgment and make complex decisions transparent and scalable
    * Help reinvent an entire industry from the inside out

 * Our founding team boasts pedigrees from Oscar, Stripe, and Spark. Lightspeed led Gyde’s Seed financing, with participation from Virtue and Crystal Venture Partners, and angels from Oscar, Uber, and more.
   

Role Summary

As Head of Data at Gyde, you will own the vision, strategy, and execution of how data powers decision-making across the company. You’ll be responsible for building the systems, team, and culture that turn raw data into actionable insights and scalable infrastructure. This role combines strategic leadership with hands-on technical expertise.

Reporting into the COO, you’ll collaborate with our Value Creation team to drive the data integration strategy of our acquired assets along with Engineering team to ensure our data pipelines and platforms are robust, secure, and built to scale. Additionally, this a cross-functional role where you’ll be expected to support each department’s data needs with varying degrees of intensity.

This role is ideal for a data leader who thrives in fast-moving environments, enjoys building from zero to one, and is motivated by the impact that clean, connected data can have across an organization

Key Responsibilities


 * Own the data strategy: Set the vision for how data is collected, structured, and used across the organization.
 * Infrastructure & Quality: Build and maintain reliable, scalable data pipelines and ensure data accuracy and governance across systems.
 * Analytics & Insights: Partner with functional leaders to design metrics, dashboards, and reporting that enable data-driven decision-making.
 * Cross-Functional Collaboration: Work with Product, Growth, and Operations to integrate data insights into business and product strategies.
 * Technology & Tools: Evaluate and implement tools for analytics, BI, and data warehousing (e.g., dbt, Redshift, Quicksights, BigQuery, Looker, etc.).
 * Security & Compliance: Partner with the Engineering and Compliance to ensure data security, privacy, and compliance standards are upheld.
   
   

What You Bring And Who You Are


 * 7–10+ years of experience in data-related roles, with at least 2+ years leading teams.
 * Strong technical foundation in SQL, data modeling, and modern data stacks (e.g. dbt, Redshift, Quicksights, BigQuery, Looker, etc.).
 * Proven ability to build or scale data systems and translate data into business insights.
 * Analytical and structured thinker with a deep understanding of metrics and experimentation.
 * Excellent communicator who can partner with technical and non-technical teams alike.
 * Collaborative mindset, you value infrastructure and engineering excellence as much as analytical insight.
 * A natural problem solver who enjoys working in “white space” and has built data pipelines from scratch in the past
 * A proactive, resourceful leader who thrives in ambiguity and builds structure where it doesn’t yet exist.
 * Experience in healthcare or financial services data environments is a plus, but not required.
   
   

What We Offer

Gyde offers a competitive benefits package to all employees.


 * Compensation: $150k - $200k + Offers Equity
 * Flexible (Unlimited) Paid Time Off
 * Hybrid Work in Austin or NYC
 * Medical, Dental, and Vision benefits for you and your family
 * Retirement Plan (e.g., 401K)
 * Parental Leave","100 applicants","Full-time","Mid-Senior level","Project Management and Information Technology","Construction, Software Development, and IT Services and IT Consulting","$150,000.00/yr - $200,000.00/yr","","","109051250","https://grnh.se/rfca110v9us","EXTERNAL",""
"Engineering Innovation Program Leader","Medina, MN","13 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/engineering-innovation-program-leader-at-polaris-inc-4340306938?trk=public_jobs_topcard-title","Polaris Inc.","https://www.linkedin.com/company/polarisinc?trk=public_jobs_topcard-org-name","At Polaris Inc., we have fun doing what we love by driving change and innovation. We empower employees to take on challenging assignments and roles with an elevated level of responsibility in our agile working environment. Our people make us who we are, and we create incredible products and experiences that empower us to THINK OUTSIDE.

Position Summary

This Engineering Innovation Leader supports the innovation pipeline – from problem discovery and ideation through evaluation, proof-of-concept, and hand-off into development. It combines strategic portfolio management with hands-on leadership of the innovation process, design-thinking workshops, rapid prototyping, and cross-functional collaboration to accelerate concept maturation and de-risk early-stage initiatives. The position requires strong analytical and storytelling skills to translate insights into ideas, influence evidence-based decisions, and align innovation efforts with overarching business strategy. Success is measured by portfolio throughput, strategic impact, and fostering a culture of innovation across the enterprise.

Responsibilities


 * Own the innovation pipeline and governance: Govern the gate system with clear entry/exit criteria, disciplined review cadence, and crisp go/kill decisions; drive progression from ideation through proof-of-concept to development hand-off.
 * Drive rigorous evaluation and portfolio decisions: Apply standardized scoring against the Innovation Review rubric (IP, income, peak sales, market readiness, risk, strategic alignment, investment) and deliver investable recommendations to leadership forums.
 * Accelerate concept creation and maturation: Lead design-thinking workshops and white-paper sprints, orchestrate rapid prototyping across engineering functions; drive to shorten cycles and de-risk early.
 * Ensure smooth integration to development: Define “definition-of-ready” for Pre-Development and PDP insertion, align requirements with Engineering for clean hand-offs.
 * Build and sustain an innovation culture: Run charrettes/challenges; codify fast-fail learning; align efforts with strategic themes to maximize business impact.
 * Partner externally and internally: Lead make/buy/partner analyses; engage suppliers and universities for feasibility accelerators and benchmarking; maintain strong ties across product and engineering teams
 * Measure what matters: Establish and track portfolio health and impact metrics (idea throughput, ARL cycle time, kill rate, number of charters, innovation vs. pre-dev investment mix, program stability/speed), and publish transparent, actionable readouts.
 * Support end-to-end innovation pipeline: Drive problem discovery, ideation, evaluation, proof-of-concept, and seamless hand-off into development to ensure disciplined progression from concept to execution.
 * Champion adherence to the innovation process: Model best practices and actively coach teams to follow established frameworks, reinforcing consistency and rigor across initiatives.
 * Mentor and develop innovation capabilities: Build organizational competency through coaching, training, and hands-on engagement, fostering a sustainable innovation ecosystem across Polaris Inc.
 * Apply critical thinking and analytics: Leverage structured analysis and data-driven insights to evaluate opportunities, mitigate risk, and optimize portfolio outcomes.
 * Facilitate cross-functional collaboration: Orchestrate technology roadmapping, ideation sessions, and portfolio reviews to align innovation efforts with enterprise priorities and accelerate decision-making.
 * Align innovation with business strategy: Ensure initiatives support overarching objectives and strategic themes, maximizing impact on growth, profitability, and competitive advantage.
   
   

Qualifications


 * Bachelor’s degree in Engineering, STEM, Business, or Strategy; advanced degree a plus.
 * 7+ years in product development/engineering with demonstrated early-stage delivery (concept through proof-of-concept) and prior ownership of stage-gate or ARL processes.
 * Ability to translate customer insights and competitive/macro scans into high-potential problem statements and investable charters; excellence in technical storytelling/white papers.
 * Portfolio judgment using the standard Innovation Review rubric; comfortable facilitating teams to make evidence-based go/kill calls and presenting to leadership.
 * Track record building cross-functional coalitions and running charrettes/white-paper sprints that result in prototypes and charters.
 * Excellent communication and interpersonal skills
 * Experience with start-ups, partnerships, and/or university initiatives and co-development exposure.
 * Prior leadership in running company-wide innovation challenges or innovation ideation initiatives.
 * Execution of engineering design projects, specifically innovation or early product design
   
   

The starting pay range for Minnesota is $104,000 to $137,000 per year. Individual salaries and positioning within the range are determined through a wide variety of factors including but not limited to education, experience, knowledge, skills, and geography. While individual pay could fall anywhere in the range based on these factors, it is not common to start at the high end or top of the range.

To qualify for this position, former employees must be eligible for rehire, and current employees must be in good standing.

We are an ambitious, resourceful, and driven workforce, which empowers us to THINK OUTSIDE. Apply today!

At Polaris we put our employees first, by offering a holistic approach to their health and financial wellbeing. Polaris is proud to offer competitive compensation, including a market-leading profit-sharing plan that is fundamental to our pay-for-performance culture. At Polaris, employees are owners of the company through company contributions to our Employee Stock Ownership Plan and discounted employee stock purchases plan. Employees receive a generous matching contribution to 401(k), financial wellness education and consultation to plan for their financial future. In addition to competitive pay, Polaris provides a comprehensive suite of benefits, including health, dental, and vision insurance, wellness programs, paid time off, gym & personal training reimbursement, life insurance and disability offerings. Through the Polaris Foundation and our Polaris Gives paid volunteer time off, we support employees who actively volunteer their time, efforts, and passions to improve the health and wellbeing of the communities in which they live, play and work. Employees at Polaris drive our success and are rewarded for their commitment.

About Polaris

As the global leader in powersports, Polaris Inc. (NYSE: PII) pioneers product breakthroughs and enriching experiences and services that have invited people to discover the joy of being outdoors since our founding in 1954. Polaris' high-quality product line-up includes the Polaris RANGER®, RZR® and Polaris GENERAL™ side-by-side off-road vehicles; Sportsman® all-terrain off-road vehicles; military and commercial off-road vehicles; snowmobiles; Indian Motorcycle® mid-size and heavyweight motorcycles; Slingshot® moto-roadsters; Aixam quadricycles; Goupil electric vehicles; and pontoon and deck boats, including industry-leading Bennington pontoons. Polaris enhances the riding experience with a robust portfolio of parts, garments, and accessories. Proudly headquartered in Minnesota, Polaris serves more than 100 countries across the globe. www.polaris.com

EEO Statement

Polaris Inc. is an Equal Opportunity Employer and will make all employment-related decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, age, disability, marital status, familial status, status with regard to public assistance, membership or activity in a local commission, protected veteran status, or any other status protected by applicable law. Applicants with a disability that are in need of an accommodation to complete the application process, or otherwise need assistance or an accommodation in the recruiting process, should contact Human Resources at 800-765-2747 or Talent.Acquisition@Polaris.com. To read more about employment discrimination protection under U.S. federal law, see: Know Your Rights: Workplace Discrimination is Illegal (eeoc.gov).

EEO/AA/M/F/Vets/Disabled

","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Motor Vehicle Manufacturing, Manufacturing, and Armed Forces","$104,000.00/yr - $137,000.00/yr","","","8885","https://www.linkedin.com/jobs/view/engineering-innovation-program-leader-at-polaris-inc-4340306938?trk=public_jobs_topcard-title","EASY_APPLY",""
"Associate Product Manager, Business Systems & Analytics - People Systems","San Mateo, CA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/associate-product-manager-business-systems-analytics-people-systems-at-verkada-4333963431?trk=public_jobs_topcard-title","Verkada","https://www.linkedin.com/company/verkada?trk=public_jobs_topcard-org-name","Who We Are

Verkada is transforming how organizations protect their people and places with an integrated, AI-powered platform. A leader in cloud physical security, Verkada helps organizations strengthen safety and efficiency through one connected software platform that includes solutions for video security, access control, air quality sensors, alarms, intercoms, and visitor management.

Over 30,000 organizations worldwide, including more than 100 companies in the Fortune 500, trust Verkada as their physical security layer for easier management, intelligent control, and scalable deployments. Founded in 2016, Verkada has expanded rapidly with 15 offices and 2,200+ full-time employees.

What You'll Do


 * Partner with leaders across: FLOPS (Finance, Legal, Operations, People and Supply Chain) and other key functions to address key business challenges – with a primary focus on People systems and technologies, data pipelines and infrastructure, and large-scale Security and IT initiatives
 * Implement best-practice solutions, including process changes, configurations, and/or custom enhancements, to drive scalability and operational efficiency .
 * Work with FLOPS engineers and stakeholders to design, build and implement engineering solutions as it pertains to FLOPS deliverables
 * Facilitate and lead cross-functional requirement sessions to elicit, document, and analyze business requirements to identify functional scope. Able to identify unspoken/ conflicting requirements and drive meaningful change even going against the grain (as needed).
 * Prepare and review documentation for current processes, pain points, and assumptions for business systems and continuously identify opportunities that will streamline workflows and processes across all of our business systems and tools.
 * Draw from your experience to recommend changes in development, maintenance, and system standards that improves the team and our users’ experience while delivering long term scalability.
 * Build lightweight technical solutions leveraging your skills with Python/JavaScript
   
   

What You Bring


 * Bachelor's degree in MIS, CS, Finance or other technical/ analytical fields.
 * Minimum 2 years of relevant business experience
 * Basic SQL, Python, JavaScript and HTML required
 * Basic understanding of UI/UX tools and Flowchart tools (ie. Figma/Lucidchart)
 * Experience with designing and supporting integrations between business systems like Workday, Netsuite, Salesforce, 3PL’s, expense systems, etc
 * Understand key processes across the entire employee lifecycle
 * Work ethic: You do what it takes to make a project go well. You are equally comfortable taking personal ownership for a task as delegating it.
 * Ideal candidate is able to handle ambiguity and work effectively in a fast paced and fluid environment.
 * Must be willing and able to commute 5 days in office (San Mateo, CA)
   
   

Employee Benefits

Verkada is committed to fostering a workplace environment that prioritizes the holistic health and wellbeing of our employees and their families by offering comprehensive wellness perks, benefits, and resources. Our benefits and perks programs include, but are not limited to:


 * Healthcare programs that can be tailored to meet the personal health and financial well-being needs - Premiums are 100% covered for the employee under at least one plan and 80% for family premiums under all plans
 * Nationwide medical, vision and dental coverage
 * Health Saving Account (HSA) with annual employer contributions and Flexible Spending Account (FSA) with tax saving options
 * Expanded mental health support
 * Paid parental leave policy & fertility benefits
 * Time off to relax and recharge through our paid holidays, firmwide extended holidays, flexible PTO and personal sick time
 * Professional development stipend
 * Fertility Stipend
 * Wellness/fitness benefits
 * Healthy lunches provided daily
 * Commuter benefits
   
   

Additional Information


 * You must be independently authorized to work in the U.S. We are unable to sponsor or take over sponsorship of an employment visa for this role, at this time.
   
   

Annual Pay Range

At Verkada, we want to attract and retain the best employees, and compensate them in a way that appropriately and fairly values their individual contribution to the company. With that in mind, we carefully consider a number of factors to determine the appropriate starting pay for an employee, including their primary work location and an assessment of a candidate's skills and experience, as well as market demands and internal parity. A Verkada employee may be eligible for additional forms of compensation, depending on their role, including sales incentives, discretionary bonuses, and/or equity in the company in the form of restricted stock units (RSUs)

Below is the annual on-target earnings (OTE) range for full-time employees for this position, comprised of base compensation and commissions (if applicable).

Estimated Annual Pay Range

$140,000—$165,000 USD

Verkada Is An Equal Opportunity Employer

As an equal opportunity employer, Verkada is committed to providing employment opportunities to all individuals. All applicants for positions at Verkada will be treated without regard to race, color, ethnicity, religion, sex, gender, gender identity and expression, sexual orientation, national origin, disability, age, marital status, veteran status, pregnancy, or any other basis prohibited by applicable law.

Your application will be handled in accordance with our Candidate Privacy Policy.","95 applicants","Full-time","Mid-Senior level","Product Management and Marketing","Software Development","$140,000.00/yr - $165,000.00/yr","","","12699415","https://www.linkedin.com/jobs/view/associate-product-manager-business-systems-analytics-people-systems-at-verkada-4333963431?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI Software Engineer","Washington, DC","4 days ago","2025-11-28","https://www.linkedin.com/jobs/view/ai-software-engineer-at-gallatin-ai-inc-4339249879?trk=public_jobs_topcard-title","Gallatin AI, Inc.","https://www.linkedin.com/company/gallatinai?trk=public_jobs_topcard-org-name","About Gallatin

At Gallatin, we are rebuilding defense logistics for the warfighters of the United States and allied forces. We take an AI-first approach to improve defense readiness through software products that streamline and modernize logistics operations from factory to foxhole and result in better decisions and outcomes.

We believe that you won’t change the world by phoning it in and as such we work from our office in El Segundo, California.

About The Role

We’re looking for an AI/ML Software Engineer to play a foundational role in developing and deploying AI-powered solutions for our core product. You’ll work across the full AI/ML lifecycle—from defining and building models to evaluating and deploying large scale ML pipelines and real-time inference systems—while collaborating with cross-functional teams to deliver impactful, real-world AI applications.

What You'll Do


 * Build and Deploy AI/ML Models
    * Own and develop an AI model aligned with our core product needs within the first three months.
    * Validate AI-driven product features through real-world testing and feedback from warfighters.
    * Establish scalable MLOps pipelines and real-time inference services to streamline model training, deployment, runtime, and monitoring.
    * Own high model reliability and uptime by implementing monitoring across your work.

 * Data Collection & Processing
    * Identify and integrate structured, unstructured, real-time, and batch data sources.
    * Work with internal logs, APIs, user interactions, and third-party datasets to improve model training quality.

 * Continuous Improvement & Best Practices
    * Stay ahead of AI trends and emerging technologies to improve model performance.
    * Document and share best practices for AI/ML development.
    * Contribute to the hiring and mentoring of AI/ML talent as we grow our team.
    * Teach the wider team about the latest trends and significance in novel approaches in AI.
      

What We’re Looking For


 * Strong Programming Skills
    * Expertise in at least one: Python, C++, or C.

 * ML Framework Proficiency
    * Hands-on experience with AI/ML training and fine-tuning frameworks, including:
       * PyTorch, TensorFlow, CUDA, Jupyter Notebooks
       * Large Language Models (LLMs) and Open-Source Models (Llama, Anthropic, Mistral)
       * LangChain, Retrieval-Augmented Generation (RAG), Hugging Face, Exo Labs

 * MLOps & Data Engineering Knowledge
    * Experience with data processing and pipeline frameworks such as Apache Kafka, Apache Airflow, AWS Kinesis, pandas, and dbt.
    * Understanding of AI model performance monitoring, data drift detection, and observability tools like Grafana or Kibana.

 * AI Fundamentals & Security Awareness
    * Deep understanding of deep neural networks (DNNs), LLMs, over/underfitting, prompt engineering, and LLM security (jailbreaking risks and protections).

 * Growth Mindset
    * Passion for continuous learning and staying current with the latest advancements in AI/ML, as well as teaching others
      

Bonus Points


 * Experience mentoring and upskilling junior engineers.
 * Familiarity with legacy systems and working with public sector customers.
 * Contributions to open-source (AI/ML) projects.
   
   

Why Gallatin?


 * Join a mission-driven, high-impact, and fast-moving startup where your work directly improves defense logistics readiness for the warfighters of the United States and allied forces.
 * Work alongside a team of passionate engineers, designers, and industry experts.
 * Competitive compensation incl. generous options grant, 100% employer-paid health insurance premiums, 401k, opportunities for rapid career growth, unlimited PTO, free lunches and snacks in the office.
   
   

This position requires the ability to obtain and maintain relevant security clearances. The successful candidate must be able to work in a classified environment when necessary.

If you’re not excited about working hard, and solving the hard problems of building AI decisions-support systems that enhance our warfighters, don’t apply.

The following ranges are based on the cost of labor across US geographic areas. The base ranges from our lowest geographic market to our highest geographic market.

Software Engineer I $80,000-$120,000

Software Engineer II $84,000-$175,000

SR Software Engineer $134,000-$210,000

","61 applicants","Full-time","Entry level","Engineering and Information Technology","Information Services","","","","106410794","https://www.linkedin.com/jobs/view/ai-software-engineer-at-gallatin-ai-inc-4339249879?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Data Architect","Austin, TX","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/senior-data-architect-at-2k-4337222680?trk=public_jobs_topcard-title","2K","https://www.linkedin.com/company/2k-games?trk=public_jobs_topcard-org-name","Who We Are

THIS IS AN ONSITE POSITION in Austin, TX

2K is headquartered in Novato, California and is a wholly owned label of Take-Two Interactive Software, Inc. (NASDAQ: TTWO). Founded in 2005, 2K Games is a global video game company, publishing titles developed by some of the most influential game development studios in the world. Our studios responsible for developing 2K's portfolio of world-class games across multiple platforms, include Visual Concepts, Firaxis, Hangar 13, CatDaddy, Cloud Chamber, 31st Union, HB Studios, and 2K SportsLab. Our portfolio of titles is expanding due to our global strategic plan, building and acquiring exciting studios whose content continues to inspire all of us! 2K publishes titles in today's most popular gaming genres, including sports, shooters, action, role-playing, strategy, casual, and family entertainment.

Our team of engineers, marketers, artists, writers, data scientists, producers, thinkers and doers, are the professional publishing stewards of 2K's portfolio currently includes several AAA, sports and entertainment brands, including global powerhouse NBA®️ 2K, renowned BioShock®️, Borderlands®️, Mafia, Sid Meier's Civilization®️ and XCOM®️ brands; popular WWE®️ 2K and WWE®️ SuperCard franchises, TopSpin 2K25, as well as the critically and commercially acclaimed PGA TOUR®️ 2K.

At 2K, we pride ourselves on creating an inclusive work environment, which means encouraging our teams to Come as You Are and do your best work! We encourage ALL applicants to explore our global positions, even if they don't meet every requirement for the role. If you're interested in the job and think you have what it takes to work at 2K, we encourage you to apply!

What you need


 * 7+ years working with data governance platforms (Collibra, Informatica Axon, DataHub) and enterprise governance operating models.
 * 5+ years designing data architectures and data models for analytics/ML.
 * Proven experience delivering data quality, lineage, and metadata management at scale.
 * Bachelor's or Master's in Engineering, Computer Science, Mathematics, or related field.
 * Deep expertise in data modeling (Kimball, Inmon, Data Vault).
 * Strong Python skills, including structured project design and APIs/services with Flask.
 * Expert SQL across Snowflake and Databricks.
 * Hands-on experience with big data and orchestration tools (Hive, Spark, Airflow).
 * Streaming technologies experience (Kafka or Kinesis).
 * Practical Databricks capabilities (Unity Catalog, Delta Lake, MLflow) and solid MLOps practices (CI/CD, model registry, monitoring).
 * Cloud experience across AWS/Azure/GCP, with strong AWS exposure preferred.
 * Robust automated testing for data pipelines (unit/integration).
 * Strong knowledge of privacy, regulatory, and audit frameworks (GDPR, CCPA, COPPA, SOX).
 * Experience in regulated/high-compliance industries (Gaming, Finance, Healthcare).
 * Excellent stakeholder management, problem-solving, and cross-functional communication with the ability to influence without authority.
   
   

What you will do

Technology, Architecture & Platforms


 * Evolve our lakehouse/analytics reference architecture across AWS, Snowflake, and Databricks (Delta Lake, Unity Catalog) for scale, cost, and reliability.
 * Standardize Databricks workspaces—cluster policies, repos/CI/CD, secrets, cost guardrails, and operational SLAs.
 * Implement MLOps with MLflow, a feature store, versioned data/code, automated CI/CD, and model promotion/rollback across environments.
 * Enforce security-by-default—IAM/SSO, RBAC, encryption, tokenization, and PII protection across platforms.
 * Build reliable ingestion, transformation, and services (Python/Flask, Spark, Airflow/Databricks Jobs) with tests, observability, and SLAs.
 * Integrate data/ML platforms with game analytics, CDP, personalization, and real-time streams via Kafka/Kinesis; coach teams on best practices.
   
   

Data Trust & Governance


 * Establish enterprise policies, standards, ownership/stewardship, and decision forums; drive adoption through enablement and training.
 * Define classification, retention, and lifecycle; enforce RBAC and encryption for sensitive player data.
 * Operate metadata and catalog (DataHub/Atlan/Informatica) to deliver end‑to‑end lineage, impact analysis, and discoverability. Align key metrics, definitions, and a central glossary across studios; publish and maintain canonical KPIs.
 * Implement data quality rules with profiling, monitoring, and remediation workflows governed by SLAs.
 * Ensure GDPR/CCPA/COPPA/SOX compliance; operationalize DSAR/Right‑to‑be‑Forgotten and partner with Legal/Security on audits and risk.
   
   

Data Modeling


 * Lead conceptual, logical, and physical models for player, gameplay, commerce, and marketing; select Kimball/Inmon/Hybrid as appropriate.
 * Deliver performant star schemas, conformed dimensions, SCDs, and data contracts in Snowflake/Databricks; govern naming, versioning, and lineage.
   
   

As an equal opportunity employer, we are committed to ensuring that qualified individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform their essential job functions, and to receive other benefits and privileges of employment. Please contact us if you need reasonable accommodation.

Please note that 2K Games and its studios never uses instant messaging apps or personal email accounts to contact prospective employees or conduct interviews and when emailing, only use 2K.com accounts.

","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Computer Games","","","","12908","https://www.linkedin.com/jobs/view/senior-data-architect-at-2k-4337222680?trk=public_jobs_topcard-title","EASY_APPLY",""
"Automation Tester","Columbia, MD","3 weeks ago","2025-11-04","https://www.linkedin.com/jobs/view/automation-tester-at-sparksoft-corporation-4334341322?trk=public_jobs_topcard-title","Sparksoft Corporation","https://www.linkedin.com/company/sparksoft-corporation?trk=public_jobs_topcard-org-name","Join us at Sparksoft, where we're not just another tech company—we're a catalyst for change. Our mission isn't just to offer IT solutions; it's to revolutionize the way you work. Here, passion isn't just a buzzword; it's the fuel behind groundbreaking ideas and transformative technologies. We serve a wide range of government clients, delivering impact that's felt across the nation.

Our true strength lies in our people. They're the problem-solvers and innovators consistently delivering extraordinary outcomes. With Sparksoft, you're not stepping into a routine job; you're joining a team committed to innovation and excellence. Our innovation extends beyond just delivering projects. Through our specialized Innovation Centers, we continuously refine our methods, ensuring we remain industry leaders.

We are Sparksoft!

ROLE & RESPONSIBILITIES:


 * The Automation Test Engineer will be responsible for designing, developing, and maintaining automated test suites using tools such as BRUNO, Selenium, and Postman. The role involves working closely with Agile development teams to ensure high-quality software delivery through continuous integration and continuous delivery (CI/CD) practices. Key responsibilities include:
 * Developing and maintaining test automation scripts in Scala, JavaScript, SQL, and basic Python.
 * Creating Gatling performance test simulations integrated with CI/CD pipelines.
 * Translating manual test cases into automated scripts and assessing test coverage.
 * Performing regular maintenance and upgrades of test frameworks to ensure optimal performance.
 * Collaborating with cross-functional teams in Agile environments to troubleshoot and resolve issues.
 * Integrating AI frameworks (e.g., Gen AI, codeAssist) into testing workflows (preferred).
 * Handling XML data conversion for mapping and validation purposes
   
   

REQUIRED EXPERIENCE:


 * Minimum 3 years of hands-on experience in test automation.
 * Advanced proficiency in:
    * Selenium
    * API Testing
    * Postman
    * Test Execution and Management
    * Agile Methodology

 * Experience with Gatling performance testing and CI/CD integration.
 * Strong problem-solving skills and ability to work independently and collaboratively.
 * Eligibility to obtain Federal Public Trust clearance.
 * Candidates must have lived in the United States 3 out of the past 5 years.
   

PREFERED EXPERIENCE:


 * Familiarity with AI framework integration (e.g., Gen AI, code Assist).
 * Good working knowledge of Bruno and Scala
 * Experience with XML data conversion and mapping.
 * Background in software development (not mandatory but beneficial).
   
   

EDUCATION & CERTIFICATIONS:


 * Bachelor's degree in Computer Science, Information Technology, Engineering, or a related field (or equivalent practical experience).
 * Relevant certifications in test automation, Agile methodologies, or API testing are a plus.
   
   

WHAT WE OFFER:

At Sparksoft, we know that people do their best work when they feel supported, inspired, and connected. That's why we've built a workplace that balances comprehensive benefits with a culture of collaboration and innovation. From flexible time off to professional growth opportunities, we're committed to helping you thrive both inside and outside of work. When you join Sparksoft, you'll enjoy:


 * Competitive compensation and a 401(k) with employer contributions to help you plan for the future
 * Flexible paid time off and hybrid ways of working that support true work-life balance
 * Comprehensive health coverage—including medical, dental, vision, life, and disability insurance
 * A curated in-office experience designed to foster community, team connections, and innovation
 * Opportunities to give back through Sparksoft Cares, including annual company-wide fundraising events
 * Training and development programs that build new skills and prepare you for leadership roles
 * A collaborative, transparent, and fun culture—recognized as a Great Place to Work®
   
   

Accessibility and Accommodations: Sparksoft Corporation is committed to providing equal employment opportunities to all individuals. If you require accommodations during the application or interview process, please contact us at Sparksoft.Accommodations@sparksoftcorp.com or call 410-424-7700. Requests are reviewed and fulfilled on a case-by-case basis.

Security Notice: Your privacy and data security are important to us. Sparksoft Corporation will never request sensitive personal information via email. If you receive any suspicious communication claiming to be from Sparksoft, please report it immediately to our security team at abuse@sparksoftcorp.com.

Artificial Intelligence (AI) Policy: While Sparksoft recognizes the value of artificial intelligence in the workplace, our hiring process is designed to assess each candidate's individual skills, judgment, and problem-solving abilities. To maintain the integrity of this process, the use of AI tools at any stage of the application or interview is strictly prohibited. Violations of this policy may result in disqualification from consideration.","46 applicants","Full-time","Mid-Senior level","Quality Assurance","IT Services and IT Consulting","","","","1528487","https://www.linkedin.com/jobs/view/automation-tester-at-sparksoft-corporation-4334341322?trk=public_jobs_topcard-title","EASY_APPLY",""
"Machine Learning Engineer","San Francisco Bay Area","2 weeks ago","2025-11-13","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-evolve-group-4340215018?trk=public_jobs_topcard-title","Evolve Group","https://uk.linkedin.com/company/evolvegrp?trk=public_jobs_topcard-org-name","Machine Learning Engineer – Early Hire at AI Startup




We’re partnered with a high-growth startup that’s building next-generation machine learning systems to power real-world decision-making at scale. The team is hiring one of its first Machine Learning Engineers to help design, train, and deploy production models that sit at the core of the company’s technology stack.




This is a rare opportunity to join an elite founding team early—working directly with experienced engineers and researchers to shape both the technical direction and product architecture from the ground up.




Key Responsibilities:

 * Design, build, and maintain machine learning models that power core product features.
 * Develop scalable data pipelines, training workflows, and deployment infrastructure.
 * Collaborate closely with product and engineering teams to bring ML systems into production.
 * Continuously monitor, evaluate, and improve model performance and reliability.
 * Explore and implement novel model architectures to solve complex technical challenges.




Requirements:

 * Bachelor’s or Master’s in Computer Science, Engineering, Math, or a related field from a top-tier university (GPA 3.7+ preferred).
 * 2–5 years of experience in machine learning or software engineering roles.
 * Proficiency in Python and modern ML frameworks (PyTorch, TensorFlow, or JAX).
 * Strong understanding of algorithms, data structures, and systems design.
 * Experience deploying and maintaining production ML systems.
 * Comfortable in a fast-paced, high-autonomy startup environment.




What You’ll Get:

 * Early ownership and impact in a technically ambitious company.
 * Opportunity to build and scale ML infrastructure from day one.
 * Direct collaboration with a world-class founding team.
 * Access to significant data resources and modern tooling.
 * Competitive compensation with meaningful equity upside.
 * A culture that prioritizes technical rigor, creativity, and rapid iteration.

","Over 200 applicants","Full-time","Mid-Senior level","Engineering and Research","IT Services and IT Consulting","","Jake Bushell","https://uk.linkedin.com/in/jake-bushell-811607225","5085557","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-evolve-group-4340215018?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Pension plan
Paid maternity leave
Paid paternity leave
Commuter benefits"
"Senior Analyst, Data and Insights, Marketing Analytics","New York, NY","2 weeks ago","2025-11-12","https://www.linkedin.com/jobs/view/senior-analyst-data-and-insights-marketing-analytics-at-the-new-york-times-company-4335632439?trk=public_jobs_topcard-title","The New York Times Company","https://www.linkedin.com/company/the-new-york-times-company?trk=public_jobs_topcard-org-name","Apply for position

Office: New York, NY

Department: Data Analytics

Job Description

p]:text-b2 [&_ul]:my-3 [&_ol]:my-3 [&_ul]:list-none [&_ol]:pl-7 [&_ol]:pb-6 [&_li]:my-0 [&_li]:pb-1.5 [&_li:last-of-type]:pb-0 [&_li]:relative [&_li]:pl-6 [&_li]:before:absolute [&_li]:before:content-['—'] [&_li]:before:left-0 [&_li]:before:top-0"">

The mission of The New York Times is to seek the truth and help people understand the world. That means independent journalism is at the heart of all we do as a company. It’s why we have a world-renowned newsroom that sends journalists to report on the ground from nearly 160 countries. It’s why we focus deeply on how our readers will experience our journalism, from print to audio to a world-class digital and app destination. And it’s why our business strategy centers on making journalism so good that it’s worth paying for.

About The Role

The Times is looking for a senior data analyst who is passionate about data and eager for the opportunity to support our journalistic mission. As part of the Data and Insights Group (DIG), you will join a large community of data analysts who partner with Product, Engineering, Marketing, and PMO teams across the business.

You will support the Owned Media team which is responsible for our owned marketing channels including email, display, audio, and print. You will report to the Senior Manager of Owned Media Analytics. This is a hybrid role, working in our New York, NY office.

Responsibilities


 * Lead the measurement framework and testing agenda for Marketing in Audio, Display, and SMS channels.
 * Collaborate with the advertising team to ensure parity on reporting of revenue numbers from Owned efforts in display and audio channels.
 * Advise the Owned Media team on areas of opportunity, specifically as pertains to shifting metrics, and improving performance.
 * Build new metrics to report on product engagement attributed to media efforts.
 * Conduct analysis to determine which surfaces, messages, and creatives are most impactful.
 * Build visualizations to communicate complex media topics and results.
 * Be responsible for monitoring and accuracy of data and reporting.
 * Demonstrate support and understanding of our value of journalistic independence and a strong commitment to our mission to seek the truth and help people understand the world.
   
   

Basic Qualifications


 * Degree in an analytical field such as economics, stats/mathematics, or computer science or 3+ years experience in an analytical role.
 * Advanced proficiency in SQL and familiarity with big data warehouses such as Google BigQuery.
 * 3+ years of experience communicating cross-functionally, presenting insights to team members and company partners.
 * 1+ years of experience with data visualization tools such as Mode, Tableau, or Lookr
 * 1+ years of experience with A/B testing.
   
   

Preferred Qualifications


 * Experience with synthetic control or geo experiments
 * Experience Advertising or Marketing data
 * R or Python Proficiency
   
   

REQ-019104

The annual base pay range for this role is between:

$101,000—$110,000 USD

The New York Times Company is committed to being the world’s best source of independent, reliable and quality journalism. To do so, we embrace a diverse workforce that has a broad range of backgrounds and experiences across our ranks, at all levels of the organization. We encourage people from all backgrounds to apply.

We are an Equal Opportunity Employer and do not discriminate on the basis of an individual's sex, age, race, color, creed, national origin, alienage, religion, marital status, pregnancy, sexual orientation or affectional preference, gender identity and expression, disability, genetic trait or predisposition, carrier status, citizenship, veteran or military status and other personal characteristics protected by law. All applications will receive consideration for employment without regard to legally protected characteristics. The U.S. Equal Employment Opportunity Commission (EEOC)’s Know Your Rights Poster is available here.

The New York Times Company will provide reasonable accommodations as required by applicable federal, state, and/or local laws. Individuals seeking an accommodation for the application or interview process should email reasonable.accommodations@nytimes.com. Emails sent for unrelated issues, such as following up on an application, will not receive a response.

The Company encourages those with criminal histories to apply, and will consider their applications in a manner consistent with applicable ""Fair Chance"" laws, including but not limited to the NYC Fair Chance Act, the Los Angeles Fair Chance Initiative for Hiring Ordinance, the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act.

For information about The New York Times' privacy practices for job applicants click here.

Please beware of fraudulent job postings. Scammers may post fraudulent job opportunities, and they may even make fraudulent employment offers. This is done by bad actors to collect personal information and money from victims. All legitimate job opportunities from The New York Times will be accessible through The New York Times careers site. The New York Times will not ask job applicants for financial information or for payment, and will not refer you to a third party to do so. You should never send money to anyone who suggests they can provide employment with The New York Times.

If you see a fake or fraudulent job posting, or if you suspect you have received a fraudulent offer, you can report it to The New York Times at NYTapplicants@nytimes.com. You can also file a report with the Federal Trade Commission or your state attorney general.

Apply for position","158 applicants","Full-time","Mid-Senior level","Information Technology","Newspaper Publishing","$101,000.00/yr - $110,000.00/yr","","","1666898","https://www.linkedin.com/jobs/view/senior-analyst-data-and-insights-marketing-analytics-at-the-new-york-times-company-4335632439?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer - Credit","New York, United States","5 days ago","2025-11-27","https://www.linkedin.com/jobs/view/data-engineer-credit-at-optiver-4347765902?trk=public_jobs_topcard-title","Optiver","https://nl.linkedin.com/company/optiver?trk=public_jobs_topcard-org-name","Optiver is a leading global market maker, powered by technology, rigorous research, and deep collaboration. As markets grow more data-driven and competitive, our ability to ingest, model, and deliver high-quality data at scale is fundamental to maintaining our trading edge.

We’re looking for a Data Engineer to join our Global Data Engineering team in New York City, with a dedicated focus on supporting our Credit Trading team and advancing our ETF and portfolio-based systematic strategies. You’ll play a key role in building the data solutions that fuel both real-time trading and long-term research, working across the full data lifecycle, from discovery to derivation and validation, for datasets used in research and production systems.

What You’ll Do

As Data Engineer, your key responsibilities include:



 * Create novel analytics and frameworks to research and analyze trade-offs between different sources of returns, flow, and risk
 * Quantify market drivers with our Quantitative Researchers and Global Market Data team to support risk taking and decision making
 * Model and normalize complex financial datasets to ensure they are clean, structured, and accessible for both research and production trading systems
 * Own the reliability of these datasets and the associated data APIs
 * Collaborate directly with alpha researchers, pricing researchers, and fellow engineers to understand evolving data needs and deliver reliable, scalable solutions
 * Ensure data quality and consistency through validation, monitoring, and robust engineering practices
   
   
   

What You’ll Get



 * The opportunity to work alongside best-in-class professionals from over 40 different countries
 * Highly competitive compensation package
 * Global profit-sharing pool and performance-based bonus structure
 * 401(k) match up to 50%
 * Comprehensive health, mental, dental, vision, disability, and life coverage
 * 25 paid vacation days alongside market holidays
 * Extensive office perks, including breakfast, lunch and snacks, regular social events, clubs, sporting leagues and more
   
   
   

Who You Are



 * 3+ years of experience as a Data Engineer, Data Scientist, or similar role in a high-performance environment, preferably in financial services
 * Strong proficiency in Python, with experience using libraries such as Pandas, Arrow, and Spark
 * Solid understanding of data modeling, normalization, and API development in support of large-scale analytical or trading systems
 * Experience working with lakehouse architectures (e.g., Delta Lake, Databricks, AWS) to manage large-scale, high-quality analytical datasets
 * Familiarity with a variety of data sources, including CDS, corporate/capital structure, and bond NAVs relevant to Fixed Income trading
 * Strong software engineering fundamentals—especially around performance, scalability, and reliability in distributed systems
 * Experience with statistical models and core methods of quantitative finance
 * Exceptional attention to detail, organization, and project management skills
 * Ability to operate productively in a fast-paced, team-oriented environment.
 * Legal authorization to work in the U.S. is required; we will not sponsor individuals for employment authorization for this job opening.
   
   
   

Who We Are

At Optiver, our mission is to improve the market by injecting liquidity, providing accurate pricing, increasing transparency and stabilising the market no matter the conditions. With a focus on continuous improvement, we prioritise safeguarding the health and efficiency of the markets for all participants. As one of the largest market making institutions, we are a respected partner on 100+ exchanges across the globe.

Our differences are our edge. Optiver does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, physical or mental disability, or other legally protected characteristics.

Below is the expected base salary for this position. This is a good-faith estimate of the base pay scale for this position and offers will ultimately be determined based on experience, education, skill set, and performance in the interview process. This position will also be eligible for a discretionary bonus (if determined by Optiver) and Optiver’s benefits package with the benefits listed above.

Base Salary Range

$150,000—$225,000 USD","Over 200 applicants","Full-time","Entry level","Information Technology","Financial Services","$150,000.00/yr - $225,000.00/yr","","","13216","https://optiver.com/working-at-optiver/career-opportunities/8308342002/?gh_src=9fb491cd2","EXTERNAL",""
"Manager 3, Data Engineering, MarTech","Mountain View, CA","2 weeks ago","2025-11-14","https://www.linkedin.com/jobs/view/manager-3-data-engineering-martech-at-intuit-4336017414?trk=public_jobs_topcard-title","Intuit","https://www.linkedin.com/company/intuit?trk=public_jobs_topcard-org-name","Overview

Come join Intuit's GTM Tech Platform team as Manager 3, Software engineering. In this role, you will lead a highly dynamic marketing platform that enables our marketers to deliver customer and revenue growth for our product portfolio spanning QuickBooks, TurboTax, Mailchimp, and Credit Karma. Your responsibilities include driving the development of core platforms for customer data lifecycle management, omnichannel campaign management across paid and owned channels, audience management coupled with customer journey orchestration, and campaign performance analytics. You will spearhead strategies to boost data quality and construct a robust platform to further the AI revolution in martech. This role requires a visionary who aligns engineering innovation with business objectives and who will inspire a culture of excellence to solidify and expand Intuit’s competencies in marketing technology to fuel our product and revenue growth.

Responsibilities


 * Technology leaders at Intuit think strategically and drive for results. They build high performing teams by putting the right people in the right job at the right time. Leaders help to innovate by thinking differently. They lead their teams to embrace new ideas that produce outstanding results for our customers. Leaders at Intuit inspire others thru action by creating a spirit of collaboration.
 * In this role you will help to bring out the best ideas from the best engineers by empowering them and leading by example.
 * Your team will create and bring customer driven software products to market that simplify and solve for current customer needs while building for the future.
 * To accomplish this you will create a shared vision and build and maintain strong cross-functional relationships / alignment with partners across the business (e.g. Program Mgmt, Product Management, Product Design, Data and AI).
   
   

Qualifications


 * 5 plus years experience as an established technical leader of software engineering teams that have successfully delivered customer-driven software products. Experience with AI or AI native experiences is a big plus.
 * Demonstrated experience leading positive change, empowering people, cultivating product technology visions and innovative solutions, and fostering effective engineering teams.
 * Adept at articulating the product vision and drive the future roadmap with strong business acumen
 * Ability to think and act strategically for all stakeholders
 * Passion for being at the leading edge of technology with a minimum of 12+ years of software development experience, specifially leading large scale data engineering pipelines
 * Experience with Agile development and methodologies and SaaS and/or mobile technologies.
 * Possesses strong verbal and written communication skills.
 * BS in Computer Science or equivalent work-related experience
   
   

Intuit provides a competitive compensation package with a strong pay for performance rewards approach. This position will be eligible for a cash bonus, equity rewards and benefits, in accordance with our applicable plans and programs (see more about our compensation and benefits at Intuit®: Careers | Benefits). Pay offered is based on factors such as job-related knowledge, skills, experience, and work location. To drive ongoing fair pay for employees, Intuit conducts regular comparisons across categories of ethnicity and gender. The expected base pay range for this position is:","51 applicants","Full-time","Mid-Senior level","Information Technology","Software Development","","","","1666","https://www.linkedin.com/jobs/view/manager-3-data-engineering-martech-at-intuit-4336017414?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Houston, TX","5 days ago","2025-11-27","https://www.linkedin.com/jobs/view/data-engineer-at-nitya-software-solutions-inc-4339225695?trk=public_jobs_topcard-title","NITYA Software Solutions Inc","https://www.linkedin.com/company/nitya-software-solutions-inc?trk=public_jobs_topcard-org-name","Who We Are Looking For


 * Design, build, and maintain scalable data pipelines to support business analytics and data science activities.
 * Utilize proper judgment in identifying data-related issues and escalate to specialized teams when necessary.
 * Work with cross-functional stakeholders to gather requirements and translate business needs into technical data solutions.
 * Manage data ingestion from multiple sources including APIs, databases, and cloud platforms.
 * Ensure data integrity, quality, and governance while following organizational policies and compliance standards.
 * Perform data modeling, ETL/ELT pipeline development, and data warehouse optimization.
 * Monitor and troubleshoot performance issues with data systems and implement necessary improvements.
 * Support storage and processing of large-scale datasets using cloud services and distributed systems.
 * Maintain documentation for data workflows and provide guidance to data consumers across the organization.
 * Stay updated with emerging data engineering technologies and contribute to continuous improvements.
   
   

Skills


 * Data Engineering
 * ETL/ELT Development
 * SQL & NoSQL Databases
 * Data Modeling
 * Python / Scala
 * Data Pipeline Automation
 * Cloud Data Platforms (AWS / Azure / GCP)
 * Big Data Tools (Spark, Hadoop, Kafka)
 * API Integration
 * Linux / Shell Scripting
 * CI/CD, Git, Docker
 * Monitoring & Troubleshooting
 * Snowflake / Redshift / BigQuery (Preferred)
 * Data Governance & Security
   
   

Top Skills Details

Data pipelines, SQL, Python, ETL, Data warehouse, AWS/Azure/GCP, Spark, Kafka, Database administration, Performance optimization.

Additional Skills & Qualifications


 * Strong analytical thinking and problem-solving skills.
 * Willingness to learn new technologies rapidly.
 * Ability to handle multiple tasks in a fast-paced environment.
 * Excellent documentation and collaboration skills.
   
   

Experience Level: Intermediate Level","162 applicants","Full-time","Entry level","Information Technology","Information Services","$60,000.00/yr - $75,000.00/yr","","","7883050","https://nityasoftwarepvtltd.betterteam.com/data-engineering/apply?utm_source=linkedin&utm_medium=web_xmlfeed&utm_campaign=linkedin_organic","EXTERNAL",""
"Data Engineer","Aberdeen Proving Ground, MD","3 weeks ago","2025-11-07","https://www.linkedin.com/jobs/view/data-engineer-at-link-solutions-inc-4334633335?trk=public_jobs_topcard-title","Link Solutions, Inc.","https://www.linkedin.com/company/link-solutions-inc.?trk=public_jobs_topcard-org-name","Company Description

Link Solutions, Inc. delivers reliable and effective Information Technology services to government clients in support of critical mission needs. Delivering a broad range of Infrastructure Operations, Application Development, Cybersecurity, Virtualization, Cloud and Mobility services.

If you’re looking for a technology company that values innovation, with a vision toward the future of the technology landscape, look no further than Link Solutions! Link is quality and compliance-focused, under our guiding philosophy, “Mission First, Customer Always"".

We are ISO 9001:2015, ISO 20000-1:2018, ISO 27001:2022 certified and appraised for CMMI ML3 for Services and Development.

Job Description

Link Solutions is seeking a Data Engineer to join our team in Aberdeen Proving Ground, MD.


 * Must be a U.S. Citizen
 * DoD Secret Clearance required
 * Non-remote (relocation incentive available)
   
   

The Data Engineer will provide mission-critical support for personnel located at the U.S. Army Combat Capabilities Development Command Chemical Biological Center (DEVCOM). The Engineer will support DEVCOM’s mission by creating data pipelines and distributed systems that integrate data solutions with cloud platforms, ensuring data is secure, accessible, and optimized for analysis.

Join a team of dedicated professionals at an industry-leading organization, where you will work on innovative projects that contribute to national security. This position offers significant opportunities for career advancement and professional growth while supporting critical missions and operations.

Job Responsibilities:


 * Ensure security and compliance with DoD cybersecurity guidelines within data pipelines.
 * Develop and maintain data infrastructure that is scalable and reliable.
 * Monitor and enhance performance of databases and data processing tasks.
 * Ensure processes are implemented and followed for data cleansing, validation, and standardization to ensure accuracy, consistency, and compliance with DoD policies.
 * Implement continuous data quality processes for accuracy and consistency.
 * Collaborate with cross-functional teams to align data solutions with mission needs.
 * Work with stakeholders to understand their data needs and support objectives to enhance efficiency.
   
   

Please note that this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job.

Qualifications


 * Must be a U.S. Citizen.
 * Must be able to obtain and maintain an active DoD Secret Clearance.
 * Must have a BA/BS degree in Computer Science, Information Systems, or a related field.
 * Five (5+) years of specialized experience in data engineering.
 * Understanding of Agile and Lean development methodologies.
   
   

Preferred:


 * DoD Secret Clearance.
 * Experience with AWS, Azure, or GCP infrastructure.
 * Proficiency with Microsoft Office products.
 * Experience creating and modifying documentation for technical processes and procedures.
 * Experience working in a Department of Defense (DoD) environment.
 * A problem solver and troubleshooter who thrives in resolving complex problems.
 * Strong self-starter requiring minimal supervision.
 * Excellent communication skills (written and oral) and interpersonal skills.
 * Excellent organizational skills, attention to detail, and ability to prioritize and manage multiple tasks.
   
   

Salary Range: $100,000 - $140,000

Several factors influence the final salary or hourly rate, including but not limited to contract wage determinations, relevant work experience, role-specific skills and competencies, geographic location, educational background, certifications, and federal government contract labor categories.

Additional Information

Link Solutions Inc. offers a competitive compensation and benefits package to include paid holidays, paid time off, medical, dental, vision, company-paid long and short-term disability, life insurance, referral bonuses, relocation incentive program, certification reimbursement program, retirement, and more.

Link Solutions, Inc. is an EOE. AA/M/F/D/V. We participate in the E-Verify Employment Verification Program. All your information will be kept confidential according to EEO guidelines.","98 applicants","Full-time","Mid-Senior level","Information Technology","IT Services and IT Consulting","$100,000.00/yr - $140,000.00/yr","","","215521","https://jobs.smartrecruiters.com/LinkSolutionsInc/744000092095312-data-engineer","EXTERNAL",""
"Senior Data Engineer, Integrations","Houston, TX","4 days ago","2025-11-28","https://www.linkedin.com/jobs/view/senior-data-engineer-integrations-at-mariana-minerals-4339229731?trk=public_jobs_topcard-title","Mariana Minerals","https://www.linkedin.com/company/mariana-minerals?trk=public_jobs_topcard-org-name","About Mariana Minerals

Mariana Minerals is a software-first, vertically integrated minerals company on a mission to supply the critical minerals powering modern energy, AI, and defense technologies.

We’re reimagining how minerals are sourced, refined, and optimized by combining deep industrial expertise with software, automation, and data-driven decision-making. Join us as we build the future of responsible mineral sourcing and supply.

The Opportunity

We’re looking for a Senior Data & Integrations Engineer to own the data platform that connects our industrial systems to ML models—building the semantic layer between process engineering and AI-driven operations.

This role goes beyond traditional ETL. You’ll design and build robust Python-based data pipelines and semantic models that translate real-world industrial processes into structured, meaningful data for our machine learning and software teams. Your work will directly enable reinforcement learning algorithms that control physical equipment—where data engineering meets real-world impact.

What You’ll Do

Core Responsibilities (≈70%)


 * Design, build, and maintain data pipelines in Python that integrate with our digital twin simulator, ML infrastructure, and operational systems.
 * Develop semantic data models and analytics layers that bridge process engineering, ML model requirements, and business metrics.
 * Architect data systems that support both real-time operations and historical analysis, prioritizing semantic accuracy and data quality over massive scale.
 * Evolve our data platform as we scale from our first facility to multiple operations—defining the foundations of a modern, industrial data stack.
 * Partner with ML engineers and process experts to ensure data is clean, consistent, and fit for model training and inference.
   
   

Integrations & Cross-Functional Work (≈30%)


 * Build and maintain API integrations with enterprise and industrial systems (PLCs, LIMS, historians, engineering tools).
 * Support real-time data exchange between control systems, dashboards, and analytics platforms.
 * Collaborate across software, process, and ML teams to translate complex operational data into actionable insights.
   
   

Required

What You’ll Bring


 * 5+ years of Python development experience, focused on data engineering and modeling.
 * Proven experience creating semantic layers and analytics models bridging technical and business contexts.
 * Strong software engineering fundamentals—version control, testing, documentation, and maintainable code.
 * Hands-on experience with modern data tools (Airflow/Dagster, dbt, data quality frameworks).
 * Clear communication and collaboration skills; ability to work with ML, software, and operations teams.
 * A structured yet creative problem-solving mindset and comfort with ambiguity.
   
   

Nice to Have


 * API integration experience (REST, OAuth, rate limiting, retries).
 * Familiarity with time-series or industrial data (PLCs, LIMS, SCADA).
 * Exposure to ML pipelines and real-time data processing.
 * Experience designing data systems in manufacturing, energy, or process industries.
   
   

Why This Role Matters

This isn’t a big-data problem—it’s a smart-data challenge. You’ll create the connective tissue between industrial operations and AI systems, turning complex process signals into meaningful data that drives real outcomes.

Your work will directly shape how AI optimizes mineral processing and define the foundation of Mariana’s data strategy as we grow.

Why Join Mariana Minerals


 * Build systems that bridge the physical and digital worlds.
 * Work alongside engineers, data scientists, and industrial experts solving hard problems that matter.
 * Join a culture that values Extreme Ownership, Engineering Out Requirements, then Automating, and Sharing Your Legos.
   
   

Be part of building the future of intelligent mineral processing.

Compensation Range: $150K - $210K

","97 applicants","Full-time","Mid-Senior level","Information Technology","Metal Ore Mining","$150,000.00/yr - $210,000.00/yr","","","105053468","https://www.linkedin.com/jobs/view/senior-data-engineer-integrations-at-mariana-minerals-4339229731?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Atlanta, GA","1 week ago","2025-11-25","https://www.linkedin.com/jobs/view/data-engineer-at-ust-4347535863?trk=public_jobs_topcard-title","UST","https://www.linkedin.com/company/ustglobal?trk=public_jobs_topcard-org-name","Role Description

Data Engineer

Lead II - Data Engineering

Who We Are

Born digital, UST transforms lives through the power of technology. We walk alongside our clients and partners, embedding innovation and agility into everything they do. We help them create transformative experiences and human-centered solutions for a better world.

UST is a mission-driven group of 29,000+ practical problem solvers and creative thinkers in more than 30 countries. Our entrepreneurial teams are empowered to innovate, act nimbly, and create a lasting and sustainable impact for our clients, their customers, and the communities in which we live.

With us, you’ll create a boundless impact that transforms your career—and the lives of people across the world.

Visit us at UST.com.

You Are

We are looking for an experienced Data Engineer with strong expertise in AWS cloud services and modern data engineering frameworks. The role involves designing, developing, and optimizing large-scale data pipelines, securing data flows, and enabling analytics across diverse business use cases.

The Opportunity


 * Hybrid: In office/remote
 * Architect, build, and maintain scalable and reliable data pipelines using AWS and distributed processing frameworks.
 * Develop ETL/ELT processes using Python, PySpark, and AWS services such as Glue and Lambda. Implement workflow orchestration using Airflow and AWS-native automation tools.
 * Optimize data storage, querying, and processing using Athena and other AWS analytics services.
 * Create and manage infrastructure-as-code components with Terraform (basic proficiency expected).
 * Work closely with data architects, analysts, and application teams to deliver robust data solutions.
 * Ensure best practices for data quality, security, governance, and monitoring across the data ecosystem.
   
   

This position description identifies the responsibilities and tasks typically associated with the performance of the position. Other relevant essential functions may be required.

What You Need


 * Must-Have skills:
 * AWS Lambda
 * AWS Glue
 * PySpark
 * Python
 * Airflow
 * Athena
 * Terraform (Basic)
 * Good-to-Have skills:
 * AWS Step Functions
 * DynamoDB
 * Nice-to-Have skills:
 * ECS
 * EKS
 * OpenSearch
 * Kinesis
 * SNS / SQS
 * Lake Formation
 * Preferred Experience: Building and optimizing data lakes and real-time/streaming data solutions. Working in cloud-native architecture with strong emphasis on automation.
 * Experience with distributed systems and performance tuning.
   
   

Compensation can differ depending on factors including but not limited to the specific office location, role, skill set, education, and level of experience. UST provides a reasonable range of compensation for roles that may be hired in various U.S. markets as set forth below.

Role Location: Georgia

Compensation Range: $76,500-$112,500

Benefits

Full-time, regular employees accrue a minimum of 10 days of paid vacation per year, receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year), 10 paid holidays, and are eligible for paid bereavement leave and jury duty. They are eligible to participate in the Company’s 401(k) Retirement Plan with employer matching. They and their dependents residing in the US are eligible for medical, dental, and vision insurance, as well as the following Company-paid Employee Only benefits: basic life insurance, accidental death and disability insurance, and short- and long-term disability benefits. Regular employees may purchase additional voluntary short-term disability benefits, and participate in a Health Savings Account (HSA) as well as a Flexible Spending Account (FSA) for healthcare, dependent child care, and/or commuting expenses as allowable under IRS guidelines. Benefits offerings vary in Puerto Rico.

Part-time employees receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year) and are eligible to participate in the Company’s 401(k) Retirement Plan with employer matching.

Full-time temporary employees receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year) and are eligible to participate in the Company’s 401(k) program with employer matching. They and their dependents residing in the US are eligible for medical, dental, and vision insurance.

Part-time temporary employees receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year).

All US employees who work in a state or locality with more generous paid sick leave benefits than specified here will receive the benefit of those sick leave laws.

What We Believe

We proudly embrace the values that have shaped UST since day one. We build our culture of Humility, Humanity, and Integrity. These values inspire us to nurture a people-first, human centric culture that fosters diversity, prioritizes sustainable solutions, and keeps our people and clients at the forefront of all decisions.

Humility

We will listen, learn, be empathetic and help selflessly in our interactions with everyone.

Humanity

Through business, we will better the lives of those less fortunate than ourselves.

Integrity

We honor our commitments and act with responsibility in all our relationships.

Equal Employment Opportunity Statement

UST is an Equal Opportunity Employer.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other applicable characteristics protected by law. We will consider qualified applicants with arrest or conviction records in accordance with state and local laws and “fair chance” ordinances.

UST reserves the right to periodically redefine your roles and responsibilities based on the requirements of the organization and/or your performance.

#UST

#CB

Skills

Aws Cloud,Aws Lambda,Python

","Over 200 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","$76,500.00/yr - $112,500.00/yr","","","12770","https://www.linkedin.com/jobs/view/data-engineer-at-ust-4347535863?trk=public_jobs_topcard-title","EASY_APPLY",""
"Manager, Business Intelligence Engineering","New York, NY","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/manager-business-intelligence-engineering-at-snap-inc-4337623119?trk=public_jobs_topcard-title","Snap Inc.","https://www.linkedin.com/company/snap-inc-co?trk=public_jobs_topcard-org-name","Snap Inc is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are Snapchat, a visual messaging app that enhances your relationships with friends, family, and the world; Lens Studio, an augmented reality platform that powers AR across Snapchat and other services; and its AR glasses, Spectacles.

The Data Science & Insights team seeks to leverage our massive data sets into actionable insights that deliver business value. As truth seekers and truth tellers, we relay what the data says without bias, even when inconvenient or difficult. We aim to improve decision-making quality and speed across the organization to enable a deeper understanding of our customers and products. We focus on efficient and effective analytic execution, positioning ourselves as the go-to experts with deep knowledge and expertise, constantly striving for better, faster insights from data.

We’re looking for a Manager, Business Intelligence Engineering to join Snap Inc!

What you’ll do:


 * Lead a team to establish foundational data and analytics capabilities for our ads platform and identify key insights around our ads platform.
 * Collaborate with Data Science, Product, and Engineering, and Business partners to design and build data tools/visualizations, operationalize metrics, conduct investigations, deliver actionable insights, and conduct in-depth product analysis.
 * Understand the challenges within our ads platform and help make decisions based on data driven insights by analyzing information from multiple sources in a logical and coherent data story
 * Build and maintain dashboards that communicate the performance of the various components of our ads platform with compelling data visualizations and consistency
 * Develop data pipelines that power our analytics data layer for analysis, reporting and dashboarding ensuring efficiency and reliability
 * Own the data model used to power our underlying data layer for monetization including the associated pipelines, data structures, and schemas
 * Maintain the key metric definitions and understand them at a deep level, offering recommendations for improvements and new metrics
 * Conduct exploratory and deep dive analysis to understand drivers of revenue performance and overall platform performance, developing actionable insights to Product and Engineering leadership
 * Own root-cause investigations starting from proactive identification of metric regressions to resolution including recommendations for long term product improvements
 * Proactively identify improvements to our platform or business that can be expected to drive increased revenue
   
   

Knowledge, Skills & Abilities:


 * Data driven and analytical mindset
 * Hands-on expertise with data warehousing tools and workflow automation
 * Comfortable with quantitative concepts
 * Strong attention to detail and organizational skills
 * Excellent verbal and written communication skills
 * Ability to work in an agile, dynamic environment
 * Ability to use tech to improve work-flows and create efficiencies
   
   

Minimum Qualifications:


 * BS/BA degree in Analytics, Statistics, Economics or other technical field or equivalent years of experience
 * 10+ years of post-Bachelor’s analytics experience; or a Master’s degree in a technical field + 9+ year of post-grad analytics experience; or a PhD in a related technical field + 6+ years of post-grad analytics experience
 * 1+ years relevant people management experience
   
   

Preferred Qualifications:


 * Advanced Degree in Analytics, Statistics, Economics, Computer Science or other technical field
 * Experience as a data scientist and/or managing a data team
 * Experience in the digital media space
 * A passion for Snapchat as a user and knowledge of our ad products
 * Proficiency in Looker, BigQuery, and Airflow
   
   

If you have a disability or special need that requires accommodation, please don’t be shy and provide us some information.

""Default Together"" Policy at Snap: At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office 4+ days per week.

At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets.

We are an Equal Opportunity Employer and will consider qualified applicants with criminal histories in a manner consistent with applicable law (by example, the requirements of the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, where applicable).

Our Benefits: Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid parental leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success!

Compensation

In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. The starting pay may be negotiable within the salary range for the position. These pay zones may be modified in the future.

Zone A (CA, WA, NYC):

The base salary range for this position is $209,000-$313,000 annually.

Zone B:

The base salary range for this position is $199,000-$297,000 annually.

Zone C:

The base salary range for this position is $178,000-$266,000 annually.

This position is eligible for equity in the form of RSUs.","121 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Software Development","$178,000.00/yr - $313,000.00/yr","","","15191764","https://wd1.myworkdaysite.com/en-US/recruiting/snapchat/snap/job/Los-Angeles-California/Manager\u002d\u002dBusiness-Intelligence-Engineering_R0043164-1?source=LinkedIn","EXTERNAL",""
"Chief Data and Analytics Office Strategy, Vice President","New York, NY","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/chief-data-and-analytics-office-strategy-vice-president-at-jpmorganchase-4267265921?trk=public_jobs_topcard-title","JPMorganChase","https://www.linkedin.com/company/jpmorganchase?trk=public_jobs_topcard-org-name","Job Description

We are looking for a talented Vice President to join The Chief Data and Analytics Office (CDAO) team at JPMorgan Chase. This team is dedicated to positioning the firm as the leading data and AI-enabled financial services firm globally. Its mission is to set the firm’s data and AI strategic direction, deliver firmwide data and AI solutions and expertise, and establish standards for responsible and controlled adoption.

The CDAO strategy team supports that mission by driving strategy development (e.g., on topics like AI-enabled value creation and AI agents), monitoring industry trends (e.g., through engagement with AI transformation leaders, academic institutions and tech innovators), and increasing internal awareness (e.g., best practice sharing on AI transformation).

As a Vice President in the CDAO Strategy team, you will manage strategy initiatives to address complex problems at the forefront of the industry. Strategy initiatives are typically team-based and include close collaboration with senior leaders and stakeholders across different functions.

Job Responsibilities


 * Manage high-priority strategy projects to address complex problems at the forefront of data and AI in financial services, with a focus on enabling business outcomes.
 * Develop and deliver executive-level strategy documents and analyses that articulate the value, impact, and direction of AI and data priorities.
 * Monitor and analyze industry trends, applying leading practices to evaluate and refine the firmwide AI and data strategy, ensuring alignment with firmwide goals.
 * Lead strategy project teams and collaborate with stakeholders across different functions to gather insights, conduct analyses and drive alignment.
 * Provide coaching to strategy team members, and emulate a culture of excellence and innovation.
   
   

Required Qualifications, Capabilities, and Skills


 * Minimum of 5 years of strategy experience from a premier management consulting firms and/or another internal strategy group.
 * Outstanding ability to analyze problems and apply quantitative, analytical and conceptual problem solving approaches.
 * Excellent communication (oral and written) and ability to develop high quality strategy end-products.
 * Strong relationship-building and interpersonal skills, with the ability to collaborate with stakeholders across functions.
 * Proven ability in leading strategy engagements, as well as coaching and developing strategy team members
 * Familiarity with AI and data, ability to engage stakeholders on complex technical concepts and generate insights for executive audiences.
   
   

Preferred Qualifications, Capabilities, and Skills:


 * Undergraduate or graduate degree in economics, finance, math, engineering, computing, or a related field, with a strong analytical background.
 * Experience in financial services across consumer and business banking, wealth and asset management and/or corporate and investment banking
   
   

ABOUT US

JPMorganChase, one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We offer a competitive total rewards package including base salary determined based on the role, experience, skill set and location. Those in eligible roles may receive commission-based pay and/or discretionary incentive compensation, paid in the form of cash and/or forfeitable equity, awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. We also make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as mental health or physical disability needs. Visit our FAQs for more information about requesting an accommodation.

JPMorgan Chase & Co. is an Equal Opportunity Employer, including Disability/Veterans

About The Team

Our professionals in our Corporate Functions cover a diverse range of areas from finance and risk to human resources and marketing. Our corporate teams are an essential part of our company, ensuring that we’re setting our businesses, clients, customers and employees up for success.","Over 200 applicants","Full-time","Mid-Senior level","Business Development and Sales","Financial Services","$175,750.00/yr - $235,000.00/yr","","","1068","https://JPMorganChase.contacthr.com/148276883","EXTERNAL",""
"Senior Data Engineer","Minneapolis, MN","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/senior-data-engineer-at-nycor-4338943452?trk=public_jobs_topcard-title","NYCOR","https://www.linkedin.com/company/nycor?trk=public_jobs_topcard-org-name","Senior Data Engineer

No Sponsorship is available. Must be a U.S. Citizen




Senior Data Engineer – Where Creativity Meets Precision

Do you see data engineering as more than just building pipelines? Do you believe that the best systems don’t just move data — they make it understandable, insightful, and actionable? We’re looking for a Senior Data Engineer who combines technical expertise with creative thinking and a collaborative spirit.



In this role, you’ll design and optimize data solutions that prioritize clarity and usability. You’ll work closely with business teams, pivot quickly when priorities shift, and ensure every solution reflects a deep understanding of the underlying processes. If you thrive on fundamentals, embrace flexibility, and bring a positive, high-integrity approach to your work, we should talk.

Responsibilities

 * Architect and maintain scalable data pipelines and models using DBT and Snowflake
 * Collaborate with business stakeholders to understand processes before building solutions
 * Ensure systems support analysis and transparency, not just functionality
 * Apply strong fundamentals in data modeling, governance, and documentation
 * Integrate data from ERP systems and manufacturing processes
 * Build dashboards and visualizations using Power BI, Tableau, or Qlik
 * Champion best practices while staying adaptable and open to new approaches

What We’re Looking For

 * 7+ years of experience in data engineering or related roles
 * Bachelor's Degree in Information Systems, Computer Science or equivalent.
 * Hands-on expertise with DBT and Snowflake
 * Proficiency in at least one programming language (Python preferred)
 * Experience with ERP systems and manufacturing environments
 * Strong knowledge of BI tools (Power BI, Tableau, or Qlik)
 * Collaborative mindset — thrives in team settings and adapts quickly
 * Positive demeanor, high integrity, and strong communication skills
 * Ability to pivot on a dime and work closely with business partners
 * Hybrid role: at least 2 days per week in the office




No Sponsorship is available. Must be a U.S. Citizen","122 applicants","Full-time","Mid-Senior level","Information Technology","Manufacturing","$118,000.00/yr - $135,000.00/yr","Mary Esposito","https://www.linkedin.com/in/maryesposito08","35624918","https://www.linkedin.com/jobs/view/senior-data-engineer-at-nycor-4338943452?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Paid paternity leave
Paid maternity leave
Disability insurance"
"Research Engineer - Applied AI","San Francisco Bay Area","2 weeks ago","2025-11-15","https://www.linkedin.com/jobs/view/research-engineer-applied-ai-at-agilesoft-4336155367?trk=public_jobs_topcard-title","Agilesoft","https://it.linkedin.com/company/agilesoft-it?trk=public_jobs_topcard-org-name","Granica is an AI research and systems company building the infrastructure for a new kind of intelligence: one that is structured, efficient, and deeply integrated with data.

Our systems operate at exabyte scale, processing petabytes of data each day for some of the world’s most prominent enterprises in finance, technology, and industry. These systems are already making a measurable difference in how global organizations use data to deploy AI safely and efficiently.

We believe that the next generation of enterprise AI will not come from larger models but from more efficient data systems. By advancing the frontier of how data is represented, stored, and transformed, we aim to make large-scale intelligence creation sustainable and adaptive.

Our long-term vision is Efficient Intelligence: AI that learns using fewer resources, generalizes from less data, and reasons through structure rather than scale. To reach that, we are first building the Foundational Data Systems that make structured AI possible.

The Role

The Applied AI Research Team sits at the center of this mission. Your work will take the ideas emerging from fundamental research and turn them into practical algorithms, optimized pipelines, and production-ready systems that operate across petabytes of structured enterprise data.

This is a high-ownership role for engineers who can think like researchers and build like systems experts. You will translate theory into measurable performance improvements and help define the foundations of structured AI.

What You’ll Do

Turn research into real systems


 * Transform foundational ideas from Granica Research and Prof. Andrea Montanari’s group into scalable algorithms and experimental prototypes.
 * Build the evaluation harnesses, metrics, and datasets that reveal real signal from research concepts.
 * Define and refine the metrics that determine progress in structured AI.
   
   

Invent and optimize algorithms for structured AI


 * Develop efficient learning methods for relational, tabular, graph, and enterprise data.
 * Prototype representation learning architectures and compression-aware models for large-scale structured information.
   
   

Build high-performance learning pipelines


 * Implement fast training and inference loops using PyTorch, JAX, or custom kernels.
 * Optimize memory, compute, and data-movement paths with a focus on cost, latency, and throughput.
   
   

Integrate symbolic, relational, and neural components


 * Design hybrid learning systems that reason over structured data natively, not through text intermediaries.
   
   

Collaborate deeply across teams


 * Work with Research Scientists to validate hypotheses at scale.
 * Work with Systems Engineers to integrate your algorithms into Granica’s core data platform.
 * Work with Product Engineering to ship features that power live enterprise workloads.
   
   

Iterate fast and measure everything


 * Run controlled experiments, analyze performance deltas, and deliver results with clear benchmarks.
 * Drive the loop from prototype to production, improving the system each cycle.
   
   

What You’ll Bring

Technical Depth


 * Strong background in machine learning, probabilistic modeling, optimization, or distributed learning.
 * Experience building and tuning algorithms for structured, tabular, graph, or relational data.
 * Ability to reason from first principles about efficiency, scaling behavior, and information flow.
   
   

Systems Ability


 * Hands-on experience with PyTorch, JAX, TensorFlow, or custom ML kernels.
 * Strong Python skills and familiarity with systems languages such as Rust, C++, or CUDA.
 * Experience with large-scale data pipelines, model evaluation frameworks, or distributed systems.
   
   

Applied Mindset


 * Demonstrated ability to turn theoretical concepts into performant, reliable code.
 * Comfort working in ambiguous research environments while delivering measurable outcomes.
 * Curiosity for how structure and efficiency reshape the next generation of AI.
   
   

Bonus Experience


 * Structured representation learning, tabular or multimodal models, or relational ML.
 * Distributed data systems, query engines, or vector/embedding infrastructure.
 * Open-source contributions or collaborative research bridging theory and production.
   
   

Why This Role Matters

The world’s most valuable data is structured. The current form of AI is not.

Your work will help close that gap. You will design the primitives that enable efficient learning at global scale and help build the foundations of structured AI. This role has real ownership, immediate impact, and a long horizon.

Why Granica


 * Fundamental Research Meets Enterprise Impact. Work at the intersection of science and engineering, turning foundational research into deployed systems serving enterprise workloads at exabyte scale.
 * AI by Design. Build the infrastructure that defines how efficiently the world can create and apply intelligence.
 * Real Ownership. Design primitives that will underpin the next decade of AI infrastructure.
 * High-Trust Environment. Deep technical work, minimal bureaucracy, shared mission.
 * Enduring Horizon. Backed by NEA, Bain Capital, and various luminaries from tech and business. We are building a generational company for decades, not quarters or a product cycle.
   
   

Compensation & Benefits


 * Competitive salary, meaningful equity, and substantial bonus for top performers
 * Flexible time off plus comprehensive health coverage for you and your family
 * Support for research, publication, and deep technical exploration
   
   

Join us to build the foundational data systems that power the future of enterprise AI.

At Granica, you will shape the fundamental infrastructure that makes intelligence itself efficient, structured, and enduring.

Compensation Range: $160K - $250K

","51 applicants","Full-time","Entry level","Engineering and Information Technology","IT Services and IT Consulting","$160,000.00/yr - $250,000.00/yr","","","9505527","https://www.linkedin.com/jobs/view/research-engineer-applied-ai-at-agilesoft-4336155367?trk=public_jobs_topcard-title","EASY_APPLY",""
"Artificial Intelligence/ Machine Learning Developer","Ashburn, VA","1 week ago","2025-11-23","https://www.linkedin.com/jobs/view/artificial-intelligence-machine-learning-developer-at-unissant-4338576167?trk=public_jobs_topcard-title","Unissant","https://www.linkedin.com/company/unissant?trk=public_jobs_topcard-org-name","Unissant, Inc. delivers innovative capabilities to the agencies that keep our nation healthy and safe. We apply our domain expertise, data acumen, and technology know-how to achieve breakthrough results for our clients. Working collaboratively, we advance missions and careers through a focus on honesty, integrity, and dependability. We continuously look for talent excited to join that effort. To learn more about our exciting organization, please visit us at www.unissant.com.

We are seeking an Artificial Intelligence/Machine Learning Developer to join our team and support our federal customer.

Qualified applicants may be subject to a security investigation and must meet minimum qualifications for access to classified information. This is a highly technical position; individuals will be screened by peers in a technical review of skills and experience.

Essential Duties And Responsibilities

Drive a big data approach to execute government requirements to manage and enrich data to gather new insights. As the AI/ML developer, an ideal candidate will be part of a team to provide consultative, architectural, program, and engineering support for a federal customer.


 * This is a client-facing position working on-site as per the requirements established by the DHS customer.
 * Develop, train, and deploy advanced AI/ML and Gen-AI models.
 * Design and implement innovative AI solutions to address complex business challenges using techniques such as natural language processing and large language models.
 * Optimize model performance, ensuring accuracy, efficiency, and scalability.
 * Develop and maintain user-friendly AI applications and interfaces, including chatbots, virtual assistants, and generative content tools.
 * Collaborate with cross-functional teams to integrate AI solutions into existing systems and workflows.
 * Stay up to date with the latest advancements in AI/ML and emerging technologies, such as generative AI and reinforcement learning.
 * Conduct research and experiments to explore new AI techniques and applications, including prompt engineering, Advanced RAGs and fine-tuning LLMs.
 * Ensure compliance with data privacy and security regulations, especially when dealing with sensitive data and generative AI outputs.
 * This role will be responsible for briefing the benefits and constraints of technology solutions to technology partners, stakeholders, team members, and senior levels of management.
   
   

Work Experience And Job Skills


 * 3+ years of experience in the Information Technology field focusing on AI/ML engineering projects, MLOps and DevSecOps and technical architecture specifically.
 * Proficiency in developing, deploying, and fine-tuning generative AI models, including large language models (LLMs).
 * Strong proficiency in programming languages such as Python, R, Java and C/C++ (optional)
 * Experience with machine learning and generative AI frameworks.
 * Experience with natural language processing techniques (e.g., text classification, language generation).
 * Solid understanding of any of the cloud platforms (e.g., AWS, Azure, GCP) and deployment strategies.
 * Solid understanding of MLOps and DevSecOps practices for deploying AI-ML models and applications
 * Proficiency in any front-end development technologies (e.g., React, Angular, Vue.js, HTML, CSS, JavaScript).
 * Knowledge of database systems (e.g., SQL, NoSQL, Vector Database, Graph Database)and data warehousing concepts.
 * An understanding and competency surrounding data storage, accesses, and loading.
    * Databases: PostgreSQL, NoSQL, Vector Databases, Graph Databases etc.
    * ETL/ELT Concepts
    * Data warehouse concepts
    * SQL

 * Competency in data exploration, analytics, and feature engineering. (Python Specific)
    * Pandas / NumPy / Polars / PySpark
    * Plotly / Matplotlib (some form of data visualization)
    * Data encoding / normalizing / regularizing / etc.

 * Understanding of Deep learning concepts and architectures like CNNs, RNNs, LSTM, and GANs and ability to apply to real world data sets and problems.
 * Proficiency in ML Modeling - Scikit-Learn, Tensorflow, Keras, Pytorch.
 * Proficiency in NLP Tools SpaCy, ThinC, Gensim.
 * Knowledge of Gen-AI Tools Hugging Face models, OpenAI models, Grok.
 * General competency in various ML disciplines like Classification, Forecasting, Transformers, Generative, Anomaly Detection and Deep Learning.
 * Enthusiastic, proactive, positive attitude with great listening skills, high integrity, and the ability to work effectively in a team environment.
 * Adaptability to changing priorities and a willingness to learn and grow are essential.
 * Excellent organizational skills, and ability to effectively manage concurrent projects.
 * Comprehensive problem-solving skills with exceptional attention to detail.
 * Ability to learn, evolve, think creatively and proactively.
 * Able to work under pressure (at times) and to be extremely flexible with changing priorities
 * Ability to work independently and in a team setting, take ownership of and complete relatively complex tasks, effectively using available resources, as needed, with minimal guidance.
   

Education


 * Bachelor's Degree in Computer Science, Information Technology Management or Engineering is preferred. Alternative work-related experience, Military Duty, and/or specialized or higher education may be substituted.
   
   

Certificates, Licenses And Registrations


 * This federal program requires the candidates to be a United States Citizen.
 * Must have an active DHS clearance.
 * Any related systems engineering, or related technical certifications are desired.
 * AWS/Azure/GCP AI/ML certifications are preferred but not required.
   
   

Communication Skills


 * Must have excellent written and verbal communication skills
 * Ability to convey technical information to non-technical individuals.
 * Demonstrated experience communicating effectively across internal and external organizations.
 * Must work well in a matrixed team environment.
   
   

Travel


 * On-site in Ashburn, VA
   
   

Environmental Requirements


 * Mainly sedentary; in an office environment
 * May be required to lift up to ten (10) pounds
 * Flexible in working extended hours
   
   

The above statements are intended to describe the general nature and level of work being performed by the individual(s) assigned to this position. They are not intended to be an exhaustive list of all duties, responsibilities, and skills required. Unissant management reserves the right to modify, add, or remove duties and to assign other duties as necessary. In addition, where applicable and available, reasonable accommodation(s) may be made to enable individuals with disabilities to perform essential functions of this position.

Please note: Candidate(s) will be required to go through pre-employment screening.

Unissant, Inc. is a proud Equal Opportunity Employer! (EOE; M/F/Disability/Vets)

Job Posted by ApplicantPro","153 applicants","Full-time","Entry level","Engineering and Information Technology","Information Technology & Services","","","","1592400","https://www.linkedin.com/jobs/view/artificial-intelligence-machine-learning-developer-at-unissant-4338576167?trk=public_jobs_topcard-title","EASY_APPLY",""
"Manager, Business Intelligence Engineering","San Francisco, CA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/manager-business-intelligence-engineering-at-snap-inc-4338372628?trk=public_jobs_topcard-title","Snap Inc.","https://www.linkedin.com/company/snap-inc-co?trk=public_jobs_topcard-org-name","Snap Inc is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are Snapchat, a visual messaging app that enhances your relationships with friends, family, and the world; Lens Studio, an augmented reality platform that powers AR across Snapchat and other services; and its AR glasses, Spectacles.

The Data Science & Insights team seeks to leverage our massive data sets into actionable insights that deliver business value. As truth seekers and truth tellers, we relay what the data says without bias, even when inconvenient or difficult. We aim to improve decision-making quality and speed across the organization to enable a deeper understanding of our customers and products. We focus on efficient and effective analytic execution, positioning ourselves as the go-to experts with deep knowledge and expertise, constantly striving for better, faster insights from data.

We’re looking for a Manager, Business Intelligence Engineering to join Snap Inc!

What you’ll do:


 * Lead a team to establish foundational data and analytics capabilities for our ads platform and identify key insights around our ads platform.
 * Collaborate with Data Science, Product, and Engineering, and Business partners to design and build data tools/visualizations, operationalize metrics, conduct investigations, deliver actionable insights, and conduct in-depth product analysis.
 * Understand the challenges within our ads platform and help make decisions based on data driven insights by analyzing information from multiple sources in a logical and coherent data story
 * Build and maintain dashboards that communicate the performance of the various components of our ads platform with compelling data visualizations and consistency
 * Develop data pipelines that power our analytics data layer for analysis, reporting and dashboarding ensuring efficiency and reliability
 * Own the data model used to power our underlying data layer for monetization including the associated pipelines, data structures, and schemas
 * Maintain the key metric definitions and understand them at a deep level, offering recommendations for improvements and new metrics
 * Conduct exploratory and deep dive analysis to understand drivers of revenue performance and overall platform performance, developing actionable insights to Product and Engineering leadership
 * Own root-cause investigations starting from proactive identification of metric regressions to resolution including recommendations for long term product improvements
 * Proactively identify improvements to our platform or business that can be expected to drive increased revenue
   
   

Knowledge, Skills & Abilities:


 * Data driven and analytical mindset
 * Hands-on expertise with data warehousing tools and workflow automation
 * Comfortable with quantitative concepts
 * Strong attention to detail and organizational skills
 * Excellent verbal and written communication skills
 * Ability to work in an agile, dynamic environment
 * Ability to use tech to improve work-flows and create efficiencies
   
   

Minimum Qualifications:


 * BS/BA degree in Analytics, Statistics, Economics or other technical field or equivalent years of experience
 * 10+ years of post-Bachelor’s analytics experience; or a Master’s degree in a technical field + 9+ year of post-grad analytics experience; or a PhD in a related technical field + 6+ years of post-grad analytics experience
 * 1+ years relevant people management experience
   
   

Preferred Qualifications:


 * Advanced Degree in Analytics, Statistics, Economics, Computer Science or other technical field
 * Experience as a data scientist and/or managing a data team
 * Experience in the digital media space
 * A passion for Snapchat as a user and knowledge of our ad products
 * Proficiency in Looker, BigQuery, and Airflow
   
   

If you have a disability or special need that requires accommodation, please don’t be shy and provide us some information.

""Default Together"" Policy at Snap: At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office 4+ days per week.

At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets.

We are an Equal Opportunity Employer and will consider qualified applicants with criminal histories in a manner consistent with applicable law (by example, the requirements of the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, where applicable).

Our Benefits: Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid parental leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success!

Compensation

In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. The starting pay may be negotiable within the salary range for the position. These pay zones may be modified in the future.

Zone A (CA, WA, NYC):

The base salary range for this position is $209,000-$313,000 annually.

Zone B:

The base salary range for this position is $199,000-$297,000 annually.

Zone C:

The base salary range for this position is $178,000-$266,000 annually.

This position is eligible for equity in the form of RSUs.","84 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Software Development","$178,000.00/yr - $313,000.00/yr","","","15191764","https://wd1.myworkdaysite.com/en-US/recruiting/snapchat/snap/job/Los-Angeles-California/Manager\u002d\u002dBusiness-Intelligence-Engineering_R0043164-1?source=LinkedIn","EXTERNAL",""
"Data Engineer","Herndon, VA","1 month ago","2025-10-29","https://www.linkedin.com/jobs/view/data-engineer-at-bespoke-technologies-inc-4331360555?trk=public_jobs_topcard-title","Bespoke Technologies, Inc.","https://www.linkedin.com/company/bespoketechinc?trk=public_jobs_topcard-org-name","BT-153 – Data Engineer (Associate Manager)

Location: Chantilly/Herndon


 * MUST HAVE AN ACTIVE TS OR TS/SCI CLEARANCE TO APPLY. Those without an active security clearance will not be considered.**
   
   

Role Description

As a senior Data Engineer, you will be a key technical contributor on the team building and maintaining the critical data pipelines for a data platform. You will apply your deep expertise to design, develop, and optimize robust ETL/ELT processes that move and transform data. In this role, you will not only build solutions but also mentor junior engineers and help drive the adoption of modern data engineering practices and automation.

Responsibilities


 * Design, build, and maintain scalable and resilient data pipelines for both new data sources and existing systems within the data ecosystem.
 * Implement and optimize pipelines using modular patterns, such as Databricks Delta Live Tables, following governance from the architecture team.
 * Develop and integrate automated monitoring, alerting, and data quality checks into every pipeline to reduce downtime and ensure data integrity.
 * Utilize Infrastructure-as-Code (IaC) with tools like Terraform to create consistent, repeatable deployments and CI/CD processes.
 * Analyze complex source data formats and collaborate with data scientists and stakeholders to design transformations that meet objectives.
 * Participate in and lead code reviews, enforce best practices, and mentor junior data engineers.
 * Troubleshoot and resolve complex issues with data pipelines, and contribute to the ongoing improvement of O&M processes.
   
   

Required Qualifications


 * 6+ years of experience in data engineering.
 * Strong experience with the development and maintenance of extract, transform, and load (ETL) tools and services.
 * Proficiency in Python, SQL, Spark, and PySpark.
 * Hands-on experience with cloud environments (AWS, Azure) and data platforms like Databricks, Palantir, or Snowflake.
 * Experience working in an Agile/Scrum development environment.
 * Familiarity with data orchestration and data quality processes.
 * Active Top Secret/SCI security clearance.
   
   

Preferred Qualifications


 * Direct experience engineering data pipelines for the data platform.
 * Experience working in high-security environments (e.g., SIPR, JWICS).
 * Hands-on experience with Databricks Delta Live Tables and Terraform.
 * Experience with containerization technologies like Docker or Kubernetes.
 * Knowledge of COTS and open-source data engineering tools such as NiFi or ElasticSearch.","55 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","","","","71291624","https://www.linkedin.com/jobs/view/data-engineer-at-bespoke-technologies-inc-4331360555?trk=public_jobs_topcard-title","EASY_APPLY",""
"Business Analyst - Data Engineering","Fort Mitchell, KY","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/business-analyst-data-engineering-at-drees-homes-4337101869?trk=public_jobs_topcard-title","Drees Homes","https://www.linkedin.com/company/drees-homes?trk=public_jobs_topcard-org-name","Drees Homes is a family-owned home building company with a passion for making custom homes easy. For over 95 years, we have taken care of our employees and our customers. It's why we rank as the 19th largest privately-owned builder in the country and have a track record of long-tenured employees. We're proud of being named a 2023, 2024 and 2025 U.S. Best Managed Company, a program sponsored by Deloitte Private and The Wall Street Journal, and we've been officially certified as a Great Place to Work in both 2023, 2024 and 2025. Enrich your career at a company that values integrity, excellence, opportunity, stability and success.

Headquartered in Fort Mitchell, Kentucky, Drees has operations in twelve metropolitan areas: Greater Cincinnati and Cleveland, Ohio; Austin, Dallas, Houston, and San Antonio, Texas; Indianapolis, Indiana; Jacksonville, Florida; Nashville, Tennessee; Raleigh, North Carolina; and Washington, DC.

Responsibilities/Qualifications

Drees Homes, a National homebuilder with a superb reputation as a leader and innovator in the industry is seeking a detail-oriented and strategic Business Analyst – Data Engineering to join our growing Business Intelligence team. This role will be instrumental in transforming data into actionable insights that drive operational efficiency, customer satisfaction, and business growth. The ideal candidate will have a strong analytical mindset, excellent communication skills, and a passion for leveraging data to solve business problems.

MUST BE ELIGIBLE TO WORK IN THE US WITHOUT SPONSORSHIP.

Some Duties And Responsibilities


 * Collaborate with stakeholders across departments (Sales, Construction, Finance, Marketing) to gather requirements and translate them into technical specifications.
 * Develop, maintain, and support ETL processes and data warehousing solutions to ensure efficient data integration, transformation, and availability for business analysis and reporting.
 * Apply advanced data modeling techniques to design scalable, efficient, and high-performing data structures that support complex analytical queries and business intelligence solutions
 * Manage system integrations and API connections by collaborating with internal and external teams to define requirements, maintain documentation, and ensure secure and efficient data flow between platforms.
 * Support data governance initiatives by ensuring data accuracy, consistency, and integrity.
 * Monitor key performance indicators (KPIs) and develop automated solutions for ongoing performance tracking.
   
   

Knowledge And Skills


 * Familiarity with CRM and ERP systems (e.g., Salesforce, JD Edwards).
 * Experience with cloud-based data platforms (e.g., Azure, Oracle, Big Query).
 * Experience in the homebuilding or real estate industry is a plus.
   
   

Requirements


 * Bachelor’s degree in Business Analytics, Information Systems, Computer Science, or a related field.
 * 5+ years of experience in a BI, data analysis, or business analytics role.
 * Experience with ETL processes and data warehousing concepts.
 * Proficiency in DAX, Python, R, SQL, and other data modeling techniques.
 * Excellent communication and interpersonal skills, with the ability to explain technical concepts to non-technical audiences.
   
   

Premier Benefits To Support YOU


 * We offer a comprehensive benefits package, including:
 * Medical, dental and vision
 * Life, AD&D, and critical illness insurance
 * Wellness rewards
 * 401(k) savings plan
 * Profit Sharing
 * Paid time off increasing with tenure
 * Tuition reimbursement
 * Long and short disability and Parental leave
 * Employee discount program on the purchase of a Drees Home
 * Employee Assistance Program and much more!
   
   

Excellent salary and bonus potential.

Join a special team that works together to make Drees a successful company and a rewarding place to work!

Summary

Equal Opportunity Employer / Drug Free Workplace

To learn more about Drees Homes, visit our website www.dreeshomes.com","Over 200 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Construction","","","","58537","https://www.linkedin.com/jobs/view/business-analyst-data-engineering-at-drees-homes-4337101869?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Data Analyst","New York, NY","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/senior-data-analyst-at-hellofresh-4337079022?trk=public_jobs_topcard-title","HelloFresh","https://de.linkedin.com/company/hellofresh?trk=public_jobs_topcard-org-name","As a Senior Marketing Analyst, you will support the acquisition strategy of one of the fastest-growing e-commerce businesses in the US. Data-driven decision making is at the core of our company culture and you will have a fundamental part in extracting insights and shaping our success. You will work with marketing and analytics to build capabilities for one of the fastest-growing US food brands and be the champion of a data-centric approach to our marketing and digital product operations. You will work collaboratively with data engineering, business intelligence and data science, to provide effective and high impact insights to drive business performance.

You will…


 * Complete proactive analysis of performance & brand marketing data to identify gaps and opportunities for KPI improvement (acquisition, CACs, brand awareness, LTV, etc.), and work with channel managers to implement insights and push initiatives forward.
 * Stay up-to-date with industry and market developments that might impact business performance.
 * Play a key role in driving the insights generated by the analytics team to tangible action and projects adopted by the rest of the marketing team.
 * Be a leading voice for the analytics department, supporting the broader US marketing team in understanding new metrics and teaching foundational analysis skills.
 * Work with other analytics departments, driving cross-team collaboration, best practice sharing, and insight generation.
 * Analyze customer data to identify pain points and opportunities in the customer journey, helping to determine customer segmentation and personalization strategies.
 * Actively support the marketing annual strategic planning process, from analysis to storytelling.
   
   

You are…


 * Results-oriented - You love transforming data into meaningful outcomes
 * Gritty - When you encounter obstacles you find creative solutions
 * Intellectually curious – You love to understand why things are the way they are, how things work, and challenge the status quo
 * A team player – You favor team victories over individual success
 * A structured problem solver – You possess strong organizational skills and consistently demonstrate a methodical approach to all your work
 * Agile – You thrive in fast-paced and dynamic environments and are comfortable working autonomously
 * A critical thinker – You use logic to identify opportunities, evaluate alternatives, and synthesize and present critical information to solve complex problems
   
   

You have…


 * 4+ years of experience in marketing analytics or a highly analytical role focused on growth, measurement, or optimization ideally in a high-growth or start-up environment.
 * Advanced proficiency in SQL and Python, with hands-on experience building data pipelines, performing marketing mix or attribution analyses, and applying statistical learning techniques (e.g., regression, causal impact, or predictive modeling)
 * .A strong grasp of marketing performance metrics you understand acquisition funnels, channel ROI, incrementality, and can connect data directly to marketing strategy and customer value.
 * Proven skill in data storytelling and visualization, using tools like Tableau or Power BI to turn complex marketing performance data into clear, actionable narratives.
 * Demonstrated ability to leverage AI tools and frameworks (such as Gemini, ChatGPT or predictive modeling libraries) to accelerate analysis, generate insights faster, and automate repetitive tasks.
 * The ability to influence cross-functional teams partnering closely with marketing, finance, and product stakeholders to align insights with business goals.
 * A degree in a quantitative or technical discipline (e.g., Statistics, Computer Science, Economics, Engineering) or equivalent hands-on experience in data science or analytics.
   
   

You’ll get…


 * Competitive hourly rate, 401K company match that vests immediately upon participation, & team bonus opportunities
 * Generous PTO and flexible attendance policy
 * Comprehensive health and wellness benefits with options at $0 monthly, effective first day of employment
 * Up to 85% discount on subscriptions to HelloFresh meal plans (HelloFresh, Green Chef, Everyplate, and Factor_)
 * Access to Employee Resource Groups that are open to all employees, including those pertaining to BIPOC, women, veterans, parents, and LGBTQ+
 * Inclusive, collaborative, and dynamic work environment within a fast-paced, mission-driven company that is disrupting the traditional food supply chain
   
   

This job description is intended to provide a general overview of the responsibilities. However, the Company reserves the right to adjust, modify, or reassign work tasks and responsibilities as needed to meet changing business needs, operational requirements, or other factors.

New York Pay Range

$115,000—$128,000 USD","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Consumer Services","$115,000.00/yr - $128,000.00/yr","","","2454643","https://careers.hellofresh.com/global/en/job/HELLGLOBAL7409246EXTERNALENGLOBAL/Senior-Data-Analyst?utm_source=linkedin&utm_medium=phenom-feeds","EXTERNAL",""
"Staff Product Data Scientist","New York, NY","8 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/staff-product-data-scientist-at-slack-4340308775?trk=public_jobs_topcard-title","Slack","https://www.linkedin.com/company/tiny-spec-inc?trk=public_jobs_topcard-org-name","To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.

Job Category

Data

Job Details

About Salesforce

Salesforce is the #1 AI CRM, where humans with agents drive customer success together. Here, ambition meets action. Tech meets trust. And innovation isn’t a buzzword — it’s a way of life. The world of work as we know it is changing and we're looking for Trailblazers who are passionate about bettering business and the world through AI, driving innovation, and keeping Salesforce's core values at the heart of it all.

Ready to level-up your career at the company leading workforce transformation in the agentic era? You’re in the right place! Agentforce is the future of AI, and you are the future of Salesforce.

Applications will be accepted until 11/11/2025.

We are looking for a seasoned Data Science expert to help build a world-class data science and analytics platform that supports and scales data-driven product decision-making.

As a Staff Product Data Scientist, you will work closely with cross-functional partners to proactively define the product landscape, derive insights from data, communicate key findings to product executives, and directly contribute to product strategy building and implementation. You’ll partner with Product, Design, and Engineering (PDE) to contribute directly to product development—shaping what we build, how we measure success, and when/how we iterate and improve.

At Slack, we foster a positive, diverse, and supportive culture. We look for people who are curious, bold, and eager to improve every day. Our team values being smart, humble, hardworking, and above all, collaborative.

What you will be doing


 * Apply advanced data science techniques to analyze Slack product usage patterns, identifying what’s working, what’s not, and opportunities for improvement.
 * Conduct evidence-based evaluations to determine key drivers of Slack’s product growth.
 * Define and report key success metrics, effectively communicating insights to Slack and Salesforce leadership to enable executive level decision making and follow-ups.
 * Synthesize insights across different product areas and business outcomes, identifying correlations and causal relationships that drive success.
 * Serve as a domain expert in product data science, guiding best practices and advancing data science methodologies and operations.
 * Champion evidence-based decision-making, making data and insights accessible and scalable for stakeholders at all levels.
   
   

What you should have


 * 5+ years of experience in data science or quantitative analysis, preferably in technology product development or enterprise software.
 * A related technical degree required.
 * Expertise in at least one programming language for data science (e.g., Python, R).
 * Experience working with large-scale data technologies (e.g., Spark, Presto, Hive, Hadoop). Expertise in Apache Airflow is a strong plus.
 * Strong communication skills. Able to translate complex technical results into clear, actionable insights.
 * Cross-functional collaboration and influencing skills, with a track record of impacting decisions at both strategic and executional levels.
 * Experience designing and implementing advanced data models with scalability and efficiency.
 * Experienced in applying advanced quant measurement techniques in a product development environment.
   
   

Unleash Your Potential

When you join Salesforce, you’ll be limitless in all areas of your life. Our benefits and resources support you to find balance and be your best, and our AI agents accelerate your impact so you can do your best. Together, we’ll bring the power of Agentforce to organizations of all sizes and deliver amazing experiences that customers love. Apply today to not only shape the future — but to redefine what’s possible — for yourself, for AI, and the world.

Accommodations

If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.

Posting Statement

Salesforce is an equal opportunity employer and maintains a policy of non-discrimination with all employees and applicants for employment. What does that mean exactly? It means that at Salesforce, we believe in equality for all. And we believe we can lead the path to equality in part by creating a workplace that’s inclusive, and free from discrimination. Know your rights: workplace discrimination is illegal. Any employee or potential employee will be assessed on the basis of merit, competence and qualifications – without regard to race, religion, color, national origin, sex, sexual orientation, gender expression or identity, transgender status, age, disability, veteran or marital status, political viewpoint, or other classifications protected by law. This policy applies to current and prospective employees, no matter where they are in their Salesforce employment journey. It also applies to recruiting, hiring, job assignment, compensation, promotion, benefits, training, assessment of job performance, discipline, termination, and everything in between. Recruiting, hiring, and promotion decisions at Salesforce are fair and based on merit. The same goes for compensation, benefits, promotions, transfers, reduction in workforce, recall, training, and education.

In the United States, compensation offered will be determined by factors such as location, job level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, and benefits. Salesforce offers a variety of benefits to help you live well including: time off programs, medical, dental, vision, mental health support, paid parental leave, life and disability insurance, 401(k), and an employee stock purchasing program. More details about company benefits can be found at the following link: https://www.salesforcebenefits.com.Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.

For New York-based roles, the base salary hiring range for this position is $200,800 to $276,100.

For Washington-based roles, the base salary hiring range for this position is $184,000 to $253,000.

For California-based roles, the base salary hiring range for this position is $200,800 to $276,100.","Be among the first 25 applicants","Full-time","Mid-Senior level","Research, Analyst, and Engineering","Technology, Information and Internet","$184,000.00/yr - $276,100.00/yr","","","1612748","https://www.linkedin.com/jobs/view/staff-product-data-scientist-at-slack-4340308775?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Chantilly, VA","3 weeks ago","2025-11-10","https://www.linkedin.com/jobs/view/data-engineer-at-bespoke-technologies-inc-4334930492?trk=public_jobs_topcard-title","Bespoke Technologies, Inc.","https://www.linkedin.com/company/bespoketechinc?trk=public_jobs_topcard-org-name","BT-66 – Data Engineer

Skill Level: Senior

Location: Herndon/Chantilly (fully on-site, no remote option)


 * MUST HAVE A POLY CLEARANCE TO APPLY. Those who do not have a Poly clearance will not be considered.**
   
   

Develop new tools, code, and services to execute data engineering activities involving data of varying types and in varying conditions. Activities include the following tasks: Movement of structure and unstructured data using approved methods. Execute data ingestion activities for storing data in a local or enterprise level location. Develop code to format data that supports exploration. Analyze source data formats and work with Data Scientists and partners to determine the formats and transforms that best meet objectives. Develop code and tools to provide one-time and on-going data extraction from various repositories, formatting and transformations into enterprise or standalone data models. Develop new ETL and perform O&M and enhancements on existing ETL code using best practices/standards. Develop and deliver documentation for each project including ETL mappings, code use guide, code location and access instructions.


 * Design and optimize Data Pipelines using tools such as Spark, Apache Iceberg, Trino, OpenSearch, EMR cloud services, NiFi and Kubernetes containers
 * Ensure the pedigree and provenance of the data is maintained such that the access to data is protected
 * Clean and preprocess data to enable access for advanced analytics
 * Collaborate with enterprise working groups to advance the state of data standards
 * Collaborate with the engineering team, data stewards, and partners to aid in getting actionable value out of the data holdings
 * Collaborate with software engineers to update, configure, and maintain data services based on the requirements
 * Ensure data quality by working with the testing and data quality team to enhance standardization of data conditioning pipelines
 * Experience adapting to various types and formats of data, and working with development teams to integrate new data processing platforms
   
   

Required Skills:

10+ years' experience with:


 * Data lifecycle engineering
 * Development and maintenance of extract, transform and load (ETL) tools and services
 * Cloud and on-prem data storage and processing solutions
 * Python, SQL, Spark and other data engineering programming
 * COTS and open source data engineering tools such as ElasticSearch and NiFi
 * Processing data within the Agile Lifecycle","54 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","","","","71291624","https://www.linkedin.com/jobs/view/data-engineer-at-bespoke-technologies-inc-4334930492?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr. Data Engineer","Chicago, IL","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/sr-data-engineer-at-ninjatrader-4338387034?trk=public_jobs_topcard-title","NinjaTrader","https://www.linkedin.com/company/ninjatrader-group-llc?trk=public_jobs_topcard-org-name","Disclaimer: Please be advised that the most accurate and up-to-date information about our open roles—including job descriptions, compensation, and benefits—can only be guaranteed on our official job board. For the latest listings and details, please visit: https://job-boards.greenhouse.io/ninjatrader.

JOIN US ON OUR MISSION TO BECOME THE #1 RETAIL TRADING PLATFORM IN THE WORLD

Welcome to the dynamic world of NinjaTrader! As an industry-leading trading platform and futures broker, we're empowering traders to take control of their financial destiny. How do we do it? We provide cutting-edge products and services that enhance the trading journey. Whether a seasoned pro or just starting out, NinjaTrader equips traders with award-winning software and brokerage services to navigate the world's leading financial markets with confidence.

Our growth story is nothing short of exhilarating. Since 2003, NinjaTrader has been dedicated to understanding and supporting traders on their journey toward trading triumph. Through those efforts, our user base has grown to over 2 million users and we have become the number one rated futures brokerage worldwide.

But we're not stopping there. We're constantly evolving, pushing boundaries, and modernizing the futures industry. Our commitment to innovation means users will always have access to dynamic tools, real-time support, and a community of like-minded traders.

So, why work at NinjaTrader? Here, you're not just part of a team; you're part of a movement. We empower employees to reach new heights in their careers by providing a dynamic culture focused on social connection, professional development, and employee recognition initiatives. Sounds too good to be true? Take it from our employees.

Join us as we redefine what's possible in trading, advocate for our customers, and continue our journey toward becoming the world's top retail-focused trading platform in the world.

What You'll Do

Your data-driven mindset and ability to use large data sets enables NinjaTrader to serve customers better, identify new opportunities, and improve processes. As an accomplished data engineer reporting to the Data & Analytics Director, this is a terrific opportunity to join a fast-growing, revolutionary company and be part of our growing Data & Analytics team.

In This Role You Will


 * Design, develop, and maintain data architecture and pipelines
 * Develop and deliver scalable unit-tested data assets and products that empower analysts and drive business workflows
 * Evaluate and continuously improve existing data products and solutions
 * Work with engineers and product managers to analyze edge cases and plan for architectural scalability
 * Manage the deployment of multiple data solutions such as business dashboards and machine learning models
 * Be a staunch advocate for best-in-class data development and design
 * Participate in design and code reviews with meaningful comments
 * Participate in the team's Agile process
 * Be a collaborative, helpful, and curious team member
   
   

What You'll Need


 * Bachelor's degree in Engineering, Computer Science, or related field
 * 5+ years of experience with ETL, SQL, PowerBI, Tableau, or similar technologies
 * Understanding of data warehousing technologies and event-driven architectures
 * Experience working in a fast-paced Agile development environment
 * Ability to work autonomously while interacting with multiple business teams and stakeholders
 * Experience delivering solutions on Cloud Data Warehouse platforms like Bigdata, RedShift, or Snowflake
 * Hands-on experience with Python/R
   
   

Bonus Points For


 * Experience with Python or other backend technologies
 * Experience in fintech
 * Passion for futures, derivatives, and trading technologies
   
   

Compensation

The salary range for this role will be $140,000.00 - $160,000.00 USD. In addition, this position will also receive an annual target bonus of 10%. Bonus pay at NinjaTrader is based on individual performance (50%) as well as company/team performance (50%).

Salary and bonus earnings are only two components of the total compensation package offered by NinjaTrader. NinjaTrader offers a 401K plan through ADP under which the company will match up to 3.5% of employee contributions. Annual paid time off allowance accrues at a rate of 18 days per year (some positions may qualify for more) plus seven paid holidays.

Location:

This role is based in Chicago, IL. *There may be remote flexibility for exceptional candidates in the following states: California, Colorado, Florida, Georgia, Illinois, Indiana, Minnesota, New Jersey, New York, North Carolina, Ohio, Oregon, Pennsylvania, South Carolina, Texas, Utah, Virginia, Washington, Washington DC, Wisconsin.

Hybrid

For Chicago-based employees, we follow a hybrid work schedule: In-office Tuesday through Thursday, with remote work on Mondays and Fridays. In addition to these weekly remote days, we offer:


 * 20 additional flex remote days annually
 * 5 Company Wide Office-Optional weeks tied to major holidays
   
   

Our Core Benefits Include


 * Generous PTO
 * 7 Paid Holidays Annually + 5 Conditional Holidays Annually
 * 1 Service Day Annually
 * 401k with 3.5% Company Match
 * Paid Parental Bonding Leave
 * Health, Vision, Dental Coverage
 * Life and Disability Insurance Covered 100% by NinjaTrader
   
   

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We are proud to be an equal opportunity workplace.","159 applicants","Full-time","Mid-Senior level","Information Technology","Financial Services","$140,000.00/yr - $160,000.00/yr","","","2689269","https://www.adzuna.com/details/5506067331?v=4B32F4D891DCEA0188B2261C4667ACC60DF7C58C&r=20758277&frd=db56af0756ef301e7a5e533618dca330&ccd=93e3e5978d30ace2f4bcca3551acf170&utm_source=linkedin7&utm_medium=organic&chnlid=1931&title=Sr.%20Data%20Engineer&a=e","EXTERNAL",""
"AI/ML Engineer","Redwood City, CA","1 week ago","2025-11-18","https://www.linkedin.com/jobs/view/ai-ml-engineer-at-spektrum-recruiting-4337013590?trk=public_jobs_topcard-title","Spektrum Recruiting","https://www.linkedin.com/company/spektrum-recruiting?trk=public_jobs_topcard-org-name","We’re partnering with a well-funded, seed-stage startup to help build their early engineering team. They’re hiring two more AI/ML Engineers and are open to candidates at the Senior, Staff, or Principal level.




If you're excited about building a product from the ground up, we’d love to hear from you. Check out the job description below to learn more.




As the AI/ML Engineer, you’ll be one of the early technical hires and play a key role in building the core machine learning systems from the ground up. You’ll own the entire lifecycle; from prototyping models to deploying production-grade systems while working closely with the founding team to influence product direction and technical architecture.




This is a rare opportunity to have deep impact, massive ownership, and the chance to shape the culture, systems, and trajectory of a category-defining company.




What You’ll Do

 * Design, build, and deploy scalable ML systems that power our core product.
 * Own end-to-end development: problem formulation, data pipelines, model training, evaluation, and production deployment.
 * Collaborate with product and engineering to translate business goals into ML solutions.
 * Evaluate and apply state-of-the-art techniques in LLMs, deep learning, classical ML, and generative AI.
 * Establish best practices for model reproducibility, monitoring, and performance tracking.
 * Build and scale our MLOps infrastructure (training pipelines, experiment tracking, deployment tooling).
 * Recruit and mentor future ML/AI hires and help grow the team and culture.




Qualifications:




 * 8+ years of experience in Artificial Intelligence, Machine Learning and Software Engineering.
 * Strong foundation in ML/DL algorithms, statistical modeling, and data processing.
 * Deep experience with modern ML/DL frameworks (e.g., PyTorch, TensorFlow, JAX).
 * Hands-on experience with LLMs, transformers, or other foundation models.
 * Proven experience building and deploying production-grade ML systems.
 * Strong software engineering skills (Python, APIs, cloud infra, containerization).
 * Familiarity with ML pipelines and platforms (e.g., Airflow, MLflow, SageMaker, Vertex AI).
 * Startup mindset: ownership, bias for action, comfort with ambiguity, and a builder mentality.
 * Degree in Computer Science, Machine Learning, Mathematics, or related field. (PhD or MS preferred but not required with equivalent experience.)

","Over 200 applicants","Full-time","Mid-Senior level","Project Management, Supply Chain, and Product Management","Software Development","$170,000.00/yr - $250,000.00/yr","Vidya M","https://www.linkedin.com/in/vidyamallik","105632358","https://www.linkedin.com/jobs/view/ai-ml-engineer-at-spektrum-recruiting-4337013590?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)"
"Data Scientist, People","New York, NY","2 weeks ago","2025-11-15","https://www.linkedin.com/jobs/view/data-scientist-people-at-doordash-4340873357?trk=public_jobs_topcard-title","DoorDash","https://www.linkedin.com/company/doordash?trk=public_jobs_topcard-org-name","About The Team

The People Data Science team is part of DoorDash’s People Intelligence organization, a multidisciplinary group that combines data science, business intelligence, analytics engineering, and data engineering to power our people decisions with trusted, scalable insights. Together, we enable DoorDash to unlock the full potential of our talent and drive measurable improvements in organizational effectiveness.

As the advanced analytics arm of People Intelligence, the People Data Science team applies statistical modeling, machine learning, and AI-driven analysis to uncover trends and patterns across the employee lifecycle — from hiring to engagement to retention. By transforming people data into meaningful insights, we help DoorDash foster a thriving, high-performing workforce and make data-informed decisions that elevate the employee experience and organizational impact.

About The Role

As a Data Scientist on the People Team at DoorDash, you will shape the future of people analytics by building and deploying AI and LLM-based models that deliver insights from both quantitative and qualitative employee data. You’ll design intelligent systems and agents that leverage large-scale employee experience, performance, and organizational data — integrating structured and unstructured signals to uncover trends that inform talent strategy and business outcomes.

This role blends deep expertise in statistical modeling, natural language processing, and applied machine learning with a strong understanding of people analytics and business context. You’ll collaborate with data engineers, applied scientists, and People Business Partners to develop scalable insight-generation systems that help leaders make more informed, data-backed decisions.

You're Excited About This Opportunity Because You Will...


 * Build AI-powered people analytics tools — develop LLM- or agent-based systems that summarize employee sentiment, extract insights from qualitative feedback, and surface trends in quantitative data.
 * Apply advanced statistical and ML techniques to understand drivers of engagement, retention, and performance.
 * Design, test, and deploy scalable models and pipelines that analyze large volumes of survey, feedback, and HR data.
 * Collaborate cross-functionally with People, Engineering, and Product partners to design AI solutions that support business strategy and improve the employee experience.
 * Translate data into action — tell compelling stories with data that shape leadership decisions and organizational priorities.
 * Explore cutting-edge GenAI and NLP approaches — from embeddings and topic modeling to fine-tuning LLMs for people analytics applications.
 * Contribute to the evolution of People Data Science at DoorDash — shaping our approach to scalable, AI-driven insights for the future of work.
   
   

We’re Excited About You Because You Have...


 * Master’s or Ph.D. in Data Science, Computer Science, Statistics, Applied Mathematics, Economics, Industrial-Organizational Psychology (quantitative track), or a related field.
 * 3+ years of experience applying data science methods to real-world problems (1–2+ years in People Analytics preferred).
 * Proficiency in Python and SQL, with experience using ML and NLP libraries (e.g., scikit-learn, statsmodels).
 * Proven experience building or applying large language models (LLMs) and NLP-based systems for text summarization, sentiment analysis, or insight extraction.
 * Strong foundation in statistical modeling, causal inference, and experimental design (e.g., regression, clustering, A/B testing, time-series).
 * Experience designing and scaling data pipelines using Snowflake, dbt, Databricks.
 * Familiarity with LLM orchestration tools (e.g., LangChain, LlamaIndex, or similar frameworks) and vector databases (e.g., Postgres with pgvector).
 * Ability to distill complex analyses into actionable insights through clear communication, visualization, and storytelling.
 * Experience creating data visualizations and dashboards using tools such as Sigma, Tableau, or Looker to communicate insights effectively.
 * Passion for building AI solutions that empower people leaders and improve organizational decision-making through ethical and responsible applications of data science.
   
   

Nice-to-have


 * Experience building or contributing to AI analytics assistants or chatbots that enable natural language access to insights.
 * Experience with data science python packages such as PyTorch, TensorFlow, and Hugging Face Transformers.
 * Experience in survey analytics, employee engagement research, or text analytics using large-scale feedback data.
 * Familiarity with HRIS systems (e.g., Workday) and core workforce metrics such as attrition and engagement.
 * Exposure to fine-tuning foundation models and evaluating LLM performance for reliability and bias.
 * Experience with graph databases (e.g., Neo4j) for modeling organizational networks.
 * Background in applied behavioral science, organizational research, or people analytics experimentation.
   
   

Notice to Applicants for Jobs Located in NYC or Remote Jobs Associated With Office in NYC Only

We use Covey as part of our hiring and/or promotional process for jobs in NYC and certain features may qualify it as an AEDT in NYC. As part of the hiring and/or promotion process, we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound from August 21, 2023, through December 21, 2023, and resumed using Covey Scout for Inbound again on June 29, 2024.

The Covey tool has been reviewed by an independent auditor. Results of the audit may be viewed here: Covey

Compensation

The successful candidate’s starting pay will fall within the pay range listed below and is determined based on job-related factors including, but not limited to, skills, experience, qualifications, work location, and market conditions. Base salary is localized according to an employee’s work location. Ranges are market-dependent and may be modified in the future.

In addition to base salary, the compensation for this role includes opportunities for equity grants. Talk to your recruiter for more information.

DoorDash cares about you and your overall well-being. That’s why we offer a comprehensive benefits package to all regular employees, which includes a 401(k) plan with employer matching, 16 weeks of paid parental leave, wellness benefits, commuter benefits match, paid time off and paid sick leave in compliance with applicable laws (e.g. Colorado Healthy Families and Workplaces Act). DoorDash also offers medical, dental, and vision benefits, 11 paid holidays, disability and basic life insurance, family-forming assistance, and a mental health program, among others.

To learn more about our benefits, visit our careers page here.

See Below For Paid Time Off Details


 * For salaried roles: flexible paid time off/vacation, plus 80 hours of paid sick time per year.
 * For hourly roles: vacation accrued at about 1 hour for every 25.97 hours worked (e.g. about 6.7 hours/month if working 40 hours/week; about 3.4 hours/month if working 20 hours/week), and paid sick time accrued at 1 hour for every 30 hours worked (e.g. about 5.8 hours/month if working 40 hours/week; about 2.9 hours/month if working 20 hours/week).
   
   

The national base pay range for this position within the United States, including Illinois and Colorado.

$124,100—$182,500 USD

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

Our Commitment to Diversity and Inclusion

We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on “protected categories,” we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.

Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.

If you need any accommodations, please inform your recruiting contact upon initial connection.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","","","","3205573","https://www.linkedin.com/jobs/view/data-scientist-people-at-doordash-4340873357?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineering Consultant","Phoenix, AZ","1 month ago","2025-10-31","https://www.linkedin.com/jobs/view/data-engineering-consultant-at-plex-consulting-llc-4333298420?trk=public_jobs_topcard-title","Plex Consulting, LLC","https://www.linkedin.com/company/plexconsulting?trk=public_jobs_topcard-org-name","Job Title: Data Engineering Consultant

Company: Plex Consulting

Location: Phoenix, AZ

About The Company

Plex Consulting is a leading technology consulting firm offering data solutions to a diverse range of clients across industries. We combine our expertise in data engineering, analytics, and data science to provide innovative and efficient solutions that drive growth and maximize business value for our clients.

Job Summary

We are seeking a highly skilled and experienced Data Engineering Consultant to join our dynamic team. The ideal candidate will possess a strong background in data engineering, data architecture, and cloud platforms. They will work closely with clients to design, develop, and implement data solutions that meet their unique business needs and align with industry best practices. The Data Engineering Consultant will also provide guidance and mentorship to junior team members and actively contribute to the continuous improvement of our data engineering capabilities.

Responsibilities


 * Collaborate with clients to understand their business objectives and data requirements.
 * Design and develop scalable data engineering solutions, including data integration, data warehousing, and data processing pipelines.
 * Implement and optimize ETL/ELT processes to ensure the efficient extraction, transformation, and loading of data.
 * Design and build data models and schemas to support analytical requirements and reporting.
 * Evaluate and recommend appropriate technologies and tools that align with clients' data infrastructure and architecture.
 * Conduct performance tuning and optimization of large-scale and complex data systems.
 * Continuously monitor, troubleshoot, and optimize data pipelines and processing workflows.
 * Provide expertise in data architecture and data governance, ensuring data quality, security, and compliance.
 * Mentor and train junior team members, fostering a culture of learning and development.
 * Stay up-to-date with the latest trends, techniques, and tools in data engineering and recommend innovative approaches to solve complex problems.
   
   

Requirements


 * Bachelor's in Computer Science, Engineering, or related field or equivalent experience.
 * Minimum 2 years in consulting environment preferred.
 * Proven experience as a Data Engineer, Database Engineer, or similar role.
 * Strong proficiency in SQL and experience with relational and NoSQL databases.
 * Expertise in designing and implementing scalable data solutions using cloud platforms (e.g., Azure, Snowflake, AWS).
 * Proficiency in programming languages such as Python, Java, or Scala.
 * Solid understanding of data modeling, data warehousing concepts, and ETL frameworks.
 * Experience with data integration tools (e.g., Informatica, Azure DataFactory, Matillion) and workflow management tools (e.g., Logic Apps).
 * Familiarity with big data technologies and distributed computing frameworks.
 * Experience with API development and supporting functions.
 * Strong analytical and problem-solving skills with the ability to analyze complex data sets and derive actionable insights.
 * Excellent communication and client engagement skills, with the ability to effectively collaborate with diverse stakeholders.
 * Strong project management skills and the ability to prioritize and execute tasks in a fast-paced environment.
   
   

We offer competitive salaries, a comprehensive benefits package, and ample opportunities for growth and professional development. Join our team and be part of our mission to empower businesses with data-driven insights.

Join our dynamic team of consultants and be part of a collaborative environment where your skills and expertise will make a significant impact on our clients' success!","27 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","IT Services and IT Consulting","","","","76652618","https://www.linkedin.com/jobs/view/data-engineering-consultant-at-plex-consulting-llc-4333298420?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer III","Kansas City, MO","3 weeks ago","2025-11-10","https://www.linkedin.com/jobs/view/data-engineer-iii-at-spring-venture-group-4339970651?trk=public_jobs_topcard-title","Spring Venture Group","https://www.linkedin.com/company/springventuregroup?trk=public_jobs_topcard-org-name","Company Description

Who We Are:

Spring Venture Group is a leading digital direct-to-consumer sales and marketing company with product offerings focused on the senior market. We specialize in distributing Medicare Supplement, Medicare Advantage, and related products via our family of brands and dedicated team of licensed insurance agents. Powered by our unique technologies that combine sophisticated marketing, comparison shopping, sales execution, and customer engagement – we help thousands of seniors across the country navigate the complex world of Medicare every day.

Job Description

This person has the opportunity to work primarily remote in the Kansas City or surrounding areas, making occasional visits to the office, but must CURRENTLY be in the Kansas City area.

We are unable to sponsor for this role, this includes international students.

Overview

The Data Management team is responsible for all things data at Spring Venture Group. Most importantly, our team is responsible for constructing high quality datasets that enable our business stakeholders and world-class Analytics department to make data informed decisions. Data engineers, combining Software Engineering and Database Engineering, serve as a primary resource for expertise with writing scripts and SQL queries, monitoring our database stability, and assisting with data governance ensuring availability for business-critical systems. The DE III works with a team of engineers of varying levels to design, develop, test, and maintain software applications and programs. The DE III will be expected to work independently when needed to solve the most complex problems encountered. They will be expected to be a leader and a mentor.

Essential Duties

The essential duties for this role include, but are not limited to:


 * Serve as a primary advisor to Data Engineering Manager to identify and bring attention to opportunities for technical improvements, reduction of technical debt, or automation of repeated tasks.
 * Build advanced data pipelines utilizing the medallion architecture to create high quality single source of truth data sources in Snowflake
 * Architect replacements of current Data Management systems with respect to all aspects of data governance
 * Design advanced services with multiple data pipelines to securely and appropriately store company assets in our enterprise data stores.
 * Technically advise any member of the data engineering department, providing direction when multiple paths forward present themselves.
 * Actively participate as a leader in regular team meetings, listening and ensuring that one is assisting others at every chance for growth and development.
 * Write advanced ETL/ELT scripts where appropriate to integrate data of various formats into enterprise data stores.
 * Take ownership (both individually and as part of a team) of services and applications
 * Write complex SQL queries, scripts, and stored procedures to reliably and consistently modify data throughout our organization according to business requirements
 * Collaborate directly and independently with stakeholders to build familiarity, fully understand their needs, and create custom, modular, and reliable solutions to resolve their requests
 * Document and demonstrate solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code
 * Work with Project Managers, Solution Architects, and Software Development teams to build solutions for Company Initiatives on time, on budget, and on value.
 * Independently architect solutions to problems of high complexity, and advise junior and mid-level engineers on problems of medium complexity.
 * Create data pipelines using appropriate and applicable technologies from Amazon Web Services (AWS) to serve the specific needs of the business.
 * Ensure 99.95% uptime of our company’s services monitoring data anomalies, batch failures, and our support chat for one week per team cycle from 8am-9pm.
 * Follow and embrace procedures of both the Data Management team and SVG Software Development Life Cycle (SDLC), including obtaining and retaining IT Security Admin III clearance.
 * Support after hours and weekend releases from our internal Software Development teams.
 * Actively participate in code review and weekly technicals with another more senior engineer or manager.
 * Assist departments with time-critical SQL execution and debug database performance problems.
   
   
   

ROLE COMPETENCIES

The competencies for this role include, but are not limited to:


 * Emotional Intelligence
 * Drive for Results
 * Continuous Improvement
 * Communication
 * Strategic Thinking
 * Teamwork and Collaboration
   
   
   

Qualifications

POSITION REQUIREMENTS

The Requirements To Fulfill This Position Are As Follows


 * Bachelor's degree in Computer Science, or a related technical field.
 * 4-7 years of practical production work in Data Engineering.
 * Expertise of the Python programming language.
 * Expertise of Snowflake
 * Expertise of SQL, databases, & query optimization.
 * Must have experience in a large cloud provider such as AWS, Azure, GCP.
 * Advanced at reading code independently and understanding its intent.
 * Advanced at writing readable, modifiable code that solves business problems.
 * Ability to construct reliable and robust data pipelines to support both scheduled and event based workflows.
 * Working directly with stakeholders to create solutions.
 * Mentoring junior and mid-level engineers on best practices in programming, query optimization, and business tact.
   
   
   

Benefits

Additional Information

The Company offers the following benefits for this position, subject to applicable eligibility requirements:


 * Competitive Compensation
 * Medical, Dental and vision benefits after a short waiting period
 * 401(k) matching program
 * Life Insurance, and Short-term and Long-term Disability Insurance
 * Optional enrollment includes HSA/FSA, AD&D, Spousal/Dependent Life Insurance, Travel Assist and Legal Plan
 * Generous paid time off (PTO) program starting off at 15 days your first year
 * 15 paid Holidays (includes holiday break between Christmas and New Years)
 * 10 days of Paid Parental Leave and 5 days of Paid Birth Recovery Leave
 * Annual Volunteer Time Off (VTO) and a donation matching program
 * Employee Assistance Program (EAP) - health and well-being on and off the job
 * Rewards and Recognition
 * Diverse, inclusive and welcoming culture
 * Training program and ongoing support throughout your Venture Spring Venture Group career
   
   
   

Security Responsibilities


 * Operating in alignment with policies and standards
 * Reporting Security Incidents Completing assigned training
 * Protecting assigned organizational assets
   
   
   

Spring Venture Group is an Equal Opportunity Employer","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Insurance","","Dani Batchelder","https://www.linkedin.com/in/dani-batchelder","860648","https://www.linkedin.com/jobs/view/data-engineer-iii-at-spring-venture-group-4339970651?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI Engineer","Atlanta, GA","4 days ago","2025-11-28","https://www.linkedin.com/jobs/view/ai-engineer-at-expedite-technology-solutions-llc-4348010577?trk=public_jobs_topcard-title","Expedite Technology Solutions LLC","https://www.linkedin.com/company/expedite-technology-solutions-llc?trk=public_jobs_topcard-org-name","Responsibilities


 * Assist in the design and implementation of AI models and systems, contributing fresh ideas and approaches to the team's efforts.
 * Translate software requirements into working and maintainable solutions within the existing application frameworks.
 * Participate in the full lifecycle of application, including design, coding, testing, implementation, deployment as well as support and maintenance.
 * Develop and adhere to best practices for developing applications.
 * Ensure optimization across all platforms including mobile-friendly UI/UX.
 * Collaborate with other developers to implement AI solutions effectively.
 * Effectively analyze a problem/task to give accurate timelines for milestones and full implementation completion.
 * Experience in developing frameworks with AI.
   
   

Must Have


 * Bachelor s degree in data science, statistics, mathematics, computer science or engineering discipline, or equivalent experience
 * 3+ years of work/educational experience leading development of Machine Learning, prompt engineering, data analysis and Artificial Intelligence
 * 2+ years of experience with production-grade design, deployment and implementation of AI models and systems, contributing fresh ideas and approaches to the team's efforts.
 * Experience with one or more general purpose programming languages including but not limited to: Java, C/C++, Python, R or equivalent
 * Experience and knowledge in designing, building, and deploying multi layered application Infrastructure involving On-premises & AWS Cloud platform using services BedRock LLM models.
 * You enjoy working with people and can put yourself in other people's shoes. You're not afraid to ask for help when you need it or help teammates when they need a boost.
 * Embraces diverse people, thinking, and styles
 * Consistently makes safety and security, of self and others, the priority
 * Experience with one or more of the following: Natural Language Processing, sentiment analysis, classification, pattern recognition
 * Consistently makes safety and security, of self and others, the priority","86 applicants","Full-time","Entry level","Engineering and Information Technology","Civil Engineering","","","","11682674","https://www.resume-library.com/feed/click/551/231732462?dpj=yes","EXTERNAL",""
"Data Engineer","Huntsville, AL","2 weeks ago","2025-11-12","https://www.linkedin.com/jobs/view/data-engineer-at-seneca-resources-4335676161?trk=public_jobs_topcard-title","Seneca Resources","https://www.linkedin.com/company/seneca-resources-inc-?trk=public_jobs_topcard-org-name","Position Title: Data Engineer

Location: Huntsville, AL - Onsite

Position Status: Direct Hire

Clearance Requirements: Active Top Secret Clearance (TS/SCI preferred)

Pay Rate: $150K - $170K




Position Description: Are you passionate about turning complex data into powerful insights that drive real-world impact? As a Data Engineer, you’ll play a key role in designing, building, and optimizing data systems that support mission-critical initiatives. You’ll collaborate with multidisciplinary teams to develop scalable pipelines, integrate structured and unstructured data, and enable advanced analytics solutions that power innovation and intelligence.

In this role, you’ll contribute to projects that matter — from national security to enterprise-level analytics — using your expertise in Java, Oracle, and modern data engineering practices to build efficient, high-performance systems.




Responsibilities:

 * Design, develop, and maintain data pipelines and ETL workflows to transform and organize large-scale datasets.
 * Write clean, secure, and efficient Java code for data processing, automation, and integration.
 * Optimize Oracle database performance through tuning and advanced PL/SQL scripting.
 * Automate build, test, and deployment processes using CI/CD best practices.
 * Collaborate with analysts, developers, and stakeholders in an agile environment to deliver data solutions that meet evolving business and technical needs.
 * Evaluate and implement new tools or technologies to enhance data engineering efficiency and scalability.




Required Skills & Education:

 * Clearance: Active Top Secret (TS/SCI preferred).
 * Education: Bachelor’s degree and 10+ years of experience as a Data Engineer in a large-scale enterprise environment, or 14+ years of equivalent experience in lieu of a degree.
 * Proven experience programming in Java for data analysis, automation, and data warehousing.
 * Strong hands-on experience with Oracle databases, including performance tuning and query optimization.
 * Skilled in PL/SQL scripting, stored procedures, and data manipulation.
 * Proficient in CI/CD pipelines, automated testing, and deployment workflows.
 * Ability to work independently and solve complex data challenges in a dynamic enterprise setting.




Preferred Qualifications:

 * Experience with ETL tools (e.g., Informatica).
 * Familiarity with data warehousing design and DevOps practices.
 * Experience working within Agile, Waterfall, or Iterative SDLC models.
 * Knowledge of Oracle VLDB (Very Large Database) concepts and optimization strategies.
 * Current TS/SCI clearance with polygraph is highly desirable.




About Seneca Resources

At Seneca Resources, we’re more than just a staffing and consulting firm — we’re your career partner. With offices across the U.S. and clients ranging from Fortune 500 corporations to federal agencies, we connect talented professionals to meaningful opportunities that drive innovation and impact.

When you join Seneca, you’ll receive competitive pay, comprehensive benefits (including health, dental, vision, and 401(k)), and dedicated support from a team committed to your professional success.

We are proud to be an Equal Opportunity Employer and value diversity at all levels of our organization. All qualified individuals are encouraged to apply.

","103 applicants","Full-time","Mid-Senior level","Information Technology","IT Services and IT Consulting","$150.00/yr - $170.00/yr","Ansh Kaushik","https://www.linkedin.com/in/ansh-kaushik-a4714216b","1394857","https://www.linkedin.com/jobs/view/data-engineer-at-seneca-resources-4335676161?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)"
"GEN AI Engineer","Raritan, NJ","1 month ago","2025-10-27","https://www.linkedin.com/jobs/view/gen-ai-engineer-at-the-dignify-solutions-llc-4341895657?trk=public_jobs_topcard-title","The Dignify Solutions, LLC","https://www.linkedin.com/company/dignify-solutions?trk=public_jobs_topcard-org-name"," * Must have 15+ years of experience working in Data science, Machine learning and especially NLP technologies.
 * Exposure to various LLM technologies and solid understanding of Transformer Encoder Networks.
 * Able to apply deep learning and generative modeling techniques to develop LLM solutions in the field of Artificial Intelligence.
 * Utilize your extensive knowledge and expertise in machine learning (Client) with a focus on generative models, including but not limited to generative adversarial networks (GANs), variational autoencoders (VAEs), and transformer-based architectures.
 * Solid understanding of Model development, model serving, training/re-training techniques in a data sparse environment.
 * Very good understanding of Prompt engineering techniques in developing Instruction based LLMs.
 * Must be able to design, and implement state-of-the-art generative models for natural language processing (NLP) tasks such as text generation, text completion, language translation, and document summarization.","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","75031133","https://www.linkedin.com/jobs/view/gen-ai-engineer-at-the-dignify-solutions-llc-4341895657?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Fort Worth, TX","2 weeks ago","2025-11-12","https://www.linkedin.com/jobs/view/data-engineer-at-search-services-4340230920?trk=public_jobs_topcard-title","Search Services","https://www.linkedin.com/company/search-services?trk=public_jobs_topcard-org-name","ABOUT OUR CLIENT

Our Client is a privately held, well-capitalized energy company based in Fort Worth, Texas with a strong track record of success across upstream, midstream, and mineral operations throughout the United States. The leadership team is composed of highly experienced professionals who have worked together across multiple ventures and basins. They are committed to fostering a collaborative, high-integrity culture that values intellectual curiosity, accountability, and continuous improvement.




ABOUT THE ROLE

Our Client is seeking a skilled and motivated Data Engineer to join their growing technology team. This role plays a key part in managing and optimizing data systems, designing and maintaining ETL processes, and improving data workflows across departments. The successful candidate will have deep technical expertise, a strong background in database architecture and data integration, and the ability to collaborate cross-functionally to enhance data management and accessibility. Candidates with extensive experience may be considered for a Senior Data Engineer title.




RESPONSIBILITIES

 * Design, implement, and evolve database architecture and schemas to support scalable and efficient data storage and retrieval.
 * Build, manage, and maintain end-to-end data pipelines, including automation of ingestion and transformation processes.
 * Monitor, troubleshoot, and optimize data pipeline performance to ensure data quality and reliability.
 * Document all aspects of the data pipeline architecture, including data sources, transformations, and job scheduling.
 * Optimize database performance by managing indexing, queries, stored procedures, and views.
 * Develop frameworks and tools for reusable ETL processes and efficient data handling across formats such as CSV, JSON, and Parquet.
 * Ensure proper version control and adherence to coding standards, security protocols, and performance best practices.
 * Collaborate with cross-functional teams including engineering, operations, land, finance, and accounting to streamline data workflows.




QUALIFICATIONS

 * Excellent verbal and written communication skills.
 * Strong organizational, analytical, and problem-solving abilities.
 * Proficient in Microsoft Office Suite and other related software.
 * Experienced in programming languages such as R, Python, and SQL.
 * Proficient in making and optimizing API calls for data integration.
 * Strong experience with cloud platforms such as Azure Data Lake, Azure Data Studio, Azure Databricks, and/or Snowflake.
 * Proficient in CI/CD principles and tools.
 * High integrity, humility, and a strong sense of accountability and teamwork.
 * A self-starter with a continuous improvement mindset and passion for evolving technologies.




REQUIRED EDUCATION AND EXPERIENCE

 * Bachelor’s degree in computer science, software engineering, or a related field.
 * 2+ years of experience in data engineering, database management, or software engineering.
 * Master’s degree or additional certification a plus, but not required.
 * Exposure to geospatial or GIS data is a plus.




PHYSICAL REQUIREMENTS

 * Prolonged periods of sitting and working at a computer.
 * Ability to lift up to 15 pounds occasionally.




***********************************************************************************

NO AGENCY OR C2C CANDIDATES WILL BE CONSIDERED

VISA SPONSORSHIP IS NOT OFFERED NOR AVAILABLE FOR H1-B NOR F1 OPT

***********************************************************************************","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Oil and Gas","","","","398355","https://www.linkedin.com/jobs/view/data-engineer-at-search-services-4340230920?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr. Process Engineer","Chicago, IL","1 week ago","2025-11-18","https://www.linkedin.com/jobs/view/sr-process-engineer-at-kind-4332324673?trk=public_jobs_topcard-title","KIND","https://www.linkedin.com/company/kind?trk=public_jobs_topcard-org-name","Who We Are...

As a collection of brands including KIND, Nature’s Bakery, and trü frü within the Health and Wellness Division of Mars Snacking, we are proud to offer healthy snacking options to our consumers. From granola to snack bars and better for you hyper-chilled and hyper-dried chocolate covered fruit, we believe that the choice to snack healthier should be an easy and desirable one. With real, recognizable ingredients in every bite, we’re on a mission to inspire everyone to snack better.

We’re on the lookout for passionate associates to join our dynamic, growth-oriented team! If you’re someone who loves to dive in and make things happen, we want you!

Join us to become the foremost leader in health & wellness and provide healthy snacking choices to our consumers! Come be part of our journey to become the leading force in health and wellness, providing tasty and nutritious snacking choices to our consumers!

What You'll Do

The Sr. Process Engineer will provide process engineering support for multiple approved Innovation and renovation projects across Mars Snacking Health & Wellness Division (H&W) with specific focus on KIND, while also supporting Natures Bakery and trü frü Business Units as needed. This role will be critical for building the H&W internal technical expertise and executing Planned Innovation opportunities. The Sr. Process Engineer will also support business initiatives around value leadership, sustainability, and manufacturing support. Collaboration with a cross-functional team is necessary for success in this role, including H&W and Business Unit stakeholders. Projects may include input into the evaluation of manufacturing technologies and commissioning of new equipment.

How You'll Do It


 * Act as support for the Business Units and other key stakeholders for all Innovation, Renovation and Productivity projects.
 * A strategic thinker and approach business initiatives with an entrepreneurial spirit.
 * Able to influence, facilitate groups with diverse perspectives, and bring teams to consensus / alignment.
 * Able to work in a fast-paced and rapidly changing environment and maintain a positive outlook.
 * Able to demonstrate prudent judgment when making important decisions by utilizing knowledge of industry best practices and current trends.
 * Excellent at planning and prioritization skills with the ability to multi-task and rapidly adapt.
 * Provide guidance and support for engineering regarding design concepts, specifications and requirements to best utilize equipment and manufacturing processes.
 * Project scope development and management.
 * Reputation of the team, i.e., how the project was achieved.
 * Responsible for understanding the manufacturing processes of the company and identifying areas where the cost/ benefit favors technology and automation.
 * Effectiveness of team, build team, manage interpersonal opportunities.
 * Keeps abreast of best practices, and current or emerging manufacturing technologies to determine options and recommend improvements.
 * Collaborate with the HSE (Health Safety Environmental) and Food Safety and Quality Teams to ensure products are manufactured to specifications and in compliance with Mars INC Safety and Food Safety Standards.
 * Execute communication processes that ensure appropriate level of communication of daily activities between all stakeholders.
 * Collaborate with external project stakeholders to ensure priorities and standards have been reviewed and scope of work is aligned.
   
   

What You'll Bring To KIND


 * Organizational Leadership
    * You bring a strong sense of urgency and a can-do attitude
    * You possess excellent verbal and written communication skills
    * You bring a partnership and relationship-based approach in working with internal and external business partners. Always presenting a “we vs. me” attitude.
    * You bring a willingness to challenge our “way of work” to maximize our resources and enhance our success rate
    * You develop and manage supplier relationships and stay abreast of industry trends and technology developments to leverage outside ideas and technical solutions
    * You network with the global R&D community to share and utilize best practices.

 * Technical Leadership
    * You bring strong technical equipment knowledge to the organization
    * You execute the qualification and approval processes for new processing equipment, new lines, and/or manufacturing locations.
    * You develop & execute well thought-out trial plans, collect data, and interpret results to drive program/project and technical knowledge forward; develop robust action plans, risk assessment, and contingency planning.
    * You are a proven problem solver and utilize analytical thinking to identify the root cause of an issue.
    * You support the pipeline development/validation/execution of all productivity projects involving process optimizations.
      

You have...


 * A BS or MS degree in Chemical Engineering, Mechanical Engineering, or a related degree.
 * At least 5+ years of relevant concept to launch experience.
 * At least 5+ years of relevant experience in Process engineering, development and manufacturing qualifications, start-ups & innovation projects.
 * Strong foundational knowledge in food process technologies and equipment.
 * Strong problem-solving and analytical skills.
 * Familiarity with the activities in Marketing, Market Research, Legal/Regulatory, QA and Manufacturing.
 * The ability to travel 30% - 50% to support project work.
   
   

Certain states and localities require employers to post a reasonable estimate of salary range. A reasonable estimate of the current base salary range for this position is $108,000.00 - $145,000.00. Actual salary will be based on a variety of factors, including location, experience, skill set, performance, licensure and certification, and business needs. The range for this position in other geographic locations may differ.

What We Offer...

We are proud to provide a robust benefits package to help support you physically, financially, and emotionally through the big milestones and in your everyday life.


 * Competitive salary, including a target bonus and an impressive benefits package.
 * A 401(k) plan, complete with a generous company match!
 * Flexible Paid Time Off.  Choose what works best for you.
 * Excellent health, dental & vision insurance, with options to fit you & your family’s needs.
 * Casual office dress code - feel free to wear your KIND, Nature’s Bakery and trü frü gear!
 * A dynamic, ambitious and fun work environment
   
   

EEO

We are committed to an inclusive workplace where diversity in all its forms is championed. We are proud to be an equal opportunity workplace and we are an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants with criminal histories, consistent with legal requirements. If you require special accommodation, please let us know. 

Privacy Policy

Mars and its family of brands is committed to transparency and responsibility in how we handle the personal data entrusted to us by our customers and consumers. To learn more about our privacy policy please follow this link.","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering","Construction, Software Development, and IT Services and IT Consulting","$108,000.00/yr - $145,000.00/yr","","","1042218","https://www.linkedin.com/jobs/view/sr-process-engineer-at-kind-4332324673?trk=public_jobs_topcard-title","EASY_APPLY",""
"GEN AI Engineer","Raritan, NJ","1 month ago","2025-10-27","https://www.linkedin.com/jobs/view/gen-ai-engineer-at-the-dignify-solutions-llc-4341935729?trk=public_jobs_topcard-title","The Dignify Solutions, LLC","https://www.linkedin.com/company/dignify-solutions?trk=public_jobs_topcard-org-name"," * Must have 15+ years of experience working in Data science, Machine learning and especially NLP technologies.
 * Exposure to various LLM technologies and solid understanding of Transformer Encoder Networks.
 * Able to apply deep learning and generative modeling techniques to develop LLM solutions in the field of Artificial Intelligence.
 * Utilize your extensive knowledge and expertise in machine learning (Client) with a focus on generative models, including but not limited to generative adversarial networks (GANs), variational autoencoders (VAEs), and transformer-based architectures.
 * Solid understanding of Model development, model serving, training/re-training techniques in a data sparse environment.
 * Very good understanding of Prompt engineering techniques in developing Instruction based LLMs.
 * Must be able to design, and implement state-of-the-art generative models for natural language processing (NLP) tasks such as text generation, text completion, language translation, and document summarization.","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","75031133","https://www.linkedin.com/jobs/view/gen-ai-engineer-at-the-dignify-solutions-llc-4341935729?trk=public_jobs_topcard-title","EASY_APPLY",""
"Full Stack Developer","Arlington, VA","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/full-stack-developer-at-swarmint-llc-4338898295?trk=public_jobs_topcard-title","SwarmInt LLC","https://www.linkedin.com/company/swarmint?trk=public_jobs_topcard-org-name","About Us:
SwarmInt is a defense AI startup developing cutting-edge computer vision and edge AI capabilities for military expeditionary forces. We strive to develop operator-in-the-loop solutions for warfighters with active contracts supporting the Department of Defense and Intelligence Community.

Job Description:
Join our engineering team as a Full Stack Developer, contributing to applications that power AI-driven intelligence systems. You'll work across the stack with a focus on Python backend development and modern frontend technologies, in a fast-paced startup environment where your work directly impacts mission success. You'll develop applications that run everywhere from edge compute devices in operational environments to supporting cloud infrastructure.

Responsibilities:

 * Develop full-stack features and applications with strong focus on Python backend development
 * Build user interfaces for real-time data visualization and analytics from sensor feeds
 * Implement backend services and APIs for data processing and integration
 * Integrate real-time sensor data feeds and video streams into applications
 * Deploy containerized applications to edge infrastructure
 * Optimize applications for performance in resource-constrained environments
 * Contribute to CI/CD pipelines and deployment automation
 * Work with databases, caching layers, and distributed systems
 * Debug and troubleshoot issues across the full stack including edge deployments
 * Participate in code reviews and technical design discussions
 * Learn defense software development practices from senior engineers

Required Qualifications:

 * Bachelor's degree in Computer Science, Software Engineering, or related field
 * 5-10+ years professional software development experience
 * Strong Python programming skills
 * Experience with modern frontend frameworks
 * Understanding of REST APIs, asynchronous programming, and real-time communication
 * Familiarity with version control, containerization (Docker), and basic DevOps concepts
 * Experience with relational and/or NoSQL databases
 * Understanding and proficiency with Linux systems and command-line tools
 * Ability to obtain and maintain security clearance
 * U.S. Citizenship required

Preferred Qualifications:

 * Experience with TypeScript and modern JavaScript tooling
 * Exposure to video streaming or real-time data applications
 * Knowledge of computer vision concepts and libraries
 * Familiarity with AI/ML integration or computer vision
 * Experience with embedded systems, edge computing, or IoT
 * Knowledge of modern Python web frameworks and API design
 * Understanding of networking concepts and protocols
 * Experience with real-time sensor data processing and visualization
 * Experience with message queuing or event streaming systems
 * Interest in hardware integration and sensor systems
 * Experience with autonomous systems, robotics frameworks (ArduPilot, ROS), or UAS platforms
 * Understanding of government security protocols (NIST 800-171, CMMC)
 * Passion for defense technology and mission-driven work

Benefits:

 * Competitive salary ($150K-$200K based on experience)
 * Annual performance bonus
 * 401k with competitive company match
 * Comprehensive health, dental, and vision insurance
 * Clearance processing support and sponsorship
 * Mentorship from experienced engineers and technical leadership
 * Rapid skill growth in AI, defense tech, and full-stack development
 * Direct customer interaction and feedback
 * Work on systems that make a real difference","Be among the first 25 applicants","Full-time","Entry level","Sales, General Business, and Education","Wireless Services, Telecommunications, and Communications Equipment Manufacturing","$150,000.00/yr - $200,000.00/yr","","","94151073","https://www.linkedin.com/jobs/view/full-stack-developer-at-swarmint-llc-4338898295?trk=public_jobs_topcard-title","EASY_APPLY",""
"AWS Data Engineer - Remote","New Jersey, United States","1 month ago","2025-10-27","https://www.linkedin.com/jobs/view/aws-data-engineer-remote-at-the-dignify-solutions-llc-4341945759?trk=public_jobs_topcard-title","The Dignify Solutions, LLC","https://www.linkedin.com/company/dignify-solutions?trk=public_jobs_topcard-org-name","Responsibilities:


 * Create AWS data pipelines, build data models and test/deploy code
 * Work with a variety of APIs to create ETL workflows.
 * Ensure that we meet delivery SLAs and adhere to Agile principles.
 * Develop a deep understanding of SVOD/AVOD business data model.
 * Create Snowflake objects, stored procedures, and tasks for modifying and storing data
 * Identify areas of improvement and optimize data storage, processing, and utilization of cloud resources
   
   

Requirements:


 * Undergrad or higher degree in a field such as computer science, software engineering, or equivalent
 * 3+ years experience of hands on as a data engineering
 * 3+ years experience with Python and SQL
 * 2+ years experience in AWS
 * Experience working with large data sets
 * Experience working with Business Intelligence tools
 * Excellent written and oral communication skills
 * Must be a detail-oriented self-starter, able to work independently as well as in a team environment
   
   

Primary Skill:

Application Development, Graphic Design, Lighting","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","75031133","https://www.linkedin.com/jobs/view/aws-data-engineer-remote-at-the-dignify-solutions-llc-4341945759?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Data Engineer","Minneapolis, MN","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/senior-data-engineer-at-skywater-search-partners-4338372032?trk=public_jobs_topcard-title","SkyWater Search Partners","https://www.linkedin.com/company/skywater-search-partners?trk=public_jobs_topcard-org-name"," * Job Tag:
 * Posted: November 13,2025
 * Salary: $150,000
   
   

We have been retained by a local manufacturer with strong growth and stability to bring on a seasoned data engineering professional for a pivotal Senior Data Engineer position. In this highly impactful and visible role you will be a hands on technical subject matter expert as they continue to modernize their data environment. Reporting to the Director of Software Development and working closely with their Director of BI you will be responsible for maintaining and modernizing their data environment as they transition from on-prem to the cloud (likely Azure).

If you are someone who has experience taking data environments to the cloud and enjoy variety, moving the needle, and being a technical data guru this should be to your liking. Hybrid role (2-3 days onsite).

Desired Skills And Experience


 * Must have strong soft skills and keen ability to break down complex technical ideas / strategy to a varied audience *Work across the business to make sure data is actionable, approachable, and helping the business meet its growth goals + initiatives *BS in a related field or equivalent experience in lieu of degree with a MS being preferred *6+ years of professional experience with expertise in SQL, Azure Data Factory, Azure Data Cloud, SSIS /SSRS, Power BI, ETL, Python is a plus *Help define technical data architecture, pipelines, analytics *Desired experience in manufacturing / production, agriculture, CPG, multisite operations
   
   ","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Staffing and Recruiting","","Alex Bowes","https://www.linkedin.com/in/alexbowesmnpermanentplacementrecruiter","2872912","https://www.linkedin.com/jobs/view/senior-data-engineer-at-skywater-search-partners-4338372032?trk=public_jobs_topcard-title","EASY_APPLY",""
"Quantitative Developer (C++ expert) | New Team Build (Seattle) | Elite Quant Hedge Fund","Greater Seattle Area","19 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/quantitative-developer-c%2B%2B-expert-new-team-build-seattle-elite-quant-hedge-fund-at-delmar-nord-4340744126?trk=public_jobs_topcard-title","Delmar Nord","https://www.linkedin.com/company/delmar-nord?trk=public_jobs_topcard-org-name","Quantitative Developer (C++ expert) | New Team Build (Seattle) | Elite Quant Hedge Fund

One of the top quantitative hedge funds globally is building out a new pod in Seattle. This is a very unique opportunity to join this team as a foundational hire under an exceptional leader. You’ll step into a startup-like environment that’s perfect for someone who’s excited about high levels of ownership, impact, rapid development, and an entrepreneurial, business building mindset. Yet, you’ll also have the extensive resources, access to centralized data, and support of an established industry leader. You’ll work to solve challenging problems, and see the immediate impact of your work. The data, compute, analytics, and trading systems you design and build from scratch will literally power this business and define how quickly and effectively this team is able to execute trades and implement their strategies. You’ll build these systems for a team of world-class quant researchers, and then help them producitionize and implement their models and strategies.




Key Responsibilities:

 * Design, develop, and maintain low-latency data, analytics, trading, and research systems and platforms.
 * Collaborate with quants to implement models and strategies in production.
 * Build robust data ingestion and processing pipelines for real-time and historical data.
 * Optimize performance across compute, storage, and network layers.
 * Contribute to the design of the team’s technical architecture and development practices.




Qualifications:

 * Bachelor’s or Master’s degree in Computer Science, Engineering, Mathematics, or related field.
 * Experience using C++ to design/build complex, large-scale, ultra low latency systems.
 * Experience with distributed systems, cloud infrastructure, and large-scale data processing.
 * Excellent problem-solving skills and a collaborative mindset.

Nice-to-have:

 * Python expertise (especially for building real-time, data intensive applications or analytical solutions)




Why Join:

 * Be part of a new, high-impact team with the backing of a globally respected hedge fund.
 * Work on complex, intellectually stimulating problems with top-tier talent.
 * Competitive compensation in a meritocratic environment with clear problems to solve and goals.
 * Access to cutting-edge tools, data, and infrastructure.
 * Flexible, innovation-driven culture with a startup feel and institutional support.","28 applicants","Full-time","Mid-Senior level","Information Technology","Investment Management, Software Development, and Capital Markets","$350,000.00/yr - $650,000.00/yr","Luke Madronal","https://www.linkedin.com/in/luke-madronal-delmarnord","100158037","https://www.linkedin.com/jobs/view/quantitative-developer-c%2B%2B-expert-new-team-build-seattle-elite-quant-hedge-fund-at-delmar-nord-4340744126?trk=public_jobs_topcard-title","EASY_APPLY","Vision insurance
Medical insurance
Pension plan
Commuter benefits
Disability insurance
Student loan assistance
Child care support
Paid maternity leave
Tuition assistance
Paid paternity leave
Dental insurance"
"Engineering Manager, Machine Learning","Brooklyn, NY","2 weeks ago","2025-11-17","https://www.linkedin.com/jobs/view/engineering-manager-machine-learning-at-etsy-4336772241?trk=public_jobs_topcard-title","Etsy","https://www.linkedin.com/company/etsy?trk=public_jobs_topcard-org-name","Company Description

Etsy is the global marketplace for unique and creative goods. We build, power, and evolve the tools and technologies that connect millions of entrepreneurs with millions of buyers around the world. As an Etsy Inc. employee, whether a team member of Etsy or Depop, you will tackle unique, meaningful, and large-scale problems alongside passionate coworkers, all the while making a rewarding impact and Keeping Commerce Human.

Salary Range

$226,000.00 - $294,000.00

What’s the role?

We are looking for an Engineering Manager, Search Ranking to join our Search Relevance initiative at Etsy. You’ll lead a talented team of engineers and applied scientists responsible for the ranking algorithms and systems that determine how hundreds of millions of unique listings are ordered for Etsy buyers.

This team plays a pivotal role in defining and delivering Etsy’s search experience — helping buyers find items they’ll love by combining relevance, personalization, and marketplace value in every search result. The work directly contributes to Etsy’s growth by driving better buyer engagement, higher conversion, and a healthier marketplace. As the Engineering Manager, you will provide technical direction, strategic focus, and people leadership — guiding your team through iterative experimentation, learning from data and outcomes, and delivering high-impact improvements to Etsy’s search ecosystem.

This is a full-time position reporting to the Director of Engineering. In addition to salary, you will also be eligible for an equity package, an annual performance bonus, and our competitive benefits that support you and your family as part of your total rewards package at Etsy.

For this role, we are considering candidates based in the United States. Candidates living within commutable distance of Etsy’s Brooklyn Office Hub or in the San Francisco Bay Area may be the first to be considered. For candidates within commutable distance, Etsy requires in-office attendance once or twice per week depending on your proximity to the office. Etsy offers different work modes to meet the variety of needs and preferences of our team. Learn more details about our work modes and workplace safety policies here.

What’s this team like at Etsy?

The Search Ranking team is a core part of the Search Relevance organization. We build large-scale ranking systems that optimize how Etsy surfaces results — ensuring every search connects buyers with the most relevant, inspiring, and meaningful listings.

Our work spans the full lifecycle of modern ranking systems: from model architecture and data pipelines, to feature engineering, experimentation, and production deployment. We use data-driven iteration and continuous learning to make every search more human, intuitive, and rewarding.

You’ll collaborate closely with product managers, data scientists, and other engineering teams to translate insights into measurable impact. The team’s focus on strategic delivery, technical excellence, and iterative experimentation is key to scaling Etsy’s marketplace while staying true to our mission.

What does the day-to-day look like?


 * Lead and grow a team of engineers and applied scientists building and maintaining ranking algorithms that power Etsy’s search results.
 * Define and execute the technical strategy for ranking systems, ensuring we balance innovation, scalability, and reliability.
 * Partner cross-functionally to set clear goals and success metrics, ensuring that the team’s work directly contributes to Etsy’s business and marketplace growth.
 * Foster a culture of experimentation and learning, using data, A/B testing, and iteration to drive continuous improvement in search relevance and engagement.
 * Collaborate with teams across Search teams, ML Platform, and Infrastructure to ensure reliable, scalable systems and shared learning across Search.
 * Ensure the team delivers strategically impactful projects that balance user experience, ranking performance, and business outcomes.
 * Promote engineering and ML best practices, from model quality evaluation to operational excellence in production environments.
 * Of course, this is just a sample of the kinds of work this role will require! You should assume that your role will encompass other tasks, too, and that your job duties and responsibilities may change from time to time at Etsy's discretion, or otherwise applicable with local law.
   
   

Qualities that will help you thrive in this role are:


 * Proven experience leading teams in search ranking, or large-scale recommendation or ads systems.
 * Strong technical foundation in ranking algorithms, personalization, and information retrieval.
 * Expertise in ML experimentation, model iteration, and data-driven product development.
 * Experience driving strategic delivery and measurable impact — connecting technical investments to business outcomes.
 * Familiarity with deep learning architectures, vector search, and large-scale distributed systems.
 * Excellent communication skills with the ability to bridge technical and product perspectives.
 * A track record of developing and coaching high-performing teams, cultivating an inclusive and collaborative environment.
 * BS/MS or PhD in Computer Science, Engineering, or a related field.
 * A learning mindset — curiosity, resilience, and passion for continuous improvement.
   
   

Additional Information

What's Next

If you're interested in joining the team at Etsy, please share your resume with us and feel free to include a cover letter if you'd like. As we hope you've seen already, Etsy is a place that values individuality and variety. We don't want you to be like everyone else -- we want you to be like you! So tell us what you're all about.

Our Promise

At Etsy, we believe that a diverse, equitable and inclusive workplace furthers relevance, resilience, and longevity. We encourage people from all backgrounds, ages, abilities, and experiences to apply. Etsy is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or veteran status, or any other characteristic protected by applicable law. If, due to a disability, you need an accommodation during any part of the application or interview process, please let your recruiter know. While Etsy supports visa sponsorship, sponsorship opportunities may be limited to certain roles and skills.","88 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Software Development","$226,000.00/yr - $294,000.00/yr","","","67849","https://etsy.wd5.myworkdayjobs.com/Etsy_Careers/job/Brooklyn-New-York/Engineering-Manager_JR5032-1?source=LinkedIn","EXTERNAL",""
"Data Engineer","Chantilly, VA","13 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-engineer-at-caci-international-inc-4340176944?trk=public_jobs_topcard-title","CACI International Inc","https://www.linkedin.com/company/caci-international-inc?trk=public_jobs_topcard-org-name","Job Category: Information Technology

Time Type: Full time

Minimum Clearance Required to Start: None

Employee Type: Regular

Percentage of Travel Required: None

Type of Travel: None

* * *

The Opportunity

DarkBlue is a leading provider of dark web intelligence. Our mission is to empower organizations with comprehensive, actionable intelligence from the hidden corners of the internet to protect against emerging threats and criminal activities. We specialize in dark web and Telegram data collection, analysis, and intelligence generation for national security, law enforcement, and enterprise customers.

We are seeking a strategic, big-picture thinking Data Engineer who will serve as a technical problem solver within our intelligence operations. This role combines deep technical expertise in data engineering with strategic analytical thinking to solve complex system-level challenges in dark web and other data collection, processing, and intelligence generation. The ideal candidate will be self-motivated, possess strong Elasticsearch and Python expertise, and demonstrate experience in cybersecurity, intelligence, or investigative domains.

Responsibilities


 * Design and implement scalable data pipelines for dark web and open-source intelligence data
 * Architect and maintain robust ETL/ELT processes for multi-source data integration
 * Develop and optimize data models for complex intelligence datasets
 * Implement data quality frameworks ensuring integrity of intelligence data
 * Design, implement, and maintain Elasticsearch clusters optimized for intelligence data
 * Implement advanced search capabilities and query optimization across terabytes of dark web data
 * Create and maintain Kibana dashboards and visualizations for intelligence analysts
 * Build and maintain ML data pipelines supporting threat detection and predictive analytics
 * Collaborate with data scientists to productionize machine learning models
 * Identify and resolve performance bottlenecks in large-scale data processing systems
 * Design fault-tolerant, highly available systems for mission-critical operations
 * Implement monitoring, alerting, and observability solutions for data infrastructure
 * Collaborate with intelligence analysts to translate requirements into technical solutions
 * Develop metrics and KPIs to measure data quality and system performance
   
   

Qualifications

Required:


 * 5+ years of experience in data engineering with focus on large-scale data processing
 * Bachelor's degree in Computer Science, Data Engineering, or related field
 * Expert-level proficiency in Elasticsearch including cluster architecture and optimization
 * Strong programming skills in Python
 * Database expertise across relational and NoSQL technologies
 * Cloud platform experience (AWS) with infrastructure-as-code tools
 * Experience with containerization and orchestration technologies
 * Strategic thinking capability with strong analytical and troubleshooting skills
 * Experience with data modeling for analytical workloads
 * Understanding of statistical concepts and machine learning principles
 * Self-motivated and autonomous work style
 * Excellent communication skills with both technical and non-technical stakeholders
 * Active security clearance or ability to obtain clearance
   
   

Desired


 * Master's degree in Computer Science, Data Engineering, or related field
 * Experience with graph databases (Neo4j, Amazon Neptune)
 * Knowledge of streaming technologies (Apache Kafka, AWS Kinesis)
 * Familiarity with security frameworks and compliance requirements
 * Intelligence or investigative experience in law enforcement or national security
 * Knowledge of dark web ecosystems and criminal marketplaces
 * Experience with OSINT tools and methodologies
   
   

________________________________________________________________________________________

What You Can Expect

A culture of integrity.

At CACI, we place character and innovation at the center of everything we do. As a valued team member, you’ll be part of a high-performing group dedicated to our customer’s missions and driven by a higher purpose – to ensure the safety of our nation.

An environment of trust.

CACI values the unique contributions that every employee brings to our company and our customers - every day. You’ll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality.

A focus on continuous growth.

Together, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground — in your career and in our legacy.

Your potential is limitless. So is ours.

Learn more about CACI here.

________________________________________________________________________________________

Pay Range: There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here.

The Proposed Salary Range For This Position Is

$86,600 - $181,800

CACI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, age, national origin, disability, status as a protected veteran, or any other protected characteristic.","51 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","$86,600.00/yr - $181,800.00/yr","","","3672","https://www.linkedin.com/jobs/view/data-engineer-at-caci-international-inc-4340176944?trk=public_jobs_topcard-title","EASY_APPLY",""
"Engineering Manager, Data Engineering","Boston, MA","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/engineering-manager-data-engineering-at-whoop-4347004935?trk=public_jobs_topcard-title","WHOOP","https://www.linkedin.com/company/whoop?trk=public_jobs_topcard-org-name","At WHOOP, we’re on a mission to unlock human performance. WHOOP empowers members to perform at a higher level through a deeper understanding of their bodies and daily lives.

We are seeking an Engineering Manager, Data Engineering to lead the team responsible for the data that powers WHOOP AI, analytics, and decision-making. In this role, you will manage the engineers who build, optimize, and maintain the data pipelines and platforms that underpin our business operations and member experiences. You’ll bring a strong technical foundation, a keen eye for operational excellence, and an ability to align cross-functional teams to deliver impactful outcomes.

As a leader, you will balance strategic vision with hands-on execution, guiding your team through complex engineering challenges while ensuring WHOOP’s data ecosystem is performant, reliable, and cost-efficient.

Responsibilities


 * Lead and Develop a High-Performing Team: Manage, mentor, and grow a team of data engineers focused on data quality, performance, and scalability across WHOOP’s platforms.
 * Prioritize and Deliver Impactful Work: Manage competing priorities and ensure the team focuses on the most critical projects that drive measurable outcomes for WHOOP and its members.
 * Drive Operational Excellence (OPEX): Establish and monitor KPIs for system reliability, cost efficiency, and delivery speed. Partner with finance and platform teams to optimize spend while maintaining high service quality.
 * Own Data Pipelines: Oversee the design and maintenance of WHOOP’s core data pipelines, ensuring scalability, reliability, and adherence to best practices in security, governance, and observability.
 * Collaborate with Key Stakeholders: Partner with the Data Science, Analytics, Product, and ML Platform teams to understand requirements, define priorities, and align on deliverables that accelerate innovation and business impact.
 * Ensure Engineering Rigor: Champion software development best practices including version control, testing, documentation, CI/CD, and AI initiatives to ensure reproducible and maintainable data systems.
 * Contribute to Technical Strategy: Help shape the roadmap for WHOOP data engineering and data platform teams, balancing long-term vision with short-term execution.
 * Evaluate emerging technologies and practices aligned with AI initiatives that improve performance, observability, and developer experience.
 * Support Cross-Team Integration: Ensure smooth data flow across internal systems, from ingestion and transformation to downstream consumption by AI, analytics, and product teams.
   
   

Qualifications


 * Bachelor’s or Master’s Degree in Computer Science, Engineering, or a related field; or equivalent professional experience.
 * 5+ years of experience in data or software engineering, including 2+ years in a people management role.
 * Deep understanding of modern data architectures (e.g. Snowflake, Iceberg, Databricks, or similar) and cloud platforms (e.g. AWS, GCP, Azure).
 * Proficiency in programming languages such as Python and familiarity with data pipeline orchestration tools (e.g., Prefect, Airflow).
 * Proven track record of balancing technical innovation with operational and financial efficiency (OpEx ownership).
 * Strong stakeholder management skills - able to translate complex data needs into clear business outcomes and communicate effectively across engineering, product, and leadership teams.
 * Passion for building high-performing teams, fostering growth, and creating systems that scale to power WHOOP’s mission.
   
   

This role is based in the WHOOP office located in Boston, MA. The successful candidate must be prepared to relocate if necessary to work out of the Boston, MA office.

Interested in the role, but don’t meet every qualification? We encourage you to still apply! At WHOOP, we believe there is much more to a candidate than what is written on paper, and we value character as much as experience. As we continue to build a diverse and inclusive environment, we encourage anyone who is interested in this role to apply.

WHOOP is an Equal Opportunity Employer and participates in E-verify to determine employment eligibility. It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.

The WHOOP compensation philosophy is designed to attract, motivate, and retain exceptional talent by offering competitive base salaries, meaningful equity, and consistent pay practices that reflect our mission and core values.

At WHOOP, we view total compensation as the combination of base salary, equity, and benefits, with equity serving as a key differentiator that aligns our employees with the long-term success of the company and allows every member of our corporate team to own part of WHOOP and share in the company’s long-term growth and success.

The U.S. base salary range for this full-time position is$150,000 - $210,000. Salary ranges are determined by role, level, and location. Within each range, individual pay is based on factors such as job-related skills, experience, performance, and relevant education or training.

In addition to the base salary, the successful candidate will also receive benefits and a generous equity package..

These ranges may be modified in the future to reflect evolving market conditions and organizational needs. While most offers will typically fall toward the starting point of the range, total compensation will depend on the candidate’s specific qualifications, expertise, and alignment with the role’s requirements.","40 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Wellness and Fitness Services","$150,000.00/yr - $210,000.00/yr","","","1110454","https://www.linkedin.com/jobs/view/engineering-manager-data-engineering-at-whoop-4347004935?trk=public_jobs_topcard-title","EASY_APPLY",""
"Solar Engineer","San Carlos, CA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/solar-engineer-at-aetherflux-4324317299?trk=public_jobs_topcard-title","Aetherflux","https://www.linkedin.com/company/aetherflux?trk=public_jobs_topcard-org-name","About Aetherflux

Aetherflux is solving the global energy crisis by building the infrastructure for abundant, resilient, and continuous space-based solar energy. We are tackling humanity’s most complex engineering challenge with a world-class team dedicated to delivering a revolutionary power platform. Aetherflux is transforming how civilization powers, computes, and connects—from orbit to Earth.

Solar Engineer

AetherFlux is seeking a highly skilled Solar Engineer to support the development, optimization, and production of advanced photovoltaic systems. The ideal candidate will bring hands-on experience in photovoltaic manufacturing processes, along with strong analytical and engineering capabilities. Experience in the aerospace industry is preferred, as our projects often involve high-performance solar technologies for both ground-based and aerospace environments.




Responsibilities

 * Design, analyze, and optimize solar cell and module architectures for performance, efficiency, durability, and manufacturability.




 * Collaborate with cross-functional teams to implement improvements throughout the PV manufacturing workflow.




 * Conduct material and component evaluations, including testing, characterization, and failure analysis.




 * Develop mathematical models, simulations, and performance forecasts for solar systems operating in varied environmental conditions.




 * Support scale-up activities from prototype development to full manufacturing deployment.




 * Document engineering requirements, test results, and product specifications in accordance with industry standards.




 * Interface with aerospace partners and internal engineering teams on solar solutions intended for high-altitude, satellite, and near-space applications.




 * Ensure compliance with all relevant safety, quality, and regulatory standards.




Required Qualifications

 * Bachelor’s degree (or higher) in Electrical Engineering, Materials Science, Mechanical Engineering, Renewable Energy Engineering, or a related field.




 * Experience in photovoltaic manufacturing—including cell processing, module assembly, thin-film processes, or related production environments.




 * Strong understanding of PV materials, semiconductor physics, and solar energy system design.




 * Proficiency in data analysis, modeling tools, and simulation software (e.g., MATLAB, Python, PVsyst, COMSOL, or similar).




 * Demonstrated ability to solve complex engineering problems and work collaboratively with multidisciplinary teams.




Preferred Qualifications

 * Experience within the aerospace industry, particularly with space-rated solar materials, high-reliability components, or thermal/mechanical analysis for space environments.




 * Knowledge of environmental testing standards such as MIL-STD, ECSS, or NASA specifications.




 * Familiarity with advanced photovoltaic technologies (multi-junction, perovskite, concentrated solar, radiation-hardened cells).




 * Experience with quality management and manufacturing process controls (Six Sigma, SPC, FMEA, etc.).

","69 applicants","Full-time","Mid-Senior level","Engineering","Defense and Space Manufacturing and Energy Technology","","Woody Garrett","https://www.linkedin.com/in/woodygarrett","105244127","https://www.linkedin.com/jobs/view/solar-engineer-at-aetherflux-4324317299?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)"
"AI Engineer/Python-ONLY W2","Houston, TX","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/ai-engineer-python-only-w2-at-saransh-inc-4339340768?trk=public_jobs_topcard-title","Saransh Inc","https://www.linkedin.com/company/saransh-inc-usa?trk=public_jobs_topcard-org-name","Position

Must Have:

AI : Agentic AI, LangGraph, LangChain, LLMs, Prompting methods and Chunking strategies

Development : Python experience, basic knowledge of react

Cloud : AWS services (knowledge of services/tools like BedRock, SageMaker)

DevOps : CICD, Kubernetes, Docker

Others : SQL queries, data model/design, LLM and SQL Tools, RAG, GitHub actions, development best practices, performance optimisations, etc

Jd

Core technical skills:


 * Python Expertise
 * Advanced proficiency in Python programming.
 * Experience with asynchronous programming, decorators, and design patterns.
 * Familiarity with Python frameworks (e.g., FastAPI, Flask, Django).
 * LLM & Agentic AI
 * Deep understanding of LLMs
 * Experience with agentic frameworks like LangChain
 * Knowledge of prompt engineering, tool integration, memory management, and planning modules.
 * Software Architecture & Design
 * Ability to design scalable, modular, and maintainable systems.
 * Experience with microservices, event-driven architecture, and API design.
 * DevOps & Deployment
 * Proficiency with CI/CD pipelines, Docker, Kubernetes.
 * Experience deploying AI models and services on cloud platforms (AWS, Azure, GCP).
 * Version Control & Collaboration
 * Strong Git skills and experience with branching strategies.
 * Familiarity with code review tools and practices.
 * Front-end Development: Solid experience with React.","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","IT Services and IT Consulting","","","","31356620","https://www.linkedin.com/jobs/view/ai-engineer-python-only-w2-at-saransh-inc-4339340768?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist, User Operations","New York, NY","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/data-scientist-user-operations-at-openai-4337484222?trk=public_jobs_topcard-title","OpenAI","https://www.linkedin.com/company/openai?trk=public_jobs_topcard-org-name","About The Team

OpenAI’s User Operations organization is building the data and intelligence layer behind AI-assisted operations — the systems that decide when automation should help users, when humans should step in, and how both improve over time. Our flagship platform is transforming customer support into a model for “agent-first” operations across OpenAI.

About The Role

As a Data Scientist on User Operations, you’ll design the models, metrics, and experimentation frameworks that power OpenAI’s human-AI collaboration loop. You’ll build systems that measure quality, optimize automation, and turn operational data into insights that improve product and user experience at scale. You’ll partner closely with Support Automation Engineering, Product, and Data Engineering to ensure our data systems are production-grade, trusted, and impactful.

This role is based in San Francisco or New York City. We use a hybrid work model of three days in the office per week and offer relocation assistance to new employees.

Why it matters

Every conversation users have with OpenAI products produces signals about how humans and AI interact. User Ops Data Science turns those signals into insights that shape how we support users today and design agentic systems for tomorrow. This is a unique opportunity to help define how AI collaboration at scale is measured and improved inside OpenAI.

In This Role, You Will


 * Build and own metrics, classifiers, and data pipelines that determine automation eligibility, effectiveness, and guardrails.
 * Design and evaluate experiments that quantify the impact of automation and AI systems on user outcomes like resolution quality and satisfaction.
 * Develop predictive and statistical models that improve how OpenAI’s support systems automate, measure, and learn from user interactions.
 * Partner with engineering and product teams to create feedback loops that continuously improve our AI agents and knowledge systems.
 * Translate complex data into clear, actionable insights for leadership and cross-functional stakeholders.
 * Develop and socialize dashboards, applications, and other ways of enabling the team and company to answer product data questions in a self-serve way
 * Contribute to establishing data science standards and best practices in an AI-native operations environment.
 * Partner with other data scientists across the company to share knowledge and continually synthesize learnings across the organization
   
   

You Might Thrive In This Role If You Have


 * 10+ years of experience in data science roles within product or technology organizations.
 * Expertise in statistics and causal inference, applied in both experimentation and observational causal inference studies.
 * Expert-level SQL and proficiency in Python for analytics, modeling, and experimentation.
 * Proven experience designing and interpreting experiments and making statistically sound recommendations.
 * Experience building data systems or pipelines that power production workflows or ML-based decisioning.
 * Experience developing and extracting insights from business intelligence tools, such as Mode, Tableau, and Looker.
 * Strategic and impact-driven mindset, capable of translating complex business problems into actionable frameworks.
 * Ability to build relationships with diverse stakeholders and cultivate strong partnerships.
 * Strong communication skills, including the ability to bridge technical and non-technical stakeholders and collaborate across various functions to ensure business impact.
 * Ability to operate effectively in a fast-moving, ambiguous environment with limited structure.
 * Strong communication skills and the ability to translate complex data into stories for non-technical partners.
   
   

Nice-to-haves


 * Familiarity with large language models or AI-assisted operations platforms.
 * Experience in operational automation or customer support analytics.
 * Background in experimentation infrastructure or human-AI interaction systems.
   
   

About OpenAI

OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.

We are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.

For additional information, please see OpenAI’s Affirmative Action and Equal Employment Opportunity Policy Statement.

Background checks for applicants will be administered in accordance with applicable law, and qualified applicants with arrest or conviction records will be considered for employment consistent with those laws, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act, for US-based candidates. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.

To notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.

We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.

OpenAI Global Applicant Privacy Policy

At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.

Compensation Range: $245K - $385K","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Research Services","$245,000.00/yr - $385,000.00/yr","","","11130470","https://www.linkedin.com/jobs/view/data-scientist-user-operations-at-openai-4337484222?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer- Sr. level","Hawaii, United States","2 weeks ago","2025-11-18","https://www.linkedin.com/jobs/view/data-engineer-sr-level-at-bluehawk-llc-intelligence-services-4341115915?trk=public_jobs_topcard-title","Bluehawk LLC, Intelligence Services","https://www.linkedin.com/company/bluehawk-intelligence-services?trk=public_jobs_topcard-org-name","Bluehawk is seeking two senior level Data Engineers who shall perform work at designated government-owned factilities at USINDOPACOM HQ Camp H.M. Smith; USINDOPACOM JIOC, Joint Base Pearl Harbor-Hickam, HI; and other military locations on the island of Oahu, HI. Locations also may include OCONUS & CONUS U.S. Government Controlled Facilities within the USINDOPACOM’s Area of Responsibility (AOR) or their Joint Detachment (JDET) Offices in Denver, CO; Minneapolis, MN; or Ft. Worth, TX.

Primary work location is Pearl Harbor, Hawaii, however government will determine based on mission requirements.


 * Conducts data analytics, data engineering, data mining, exploratory analysis, predictive analysis, and statistical analysis, and uses scientific techniques to correlate data into graphical, written, visual and verbal narrative products, enabling more informed analytic decisions. Proactively retrieves information from various sources, analyzes it for better understanding about the data set, and builds Artificial Intelligence (AI) tools that automate certain processes. Duties typically include creating various Machine Learning (ML)-based tools or processes, such as recommendation engines or automated lead scoring systems. Performs statistical analysis, applies data mining techniques, and builds high quality prediction systems. Should be skilled in data visualization and use of graphical applications, including Microsoft Office (Power BI) and Tableau; major data science languages, such as R and Python; managing and merging of disparate data sources, preferably through R, Python, or SQL; statistical analysis; and data mining algorithms. Should have prior experience with large data Multi-INT analytics, ML, and automated predictive analytics.
 * Designs, implements, and operates data management systems for intelligence needs. Designs how data will be stored, accessed, used, integrated, and managed by different data regimes and digital systems. Works with data users to determine, create, and populate optimal data architectures, structures, and systems. Plans, designs, and optimizes data throughput and query performance. Participates in the selection ofbackend database technologies (e.g. SQL, NoSQL, HPC, etc.), their configuration and utilization, and the optimization of the full data pipeline infrastructure to support the actual content, volume, ETL, and periodicity of data to support the intended kinds of queries and analysis to match expected responsiveness
 * Contractor shall design and build web prototypes and assist in the continuous improvement of data visualization to support Intelligence Mission Management functions.
 * Contractor shall conduct scalable data research of internal and external sources to support various collection management and collection assessment processes.
 * Implements automated processes for efficiently integrating various datasets, to include data conditioning of non-standard datasets to support collection management, assessment, All-source and single source collection requirement manager functions.
 * Collaborates with collection managers, knowledge managers, and computer scientists to design, modify and build new data processes, and generate algorithms for automated collection strategies.
 * Develops various scripts designed to condition, integrate, and handle data more efficiently.
 * Develops various scripts designed to automate various manually intensive tasks.
 * Determine new ways to improve data, search quality, and predictive capabilities to inform collection strategy development.
 * Assignments and tasks may include data management or data scientist functions.
 * Contractor shall evaluate and assess automated collection criteria and logic improve collection strategy performance.
 * Contractor shall evaluate existing data management capabilities and recommend data integration solutions to support various aspects of the Tasking. Collection, and Production, Exploitation, and Dissemination process.
 * Contractor shall perform systems analysis and feasibility studies to define concepts and design specification for new or existing databases and content management solutions.
 * Contractor shall discover sources of redundancy and recommend solutions for the efficient integration of multiple data sources.
 * Participates in briefings and meetings to provide advice and apply data management skills to resolve issues across the Tasking, Collection, Production, Exploitation, and Dissemination process.
 * Contractor shall support and participate in conferences, exercise (planning and execution), and working groups (via secure VTC or in person), JCMB, JCWG, DCMB, and NCMB as requested by the Government.
 * Demonstrates in-depth knowledge and understanding of the labor category activities required to meet mission requirements.
 * Demonstrates mastery of qualitative and quantitative analytic methodologies and pursue developments in academia or other fields that affect tradecraft methodology.
 * Demonstrates ability to define comprehensive, new, or unique research approaches that enable rigorous assessments to address and contribute to high-level tasks.
 * Demonstrates in-depth analysis of analytic operations and knowledge management issues across organizational and intra-IC boundaries and clearly articulates key findings.
 * Demonstrates ability to work independently and with minimal oversight.
 * Demonstrates ability to review analytic products for cogent arguments, tradecraft standards, and adequate support for conclusions; routinely tests analytic rigor of analytic products.
   
   
   

Desired Experience


 * Minimum 12 years of experience related to the specific labor category with at least a portion of the experience within the last 2 years
   
   
   

Desired Education


 * Master’s degree in an area related to the labor category from a college or university accredited by an agency recognized by the U.S. Department of Education; or have Bachelor’s degree related to the labor category from a college or university accredited by an agency recognized by the U.S. Department of Education and an additional 5 years of related senior experience, for a total of 17 years, as a substitute to the Master’s degree.
   
   
   

Bluehawk, LLC. is an Equal Opportunity/Affirmative Action Employer

EOE Minority/Female/Disabled/Veteran/Sexual Orientation/Gender Identity","67 applicants","Full-time","Mid-Senior level","Information Technology","Defense and Space Manufacturing","","","","15248206","https://www.linkedin.com/jobs/view/data-engineer-sr-level-at-bluehawk-llc-intelligence-services-4341115915?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Rockville, MD","2 weeks ago","2025-11-12","https://www.linkedin.com/jobs/view/data-engineer-at-hyertek-4335611283?trk=public_jobs_topcard-title","HyerTek","https://www.linkedin.com/company/hyertekinc?trk=public_jobs_topcard-org-name","Description


 * The Data Engineer is responsible for architecting, developing, and managing data solutions across the Microsoft Power Platform and Dynamics 365 Finance & Operations (F&O) ecosystem. This role focuses on building scalable, secure, and reliable data pipelines and integration frameworks that enable seamless data movement, transformation, and analytics across Power Platform, Azure, and enterprise systems. The Data Engineer works closely with functional, development, and analytics teams to ensure D365 and Power Platform environments are optimized for data integrity, performance, and business intelligence.
   
   

Requirements

Data Architecture & Integration Design


 * Design and implement data integration architectures connecting D365 Finance, Power Platform (Dataverse, Power Apps, Power Automate), and external enterprise systems.
 * Develop robust data pipelines using Azure Data Factory, Logic Apps, or Power Automate for batch and real-time data movement.
 * Build and maintain Dataverse data models, including tables, relationships, and security roles.
   
   

Data Transformation & Management


 * Engineer and optimize ETL/ELT workflows to transform, cleanse, and load financial and operational data from multiple sources.
 * Leverage Dataflows and Power Query (M language) for in-platform data shaping and enrichment.
 * Configure and manage D365 Data Management Framework (DMF) entities for master data, transaction data, and recurring imports/exports.
   
   

Performance, Security, and Governance


 * Implement data governance policies including ownership, lineage, versioning, and audit trails.
 * Apply row-level security (RLS) and Azure Active Directory (AAD) role mapping for controlled access.
 * Monitor data refresh performance, error handling, and automation health across environments.
   
   

Analytics Enablement & Collaboration


 * Partner with Power BI developers to expose optimized datasets for analytics and executive dashboards.
 * Integrate D365 and Power Platform data into Azure Synapse, Data Lake, or Fabric for advanced reporting.
 * Document integration flows, schema mappings, and reusable data assets for ongoing operations.
   
   

Automation & Continuous Improvement


 * Use Power Automate and Logic Apps to orchestrate recurring data operations and workflow triggers.
 * Collaborate with D365 developers to align extensions and APIs with data design standards.
 * Continuously refine data models and processes to improve efficiency, maintainability, and reliability.
   
   

Qualifications


 * 5+ years of experience in data engineering, integration, or analytics architecture within Microsoft’s business applications ecosystem.
 * Deep technical expertise with Microsoft Power Platform (Dataverse, Power Apps, Power Automate) and Dynamics 365 Applications, particularly Finance and Sales Enterprise
 * Proficiency in Azure Data Factory, Logic Apps, Power Query (M), and SQL.
 * Experience working with D365 Data Entities, OData endpoints, and REST/JSON APIs.
 * Strong understanding of data modeling, normalization, and data warehousing principles.
 * Familiarity with Azure Synapse, Data Lake, or Microsoft Fabric for enterprise reporting enablement.
 * Knowledge of CI/CD pipelines, Git repositories, and environment promotion using Azure DevOps.
 * Excellent communication skills, with the ability to collaborate effectively across functional and technical teams.","106 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","","","","11393263","https://dc1prodrecruiting.paylocity.com/Recruiting/Jobs/Details/3709974/Hyertek?source=LinkedIn_Feed","EXTERNAL",""
"Business Intelligence and Data Visualization Analyst","Green Bay, WI","2 weeks ago","2025-11-13","https://www.linkedin.com/jobs/view/business-intelligence-and-data-visualization-analyst-at-american-foods-group-4335864918?trk=public_jobs_topcard-title","American Foods Group","https://www.linkedin.com/company/american-foods-group?trk=public_jobs_topcard-org-name","JOB SUMMARY

The Business Intelligence and Data Visualization Analyst will partner with the Manager of Business Intelligence & Analytics as

well as cross-functional leaders and departments on a growth journey by transforming operational data into actionable insights and measurable business value. This role is responsible for the design, implementation, and development of reporting and analytics solutions, with particular emphasis on data visualizations across Supply Chain (procurement, sales, distribution, operations and finance) and beyond. The ideal candidate must have a strong understanding of data visualization and an ability to deliver engaging, information data stories using a variety of techniques and tools.



This role requires a strategic thinker with a solid technical skill set and the ability to interact with cross-functional leaders and departments within the organization to find, consolidate, and manipulate data from multiple large data sets; analyze and understand results; and create reports, presentations, and/or dashboards.



ESSENTIAL FUNCTIONS AND RESPONSIBILITIES

 * Data Analysis and Data Visualization:
   * Assist with enterprise-wide reporting and analytics, translating complex data into dashboards that empower all teams making up the Supply Chain (procurement, finance, sales, operations, and distribution).
   * Develop data strategies&mdash;specifically around data structures, identifying critical information, as well as the tools used to retrieve and analyze the data. Performs research and analysis on large data sets, including data exploration, trending, modeling, etc.
   * Analyze business intelligence needs and requirements and provide data storage, analytical, or reporting tools in response.
   * Recommend data architecture and engineering structures necessary to support reports and dashboards.
   * Create dashboards, automated reports, report templates, and presentations. Using advanced data visualization tools, such as Power BI, to provide an easy-to-understand interface for end users to quickly identify key themes within data.
   * Develop standard or custom reports, queries, or dashboards that access and consolidate information from a variety of data sources and provide ongoing support for data users.
   * Utilize data mining techniques and develop data models to assist in the visualization and interpretation of data.
   * Assist with influencing business decisions through analytics and identify actionable, data-driven insights.
   * Responsible for daily/weekly/monthly reporting on business trends and the status of digital experience initiatives for senior management.
 * Continuous Improvement:
   * Understand and analyze interactive dashboards and reports in Power BI or One Steam to track KPIs, operational
   * performance, financial metrics, and business outcomes.
   * Participant in and complete end-to-end analytics projects: from scoping business questions, extracting and validating data, performing analysis, to presenting actionable findings and driving implementation.
   * As directed by the Manager, create and continuously improve dashboards and data analysis to support internal stakeholders ensuring insights are easily accessible and actionable.
   * Inform Manager on cutting edge data analytics and visualization technologies, that assist with the continuous improvement of processes and solutions.
   * Support strategic initiatives aimed at cost efficiency, process improvement, organizational design, and margin optimization.
   * Maintain current knowledge of updates to Power BI Service and Power BI Desktop and the ability to incorporate necessary and desired updates into new and existing reports.
   * Ensure accuracy, integrity, and consistency of data across all platforms and systems.

 * 
   

QUALIFICATIONS, KNOWLEDGE, SKILLS, AND EXPERIENCE

 * Bachelor’s degree in finance, accounting, data, economics or related field preferred.
 * 3+ years of professional experience required, with experience performing either strategic digital analysis, financial
 * analysis, or business intelligence analytics highly preferred.
 * Experience in financial modeling, analysis, and visualization including but not limited to cash flow, financial modeling and analysis and financial planning systems and ERP platforms (e.g. Infor M3, OneStream, Power BI, SQL, Tableau).
 * Experience working with exceptionally large data sets (on relational as well as non-relational data stores).
 * Expertise in Microsoft products including but not limited to Word, Excel, PowerPoint.

ADDITIONAL SKILLS/EXPERIENCE/REQUIREMENTS

 * Highly analytical, detail-oriented, and self-motivated, with the ability to work independently and cross functionally.
 * Ability to work effectively within a complex system, influence others, and drive results.
 * Strategic thinking, analytical and problem-solving skills with the ability to identify and drive business opportunities forward.
 * Complex problem-solving skills including Identifying complex problems and reviewing related information to develop and evaluate options and implement solutions.
 * Interpersonal and collaborative skills with a professional demeanor and the ability to interact with all levels of an organization.
 * Commitment to demonstrating the highest standard of ethical conduct and integrity; a willingness to continually embrace personal and professional development.

INTENT AND FUNCTION OF JOB DESCRIPTIONS

Job descriptions assist organizations in ensuring that the hiring process is fairly administered and that qualified employees are selected. All descriptions have been reviewed to ensure that only essential functions and basic duties have been included. Requirements, skills, and abilities included have been determined to be the minimal standards required to successfully perform the positions. In no instance, however, should the duties, responsibilities, and requirements delineated be interpreted as all-inclusive. Additional functions and requirements may be assigned by supervisors as deemed appropriate. Job descriptions are not intended as and do not create employment contracts. The organization maintains its status as an at-will employer. Employees can be terminated for any reason not prohibited by law.","Over 200 applicants","Full-time","Mid-Senior level","Finance and Manufacturing","Meat Products Manufacturing","","","","2127711","https://www.aplitrak.com/?adid=VHJpc3Rhblppb2xrb3dza2kuNjQ2ODYuMTU1MEBhbWVyaWNhbmZvb2RzZ3JvdXAuYXBsaXRyYWsuY29t","EXTERNAL",""
"Senior Market Data Engineer","New York City Metropolitan Area","3 weeks ago","2025-11-04","https://www.linkedin.com/jobs/view/senior-market-data-engineer-at-oakridge-staffing-4333969024?trk=public_jobs_topcard-title","Oakridge Staffing","https://www.linkedin.com/company/oakridge-staffing?trk=public_jobs_topcard-org-name","Our client, a leading hedge fund in New York City, is seeking an experienced Data Developer to join its core Data Engineering team. This group is responsible for designing, building, and maintaining the data pipelines and infrastructure that power investment research, trading strategies, and risk systems across the firm.

 * The ideal candidate is highly proficient in Python and SQL, with working experience in Databricks, and large-scale financial data environments.
 * The role involves working with both traditional vendor data (Bloomberg, FactSet, MSCI Barra, Refinitiv) and alternative datasets used in quantitative research and portfolio analytics.

Onsite New York City","186 applicants","Full-time","Mid-Senior level","Information Technology","Venture Capital and Private Equity Principals, Investment Management, and Investment Banking","$195,000.00/yr - $395,000.00/yr","Diana Gjuraj","https://www.linkedin.com/in/dianagjuraj","1772177","https://www.linkedin.com/jobs/view/senior-market-data-engineer-at-oakridge-staffing-4333969024?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Commuter benefits
Disability insurance"
"Senior Data Engineer","Phoenix, AZ","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/senior-data-engineer-at-u-haul-4338994263?trk=public_jobs_topcard-title","U-Haul","https://www.linkedin.com/company/u-haul-international-inc-?trk=public_jobs_topcard-org-name","Job Duties


 * Develop, debug and support applications for big data analytics platforms;
 * Designing, building, testing, implement technical architecture for big data applications;
 * Develop or Implement multi-threading and distributed systems;
 * Create big data pipelines using various analytics platforms;
 * Work with Data Science team to implement machine learning models using various container orchestration systems;
 * Demonstrate analytical and problem-solving skills in a Distributed Big Data Computing Environment;
 * Train, mentor and advise team members;
 * Quickly understand technical and business requirements and translate them into technical implementation;
 * Apply data science or machine learning to build data-driven products for solving business problems; and
 * Discuss requirements or knowledge/facts effectively with technical and non-technical members of the project team
   
   

Minimum Requirements

Master’s degree (or foreign equivalent) in Computer Science, Data Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics or a related field, more than five years of work experience coding software and two years of experience involving each of the following:


 * Java or Scala
 * Hadoop, Kafka, Data Lake or Databricks environments.
 * SQL
 * Apache Spark
 * Linux, Unix
 * HDFS or Databricks File System (DBFS)
 * Data science, data analytics, or machine learning
 * Scalability analysis and performance monitoring and measuring techniques
 * Hive and HBase
 * Zookeeper
   
   

OR Bachelor’s Degree (or Foreign Equivalent) In Computer Science, Data Science, Statistics, Mathematics, Engineering, Bioinformatics, Physics Or a Related Field, More Than Eight Years Of Work Experience Coding Software And Five Years Of Progressive Post-baccalaureate Experience Involving Each Of The Following


 * Java or Scala
 * Hadoop, Kafka, Data Lake or Databricks environments.
 * SQL
 * Apache Spark
 * Linux, Unix
 * HDFS or Databricks File System (DBFS)
 * Data science, data analytics, or machine learning
 * Scalability analysis and performance monitoring and measuring techniques
 * Hive and HBase
 * Zookeeper
   
   

U-Haul Offers


 * Full Medical coverage
 * Prescription plans
 * Dental & Vision Plans
 * New indoor fitness gym
 * Gym Reimbursement Program
 * Registered Dietitian Program 
 * Weight Watchers 
 * Onsite medical clinic for you and your family
 * Career stability
 * Opportunities for advancement
 * Valuable on-the-job training
 * Tuition reimbursement program
 * Free online courses for personal and professional development at U-Haul University®
 * Business and travel insurance
 * You Matter Employee Assistance Program
 * Paid holidays, vacation, and sick days 
 * Employee Stock Ownership Plan (ESOP)
 * 401(k) Savings Plan
 * Life insurance
 * Critical Illness/Group Accident
 * 24-hour physician available for kids
 * MetLaw Legal program
 * MetLife auto and home insurance
 * Mindset App Program
 * Discounts on cell phone plans, hotels, and more
 * LifeLock Identity Theft
 * Savvy consumer wellness programs - from health care tips to financial wellness
 * Dave Ramsey’s SmartDollar Program
 * U-Haul Federal Credit Union
 * Wellness Program","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Retail","","","","291044","https://uhaul.wd1.myworkdayjobs.com/UhaulJobs/job/Phoenix-Arizona/Senior-Data-Engineer_R233206/apply?source=LinkedIn","EXTERNAL",""
"Senior Data Engineer","Tysons Corner, VA","2 weeks ago","2025-11-14","https://www.linkedin.com/jobs/view/senior-data-engineer-at-the-swift-group-llc-4332002672?trk=public_jobs_topcard-title","The Swift Group, LLC","https://www.linkedin.com/company/the-swift-group-inc.?trk=public_jobs_topcard-org-name","The Swift Group is a privately held, mission-driven and employee-focused services and solutions company headquartered in Reston, VA. Our capabilities include Software Development, Engineering & IT, Data Science, Cyber Enablement, Logistics, and Training. Founded in 2019, Swift supports Civilian, Defense, and Intelligence Community customers across the country and around the globe.

We are looking for a Senior Data Engineer to join our dynamic data engineering team in Tysons Corner, VA. In this role, you will design, build, and operationalize robust and scalable data pipelines to enable secure data brokering and exchange across diverse producers and consumers. You will work hands-on with AWS cloud environments, automation tools, and modern data frameworks to drive reliability, performance, and innovation across distributed data ecosystems.

Responsibilities


 * Design, build, and maintain scalable, cloud-based data pipelines and supporting infrastructure
 * Collaborate with internal teams and external partners to broker and exchange data through APIs, S3, and other secure interfaces
 * Operationalize data pipelines leveraging Python-native and AWS-native tools for ingestion, transformation, and delivery
 * Provide day-to-day operational support, including Tier 2/3 troubleshooting and incident response for production data pipelines
 * Automate deployment and monitoring processes using Infrastructure-as-Code (IaC) tools such as Terraform, CloudFormation, or Ansible
 * Implement data security and compliance controls aligned with RMF principles across multiple classification domains
 * Participate in Agile development activities and contribute to continuous improvement of data engineering workflows
 * Stay informed on emerging data engineering technologies and best practices to drive innovation within the team
   
   

Requirements


 * US citizenship with an active TS/SCI with CI Polygraph required
 * 4+ years of hands-on experience in data engineering, data pipeline development, or cloud data systems
 * Proficiency in designing and deploying data pipelines leveraging AWS services across multiple classification domains (e.g., IL5 to IL6+)
 * Experience with Infrastructure-as-Code (IaC) tools such as Terraform, CloudFormation, or Ansible
 * Understanding of RMF security principles and experience implementing security controls for cloud data systems
 * Strong programming and scripting skills in Go, Python, and Bash
 * Experience with data pipeline tools and platforms such as NiFi, Hadoop, HDFS, Kafka, or Cloudera Data Platform
 * Proficiency with Linux environments and troubleshooting distributed data systems
 * Excellent communication skills and ability to collaborate effectively with cross-functional teams
   
   

Desired Experience


 * Experience working with data lake and big data technologies such as Spark, Accumulo, or Elasticsearch
 * Experience automating data delivery workflows and monitoring systems for high availability
 * Familiarity with Agile methodologies and collaboration tools like Jira and Confluence
 * Background in performance optimization and tuning of large-scale data pipelines
   
   

Please note: we are not working with staffing agencies to fill these positions and are not accepting any unsolicited resumes from agencies.

#Onsite

The Swift Group and Subsidiaries are an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status, or any other protected class.

Pay Range: $49,996.80 - $290,004.00

Pay ranges are a general guideline and not intended as a guaranteed and/or implied final compensation or salary for this job opening. Determination of official compensation or salary relies on several different factors including, but not limited to: level of position, complexity of job responsibilities, geographic location, work experience, education, certifications, Federal Government contract labor categories, and contract wage rates.

At The Swift Group and Subsidiaries, you will receive comprehensive benefits including but not limited to: healthcare, wellness, financial, retirement, education, and time off benefits.

","Be among the first 25 applicants","Full-time","Mid-Senior level","Information Technology, Analyst, and General Business","IT Services and IT Consulting","$49,996.80/yr - $290,004.00/yr","Dan Irish","https://www.linkedin.com/in/dtirish","15413468","https://www.linkedin.com/jobs/view/senior-data-engineer-at-the-swift-group-llc-4332002672?trk=public_jobs_topcard-title","EASY_APPLY",""
"Manager, Business Intelligence Engineering","Palo Alto, CA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/manager-business-intelligence-engineering-at-snap-inc-4338442438?trk=public_jobs_topcard-title","Snap Inc.","https://www.linkedin.com/company/snap-inc-co?trk=public_jobs_topcard-org-name","Snap Inc is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are Snapchat, a visual messaging app that enhances your relationships with friends, family, and the world; Lens Studio, an augmented reality platform that powers AR across Snapchat and other services; and its AR glasses, Spectacles.

The Data Science & Insights team seeks to leverage our massive data sets into actionable insights that deliver business value. As truth seekers and truth tellers, we relay what the data says without bias, even when inconvenient or difficult. We aim to improve decision-making quality and speed across the organization to enable a deeper understanding of our customers and products. We focus on efficient and effective analytic execution, positioning ourselves as the go-to experts with deep knowledge and expertise, constantly striving for better, faster insights from data.

We’re looking for a Manager, Business Intelligence Engineering to join Snap Inc!

What you’ll do:


 * Lead a team to establish foundational data and analytics capabilities for our ads platform and identify key insights around our ads platform.
 * Collaborate with Data Science, Product, and Engineering, and Business partners to design and build data tools/visualizations, operationalize metrics, conduct investigations, deliver actionable insights, and conduct in-depth product analysis.
 * Understand the challenges within our ads platform and help make decisions based on data driven insights by analyzing information from multiple sources in a logical and coherent data story
 * Build and maintain dashboards that communicate the performance of the various components of our ads platform with compelling data visualizations and consistency
 * Develop data pipelines that power our analytics data layer for analysis, reporting and dashboarding ensuring efficiency and reliability
 * Own the data model used to power our underlying data layer for monetization including the associated pipelines, data structures, and schemas
 * Maintain the key metric definitions and understand them at a deep level, offering recommendations for improvements and new metrics
 * Conduct exploratory and deep dive analysis to understand drivers of revenue performance and overall platform performance, developing actionable insights to Product and Engineering leadership
 * Own root-cause investigations starting from proactive identification of metric regressions to resolution including recommendations for long term product improvements
 * Proactively identify improvements to our platform or business that can be expected to drive increased revenue
   
   

Knowledge, Skills & Abilities:


 * Data driven and analytical mindset
 * Hands-on expertise with data warehousing tools and workflow automation
 * Comfortable with quantitative concepts
 * Strong attention to detail and organizational skills
 * Excellent verbal and written communication skills
 * Ability to work in an agile, dynamic environment
 * Ability to use tech to improve work-flows and create efficiencies
   
   

Minimum Qualifications:


 * BS/BA degree in Analytics, Statistics, Economics or other technical field or equivalent years of experience
 * 10+ years of post-Bachelor’s analytics experience; or a Master’s degree in a technical field + 9+ year of post-grad analytics experience; or a PhD in a related technical field + 6+ years of post-grad analytics experience
 * 1+ years relevant people management experience
   
   

Preferred Qualifications:


 * Advanced Degree in Analytics, Statistics, Economics, Computer Science or other technical field
 * Experience as a data scientist and/or managing a data team
 * Experience in the digital media space
 * A passion for Snapchat as a user and knowledge of our ad products
 * Proficiency in Looker, BigQuery, and Airflow
   
   

If you have a disability or special need that requires accommodation, please don’t be shy and provide us some information.

""Default Together"" Policy at Snap: At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office 4+ days per week.

At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets.

We are an Equal Opportunity Employer and will consider qualified applicants with criminal histories in a manner consistent with applicable law (by example, the requirements of the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, where applicable).

Our Benefits: Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid parental leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success!

Compensation

In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. The starting pay may be negotiable within the salary range for the position. These pay zones may be modified in the future.

Zone A (CA, WA, NYC):

The base salary range for this position is $209,000-$313,000 annually.

Zone B:

The base salary range for this position is $199,000-$297,000 annually.

Zone C:

The base salary range for this position is $178,000-$266,000 annually.

This position is eligible for equity in the form of RSUs.","65 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Software Development","$178,000.00/yr - $313,000.00/yr","","","15191764","https://wd1.myworkdaysite.com/en-US/recruiting/snapchat/snap/job/Los-Angeles-California/Manager\u002d\u002dBusiness-Intelligence-Engineering_R0043164-1?source=LinkedIn","EXTERNAL",""
"Business Intelligence Developer","Core, WV","6 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/business-intelligence-developer-at-wvu-medicine-4348154250?trk=public_jobs_topcard-title","WVU Medicine","https://www.linkedin.com/company/wvumedicine?trk=public_jobs_topcard-org-name","Welcome! We’re excited you’re considering an opportunity with us! To apply to this position and be considered, click the Apply button located above this message and complete the application in full. Below, you’ll find other important information about this position.

Responsible for design, development, testing, implementation, and maintenance of enterprise analytics, reporting and data warehousing needs. Design, innovate, and implement solutions as needed to improve systems and processes. Assists customers in identifying reporting/data extraction solutions to meet functional needs, streamline or assist with operations, and ensure patient safety and confidentiality. Possesses critical thinking skills to assess analytical needs and determine the appropriate course of action. Use of performance improvement, project management, cost accounting, industrial engineering, and technology skills will be employed to work with all levels of WVUHS management and medical staff. Continuous learning of current data base structure, tools, and extraction methods are required to confer with customers and other members of the application teams.

MINIMUM QUALIFICATIONS:

EDUCATION, CERTIFICATION, AND/OR LICENSURE:


 * Master’s degree in Information Technology/Computer Science, Engineering, Business Management, Business Administration,
   
   

Accounting, or Hospital Administration, OR 4 years of data analytics experience required.


 * This position may require certification in support of the responsibilities of the position, which will be provided by WVUHS Information Technology. Certification completion will be required within the new hire probationary period.
   
   

EXPERIENCE:


 * Minimum 1 year experience working with relational data base structures including design, testing, troubleshooting problems and/or training required.
 * 1 year of experience in data analysis and/or health care planning background required.
 * 1 year of experience with reporting tools such as Crystal Reports required.
 * Experience with Structured Query Language (SQL/Oracle) and/or Business Objects required.
 * Internal employees must meet all mandatory competencies in current position in order to qualify for promotion within IT.
   
   

OR

EDUCATION, CERTIFICATION, AND/OR LICENSURE:


 * Bachelor’s degree in Information Technology/Computer Science, Engineering, Business Management, Business Administration, Accounting, OR 4 years of data analytics experience required
 * This position may require certification in support of the responsibilities of the position, which will be provided by WVUHS Information Technology. Certification completion will be required within four months of formal certification training completion.
   
   

EXPERIENCE:


 * 2 years of experience working with relational data base structures including design, testing, troubleshooting problems and/or training required.
 * 2 years of experience in data analysis and/or health care planning background required.
 * 2 years of experience with reporting tools such as Crystal Reports required.
 * Experience with Structured Query Language (SQL/Oracle) and/or Business Objects required.
 * Internal employees must meet all mandatory competencies in current position in order to qualify for promotion within IT.
   
   

EXPERIENCE:

PREFERRED QUALIFICATIONS:


 * Familiarity of applications to be supported preferred.
   
   

CORE DUTIES AND RESPONSIBILITIES: The statements described here are intended to describe the general nature of work being performed by people assigned to this position. They are not intended to be constructed as an all-inclusive list of all responsibilities and duties. Other duties may be assigned.


 * Business Requirements, Process Analysis and Report Writing: Writes and develops reports independently and generates business analysis. Ensures end users' knowledge and usage of the developed tools and reports are satisfactory. Makes suggestions for problems, solutions, or enhancements; partners with subject matter expert to understand problems and/or inefficiencies. Completes service requests independently. Meets with customers to understand business needs for reporting requests and help identify opportunities to deliver business intelligence solutions that align with organizational strategies. Utilizes knowledge of all aspects of information technology including data management, data standards, data relationships, database structures, system design, systems implementation to create moderate to complex reports. Produces moderate to complex reports using reporting tools such as Access, Crystal, Sequel Developer or. Identifies data sources and the appropriate data fields to use for reporting and analytic needs. Determines the most ideal business tool. Communicates systems improvement analysis, findings, recommendations, and PI tools. Provides formal and informal presentations and overviews to all levels of staff and management of WVUHS and related parties. Educates Performance Improvement teams regarding process and data issues. Maintains superior software skills needed to produce high quality graphics and presentations and formal written reports. Confers with users to design and maintain analytics that effectively communicate data trends needed to measure PI activities and/or project goals.
 * Operations Analysis: Independently diagnoses and resolves issues and/or incidents for moderate complex business systems or processes. Analyzes information in the reports developed to identify issues, trends, or interesting findings to be shared with the customer and propose alternative solutions.
 * Systems Analysis and Integration: Independently active in system upgrades and enhancements. Independently completes functional testing. Creates prototype designs for basic to moderately complex workflow and/or programs. Development of solutions by applying knowledge of data structures and extraction techniques. Builds, tests and implements basic to moderately complex specifications and changes with customers. Ability to define system capabilities and requirements of customers. Assists in training of customer’s team members.
 * Project Coordination: Defines tasks and creates team work plans with moderate supervision. Delegates work to others and monitors progress. Identifies issues affecting work progress and recommends solutions. Assists Senior BI Developer in controlling project costs, communicating any project-related expenses and recommends ways to control costs (if assigned).schedule variances and potential scope changes, task, goals and milestones in status reports and/or appropriate personnel. Measures the progress toward goals and revises work plan accordingly. Participates with management personnel in planning, direction, and coordinating operational and/or procedural matters to meet goals and objectives. Functions as the project coordinator when assigned by management. Duties include project time management, task and personnel coordination and scope management. Follows hospital’s project management methodology. Provides project coordination services to customers as assigned. Delegates work to associate and monitors progress. Assures project changes or additions updated using appropriate project management toolsets. Ability to organize and prioritize multiple simple to moderately complex assigned task. Provides input into the assessment of appropriate work effort for a task or project.
 * Team Building: Assists and mentors co-workers. Seeks and respects the views of others, including patients/families and customers when appropriate. Creates and updates internal documentation for team members to use. Coaches and provides support/encouragement for employees to exceed their own expectations.
 * Adheres to the established policies of the West Virginia United Health System (WVUHS) as well as the policies of the entity or entities where the IT team member is assigned to work and/or employed.
 * This position may require travel to other West Virginia United Health System (WVUHS) facilities or affiliated sites to assist with implementations, training, and/or support
 * Accepts on-call responsibilities and responds with action, either by phone call or on-site as defined by Department Policy.
 * Other duties may be assigned.
   
   

PHYSICAL REQUIREMENTS: The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.


 * Frequent walking, standing, stooping, kneeling, reaching, pushing, pulling, lifting, grasping are necessary body movements utilized in performing duties through the work shift.
   
   

WORKING ENVIRONMENT: The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.


 * The work environment is a standard office environment.
   
   

SKILLS AND ABILITIES:


 * Ability to handle and maintain confidential information
 * Ability to work well under high stress conditions.
 * Ability to work independently or cooperatively as a team member.
 * Ability to adapt to various workloads and assignments.
 * Ability to work with multi-disciplinary groups and facilitate meetings.
 * Must have reading and comprehension ability.
 * Must be able to type.
 * Possess good oral and written communication skills.
 * Ability to prioritize tasks.
 * Must have independent decision-making ability.
 * Ability to work in a fast paced and rapidly changing environment. Must be flexible.
   
   

Additional Job Description:

Scheduled Weekly Hours:

40

Exempt/Non-Exempt:

Shift:

United States of America (Exempt)

Company:

SYSTEM West Virginia University Health System

Cost Center:

525 SYSTEM IT Strategic Analytics","26 applicants","Full-time","Mid-Senior level","Information Technology","Hospitals and Health Care","","","","6738","https://www.linkedin.com/jobs/view/business-intelligence-developer-at-wvu-medicine-4348154250?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Jersey City, NJ","2 weeks ago","2025-11-17","https://www.linkedin.com/jobs/view/data-engineer-at-mastech-digital-4341123256?trk=public_jobs_topcard-title","Mastech Digital","https://www.linkedin.com/company/mastech?trk=public_jobs_topcard-org-name","Mastech Digital Inc. (NYSE: MHH) is a minority-owned, publicly traded IT staffing and digital transformation services company. Headquartered in Pittsburgh, PA, and established in 1986, we serve clients nationwide through 11 U.S. offices.




Role: Data Engineer

Location: Merrimack, NH/Smithfield, RI/Jersey City, NJ

Duration: Full-Time/W2




 * Job Description:
 * Must-Haves:

Python for running ETL batch jobs

Heavy SQL for data analysis, validation and querying

AWS and the ability to move the data through the data stages and into their target databases.

The Postgres database is the target, so that is required.




Nice to haves:

 * Snowflake
 * Java for API development is a nice to have (will teach this)
 * Experience in asset management for domain knowledge.
 * Production support debugging and processing of vendor data




The Expertise and Skills You Bring

 * A proven foundation in data engineering – bachelor’s degree + preferred, 10+ years’ experience
 * Extensive experience with ETL technologies
 * Design and develop ETL reporting and analytics solutions.
 * Knowledge of Data Warehousing methodologies and concepts – preferred
 * Advanced data manipulation languages and frameworks (JAVA, PYTHON, JSON) – required
 * RMDS experience (Snowflake, PostgreSQL ) – required
 * Knowledge of Cloud platforms and Services (AWS – IAM, EC2, S3, Lambda, RDS ) – required
 * Designing and developing low to moderate complex data integration solution – required
 * Experience with DevOps, Continuous Integration and Continuous Delivery (Maven, Jenkins, Stash, Ansible, Docker) will be preferred
 * Expert in SQL and Stored Procedures on any Relational databases
 * Good in debugging, analyzing and Production Support
 * Application Development based on JIRA stories (Agile environment)
 * Demonstrable experience with ETL tools (Informatica, Snaplogic)
 * Experience in working with Python in an AWS environment
 * Create, update, and maintain technical documentation for software-based projects and products.
 * Solving production issues.
 * Interact effectively with business partners to understand business requirements and assist in generation of technical requirements.
 * Participate in architecture, technical design, and product implementation discussions.
 * Working Knowledge of Unix/Linux operating systems and shell scripting
 * Experience with developing sophisticated Continuous Integration & Continuous Delivery (CI/CD) pipeline including software configuration management, test automation, version control, static code analysis.
 * Excellent interpersonal and communication skills
 * Ability to work with global Agile teams
 * Proven ability to deal with ambiguity and work in fast paced environment
 * Ability to mentor junior data engineers.




The Value You Deliver

 * The associate would help the team in designing and building a best-in-class data solutions using very diversified tech stack.
 * Strong experience of working in large teams and proven technical leadership capabilities
 * Knowledge of enterprise-level implementations like data warehouses and automated solutions.
 * Ability to negotiate, influence and work with business peers and management.
 * Ability to develop and drive a strategy as per the needs of the team




Good to have: Full-Stack Programming knowledge, hands-on test case/plan preparation within Jira

","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Banking, Financial Services, and IT Services and IT Consulting","","Gulati Gaurav","https://in.linkedin.com/in/gulati-gaurav","3684","https://www.linkedin.com/jobs/view/data-engineer-at-mastech-digital-4341123256?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
Disability insurance"
"Sr Data Analyst","Clearwater, FL","2 days ago","2025-11-29","https://www.linkedin.com/jobs/view/sr-data-analyst-at-lincare-4338147888?trk=public_jobs_topcard-title","Lincare","https://www.linkedin.com/company/lincare?trk=public_jobs_topcard-org-name","This employee will be responsible for completing any and all assigned projects including but not limited to; learning the necessary skills required, managing work time to meet deadlines, take initiative and architect a solution for any obstacles, and work respectfully with their fellow co-workers. They will be expected to take on more complex projects which may include more advanced skills such as coding in advanced languages, building machine learning algorithms, maintaining advanced department tools, using advanced mathematics to produce valid statistical

models, or use any other advanced techniques. Finally, they will be required to openly share/teach and lead junior analysts in the development of their skills and knowledge for the overall advancement of the department.

JOB FUNCTIONS


 * Perform analysis on large volume of complex call center data, medication, diagnosis, and patient information from diverse sources to generate actionable insights aimed at increasing revenue and margin. Create end-to-end analytics solutions with the experience of designing scalable data models and ETLs partnering with developers to design, build and operationalize dashboards, reports and data sources.
 * Design data lakes and architect robust pipelines in Azure cloud, including but not limited to, Azure virtual machines, Azure data factory (ADF), and Azure data lake storage (ADLS), and generate insightful reports using visualization tools such as Tableau, Power BI, and Excel alongside programming languages, including SQL, Python, and R to align business objectives.
 * Utilize statistical techniques and predictive modelling to forecast patient compliance and call recommendation based on device usage by patients and call patterns.
 * Facilitate knowledge sharing and maintain a library of reusable assets, such as scripts and queries in Azure DevOps enabling version control to enhance efficiency.
 * Lead the synthesis of current business intelligence, perform data collection from various sources, data mining, and determine storage methods and analysis related to call center operations involving AVAYA Proactive Outreach Manager (POM) to support actionable recommendations for executives, managers, and stakeholders, focusing on operations and omnichannel outreach strategies.
 * Drive BI engineering best practices, including code reviews, syntax and naming conventions, metric definitions, and BI operational excellence.
 * Spearhead process enhancement and identify manual data/business process for automation, leveraging Lean principles, appropriate technologies, and tools such as Celonis and Power-automate.
 * Drive project initiatives to enhance revenue, profitability, and customer experience by proactively identifying opportunities and scope, and presenting findings to the senior executives.
 * Directly supervise one (1) Operations Analyst.
 * Remote work may be permitted within a commutable distance from the worksite.
 * 10% of domestic travel required.
   
   

JOB FUNCTIONS


 * Full Time - Mon-Fri (40/hrs a week)
   
   

We are looking forward to receiving your complete application by selecting the 'Apply' button.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Hospitals and Health Care","","","","471174","https://myjobs.adp.com/externallincarecareers/cx/job-details?reqId=5001135581606&rb=LINKEDIN","EXTERNAL",""
"Data Engineer, Business Solutions","Boston, MA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/data-engineer-business-solutions-at-audax-group-4339091834?trk=public_jobs_topcard-title","Audax Group","https://www.linkedin.com/company/audaxgroup?trk=public_jobs_topcard-org-name","Founded in 1999, Audax Group is a leading alternative investment manager with offices in Boston, New York, San Francisco, London and Hong Kong. With approximately $42 billion of assets under management and more than 475 employees, Audax is a leading capital partner for middle market companies, operating through three business lines: Audax Private Equity, Audax Private Debt, and Audax Strategic Capital.

For more information, visit the Audax Group website www.audaxgroup.com. or follow us on LinkedIn.

Position Summary

Audax is looking for a dynamic, motivated Data Engineer to join the business solutions team in our Boston office. This position will have responsibility for technical design, implementation, support and maintenance of the firm's strategic data warehouse. This position will also play a key role in selection, design, and implementation of data ingestions, integration and transformation technologies.

The candidate will have the opportunity to utilize a wide range of internal and external data sources to drive insights and growth at Audax across the Private Debt strategy. The candidate will have access to the top middle market investment professionals and help to devise a scalable data infrastructure and strategy to meet the needs of our investment strategy and growth plans.

Responsibilities

Designing, implementing, maintaining and scaling the Audax data ecosystem


 * Working with business solutions and private debt professionals to address the firm’s business priorities in an innovative and scalable way.
 * Help design, implement, and grow private debt’s Snowflake data infrastructure and capabilities.
 * Assist in data architecture for AI enablement.
 * Review data work done internally and externally and provide meaningful feedback and insights.
 * Implement best practices in data transformation and storage.
 * Tackling new data sources and devising the best way to distill and store data.
 * Solving problems and troubleshooting data issues as they arise
   
   

Technology Competencies


 * Knowledge of/Experience designing, building, and maintaining a scalable data architecture.
 * Excellent understanding and proven experience in the areas of data transformation and storage.
 * Experience designing and implementing optimal data schema
 * Understanding of different data use cases and the most effective way to address them
 * Experience working with cloud-based data storage technologies (Snowflake)
 * Knowledge of/Experience with implementing best practices in data governance
   
   

Requirements/Qualifications


 * BS/BA and/or MS in Data engineering, Computer science or related field
 * 2-4 years professional experience in a data engineering role
 * Deep knowledge of data transformation and integration
 * Deep knowledge of database storage technologies
 * Experience taking large data sets, and cleaning/distilling these data sets
 * Ability to think critically and recognize opportunities for optimization
 * Curiosity to learn and explore new solutions and technologies in the data space
 * Experience with SQL, cloud database technologies required
 * Experience with python required
 * Experience with Alteryx and its advanced capabilities a plus
 * Experience with Streamlit a plus
 * Experience with capturing and storing data streams required; experience with demographic and financial data streams, a major plus
 * Strong written and oral communication skills required
 * Ability to interact in an efficient and meaningful way with all levels of the organization required
   
   

Other Duties

This job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee. Duties, responsibilities and activities may change or new ones may be assigned at any time with or without notice.

LOCATION: Boston, MA. 4 days/week in office. These in-office requirements may change based on the needs of the business.

For Massachusetts only: The base salary range for this position is $108,000- $130,000. The base salary range represents the estimated low and high end for this position at the time of this posting. Consistent with applicable law, compensation may vary and will be determined based on but not limited to, the skills, qualifications, and experience of the applicant along with the requirements of the position, and Audax reserves the right to modify this pay range at any time. An employee may also be eligible for annual discretionary incentive compensation based on performance.

Audax offers a wide range of employee benefits, including health insurance, life insurance, disability insurance, paid time off (including sick leave, parental leave, volunteer leave, and vacation), charitable donation match, family support services (including Bright Horizons and Benefit Advocate Center), and a 401(k) in addition to other benefits.

This job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee. Duties, responsibilities and activities may change or new ones may be assigned at any time with or without notice.

Audax Management Co. is an equal opportunity employer.

Please note that Audax Group and its affiliated entities do not accept unsolicited resumes from a third-party recruiting agency not currently under a signed agreement. Any unsolicited resume that is sent to directly to Audax Group or one of its affiliated entities, or its employees, including those submitted to hiring managers by a third-party recruiting agency not currently under a signed agreement, will be considered property of Audax Group. If a third-party recruiting agency submits a resume without an agreement, Audax Group or its affiliated entities explicitly reserves the right to pursue and hire those candidate(s) without any financial obligation to the third-party recruiting agency. Any third-party recruiting agency should contact either a member of the Talent Acquisition or Human Resource team at Audax Group, in conjunction with a valid, fully executed contract for service based upon a specific job opening.","Over 200 applicants","Full-time","Entry level","Information Technology","Investment Management","$108,000.00/yr - $130,000.00/yr","","","1137783","https://www.linkedin.com/jobs/view/data-engineer-business-solutions-at-audax-group-4339091834?trk=public_jobs_topcard-title","EASY_APPLY",""
"Machine Learning Engineer","Tampa, FL","3 weeks ago","2025-11-06","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-premier-group-4334771000?trk=public_jobs_topcard-title","Premier Group","https://uk.linkedin.com/company/premier-group-recruitment?trk=public_jobs_topcard-org-name","Machine Learning Engineer




Tampa, Sun Bay South




Onsite




$180K - $210K + benefits




Premier Group has partnered with a leading defense technology company developing mission-critical AI and data-driven solutions that support national security, intelligence, and military operations. Their team work on cutting-edge projects at the intersection of artificial intelligence, data science, and advanced engineering, helping defence and government agencies make faster, smarter decisions.




Due to the nature of the work, this is an onsite role & you must have an active U.S Government Security Clearance with SCI eligibility.




As a Machine Learning Engineer, you’ll design, build, and deploy intelligent systems that extract actionable insights from complex data sources. You’ll work alongside data scientists, software engineers, and domain experts to develop scalable ML pipelines and algorithms for applications such as situational awareness, predictive maintenance, signal processing, and autonomous systems.




Responsibilities:

 * Able to build robust pipelines across divers compute environments.
 * Implement CI/CD pipelines for ML workflows.
 * Manage ML infrastructure using Docker, Kubernetes.

Skills:

 * 5 years’ experience in a software engineering or machine learning.
 * Experienced in MLOps and frameworks.
 * Familiar with PyTorch.

If you’re a Machine Learning Engineer who’s looking to join a business at the forefront of defense, please do apply now for immediate consideration.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Information Services and Defense and Space Manufacturing","$180,000.00/yr - $210,000.00/yr","Conor Pearce","https://www.linkedin.com/in/conor-pearce","401618","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-premier-group-4334771000?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Pension plan"
"Data Engineer","Herndon, VA","3 weeks ago","2025-11-07","https://www.linkedin.com/jobs/view/data-engineer-at-bespoke-technologies-inc-4333012402?trk=public_jobs_topcard-title","Bespoke Technologies, Inc.","https://www.linkedin.com/company/bespoketechinc?trk=public_jobs_topcard-org-name","BT-152 – Data Engineer

Skill Level: Mid

Location: Chantilly/Herndon


 * MUST HAVE AN ACTIVE TS OR TS/SCI CLEARANCE TO APPLY. Those without an active security clearance will not be considered.**
   
   

Role Description

As a Data Engineer, you will be a hands-on builder and a key member of the team creating and sustaining the data lifeblood of the platform. You will apply your technical skills to develop, deploy, and maintain resilient and efficient data pipelines. This role is perfect for a practitioner who is passionate about leveraging modern tools and automation to solve complex data challenges and deliver high-quality data solutions.

Responsibilities


 * Design, develop, and maintain robust and scalable data pipelines for both new development and ongoing operations & maintenance (O&M).
 * Build new pipelines using modern, modular patterns like Databricks Delta Live Tables, adhering to established governance standards.
 * Implement reusable pipeline templates and automated monitoring patterns to ensure consistency and scalability across all data flows.
 * Utilize Infrastructure-as-Code (IaC) with tools like Terraform to create consistent and repeatable CI/CD deployments.
 * Integrate automated data quality checks and profiling using frameworks like Great Expectations to ensure data integrity and validate SLAs.
 * Troubleshoot pipeline issues, optimize performance, and contribute to the continuous improvement of O&M processes.
 * Participate in code reviews and create clear documentation for ETL mappings, code, and deployment processes.
   
   

Required Qualifications


 * 4+ years of experience in data engineering.
 * Experience with the development and maintenance of extract, transform, and load (ETL) tools and services.
 * Proficiency in Python, SQL, and Spark/PySpark.
 * Experience with cloud data platforms (e.g., AWS, Azure) and data engineering platforms like Databricks, Palantir, or Snowflake.
 * Experience working in an Agile/Scrum environment.
   
   

Preferred Qualifications


 * Direct experience with the data platform.
 * Experience working in high-security environments (e.g., SIPR, JWICS).
 * Hands-on experience with Databricks Delta Live Tables and Terraform.
 * Familiarity with data orchestration tools (e.g., Airflow) and containerization (Docker, Kubernetes).
 * Knowledge of COTS and open-source data engineering tools such as NiFi or ElasticSearch.","94 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","","","","71291624","https://www.linkedin.com/jobs/view/data-engineer-at-bespoke-technologies-inc-4333012402?trk=public_jobs_topcard-title","EASY_APPLY",""
"Distinguished Planning Machine Learning Engineer - Autonomous Vehicles","Santa Clara, CA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/distinguished-planning-machine-learning-engineer-autonomous-vehicles-at-nvidia-4333108187?trk=public_jobs_topcard-title","NVIDIA","https://www.linkedin.com/company/nvidia?trk=public_jobs_topcard-org-name","NVIDIA is looking for an experienced Machine Learning Engineer to join its Autonomous Vehicle team. As a member of our team you will develop key features for our autonomous driving platform. In this role, you will apply machine learning to a mix of prediction, planning, and control problems. You will create innovative ML solutions for NVIDIA’s next-generation automotive products. The candidate is required to have hands-on experience and deep knowledge in machine learning. Understanding of deep neural networks, autonomous vehicles, and domain adaptation is highly desirable. You are encouraged to work across people and project boundaries, and among computer vision, computer graphics, and machine learning approaches. You should have strong research, SW development, communication, interpersonal, and analytical skills. Join us and help craft the future of AI automation.

What You’ll Be Doing


 * Researching, implementing, and evaluating deep-learning-based methods for prediction and planning for NVIDIA's Autonomous Vehicle products.
 * Leading, Designing, running, and analyzing experiments and testing to evaluate the efficiency of our solutions on real-world data.
 * Partnering with system software engineering specialists to ship industrial strength ML models.
 * Communicating and collaborating with multi-functional teams.
   
   

What We Need To See


 * BS/MS/PhD in computer science, electrical engineering, mechanical engineering, applied math, or related fields (or equivalent experience)
 * 25+ years of proven experience building ML systems for autonomous vehicles or similar robotics applications
 * Deep understanding of large language models (LLM) and transformers
 * Hands on experience building large scale production ML systems and deploying them at scale
 * Excellent leadership and track record for innovation to help us build the next generation of our ML based planning solutions
 * Experience with deep neural network (DNN) training, inference and optimization in leading frameworks (Pytorch, Tensorflow, TensorRT, etc.).
 * Excellent understanding of the mathematical foundations of machine learning and deep learning.
   
   

Ways To Stand Out From The Crowd


 * Prior experience as a ML planning lead
 * Proven publication record in ML for planning, vision, or related fields
 * Prior experience building and deploying vision language action or chain of thought models
   
   

Academic and commercial groups around the world are powering a revolution in AI using deep learning techniques running on NVIDIA GPUs, enabling breakthroughs in problems from image classification to speech recognition to natural language processing and autonomous vehicles. Intelligent AI computers that can learn, reason and interact with people are no longer science fiction. Today, a self-driving car powered by AI can meander through a country road at night and find its way. An AI-powered robot can learn motor skills through trial and error. This is truly an outstanding time. The era of AI has begun and NVIDIA is leading the way with revolutionary hardware and software. Come join us at NVIDIA!

Your base salary will be determined based on your location, experience, and the pay of employees in similar positions. The base salary range is 308,000 USD - 471,500 USD.

You will also be eligible for equity and benefits .

Applications for this job will be accepted at least until July 29, 2025.NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.

JR1996559

","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering","Computer Hardware Manufacturing, Software Development, and Computers and Electronics Manufacturing","$308,000.00/yr - $471,500.00/yr","","","3608","https://nvidia.wd5.myworkdayjobs.com/NVIDIAExternalCareerSite/job/US-CA-Santa-Clara/Distinguished-Planning-Machine-Learning-Engineer\u002d\u002d-Autonomous-Vehicles_JR1996559-1?source=jobboardlinkedin","EXTERNAL",""
"Senior Data Engineer","West Hollywood, CA","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/senior-data-engineer-at-pluto-tv-4336294444?trk=public_jobs_topcard-title","Pluto TV","https://www.linkedin.com/company/pluto-tv?trk=public_jobs_topcard-org-name","#WeAreParamount on a mission to unleash the power of content… you in?

We’ve got the brands, we’ve got the stars, we’ve got the power to achieve our mission to entertain the planet – now all we’re missing is… YOU! Becoming a part of Paramount means joining a team of passionate people who not only recognize the power of content but also enjoy a touch of fun and uniqueness. Together, we co-create moments that matter – both for our audiences and our employees – and aim to leave a positive mark on culture.

In This Role You’ll:

The Senior Data Engineer should possess a deep sense of curiosity and a passion for building data pipelines, data structures and data products and the ability to communicate data structures and tools throughout the Paramount Digital Media organization.

The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. They will have experience supporting data pipeline development, which includes machine learning algorithms using disparate data sources. They will work closely with BI, Research, Engineering, Marketing, Finance, and Product teams to implement data-driven plans that drive the business. They will also be able to lead a project from inception to completion, as well as help mentor junior members of the team on standard processes and approaches around data.

Responsibilities Include:


 * Works with large volumes of traffic data and user behaviors to build pipelines that enhance raw data.
 * Able to break down and communicate highly complex data problems into simple, feasible solutions.
 * Extract patterns from large datasets and transform data into an informational advantage.
 * Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations.
 * Partner with the internal product and business intelligence teams to determine the best approach around data ingestion, structure, and storage, and ensure successful implementation in partnership with the team.
 * Lead initiatives to improve data quality and effectiveness by contributing ideas and collaborating with engineering, BI teams, and business units to implement changes.
 * Ongoing development of technical solutions while developing and maintaining documentation, at times training impacted teams.
 * Early on collaboration with the team on internal initiatives to create strategies that improve company processes.
 * Look at ways of improving efficiency by staying current on the latest technology and trends and introducing team members to such.
 * Develop prototypes to proof out strategies for data pipelines and products.
   
   

Basic Qualifications You Bring:


 * Bachelor's degree and 4+ years of experience in Data Engineering and Analytics fields or consulting roles with a focus on digital analytics implementations.
 * Experience with large scale data warehouse management systems such as BigQuery with advanced level understanding of warehouse cost management and query optimization
 * Proficient in Python.
 * Experience with Airflow or equivalent tools for orchestration of pipelines.
 * Experience with Data Modeling of performant table structures.
 * Able to write SQL to perform common types of analysis and transformations.
 * Strong problem-solving and creative-thinking skills.
 * Ability to design and implement technical solutions, maintain accurate documentation, and deliver training to impacted teams as needed.
 * Experience developing solutions to business requirements via hands-on discovery and exploration of data.
 * Excellent written and verbal communication skills, including the ability to communicate technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions
 * Strong experience with ETL & ELT.
 * Experience building and deploying applications on GCP cloud platform.
 * Influences and applies data standards, policies, and procedures
 * Builds strong commitment within the team to support the appropriate team priorities
 * Knowledge of new and evolving technologies via formal training and self-directed education
   
   

Bonus Skills:


 * Experience with BigQuery and other GCP technologies.
 * Experience with Docker and container deployment.
 * Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus.
 * Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc.
 * Familiarity in Hadoop pipelines using Spark, Kafka.
 * Familiar with GIT.
 * Familiar with Adobe Analytics (Omniture) or Google Analytics.
 * Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising
   
   

Paramount Skydance Corporation (NASDAQ: PSKY) is a leading global media and entertainment company that creates premium content and experiences for audiences worldwide. Driven by iconic studios, networks and streaming services, Paramount's portfolio of consumer brands includes CBS, Showtime Networks, Paramount Pictures, Nickelodeon, MTV, Comedy Central, BET, Paramount+, and Pluto TV, among others. Paramount delivers the largest share of the U.S. television audience and boasts one of the industry's most important and extensive libraries of TV and film titles. In addition to offering innovative streaming services and digital video products, the company provides powerful capabilities in production, distribution and advertising solutions.

Additional Information

Hiring Salary Range: $98,400.00 - 155,000.00.

The hiring salary range for this position applies to New York City, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.

What We Offer:


 * Attractive compensation and comprehensive benefits packages. Check out our full list of benefits here: https://www.paramount.com/careers/benefits
 * Generous paid time off.
 * An exciting and fulfilling opportunity to be part of one of Paramount’s most dynamic teams.
 * Opportunities for both on-site and virtual engagement events.
 * Unique opportunities to make meaningful connections and build a vibrant community, both inside and outside the workplace.
 * Explore life at Paramount: https://www.paramount.com/careers/life-at-paramount
   
   

Paramount is an equal opportunity employer (EOE) including disability/vet.

At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.

If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Entertainment Providers","$98,400.00/yr - $155,000.00/yr","","","3656219","https://careers.paramount.com/job/West-Hollywood-Senior-Data-Engineer-CA-90069/1343190300/?feedId=404800&utm_source=LinkedInJobPostings&utm_campaign=Paramount_LinkedIn","EXTERNAL",""
"Estimator - Multifamily Construction","Tampa, FL","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/estimator-multifamily-construction-at-scott-humphrey-corporation-4339000543?trk=public_jobs_topcard-title","Scott Humphrey Corporation","https://www.linkedin.com/company/scott-humphrey-corporation?trk=public_jobs_topcard-org-name","Job description

A top Florida GC is looking to add an estimator to their team. Specializing in multifamily Midrise, Highrise and assisted living, they are looking for an experienced estimator in South FL to work on their pipeline.




What's on Offer:

 * Competitive base salary
 * Vehicle and cell phone allowances
 * Bonus program
 * Comprehensive health benefits and 401k
 * PTO

About the Company:

 * Family Centered GC in South FL seeking a seasoned Estimator with multifamily experience.
 * Billion dollar pipeline

Estimator Job Description:

 * The Estimator will be responsible for developing detailed cost estimates including experience with conceptual estimating for both negotiated and hard bids as well as overseeing an estimating team.
 * Join the largest developer in the South Florida market




Estimator Responsibilities:

 * Participate in the preparation of conceptual cost models, budgets and feasibility models based on historical cost data and/or subcontractor input as appropriate
 * Identify and report problems or deficiencies to the Project Manager
 * Analyze project program, design, costs, and subcontractor input; provide comparisons, cost-saving, and value engineering options
 * Prepare cost analysis by recapitulating material, labor, equipment, subcontractor, and overhead costs occurred in heavy civil industry projects
 * Must have the ability to explain details behind each estimate, including the basis of the man-hours allocated for each task, personnel resources needed to execute each task, etc.
 * Provide estimating review support to the development team
 * Prepare project cost estimates from the client’s RFQ documents and drawings and any other information learned during the pre-bid showing
 * Maintain lines of communications between company departments, project manager, and client with regards to cost estimating activities




Estimator Qualifications:




 * Bachelor’s Degree in Construction Management or Business preferred
 * 7+ years' experience as an Estimator within Commercial Construction
 * Proven record of success on large and/or complex projects
 * Proficient with relevant construction technology; Procore experience




Job Type: Full-time




Salary: $100,000.00 - $200,000.00 per year




Benefits:

 * 401(k)
 * 401(k) matching
 * Dental insurance
 * Health insurance
 * Life insurance
 * Paid time off
 * Vision insurance

Schedule:

 * 8 hour shift
 * Monday to Friday




Work Location: In person","Be among the first 25 applicants","Full-time","Mid-Senior level","Project Management","Construction","$100,000.00/yr - $200,000.00/yr","Camilo Calderon, MBA","https://www.linkedin.com/in/camilo-calderon-mba-485587261","68277511","https://www.linkedin.com/jobs/view/estimator-multifamily-construction-at-scott-humphrey-corporation-4339000543?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Commuter benefits"
"Analytics Director","New York, NY","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/analytics-director-at-fractal-4323695874?trk=public_jobs_topcard-title","Fractal","https://www.linkedin.com/company/fractal-analytics?trk=public_jobs_topcard-org-name","Analytics Director




Fractal is a strategic AI partner to Fortune 500 companies with a vision to power every human decision in the enterprise. Fractal is building a world where individual choices, freedom, and diversity are the greatest assets. An ecosystem where human imagination is at the heart of every decision. Where no possibility is written off, only challenged to get better. We believe that a true Fractalite is the one who empowers imagination with intelligence. Fractal has been featured as a Great Place to Work by The Economic Times in partnership with the Great Place to Work® Institute and recognized as a ‘Cool Vendor’ and a ‘Vendor to Watch’ by Gartner.




Please visit Fractal | Intelligence for Imagination for more information about Fractal.




Position Overview:

Fractal is seeking an experienced and highly influential Analytics Leader in the Technology, Media and Entertainment Practice, responsible to own parts of our client relationships, make them successful (NPS), and grow these relationships while building a world-class analytics team. This is a client facing role where you will be a key strategic partner to clients across multiple functional areas ex. Marketing, engineering, analytics & user experience, using data to shape the future of our client’s products & services.




You will play the role of a strategic AI & Analytics advisor to the clients, a role in which you would help bring the best of thinking on AI, Engineering and Design to our client’s workstreams and help identify solutions to the problems. You will also be responsible for defining and analyzing metrics that measure success, conducting deep-dive analyses to uncover critical insights and opportunities, and driving a culture of data-informed decision-making.




The ideal candidate is a master of their craft, possessing deep technical skills combined with strong business acumen, ability to translate complex data into a compelling narrative that inspires action and drives product strategy, and the operational expertise to run a globally distributed delivery team.




Role & Responsibilities:

 * Delivery Excellence - Guide team to ensure implementation of delivery best practices
 * Client Management: Liaise between the clients & Fractal team, for gathering analytics requirements and managing the quality of delivery
 * Business overview - Help the team understand business context and map the analysis back to business problem
 * Storyboarding & Problem Solving - Lead in problem solving for all projects, ensure first principles thinking is applied
 * Standardization - Implement usage of standard template for all analysis (Excel, Presentations, dashboards), project plan, dashboard development docs etc.
 * Accuracy - Be accountable for the correctness of output
 * Timeliness - Ensure timely completion of projects with regular updates, and escalations / recommendations if timelines are going to be missed.
 * Communication - Coach and guide the team to share summarized observations and insights
 * Documentation - Ensure the preparation of analysis documents, BRDs, scoping documentation, presentation decks, code check-ins, consistent code formatting, etc.

Consulting excellence: Co-own business/ success with the client

 * Outside in perspective: Bring outside in perspective to projects being delivered (ex. Impact of AI on Content creation, Impact on AI on Product growth)
 * Business ownership: Showcase end to end ownership of client’s business problem, showcase thinking beyond immediate focus areas for the client
 * AED Led solutioning: Expand footprint by bringing in AI, Design and Engineering workstream to the pod

AI - Leverage ML / AI / Gen AI based solution approaches to elevate the quality of solutions

Engineering - Help the team adopt engineering best practices around data design, pipeline design, code quality, code check-in etc.

Design - Leverage design thinking and behavioral science-based approaches

Productivity & Utilization - Strategically partner to increase the productivity of the team

 * Improve processes, anticipate requirements, and develop and implement solutions
 * Ensure appropriate utilization of team member’s time across teams to maximize productivity
 * Manage weekly / monthly workstack by allocating projects, developing and monitoring the implementation of project plans, and optimizing bandwidth across the team

Team Management - Performance management and Engagement

 * Collect regular performance feedback and be responsible for the training and coaching of the team based on the performance feedback provided
 * Ensure each feedback is acknowledged, and a remedial plan recommended and actioned if areas of improvement are flagged
 * Ensure high engagement to maximize retention

Business Continuity - Ensure business continuity in case of unforeseen circumstances

 * Facilitate analytics continuity by planning, managing and communicating leaves, backups during leaves, and exit / onboarding transitions with no/minimal impact on operations.
 * Create onboarding documents for new hires that enlist the process to get their access enabled and complete their KT within 3-5weeks from joining.

Periodic Updates and Governance Mechanism- Provide regular updates on progress, future plan, blockers, risks etc

 * Create and update documents that tracks weekly / bi-weekly/ monthly updates for the projects delivered and share with key stakeholders on regular basis
 * Share weekly documented updates to client stakeholders over an email

Growth enablement-

 * Ensure project work is marketable using case studies & demos (where applicable) such that each project / workstream should have a case study
 * Lead development of new solutions through POVs during QBRs and other mediums




Qualifications & Experience:

 * 10+ years of relevant Data Science & Analytics, project management, client relationship management & people management within AI/Data Analytics services industry with a Bachelors / Master’s degree in Engineering, Business, Economics/ Statistics or equivalent
 * Possess strong marketing, customer analytics/ logical thinking skills and clarity of thought
 * Clear & articulate communication with senior executives
 * Enable and demonstrate innovative thinking and inspire innovative action
 * Exhibit a commitment to be a team player with a flexible “can do” attitude and strong interpersonal skills; be a Self-Starter; Proactive; Takes accountability and ownership
 * Possess cross-cultural/geographical sensitivities
 * 3+ years of experience working in TMT data and analytics consulting, understands data landscape and value creation through consulting services for TMT
 * Demonstrate the knowledge, skills and abilities concerning global business fundamentals, business models, ethics, competitive analysis and cross-cultural/geographical sensitivities




Nice to have:

 * Embed Artificial Intelligence & Machine Learning in all projects & proposals




Pay:

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions, including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Fractal, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is: $132,000 - $180,000. In addition, you may be eligible for a discretionary bonus for the current performance period.




Benefits:

As a full-time employee of the company or as an hourly employee working more than 30 hours per week, you will be eligible to participate in the health, dental, vision, life insurance, and disability plans in accordance with the plan documents, which may be amended from time to time. You will be eligible for benefits on the first day of employment with the Company. In addition, you are eligible to participate in the Company 401(k) Plan after 30 days of employment, in accordance with the applicable plan terms. The Company provides for 11 paid holidays and 12 weeks of Parental Leave. We also follow a “free time” PTO policy, allowing you the flexibility to take the time needed for either sick time or vacation.




Fractal provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.","55 applicants","Full-time","Mid-Senior level","Management, Project Management, and Information Technology","IT Services and IT Consulting and Business Consulting and Services","$132,000.00/yr - $180,000.00/yr","","","26945","https://www.linkedin.com/jobs/view/analytics-director-at-fractal-4323695874?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Paid maternity leave
Paid paternity leave
Disability insurance
Commuter benefits
Child care support"
"Data Analyst | Onshore","Newtok, AK","3 weeks ago","2025-11-07","https://www.linkedin.com/jobs/view/data-analyst-onshore-at-photon-4338065615?trk=public_jobs_topcard-title","Photon","https://uk.linkedin.com/company/photon-interactive?trk=public_jobs_topcard-org-name","Key Responsibilities

- Work closely with the existing analyst to enhance and stabilize data pipelines feeding the Snowflake data warehouse.

- Ingest and reconcile data from multiple dental clinic EMRs, Sage ERP/Finance system, and other operational sources.

- Design and publish Power BI dashboards for:

- Revenue cycle management (R30/60/90 aging, collections, forecasts)

- Clinic-level and regional performance metrics

- Financial vs clinical KPI alignment

- Partner with the CFO and finance team to validate metrics and ensure accuracy of financial reporting.

- Implement data quality checks, documentation, and version control for reports and SQL queries.

- Recommend improvements to data architecture and help shape the longer-term data strategy.

Required Skills & Experience

- 8+ years of hands-on experience in data analytics or engineering.

- Proven experience with:

- Snowflake data warehouse – schema design, SQL, data pipeline optimization.

- Power BI – DAX, data modeling, dashboard design, publishing.

- SQL and Python (preferred) for data transformation.

- Integrating financial systems (e.g., Sage, QuickBooks, NetSuite) with data warehouses.

- Working with healthcare or multi-location business data (nice to have: EMR data familiarity).

- Strong analytical mindset with ability to interpret financial metrics, AR aging, and revenue cycle KPIs.

- Excellent communication and collaboration skills with non-technical business users.

Self-starter, comfortable in fast-paced PE-backed environments.



Compensation, Benefits and Duration
Minimum Compensation: USD 48,000
Maximum Compensation: USD 168,000
Compensation is based on actual experience and qualifications of the candidate. The above is a reasonable and a good faith estimate for the role.
Medical, vision, and dental benefits, 401k retirement plan, variable pay/incentives, paid time off, and paid holidays are available for full time employees.
This position is available for independent contractors
No applications will be considered if received more than 120 days after the date of this post","Be among the first 25 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","$48,000.00/yr - $168,000.00/yr","","","165464","https://www.linkedin.com/jobs/view/data-analyst-onshore-at-photon-4338065615?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Data Analyst - Remote","Minnetonka, MN","16 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/senior-data-analyst-remote-at-unitedhealthcare-4340325295?trk=public_jobs_topcard-title","UnitedHealthcare","https://www.linkedin.com/company/unitedhealthcare?trk=public_jobs_topcard-org-name","At UnitedHealthcare, we're simplifying the health care experience, creating healthier communities and removing barriers to quality care. The work you do here impacts the lives of millions of people for the better. Come build the health care system of tomorrow, making it more responsive, affordable and optimized. Ready to make a difference? Join us to start Caring. Connecting. Growing together

The Senior Data Analyst, Business Intelligence reports to the Senior Manager Data Analytics and is accountable for a cross functional STARS Quality & Business Intelligence Reporting, enhancements, issue resolution, supporting operational activities for our members.

You'll enjoy the flexibility to work remotely * from anywhere within the U.S. as you take on some tough challenges. For all hires in the Minneapolis or Washington, D.C. area, you will be required to work in the office a minimum of four days per week.

Primary Responsibilities


 * Demonstrate data literacy, and be resourceful in terms of understanding Medicare overall, STAR measures, gap closures and claims
 * Work closely with business to gather and finalize requirements, business documents, or user stories
 * Design, build, and maintain architecture pertaining to data handling/processing
 * Load data and be able to create user friendly reports, providing technical solutions
 * Develop views for end users utilizing reporting platforms such as SSRS, Tableau, or any other reporting tools
 * Validate new or enhanced technical development and implementation and work closely with Quality Assurance Engineers to achieve data quality and accuracy
 * Maintaining existing data load process, building blocks and customizations
 * Support data processing, preexisting reporting, applications, and customer-facing reports, or data
 * Learn about the products, share ideas and be able to train or influence other team members
   
   

You'll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.

Required Qualifications


 * 5+ years of solid working experience in complex SQL Programming (Snowflake, SQL Server, or similar databases)
 * 5+ years of working experience in ETL data processing (Azure Data Factory, SSIS or equivalent), that involves data movement between various databases, working with text delimited files, and other data sources
 * 5+ years of experience building reports in SSRS, Tableau and/or Power BI
 * Experience with the software development life cycle (i.e. Business Requirements, Technical Documentation, Quality Assurance)
 * Proven expert in SQL programming, data analysis, and data management
 * Proven self-guided in terms of understating data in physical tables or views, and be able to create/ enhance stored procedures or functions pertaining to report feeds, or any input/output
 * Proven ability to develop and manage multiple projects with minimal direction and supervision
 * Proven ability to perform system investigation, reverse engineering, and new development while adhering to development standards and good change control practices
 * Proven solid communication skills with experience presenting ideas and solutions to business customers
   
   

Preferred Qualifications


 * Experience in Healthcare, Financial Services, or Insurance Industry
 * Experience with automating ETL package
 * Experience in Snowflake
 * Knowledge of Medicare
 * All employees working remotely will be required to adhere to UnitedHealth Group's Telecommuter Policy
   
   

Pay is based on several factors including but not limited to local labor markets, education, work experience, certifications, etc. In addition to your salary, we offer benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with us, you'll find a far-reaching choice of benefits and incentives. The salary for this role will range from $89,900 to $160,600 annually based on full-time employment. We comply with all minimum wage laws as applicable.

Application Deadline: This will be posted for a minimum of 2 business days or until a sufficient candidate pool has been collected. Job posting may come down early due to volume of applicants.

At UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone-of every race, gender, sexuality, age, location and income-deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes - an enterprise priority reflected in our mission.

UnitedHealth Group is an Equal Employment Opportunity employer under applicable law and qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status, or any other characteristic protected by local, state, or federal laws, rules, or regulations.

UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Business Content","$89,900.00/yr - $160,600.00/yr","","","3617441","https://www.linkedin.com/jobs/view/senior-data-analyst-remote-at-unitedhealthcare-4340325295?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI Engineer","Palo Alto, CA","1 day ago","2025-11-30","https://www.linkedin.com/jobs/view/ai-engineer-at-hippocratic-ai-4333291067?trk=public_jobs_topcard-title","Hippocratic AI","https://www.linkedin.com/company/hippocratic-ai-health?trk=public_jobs_topcard-org-name","About Us

Hippocratic AI has developed a safety-focused Large Language Model (LLM) for healthcare. The company believes that a safe LLM can dramatically improve healthcare accessibility and health outcomes in the world by bringing deep healthcare expertise to every human. No other technology has the potential to have this level of global impact on health.

Why Join Our Team


 * Innovative Mission: We are developing a safe, healthcare-focused large language model (LLM) designed to revolutionize health outcomes on a global scale.
 * Visionary Leadership: Hippocratic AI was co-founded by CEO Munjal Shah, alongside a group of physicians, hospital administrators, healthcare professionals, and artificial intelligence researchers from leading institutions, including El Camino Health, Johns Hopkins, Stanford, Microsoft, Google, and NVIDIA.
 * Strategic Investors: We have raised a total of $278 million in funding, backed by top investors such as Andreessen Horowitz, General Catalyst, Kleiner Perkins, NVIDIA’s NVentures, Premji Invest, SV Angel, and six health systems.
 * World-Class Team: Our team is composed of leading experts in healthcare and artificial intelligence, ensuring our technology is safe, effective, and capable of delivering meaningful improvements to healthcare delivery and outcomes.
   
   

For more information, visit www.HippocraticAI.com.

We value in-person teamwork and believe the best ideas happen together. Our team is expected to be in the office five days a week in Palo Alto, CA unless explicitly noted otherwise in the job description.

About The Role

As an AI Engineer at Hippocratic AI, you’ll play a pivotal role in shaping the future of voice-based generative AI in healthcare. You’ll design and build the intelligent systems that power our clinically safe healthcare agents, working at the intersection of large language models, real-time voice, and human-centered product design.

This is a deeply hands-on and cross-functional role, partnering closely with AI researchers, product managers, and clinical experts to bring advanced language and speech models into production. From building scalable RAG and multi-agent pipelines to conversational interactions, your work will directly influence how patients and providers safely interact with generative AI at scale.

We’re looking for experienced engineers who are passionate about AI in the real world—people who love taking cutting-edge research, turning it into robust products, and advancing the frontier of what’s possible in safe, agentic healthcare systems.

What You'll Do:


 * Design, build, and optimize production-grade AI pipelines that power our voice-based generative healthcare agents—from retrieval-augmented generation (RAG) to multi-step reasoning systems.
 * Collaborate cross-functionally with product, clinical, and engineering teams to translate healthcare workflows into safe, scalable, and human-centered AI experiences.
 * Prototype and deploy zero-to-one features using state-of-the-art LLMs, retrieval systems, and streaming architectures—balancing innovation with reliability.
 * Develop and refine AI-native workflows that support real-time, conversational, and long-running interactions across diverse healthcare contexts.
 * Drive continuous improvement in model evaluation, safety testing, and observability, ensuring every agent interaction meets clinical safety standards
   
   

What You Bring

Must Have:


 * 3+ years of professional experience in software, ML, or AI engineering.
 * Proven track record building and shipping AI- or ML-powered products in production environments.
 * Strong programming skills in Python with experience in distributed systems, APIs, and data pipelines.
 * Deep understanding of prompt engineering, vector databases, and retrieval systems (RAG), voice agents or willingness to learn rapidly.
 * Experience with cloud environments (AWS/GCP/Azure) and modern DevOps practices (Terraform, CI/CD, monitoring).
 * Excellent communication, cross-functional collaboration, and an ability to move fast in high-impact domains.
   
   

Nice-to-Have:


 * Experience building or deploying LLM-based or multi-agent systems at scale.
 * Hands-on work with speech recognition, text-to-speech, or streaming architectures for real-time AI experiences.
 * Prior exposure to healthcare, safety-critical domains, or regulated product development.
   
   

If you’re an AI engineer who thrives at the intersection of cutting-edge research and real-world product impact, we’d love to hear from you.

Join Hippocratic AI and help shape the future of clinically safe, voice-enabled AI systems that are already transforming patient care at scale.


 * Be aware of recruitment scams impersonating Hippocratic AI. All recruiting communication will come from @hippocraticai.com email addresses. We will never request payment or sensitive personal information during the hiring process. If anything","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Hospitals and Health Care","","","","91431767","https://www.linkedin.com/jobs/view/ai-engineer-at-hippocratic-ai-4333291067?trk=public_jobs_topcard-title","EASY_APPLY",""
"Quantitative Developer","New York, United States","1 week ago","2025-11-18","https://www.linkedin.com/jobs/view/quantitative-developer-at-upward-trend-4335950615?trk=public_jobs_topcard-title","Upward Trend","https://uk.linkedin.com/company/upward-trend?trk=public_jobs_topcard-org-name","Quantitative Developer




Major global hedge fund




New York




Our client, a multibillion AUM hedge fund headquartered in the United States, is looking for a Quantitative Developer to join its team in New York.




Key responsibilities

 * Build scalable, high-performance systems that power trading across all asset classes.
 * Partner with traders, quants, and technologists to deliver innovative solutions.
 * Design and develop a next-generation risk analytics platform.
 * Tackle large-scale financial data challenges in a fast-paced, collaborative environment.
 * Evaluate and implement new technologies that make a direct impact on trading and investment decisions




About you

 * Strong software engineering background in Java, C++ or Python.
 * Deep understanding of computer science fundamentals and complex system design.
 * Experience with real-time financial data, pricing, and risk systems.
 * Comfortable working closely with quants and traders to turn analytical ideas into robust solutions.
 * Curious, driven, and passionate about building world-class technology for financial markets.




Benefits

 * Comprehensive medical, life insurance, retirement, and tax-free savings plans.
 * A culture that values innovation, collaboration, and impact.","59 applicants","Full-time","Mid-Senior level","Finance, Information Technology, and Engineering","Investment Management, Financial Services, and Investment Banking","$150,000.00/yr - $200,000.00/yr","","","75388921","https://www.linkedin.com/jobs/view/quantitative-developer-at-upward-trend-4335950615?trk=public_jobs_topcard-title","EASY_APPLY",""
"Strategic Solutions Engineer","San Francisco, CA","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/strategic-solutions-engineer-at-postman-4336996413?trk=public_jobs_topcard-title","Postman","https://www.linkedin.com/company/postman-platform?trk=public_jobs_topcard-org-name","Who Are We?

Postman is the world’s leading API platform, used by more than 40 million developers and 500,000 organizations, including 98% of the Fortune 500. Postman is helping developers and professionals across the globe build the API-first world by simplifying each step of the API lifecycle and streamlining collaboration—enabling users to create better APIs, faster.

The company is headquartered in San Francisco and has offices in Boston, New York, and Bangalore - where Postman was founded. Postman is privately held, with funding from Battery Ventures, BOND, Coatue, CRV, Insight Partners, and Nexus Venture Partners. Learn more at postman.com or connect with Postman on X via @getpostman.

P.S: We highly recommend reading The ""API-First World"" graphic novel to understand the bigger picture and our vision at Postman.

The Opportunity

With so many organizations using Postman, we are looking for an exceptional Strategic Solutions Engineer to join our team & help us support the growth of our enterprise business. You will partner with our sales team to promote an API-first development culture, nurture customer relationships, and guide Postman users in leveraging our platform to build their APIs most effectively. Ideally, we are looking for someone who lives & breathes APIs, has experience in enterprise sales, is comfortable with JavaScript & is an expert Postman user already!

In addition to working with a product that customers already know and love, our sales, customer success, product, and engineering teams will support you well in this role.

What You’ll Do


 * Help drive enterprise sales by nurturing prospects & supporting Strategic & Enterprise customers
 * Conduct discovery, qualification, technical demos, & proof of value workshops with prospective customers looking to embrace Postman for their API lifecycle
 * Handle Postman technical questions or objections & provide solutions or workarounds to address customer needs
 * Understand deeply our customer workflows today & how they can adopt API-first development best practices
 * Share customer feedback with appropriate teams & provide general customer advocacy
 * Remain up-to-date with the competitive landscape, current trends, & challenges in the API market
 * Create proof of concept integrations, tooling, & workflows as needed to support prospective customers
 * Maintain & develop customer sandbox environments & best practices for working with the product
 * Act as a technical intermediary between sales & other teams to best fit our customer needs
   
   

About You


 * 10+ years of enterprise sales/solutions engineering experience
 * 6+ years of software development experience
 * 6+ API’s and Data platforms experience
 * Bachelor's degree in Computer Science, a related field, or relevant work experience
 * Remote work friendly, with the ability to travel up to 50%
 * Loves teamwork & collaboration in a fast-paced environment
 * Customer-facing experience & comfortable engaging all levels of technologists, including individual developers, QA, product, & engineering leaders
 * Experience engaging senior management & executive audiences to convey Postman's value proposition
 * Capable of forging deep, long-lasting relationships with Strategic customers
 * Strong understanding of APIs, & experience with producing & consuming APIs across different domains
 * Strong understanding of modern development methodologies & DevOps with an appreciation of the software development life cycle
 * Comfortable with the enterprise SaaS sales process & common security concerns of cloud services
 * Experience executing enterprise sales strategies & sales methodologies like MEDDIC, Challenger Sale, Command of the Message, etc.
 * Excellent listener who seeks to understand what a customer is trying to achieve rather than pre-supposing solutions
 * Familiar with typical developer tooling: IDEs, Git, CI/CD, monitoring services, microservices, containers, cloud computing services, etc.
 * Fast learner, excited & willing to learn new technology on an ongoing basis
 * Excellent communication skills (presentation, verbal & written)
   
   

What Else?

In addition to Postman's pay-on-performance philosophy, and a flexible schedule working with a fun, collaborative team, Postman offers a comprehensive set of benefits, including full medical coverage, flexible PTO, wellness reimbursement, and a monthly lunch stipend. Along with that, our wellness programs will help you stay in the best of your physical and mental health. Our frequent and fascinating team-building events will keep you connected, while our donation-matching program can support the causes you care about. We’re building a long-term company with an inclusive culture where everyone can be the best version of themselves.

At Postman, we embrace a hybrid work model. For all roles based out of San Francisco Bay Area, Boston, Bangalore, Hyderabad, and New York, employees are expected to come into the office 3-days a week. We were thoughtful in our approach which is based on balancing flexibility and collaboration and grounded in feedback from our workforce, leadership team, and peers. The benefits of our hybrid office model will be shared knowledge, brainstorming sessions, communication, and building trust in-person that cannot be replicated via zoom.

Our Values

At Postman, we create with the same curiosity that we see in our users. We value transparency and honest communication about not only successes, but also failures. In our work, we focus on specific goals that add up to a larger vision. Our inclusive work culture ensures that everyone is valued equally as important pieces of our final product. We are dedicated to delivering the best products we can.

Equal opportunity

Postman is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. Postman does not accept unsolicited headhunter and agency resumes. Postman will not pay fees to any third-party agency or company that does not have a signed agreement with Postman.","Be among the first 25 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","","","","3795851","https://www.linkedin.com/jobs/view/strategic-solutions-engineer-at-postman-4336996413?trk=public_jobs_topcard-title","EASY_APPLY",""
"Junior Software Engineer","Fort Meade, MD","2 weeks ago","2025-11-17","https://www.linkedin.com/jobs/view/junior-software-engineer-at-tap-engineering-4347463729?trk=public_jobs_topcard-title","TAP Engineering","https://www.linkedin.com/company/tapengineers?trk=public_jobs_topcard-org-name","Job ID: TAP00138 

Position: Software Engineer Level 2 
Location: US – MD, Ft. Meade 
Category: Software Engineering / Development 

Clearance Requirement: Active TS/SCI with Full Scope Polygraph 
Education Requirement: BS in Computer Science (or related field) 

Experience Requirement: 8 years 



We are seeking a Level 2 Software Engineer to design, develop, enhance, and maintain a wide range of complex software systems, including analytics platforms, real-time processing systems, large-scale data applications, and mission-support tools. This role supports both independent development and collaborative team efforts while following established software engineering standards. You’ll contribute across the full lifecycle, from requirements of analysis and coding to testing, optimization, and integration, while providing technical leadership to software teams as needed. 



Key Responsibilities: 

• Analyze user requirements to derive software design and performance specifications 
• Design, code, test, and integrate new software features or enhancements 
• Debug, troubleshoot, and resolve defects in existing software systems 
• Develop or improve documentation and software development process standards 
• Integrate existing software into new or modified systems and environments 
• Build data queries and database interfaces for existing or proposed repositories 
• Write and review software and system design documentation 
• Serve as a team lead in alignment with the development process for assigned projects 
• Design and implement complex algorithms and database interfaces 
• Apply scientific analysis and mathematical models to predict outcomes and inform design decisions 
• Assist in developing and executing software component test procedures 
• Modify existing software to adapt to new hardware or improve system performance 
• Evaluate system performance standards, data flows, and work processes to recommend improvements 
• Provide quality control reviews for team-produced code and documentation 
• Oversee one or more software development teams to ensure compliance with established processes 
• Collaborate with system and hardware engineers to derive and refine software requirements 
• Coordinate installation of software systems and validate operational performance 

Qualifications: 

 * Bachelor's degree in computer science, Software Engineering, or related technical field (or equivalent experience) 

 * 8+ years of software engineering experience 

 * Proficiency in Java, Python, or C++ 

 * Experience developing software in Linux environments 

 * Hands-on experience with Agile methodologies 

 * Strong understanding of software design, debugging, testing, and documentation 

 * Experience with REST APIs, microservices, or distributed systems 

 * Familiarity with version control tools (Git preferred) 

 * Ability to perform troubleshooting, fault isolation, and system optimization 

 * Experience integrating software with large-scale or multi-component systems 

 * Ability to support on-site operations when required 

 * Strong communication and teamwork skills 

 
 

Clearance Requirement: This position requires ability to obtain and maintain a Top Secret/SCI security clearance, based on current background investigation (SBI), as well as the favorable completion of full scope polygraph. Clearance and polygraph processing will be completed by the U.S. Government. Factors considered for a U.S. Government Security Clearance include, but are not limited to: 

 * U.S. Citizenship 

 * Favorable Criminal History Check 

 * Education Verification 

 * Abuse/Illegal Drug Use 

 * Credit Check 

 * Subject Interview 

By submitting your resume for this position, you understand and agree that TAP Engineering may share your resume, as well as any other related personal information or documentation you provide, with its subsidiaries and affiliated companies for the purpose of considering you for other available positions.  

TAP Engineering is an Equal Opportunity Employer and applicants receive lawful consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status. ","Be among the first 25 applicants","Full-time","Entry level","Sales, General Business, and Education","Wireless Services, Telecommunications, and Communications Equipment Manufacturing","","","","76272155","https://www.linkedin.com/jobs/view/junior-software-engineer-at-tap-engineering-4347463729?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","McLean, VA","1 week ago","2025-11-22","https://www.linkedin.com/jobs/view/data-engineer-at-steampunk-inc-4347231381?trk=public_jobs_topcard-title","Steampunk, Inc.","https://www.linkedin.com/company/steampunk-inc?trk=public_jobs_topcard-org-name","We are looking for seasoned Data Engineer to work with our team and our clients to develop enterprise grade data platforms, services, and pipelines. We are looking for more than just a ""Data Engineer"", but a technologist with excellent communication and customer service skills and a passion for data and problem solving.

Contributions


 * Lead and architect migration of data environments with performance and reliability.
 * Assess and understand the ETL jobs, workflows, BI tools, and reports
 * Address technical inquiries concerning customization, integration, enterprise architecture and general feature / functionality of data products
 * Experience in crafting database / data warehouse solutions in cloud (Preferably AWS. Alternatively Azure, GCP).
 * Key must have skill sets – Python, AWS
 * Support an Agile software development lifecycle
 * You will contribute to the growth of our Data Exploitation Practice!
   
   

Qualifications


 * Ability to hold a position of public trust with the US government.
 * 2 years industry experience coding commercial software and a passion for solving complex problems.
 * Bachelor's degree and 2 years direct experience in Data Engineering with experience in tools such as:
    * Big data tools: Hadoop, Spark, Kafka, etc.
    * Relational SQL and NoSQL databases, including Postgres and Cassandra.
    * Data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
    * AWS cloud services: EC2, EMR, RDS, Redshift (or Azure equivalents)
    * Data streaming systems: Storm, Spark-Streaming, etc.
    * Search tools: Solr, Lucene, Elasticsearch
    * Object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

 * Advanced working SQL knowledge and experience working with relational databases, query authoring and optimization (SQL) as well as working familiarity with a variety of databases.
 * Experience with message queuing, stream processing, and highly scalable ‘big data’ data stores.
 * Experience manipulating, processing, and extracting value from large, disconnected datasets.
 * Experience manipulating structured and unstructured data for analysis
 * Experience constructing complex queries to analyze results using databases or in a data processing development environment
 * Experience with data modeling tools and process
 * Experience architecting data systems (transactional and warehouses)
 * Experience aggregating results and/or compiling information for reporting from multiple datasets
 * Experience working in an Agile environment
 * Experience supporting project teams of developers and data scientists who build web-based interfaces, dashboards, reports, and analytics/machine learning models
   

About Steampunk

Steampunk relies on several factors to determine salary, including but not limited to geographic location, contractual requirements, education, knowledge, skills, competencies, and experience. The projected compensation range for this position is $125,000 to $160,000. The estimate displayed represents a typical annual salary range for this position. Annual salary is just one aspect of Steampunk’s total compensation package for employees. Learn more about additional Steampunk benefits here.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Steampunk is a Change Agent in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our Human-Centered delivery methodology, we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an employee owned company, we focus on investing in our employees to enable them to do the greatest work of their careers – and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com .

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.","48 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","$125,000.00/yr - $160,000.00/yr","","","23690866","https://careers-steampunk.icims.com/jobs/7059/data-engineer/job?mode=apply&iis=LinkedIn","EXTERNAL",""
"Data Engineer","Plantation, FL","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/data-engineer-at-nationsbenefits-4337075289?trk=public_jobs_topcard-title","NationsBenefits","https://www.linkedin.com/company/nationsbenefits?trk=public_jobs_topcard-org-name","Company Overview:

NationsBenefits is recognized as one of the fastest growing companies in America and a Healthcare Fintech provider of supplemental benefits, flex cards, and member engagement solutions. We partner with managed care organizations to provide innovative healthcare solutions that drive growth, improve outcomes, reduce costs, and bring value to their members.

Through our comprehensive suite of innovative supplemental benefits, fintech payment platforms, and member engagement solutions, we help health plans deliver high-quality benefits to their members that address the social determinants of health and improve member health outcomes and satisfaction.

Our compliance-focused infrastructure, proprietary technology systems, and premier service delivery model allow our health plan partners to deliver high-quality, value-based care to millions of members.

We offer a fulfilling work environment that attracts top talent and encourages all associates to contribute to delivering premier service to internal and external customers alike. Our goal is to transform the healthcare industry for the better! We provide career advancement opportunities from within the organization across multiple locations in the US, South America, and India.




Description:

We are seeking a Data Engineer to join our Data Platforms team and focus on building and maintaining the critical data pipelines that power our data-driven organization. In this role, you will work with modern data stack technologies including Databricks, Airflow, and Azure cloud services to deliver reliable, high-quality data products that support business analytics, reporting, and decision-making across the enterprise.

You will collaborate closely with data platform engineers, architects, and business stakeholders to design, implement, and optimize ETL/ELT workflows that ingest, transform, and deliver data at scale. This role emphasizes hands-on development of data pipelines using Python and SQL, working within our established metadata-driven frameworks and cloud-native infrastructure.

The ideal candidate is passionate about data engineering fundamentals, comfortable working with large-scale data processing, and committed to delivering reliable data products in a regulated healthcare environment. You will contribute to a collaborative team environment where data quality, operational excellence, and continuous improvement are paramount.




Key Responsibilities

• Design, build, and maintain ETL/ELT pipelines using metadata-driven frameworks within Airflow, Databricks, and our broader data platform stack.

• Implement data ingestion processes from various source systems into our data platform, including databases, APIs, file-based systems, and streaming sources.

• Build and optimize data delivery mechanisms to support analytics, reporting, and downstream data products consumed by business users.

• Collaborate with team leads, architects, and stakeholders to implement data solutions that align with architectural standards and business requirements.

• Monitor and troubleshoot data pipelines to ensure reliable, timely data delivery with appropriate error handling and alerting.

• Implement comprehensive data quality and integrity checks throughout the ETL/ELT process to ensure reliable data delivery.

• Participate in code reviews and contribute to team knowledge sharing and best practices around data engineering patterns.

• Support data consumers by optimizing data access patterns and query performance on cloud-native table formats.

• Write high-quality, maintainable code in Python and SQL that follows software engineering best practices.

• Maintain comprehensive documentation for data pipelines, transformations, and data flows.




Required Skills & Qualifications:

• Bachelor's degree in Computer Science, Information Technology, Engineering, or a related field.

• 3-5 years of data engineering experience with hands-on expertise in ETL/ELT development and data pipeline implementation.

• Strong proficiency in Python and SQL for data processing, transformation, and analysis.

• Experience with workflow orchestration tools such as Airflow, or similar technologies for scheduling and managing data pipelines.

• Strong Hands-on experience with PySpark.

• Hands-on experience with cloud data platforms, preferably Azure, and modern data stack technologies.

• Familiarity with database systems (SQL Server, PostgreSQL, or similar) and modern table formats such as Delta Lake or Iceberg.

• Strong understanding of data quality frameworks and experience implementing data validation and integrity checks.

• Experience with version control systems (Git) and familiarity with DevOps processes and CI/CD concepts.

• Excellent problem-solving skills and ability to work collaboratively in a team environment.

• Strong communication skills with ability to explain technical concepts to diverse audiences.




Preferred Qualifications

• Experience with Databricks and Unity Catalog for data lakehouse implementations.

• Knowledge of streaming data processing and real-time data pipelines using Kafka, EventHub, or similar technologies.

• Experience working in regulated industries or with sensitive data, particularly HIPAA compliance knowledge.

• Familiarity with Infrastructure as Code tools such as Terraform for managing data infrastructure.

• Experience with dbt (data build tool) for analytics engineering and data transformation.

• Knowledge of data modeling principles and dimensional modeling techniques.

• Understanding of data governance, metadata management, and data cataloging practices.

• Experience with monitoring and observability tools for data pipeline reliability.

","Over 200 applicants","Full-time","Mid-Senior level","Health Care Provider","Public Health","$100,000.00/yr - $120,000.00/yr","Arjun K.","https://in.linkedin.com/in/arjun-k-94166796","11490204","https://www.linkedin.com/jobs/view/data-engineer-at-nationsbenefits-4337075289?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Dental insurance
401(k)
Disability insurance"
"Engineering Innovation Program Leader","Plymouth, MN","13 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/engineering-innovation-program-leader-at-polaris-inc-4340366601?trk=public_jobs_topcard-title","Polaris Inc.","https://www.linkedin.com/company/polarisinc?trk=public_jobs_topcard-org-name","At Polaris Inc., we have fun doing what we love by driving change and innovation. We empower employees to take on challenging assignments and roles with an elevated level of responsibility in our agile working environment. Our people make us who we are, and we create incredible products and experiences that empower us to THINK OUTSIDE.

Position Summary

This Engineering Innovation Leader supports the innovation pipeline – from problem discovery and ideation through evaluation, proof-of-concept, and hand-off into development. It combines strategic portfolio management with hands-on leadership of the innovation process, design-thinking workshops, rapid prototyping, and cross-functional collaboration to accelerate concept maturation and de-risk early-stage initiatives. The position requires strong analytical and storytelling skills to translate insights into ideas, influence evidence-based decisions, and align innovation efforts with overarching business strategy. Success is measured by portfolio throughput, strategic impact, and fostering a culture of innovation across the enterprise.

Responsibilities


 * Own the innovation pipeline and governance: Govern the gate system with clear entry/exit criteria, disciplined review cadence, and crisp go/kill decisions; drive progression from ideation through proof-of-concept to development hand-off.
 * Drive rigorous evaluation and portfolio decisions: Apply standardized scoring against the Innovation Review rubric (IP, income, peak sales, market readiness, risk, strategic alignment, investment) and deliver investable recommendations to leadership forums.
 * Accelerate concept creation and maturation: Lead design-thinking workshops and white-paper sprints, orchestrate rapid prototyping across engineering functions; drive to shorten cycles and de-risk early.
 * Ensure smooth integration to development: Define “definition-of-ready” for Pre-Development and PDP insertion, align requirements with Engineering for clean hand-offs.
 * Build and sustain an innovation culture: Run charrettes/challenges; codify fast-fail learning; align efforts with strategic themes to maximize business impact.
 * Partner externally and internally: Lead make/buy/partner analyses; engage suppliers and universities for feasibility accelerators and benchmarking; maintain strong ties across product and engineering teams
 * Measure what matters: Establish and track portfolio health and impact metrics (idea throughput, ARL cycle time, kill rate, number of charters, innovation vs. pre-dev investment mix, program stability/speed), and publish transparent, actionable readouts.
 * Support end-to-end innovation pipeline: Drive problem discovery, ideation, evaluation, proof-of-concept, and seamless hand-off into development to ensure disciplined progression from concept to execution.
 * Champion adherence to the innovation process: Model best practices and actively coach teams to follow established frameworks, reinforcing consistency and rigor across initiatives.
 * Mentor and develop innovation capabilities: Build organizational competency through coaching, training, and hands-on engagement, fostering a sustainable innovation ecosystem across Polaris Inc.
 * Apply critical thinking and analytics: Leverage structured analysis and data-driven insights to evaluate opportunities, mitigate risk, and optimize portfolio outcomes.
 * Facilitate cross-functional collaboration: Orchestrate technology roadmapping, ideation sessions, and portfolio reviews to align innovation efforts with enterprise priorities and accelerate decision-making.
 * Align innovation with business strategy: Ensure initiatives support overarching objectives and strategic themes, maximizing impact on growth, profitability, and competitive advantage.
   
   

Qualifications


 * Bachelor’s degree in Engineering, STEM, Business, or Strategy; advanced degree a plus.
 * 7+ years in product development/engineering with demonstrated early-stage delivery (concept through proof-of-concept) and prior ownership of stage-gate or ARL processes.
 * Ability to translate customer insights and competitive/macro scans into high-potential problem statements and investable charters; excellence in technical storytelling/white papers.
 * Portfolio judgment using the standard Innovation Review rubric; comfortable facilitating teams to make evidence-based go/kill calls and presenting to leadership.
 * Track record building cross-functional coalitions and running charrettes/white-paper sprints that result in prototypes and charters.
 * Excellent communication and interpersonal skills
 * Experience with start-ups, partnerships, and/or university initiatives and co-development exposure.
 * Prior leadership in running company-wide innovation challenges or innovation ideation initiatives.
 * Execution of engineering design projects, specifically innovation or early product design
   
   

The starting pay range for Minnesota is $104,000 to $137,000 per year. Individual salaries and positioning within the range are determined through a wide variety of factors including but not limited to education, experience, knowledge, skills, and geography. While individual pay could fall anywhere in the range based on these factors, it is not common to start at the high end or top of the range.

To qualify for this position, former employees must be eligible for rehire, and current employees must be in good standing.

We are an ambitious, resourceful, and driven workforce, which empowers us to THINK OUTSIDE. Apply today!

At Polaris we put our employees first, by offering a holistic approach to their health and financial wellbeing. Polaris is proud to offer competitive compensation, including a market-leading profit-sharing plan that is fundamental to our pay-for-performance culture. At Polaris, employees are owners of the company through company contributions to our Employee Stock Ownership Plan and discounted employee stock purchases plan. Employees receive a generous matching contribution to 401(k), financial wellness education and consultation to plan for their financial future. In addition to competitive pay, Polaris provides a comprehensive suite of benefits, including health, dental, and vision insurance, wellness programs, paid time off, gym & personal training reimbursement, life insurance and disability offerings. Through the Polaris Foundation and our Polaris Gives paid volunteer time off, we support employees who actively volunteer their time, efforts, and passions to improve the health and wellbeing of the communities in which they live, play and work. Employees at Polaris drive our success and are rewarded for their commitment.

About Polaris

As the global leader in powersports, Polaris Inc. (NYSE: PII) pioneers product breakthroughs and enriching experiences and services that have invited people to discover the joy of being outdoors since our founding in 1954. Polaris' high-quality product line-up includes the Polaris RANGER®, RZR® and Polaris GENERAL™ side-by-side off-road vehicles; Sportsman® all-terrain off-road vehicles; military and commercial off-road vehicles; snowmobiles; Indian Motorcycle® mid-size and heavyweight motorcycles; Slingshot® moto-roadsters; Aixam quadricycles; Goupil electric vehicles; and pontoon and deck boats, including industry-leading Bennington pontoons. Polaris enhances the riding experience with a robust portfolio of parts, garments, and accessories. Proudly headquartered in Minnesota, Polaris serves more than 100 countries across the globe. www.polaris.com

EEO Statement

Polaris Inc. is an Equal Opportunity Employer and will make all employment-related decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, age, disability, marital status, familial status, status with regard to public assistance, membership or activity in a local commission, protected veteran status, or any other status protected by applicable law. Applicants with a disability that are in need of an accommodation to complete the application process, or otherwise need assistance or an accommodation in the recruiting process, should contact Human Resources at 800-765-2747 or Talent.Acquisition@Polaris.com. To read more about employment discrimination protection under U.S. federal law, see: Know Your Rights: Workplace Discrimination is Illegal (eeoc.gov).

EEO/AA/M/F/Vets/Disabled

","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Motor Vehicle Manufacturing, Manufacturing, and Armed Forces","$104,000.00/yr - $137,000.00/yr","","","8885","https://www.linkedin.com/jobs/view/engineering-innovation-program-leader-at-polaris-inc-4340366601?trk=public_jobs_topcard-title","EASY_APPLY",""
"Quantitative Risk Developer","Boston, MA","21 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/quantitative-risk-developer-at-massmutual-4340153754?trk=public_jobs_topcard-title","MassMutual","https://www.linkedin.com/company/massmutual-financial-group?trk=public_jobs_topcard-org-name","The Opportunity

This is an exciting opportunity for a highly motivated and collaborative risk professional with strong quantitative and development expertise to join the Credit Risk Management team within the Capital and Investment Risk Management team and the broader Enterprise Risk Management division.

As a quantitative risk developer within the Capital & Investment Risk Management team, you will be responsible for leading quantitative model implementation, development, and analysis. The ideal candidate will join a quant team to enhance Enterprise Risk Management (ERM)’s analytical and reporting capabilities, by expanding the use of existing models as well as designing and developing new tools and risk frameworks.

You will work with capital, credit, market and portfolio risk teams, and ERM more broadly. This is an excellent opportunity to collaborate with risk, investment and finance, and enterprise technology (including data science) teams.

The Team

The Capital & Investment Risk team brings together a diverse team of experts across capital markets, risk management, actuarial, and quantitative disciplines that works together to deliver analysis and recommendations related to the management of credit, market, liquidity and capital risk, consistent with the enterprise risk appetite framework for which the team is also responsible.

The team continues to be successful in driving improvements in tools, technology and processes, for more consistent risk analysis and reporting, and enabling greater opportunities for scale and efficiency within ERM and with stakeholders in Investment Management and Finance.

The Impact


 * In this role, you will play a critical part in ensuring company’s credit risks are effectively identified, measured and mitigated, by bringing your deep analytical expertise and strong understanding of credit risk/ investment risk modeling, data and infrastructure.
 * Your work will help shape robust, data-driven decision-making across risk and investment areas and influence MassMutual’s evolving business strategy and operating environment.
 * You will partner with your peers in driving improvements in tools, technology and processes, for more consistent risk analysis and reporting, and enabling greater opportunities for scale and efficiency within ERM and with stakeholders in Investment Management and Finance.
 * There is a strong emphasis on innovation, with growing opportunity to apply AI-driven techniques and scalable data solutions to drive more forward-looking, efficient risk analytics that embrace emerging technologies.
 * The key to success in this role is a sharp analytical mindset, the ability to translate complex risk metrics into actionable insights, and a strong partnership approach with stakeholders across risk, investment management, finance, and technology.
   
   

Notable Responsibilities Include


 * Implement, develop and enhance ERM’s analytical capabilities related to credit/market risk across a wide range of fixed income asset classes
 * Building on MassMutual’s current approach, assist in developing and syndicating a comprehensive framework for measuring portfolio credit & market risk, that considers different accounting and capital regimes, including asset and liability impacts, with a particular emphasis on economic capital
 * Automate and expand the use of Moody’s credit risk tools in place today and build risk- reward framework
 * Use of Python/ SQL. Also, use of spreadsheets and VBA to prototype and analyze data including data investigation/cleanup
 * Strengthen ERM’s use and development of tools and analytics to support derivatives counterparty risk, portfolio concentration risk & stress testing capabilities
 * Mentor junior quantitative analysts
 * Scope and implement modeling, including building out requirements where not yet fully defined or understood.
 * The right candidate will be agile, accountable and resilient in driving initiatives and the results
   
   

The Minimum Qualifications


 * Bachelors degree in Computer Science, Financial Engineering, Mathematics, Physics, Engineering or similar quantitative discipline
 * Minimum 8 years of relevant work experience with 5 years in investment (credit/market) quantitative risk analytics OR 5 years of relevant work experience in investment (credit/ market) quantitative risk analytics combined with graduate studies
 * 5+ years of experience with expertise in Python, SQL and development skills in object-oriented programing
 * 5+ years of experience with strong quantitative model development & implementation skills and ability to validate/understand and explain analytical results
 * 5+ years of experience in quantitative risk modeling across a wide range of asset classes
 * 3+ years of experience with ability to engage with operational work in production environment with IT developers/solution architects in maintaining infrastructure
 * 5+ years of experience with quantitative and programming skills in a hands-on setting to deliver new functionality
   
   

The Ideal Qualifications


 * 7+ years of relevant work experience in investment (credit/market) quantitative risk analytics is desirable
 * Advanced degree in Computer Science, Financial Engineering, Mathematics, Physics, Engineering or similar quantitative discipline is preferred
 * Knowledge and experience working with derivatives and hedging risk management
 * Experience in using Moody’s Analytics credit risk tools is desirable.
 * Experience in CECL compliant portfolio credit models
 * Experience applying machine learning techniques in the financial industry is desirable
 * Software development using GitHub and Docker, adhering to enterprise standards and best practices ensuring models are validated and governed
 * Previous experience working on liability-driven investing projects within an insurance company is desirable
   
   

What to Expect as Part of MassMutual and the Team


 * Regular meetings with the Quantitative teams within ERM, Investment management & ETX project teams
 * Focused one-on-one meetings with your manager
 * Networking opportunities including access to Asian, Hispanic/ Latinx, African American, women, LGBTQ, Veteran and disability-focused Business Resource Groups
 * Access to learning content on Degreed and other informational platforms
 * Your ethics and integrity will be valued by a company with a string and stable ethical business with industry leading pay and benefits
   
   

MassMutual is an equal employment opportunity employer. We welcome all persons to apply.

If you need an accommodation to complete the application process, please contact us and share the specifics of the assistance you need.

California residents: For detailed information about your rights under the California Consumer Privacy Act (CCPA), please visit our California Consumer Privacy Act Disclosures page.

","Be among the first 25 applicants","Full-time","Entry level","Finance and Sales","Financial Services","","","","3631","https://www.linkedin.com/jobs/view/quantitative-risk-developer-at-massmutual-4340153754?trk=public_jobs_topcard-title","EASY_APPLY",""
"Manager, Operations Engineering","Hawthorne, CA","2 weeks ago","2025-11-14","https://www.linkedin.com/jobs/view/manager-operations-engineering-at-spacex-4323955329?trk=public_jobs_topcard-title","SpaceX","https://www.linkedin.com/company/spacex?trk=public_jobs_topcard-org-name","SpaceX was founded under the belief that a future where humanity is out exploring the stars is fundamentally more exciting than one where we are not. Today SpaceX is actively developing the technologies to make this possible, with the ultimate goal of enabling human life on Mars.

OPERATIONS ENGINEERING MANAGER

This leader will be responsible for optimizing operations, conducting strategic planning, aligning resources to priorities, and assessing progress toward targets for our critical facilities in Hawthorne, CA. They will lead a team of highly skilled engineers, schedulers, and data analysts who proactively identify and address operational challenges, implement industrial engineering practices, derive actionable information from data, and synchronize work priorities across our campus. Scope includes managing internal department priorities and resources and synchronizing efforts with cross functional partners.

Responsibilities


 * Manage a team of operations engineers, industrial engineers, and data analysts to focus them on the company’s most critical problems. Manage their development and career progression to become SpaceX people-leaders.
 * Align people, processes, products, parts, and physical plants to meet ambitious safety, quality, output, and efficiency targets.
 * Conduct operations engineering at a strategic level by optimizing resources, schedules, and risk under uncertainty across SpaceX production and launch.
 * Analyze complex problems involving multiple stakeholders, driving toward optimal solutions in an uncertain and ambiguous future landscape.
 * Manage the development of advanced tools to analyze delivery, capacity, costs vs benefits, supply chain, and operations to guide executive decisions in anticipation of change.
 * Leverage operational data to identify trends, propose leading indicators, and provide predictive information to steer executive decisions.
 * Lead inter-disciplinary and cross-functional teams to develop and manage production strategy, mitigate future risks, and seize emerging opportunities.
 * Identify operational challenges within the organization, lead problem formulation, determine root cause, and implement creative and effective solutions.
 * Develop key performance measures, and identify decision points and actions to optimize production to meet demand, ensuring measured parameters correlate with overall company objectives.
 * Collaborate with cross-departmental partners in supply chain, engineering, operations, and finance groups to synchronize efforts.
 * Capture best practices of production systems and manage organizational knowledge and lessons-learned.
 * Manage production workforce development efforts to ensure technicians and engineers are trained, qualified, and incentivized to perform their assigned roles.
   
   

Basic Qualifications


 * Bachelor's degree in an engineering discipline.
 * 4+ years of experience in one or more of the following:
    * Engineering
    * Production operations
    * Supply chain management
    * Military operations

 * 1+ years of experience in a leadership role with direct reports.
   

Preferred Skills And Experience


 * Experience or education in management science and engineering, operations engineering, operations research, or industrial engineering.
 * Experience with data-based decision making, modeling of complex systems, and framing executive decisions supported by engineering analysis.
 * Ability to work in fast-paced, high stress environments.
 * Excellent written and executive communication skills.
 * Proficiency with statistics, data analysis, cost/benefit analysis, and visualization.
 * Experience with data visualization tools, discrete event modeling tools, data queries and analysis.
 * Experience leading in a developmental manufacturing environment, in aerospace production, or in a dynamic multi-dimensional industry.
 * Ability to work autonomously, prioritize work, and make resource allocation recommendations that involve risk and uncertainty.
   
   

Additional Requirements


 * Must be able to work extended hours and/or weekends as needed, including occasional short-notice domestic travel.
   
   

Compensation And Benefits

Pay range:

Operations Engineering/Manager: $150,000.00 - $190,000.00/per year

Your actual level and base salary will be determined on a case-by-case basis and may vary based on the following considerations: job-related knowledge and skills, education, and experience.

Base salary is just one part of your total rewards package at SpaceX. You may also be eligible for long-term incentives, in the form of company stock, stock options, or long-term cash awards, as well as potential discretionary bonuses and the ability to purchase additional stock at a discount through an Employee Stock Purchase Plan. You will also receive access to comprehensive medical, vision, and dental coverage, access to a 401(k) retirement plan, short and long-term disability insurance, life insurance, paid parental leave, and various other discounts and perks. You may also accrue 3 weeks of paid vacation and will be eligible for 10 or more paid holidays per year. Employees accrue paid sick leave pursuant to Company policy which satisfies or exceeds the accrual, carryover, and use requirements of the law.

Itar Requirements


 * To conform to U.S. Government export regulations, applicant must be a (i) U.S. citizen or national, (ii) U.S. lawful, permanent resident (aka green card holder), (iii) Refugee under 8 U.S.C.
 * 1157, or (iv) Asylee under 8 U.S.C.
 * 1158, or be eligible to obtain the required authorizations from the U.S. Department of State. Learn more about the ITAR here.
   
   

SpaceX is an Equal Opportunity Employer; employment with SpaceX is governed on the basis of merit, competence and qualifications and will not be influenced in any manner by race, color, religion, gender, national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability or any other legally protected status.

Applicants wishing to view a copy of SpaceX’s Affirmative Action Plan for veterans and individuals with disabilities, or applicants requiring reasonable accommodation to the application/interview process should reach out to EEOCompliance@spacex.com.","86 applicants","Full-time","Mid-Senior level","Management and Manufacturing","Aviation and Aerospace Component Manufacturing","$150,000.00/yr - $190,000.00/yr","","","30846","https://www.linkedin.com/jobs/view/manager-operations-engineering-at-spacex-4323955329?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr. Manager, Software Engineering (Mobile)","San Diego, CA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/sr-manager-software-engineering-mobile-at-petco-4338961112?trk=public_jobs_topcard-title","Petco","https://www.linkedin.com/company/petco-animal-supplies-inc-?trk=public_jobs_topcard-org-name","Create a healthier, brighter future for pets, pet parents and people!
If you want to make a real difference, create an exciting career path, feel welcome to be your whole self and nurture your wellbeing, Petco is the place for you.
Our core values capture that spirit as we work to improve lives by doing what’s right for pets, people and our planet.

 * We love all pets like our own
 * We’re the future of the pet industry
 * We’re here to improve lives
 * We drive outstanding results together
 * We’re welcome as we are
   

Petco is a category-defining health and wellness company focused on improving the lives of pets, pet parents and Petco partners. We are 29,000 strong and operate 1,500+ pet care centers in the U.S., Mexico and Puerto Rico, including 250+ Vetco Total Care hospitals, hundreds of preventive care clinics and eight distribution centers. We’re focused on purpose-driven work, and strongly believe what’s good for pets, people and our planet is good for Petco.
Job Summary
We are seeking an experienced Senior Manager, Software Engineering (Digital Commerce/Mobile) to lead and scale our mobile engineering team responsible for delivering high-performance, customer-focused e-commerce applications. This role involves driving technical excellence, shaping product direction, and managing cross-functional collaboration to deliver seamless mobile shopping experiences on iOS and Android platforms.
Key Responsibilities
Team Leadership & Development

 * Lead, mentor, and grow a team of iOS and Android engineers, fostering a culture of ownership, innovation, and continuous learning.
 * Set clear goals, conduct regular performance reviews, and provide technical guidance and career development support.
   

Technical Strategy & Execution

 * Collaborate with Product Management, Design, and QA to define the mobile roadmap aligned with business goals.
 * Own the technical vision for the mobile app, ensuring scalability, performance, reliability, and security.
 * Review architecture and code to ensure high standards and maintainability.
 * Drive the adoption of best practices in mobile development, testing, and CI/CD pipelines.
   

Project Management

 * Plan, track, and deliver key mobile initiatives on time and within budget.
 * Manage priorities, delegate tasks, and remove blockers in a fast-paced, agile environment.
   

Cross-functional Collaboration

 * Work closely with backend, DevOps, product, marketing, and customer support teams to ensure a seamless user experience.
 * Champion customer-centric engineering decisions based on data, feedback, and market trends.
   

Innovation & Continuous Improvement

 * Stay current with mobile technologies and trends; evaluate and adopt tools and frameworks that improve developer productivity and user experience.
 * Drive A/B testing, analytics, and performance monitoring strategies to optimize app performance and customer engagement.
   

Required Qualifications

 * 12+ years of software engineering experience, with at least 3 years in a management or leadership role.
 * Proven experience managing mobile teams delivering high-traffic consumer-facing apps (e-commerce experience preferred).
 * Strong understanding of native iOS and Android development (Swift, Kotlin, Java), as well as cross-platform solutions (e.g., Flutter or React Native) is a plus.
 * Deep knowledge of mobile app architecture, API integration, mobile security, and app store deployment.
 * Experience with Agile methodologies, CI/CD, and modern software delivery practices.
 * Strong communication and interpersonal skills.
   

Preferred Qualifications

 * Experience in scaling mobile apps to millions of users.
 * Familiarity with personalization, in-app analytics, A/B testing tools (e.g., Firebase, Adobe Analytics, Adobe target).
 * Experience working with cloud platforms (AWS, GCP) and backend e-commerce systems (IBM WCS, Hybris, custom solutions).
 * Bachelor’s or Master’s degree in Computer Science or related field.
   

Qualified applications with arrest or conviction records will be considered for employment in accordance with the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act.
The pay ranges outlined below are presented in accordance with state-specific regulations. These ranges may differ in other areas and could be subject to variation based on regulatory minimum wage requirements. Actual pay rates will depend on factors such as position, location, level of experience, and applicable state or local minimum wage laws. If the regulatory minimum wage exceeds the minimum indicated in the pay range below, the regulatory minimum wage will be the minimum rate applied.
Salary Range: $142,100.00 - $213,100.00
Hourly or Salary Range will be reflected above. For a more detailed overview of Petco Total Rewards, including health and financial benefits, 401K, incentives, and PTO - see https://careers.petco.com/us/en/key-benefits
Petco Animal Supplies, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, protected veteran status, or any other protected classification.
To translate this webpage to Spanish or other languages on your internet browser, click the translate button to the right of your browser address bar. Additional instructions can be found here: Google Chrome Help .
Para traducir esta página web al español u otros idiomas en su navegador de Internet, haga clic en el botón de traducción a la derecha de la barra de direcciones de su navegador. Puede encontrar instrucciones adicionales aquí: Google Chrome Ayuda.","33 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Retail","$142,100.00/yr - $213,100.00/yr","","","7795","https://www.linkedin.com/jobs/view/sr-manager-software-engineering-mobile-at-petco-4338961112?trk=public_jobs_topcard-title","EASY_APPLY",""
"Javascript Developer","Richardson, TX","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/javascript-developer-at-ltimindtree-4324495024?trk=public_jobs_topcard-title","LTIMindtree","https://in.linkedin.com/company/ltimindtree?trk=public_jobs_topcard-org-name","


About Us:

LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com.





Job Title: React Develope




r
Work Location: Richardson TX (Onsit




e)
Job descriptio




n:
Key Responsibili

 * tiesDesign develop and maintain full stack web applications using React Nodejs Go Py
 * thonBuild and integrate AI driven features using LLM frameworks and tools such as Lang Chain Lang Graph Cre
 * w AIDevelop pipelines and APIs for AI model integration data processing and infer
 * enceCollaborate with AI researchers product teams and DevOps engineers to design scalable and efficient AI enabled sys
 * temsImplement CICD pipelines and manage containerized deployments using Docker and Kubern
 * etesOptimize system performance and ensure reliability security and maintainabi
 * lityMentor team members and contribute to the continuous improvement of engineering pract




ices
Required Skills and Qualifica

 * tionsBachelors degree in Computer Science Engineering or a related
 * field8-10 years of software development experience in full stack technol
 * ogiesProficiency in Reactjs Nodejs and Go P
 * ythonHandson experience with LLM integration Generative AI applications and frameworks like Lang Chain Lang Graph Cr
 * ew AIExperience developing and deploying AI or ML based features within production environ
 * mentsStrong understanding of RESTful APIs microservices and system d
 * esignWorking knowledge of Docker Kubernetes and CICD pipe
 * linesFamiliarity with database systems such as Postg




reSQL
Benefits and

 * Perks:Comprehensive Medical Plan Covering Medical, Dental,
 * VisionShort Term and Long-Term Disability Co
 * verage401(k) Plan with Company
 * matchLife Ins
 * uranceVacation Time, Sick Leave, Paid Ho
 * lidaysPaid Paternity and Maternity




Leave
LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted







by law.

Safe return t

o office:In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable p




rocesses.","97 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","IT Services and IT Consulting","","","","86813252","https://www.linkedin.com/jobs/view/javascript-developer-at-ltimindtree-4324495024?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)"
"AI Operations Engineer – Finance","Santa Clara, CA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/ai-operations-engineer-%E2%80%93-finance-at-nvidia-4332978719?trk=public_jobs_topcard-title","NVIDIA","https://www.linkedin.com/company/nvidia?trk=public_jobs_topcard-org-name","NVIDIA has been transforming computer graphics, PC gaming, and accelerated computing for more than 25 years. It’s a unique legacy of innovation that’s fueled by great technology—and amazing people. Today, we’re tapping into the unlimited potential of AI to define the next era of computing. An era in which our GPU acts as the brains of computers, robots, and self-driving cars that can understand the world. Doing what’s never been done before takes vision, innovation, and the world’s best talent. As an NVIDIAN, you’ll be immersed in a diverse, supportive environment where everyone is encouraged to do their best work. Come join the team and see how you can make a lasting impact on the world.

NVIDIA is hiring an AI operations engineer within the Finance AI and Data Science team. You will work alongside data scientists, data engineers, AI developers, finance, IT, and other business partners enabling robust agentic systems supporting our finance organization. Your work will ensure continued best-in-class accuracy of production agents, automate assessment of citizen-developed models, help us implement Nvidia-on-Nvidia AI solutions, and prevent unexpected behavior in deployed models from reaching business stakeholders.

What You’ll Be Doing


 * Leverage AI, automation, and business knowledge to systematically assess bot & agent answer quality, flagging potentially incorrect or incomplete answers for human review.
 * Create robust evaluation data sets and data flywheels based on finance feedback, business priorities, and knowledge bases.
 * Monitor & optimize AI systems using observability stacks to track model performance, system health, and lifecycle metrics. Build continuous evaluation pipelines to measure production model outputs, accuracy, and confidence distributions.
   
   

What We Need To See


 * 5+ years of experience in AI-adjacent areas (ML ops, NLP, or related roles), with at least 2 years applying gen AI to business problems.
 * BS/MS or equivalent experience in Data Science, Computer Science, Information Systems, Software Engineering, Economics, or other technical fields. Technical Master’s with corp / ops finance or business background is preferred.
 * Experience working with production AI applications, including monitoring, tracing, logging, performance evaluation, and data flywheels.
 * Hands-on expertise in model evaluation frameworks, including LLM-as-a-judge and human-in-the-loop review workflows.
 * Excellent communication to work with business partners, IT, internal development teams, and senior management.
   
   

Ways To Stand Out From The Crowd


 * Subject matter expertise in corporate finance, ops finance, and/or adjacent areas.
 * GenAI expertise including prompt optimization, vector databases, RAG pipeline implementation, mixture-of-experts, and MCP. Deep understanding of integrating generative technology into deterministic systems.
 * Experience with complex multi-agentic systems.
 * Experience implementing secure authentication and authorization systems for AI services with role-based access controls.
 * Teaching or mentoring experience in technical domains, enthusiasm for exploring and implementing new technologies, and creative problem-solving skills.
   
   

NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people in the world working for us. If you're creative, ambitious and enjoy having fun, then what are you waiting for apply today!

Your base salary will be determined based on your location, experience, and the pay of employees in similar positions. The base salary range is 152,000 USD - 230,000 USD for Level 3, and 168,000 USD - 264,500 USD for Level 4.

You will also be eligible for equity and benefits .

Applications for this job will be accepted at least until September 30, 2025.NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.

JR2003659

","88 applicants","Full-time","Entry level","Engineering and Information Technology","Computer Hardware Manufacturing, Software Development, and Computers and Electronics Manufacturing","$152,000.00/yr - $264,500.00/yr","","","3608","https://www.linkedin.com/jobs/view/ai-operations-engineer-%E2%80%93-finance-at-nvidia-4332978719?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Chicago, IL","3 weeks ago","2025-11-04","https://www.linkedin.com/jobs/view/data-engineer-at-jss-search-4337319290?trk=public_jobs_topcard-title","JSS Search","https://uk.linkedin.com/company/jss-search?trk=public_jobs_topcard-org-name","Data Engineer –Trading Firm

Up to $110,000

Chicago Based - 2x a week




I’m hiring a Data Engineer for a lean collaborative trading firm, where you’ll work closely with teams across the US (Chicago, New York, Texas), the UK, and Europe — making a genuine impact in a flat, agile structure with minimal red tape.




The Role:

You’ll join the central data engineering team (3 engineers globally) focused on building and scaling robust, production-grade pipelines. The firm’s data ecosystem is currently on-prem, with a major project underway to transition to Airflow-based orchestration.




Key Responsibilities:

 * Build and maintain data pipelines (weekly/monthly) from internal systems and external APIs.
 * Work with large, complex datasets, ensuring scalability and reliability.
 * Support the move from on-prem to more automated workflows using Airflow.
 * Collaborate with global engineering and trading teams in an Agile, sprint-based setup.
 * Contribute to data lake and warehouse design — focusing on architecture and performance.




Tech Stack & Skills:

 * Must have: Python & Airflow
 * Strongly preferred: SQL, AWS (S3), Docker, Kubernetes, Git, CI/CD
 * Experience working with large-scale data ingestion and transformation
 * Comfortable adapting to legacy systems and driving modernisation

","Over 200 applicants","Full-time","Mid-Senior level","Engineering","Software Development","","Lydia Morfett-Murdock","https://uk.linkedin.com/in/lydia-morfett-murdock-jss","10919243","https://www.linkedin.com/jobs/view/data-engineer-at-jss-search-4337319290?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist, Customer Engineering","Boston, MA","1 month ago","2025-10-27","https://www.linkedin.com/jobs/view/data-scientist-customer-engineering-at-datarobot-4290310631?trk=public_jobs_topcard-title","DataRobot","https://www.linkedin.com/company/datarobot?trk=public_jobs_topcard-org-name","Job Description:

DataRobot delivers AI that maximizes impact and minimizes business risk. Our platform and applications integrate into core business processes so teams can develop, deliver, and govern AI at scale. DataRobot empowers practitioners to deliver predictive and generative AI, and enables leaders to secure their AI assets. Organizations worldwide rely on DataRobot for AI that makes sense for their business — today and in the future.

Job Description

The Data Scientist role in the Customer Engineering team plays a pivotal role at the intersection of AI/ML engineering, solution development, and go-to-market strategy. We are looking for an experienced data scientist who excels in hands-on problem-solving, can lead technical initiatives, and can serve as a trusted advisor to both internal teams and customers.

Your work will focus on designing, developing, and delivering production-ready AI solutions that accelerate customer adoption of the DataRobot platform, with a particular focus on SAP workflows.

Beyond solution development, you will work directly with clients in various industries as the DataRobot product and data science subject matter expert.

This role is ideal for a motivated data scientist with proven experience who wants to work hands-on with Python, pandas, and modern AI tooling while making a significant impact on customer success and AI adoption. If you thrive in a fast-paced, highly autonomous environment and want to build AI solutions that truly scale, we'd love to hear from you!

Key Responsibilities:



 * Design and develop sophisticated, production-ready assets that accelerate AI/ML adoption for customers, ranging from reusable solution templates to deployable frameworks.
 * Lead the implementation of AI/ML workflows using Python, pandas, and modern AI tooling, ensuring they are scalable, maintainable, and customer-ready.
 * Establish and champion engineering best practices to improve performance, scalability, and maintainability of AI/ML solutions.
 * Work within existing infrastructure to support scalable AI deployments, including CI/CD automation, API integrations, and containerized environments (Docker, Kubernetes).
 * Create comprehensive testing strategies and implement automated tests for AI/ML workflows.
 * Lead cross-functional collaboration with product, sales, and marketing teams to scale high-impact solutions.
 * Address complex real-world deployment challenges, including monitoring, logging, and improving reliability in AI/ML workflows.
 * Serve as a technical liaison in customer engagements, representing the DataRobot product to various personas from data scientists to C-level executives.
 * Lead proof of value processes and quantify the business impact of DataRobot solutions.
 * Ensure the success of our customers by collaborating with business stakeholders to ensure that AI solutions deliver successful business outcomes
 * Stay ahead of industry trends, continuously refining our approaches and advocating for best practices in AI/ML engineering.
 * Work closely with enablement teams to develop documentation, content, and training materials that scale adoption of our solutions.
   
   
   

What this Role is Not:



 * A SWAT demo team - while you will be customer-facing, this role is about building reusable solutions, not one-off demos.
 * A technical marketing role - you'll collaborate with marketing but won't be driving content strategy.
 * A pure research role - we need hands-on builders who can ship working solutions that make an impact.
   
   
   

Knowledge, Skills and Abilities:



 * Strong Python ecosystem expertise with the ability to design, develop, and troubleshoot complex ML workflows using libraries like pandas, NumPy, scikit-learn, and web server tools like FastAPI.
 * 3-5 years of experience in data science, machine learning, or AI development with a proven track record of delivering production solutions.
 * Experience with ML model development, deployment, and evaluation. You should be comfortable leading data-to-insights projects and optimizing predictive models.
 * Strong data engineering capabilities, including working with structured/unstructured data, feature engineering, and optimizing ML pipelines.
 * Proficiency in writing efficient, maintainable, and well-structured code, with an emphasis on reusability, scalability, and production readiness.
 * Experience with software engineering best practices, including containerization (Docker), CI/CD automation, and cloud-based ML deployment.
 * Experience with APIs, SDK development, or ML platform integrations.
 * Proven experience in consultative sales processes in the data/analytics marketplace, with the ability to translate complex technical concepts into business value.
 * Excellent communication skills, with the ability to influence stakeholders at various technical and business levels.
 * Self-motivated, driven, and eager to take on challenges. We're looking for someone who thrives in a fast-moving, high-growth, and high-autonomy environment.
   
   
   

Nice to Have:



 * Experience with SAP workflows and integration points
 * Experience with cloud platforms (AWS, Azure, GCP) for AI/ML deployment
 * Strong knowledge of automated testing and test-driven development
 * Familiarity with generative AI solutions like RAG, finetuning, etc.
 * Experience with DataRobot platform or similar enterprise AI platforms
 * Masters' degree in Data Science, Computer Science, or related field
 * Experience presenting at conferences or creating technical content
   
   
   

Why Join Us?



 * Hands-on, high-impact work - you'll be building real, production-ready AI solutions that customers actually use.
 * Small, elite team with direct influence - you'll work closely with product, engineering, and go-to-market teams to shape AI adoption strategies.
 * Fast learning environment - we invest in our people, providing opportunities to grow and expand your skills.
 * Clear career trajectory - whether you want to specialize in data science, transition into engineering, or take on leadership, we'll help you get there.
 * Work on cutting-edge AI solutions that have real-world impact and are used by enterprises worldwide.
   
   
   

This is a unique opportunity to build AI applications, ensuring that data scientists and developers can seamlessly create, customize, and deploy AI solutions at scale. If you're passionate about impacting the future of AI adoption, we'd love to hear from you.

The talent and dedication of our employees are at the core of DataRobot’s journey to be an iconic company. We strive to attract and retain the best talent by providing competitive pay and benefits with our employees’ well-being at the core. Here’s what your benefits package may include depending on your location and local legal requirements: Medical, Dental & Vision Insurance, Flexible Time Off Program, Paid Holidays, Paid Parental Leave, Global Employee Assistance Program (EAP) and more!

DataRobot Operating Principles:



 * Wow Our Customers
 * Set High Standards
 * Be Better Than Yesterday
 * Be Rigorous
 * Assume Positive Intent
 * Have the Tough Conversations
 * Be Better Together
 * Debate, Decide, Commit
 * Deliver Results
 * Overcommunicate
   
   
   

Research shows that many women only apply to jobs when they meet 100% of the qualifications while many men apply to jobs when they meet 60%. At DataRobot we encourage ALL candidates, especially women, people of color, LGBTQ+ identifying people, differently abled, and other people from marginalized groups to apply to our jobs, even if you do not check every box. We’d love to have a conversation with you and see if you might be a great fit.

DataRobot is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. DataRobot is committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. Please see the United States Department of Labor’s EEO poster and EEO poster supplement for additional information.

All applicant data submitted is handled in accordance with our Applicant Privacy Policy.","Over 200 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Software Development","","","","2672915","https://www.linkedin.com/jobs/view/data-scientist-customer-engineering-at-datarobot-4290310631?trk=public_jobs_topcard-title","EASY_APPLY",""
"Member of Technical Staff, Pre-training Data","Palo Alto, CA","3 weeks ago","2025-11-10","https://www.linkedin.com/jobs/view/member-of-technical-staff-pre-training-data-at-xai-4335305380?trk=public_jobs_topcard-title","xAI","https://www.linkedin.com/company/xai?trk=public_jobs_topcard-org-name","About xAI

xAI’s mission is to create AI systems that can accurately understand the universe and aid humanity in its pursuit of knowledge. Our team is small, highly motivated, and focused on engineering excellence. This organization is for individuals who appreciate challenging themselves and thrive on curiosity. We operate with a flat organizational structure. All employees are expected to be hands-on and to contribute directly to the company’s mission. Leadership is given to those who show initiative and consistently deliver excellence. Work ethic and strong prioritization skills are important. All engineers are expected to have strong communication skills. They should be able to concisely and accurately share knowledge with their teammates.

About the Team

The pre-training data team at xAI is dedicated to crafting the ultimate data recipe for training an omni-model that unlocks the universe's secrets through text, image, video, and audio. To achieve this vision, we're seeking visionary engineers with deep expertise in multimodal pre-training data.

Tech Stack
 * Python
 * Spark
 * Ray

Location

The role is based in the Bay Area [San Francisco and Palo Alto]. Candidates are expected to be located near the Bay Area or open to relocation.

In this role, you might:
 * Collaborate with the crawling team to discover and source datasets.
 * Architect pipelines to transform datasets at petabyte scales with efficiency and precision.
 * Develop robust and diverse evaluations for pre-training models.
 * Craft insightful experiments to assess dataset performance.
 * Innovate the recipe for scaling pre-training data to new frontiers.

Exceptional candidates may have:
 * Expertise in ML and large model scaling, with familiarity across all kinds of scaling laws.
 * Strong ability to design ML experiments.
 * Familiarity with state-of-the-art techniques for curating AI training data for text, image, audio, and video modalities.
 * Strong engineering abilities in Spark, Ray, and other frameworks for large-scale data processing.

Interview Process

After submitting your application, the team reviews your CV and statement of exceptional work. If your application passes this stage, you will be invited to a 15-minute interview (“phone interview”) during which a member of our team will ask some basic questions. If you clear the initial phone interview, you will enter the main process, which consists of four technical interviews:

 1. Coding assessment in a language of your choice.
 2. Technical sessions (2): These sessions will be testing your ability to formulate, design and solve concrete problems in real world with LLM. 
 3. Meet the Team: Present your past exceptional work and your vision with xAI to a small audience.

Our goal is to finish the main process within one week. All interviews will be conducted via Google Meet.

Annual Salary Range

$180,000 - $440,000 USD

Benefits

Base salary is just one part of our total rewards package at xAI, which also includes equity, comprehensive medical, vision, and dental coverage, access to a 401(k) retirement plan, short & long-term disability insurance, life insurance, and various other discounts and perks.

xAI is an equal opportunity employer.

California Consumer Privacy Act (CCPA) Notice","37 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Technology, Information and Internet","$180,000.00/yr - $440,000.00/yr","","","96151950","https://grnh.se/b8pz906d7us?source=LinkedIn","EXTERNAL",""
"Manager, Business Intelligence Engineering","Seattle, WA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/manager-business-intelligence-engineering-at-snap-inc-4338282865?trk=public_jobs_topcard-title","Snap Inc.","https://www.linkedin.com/company/snap-inc-co?trk=public_jobs_topcard-org-name","Snap Inc is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are Snapchat, a visual messaging app that enhances your relationships with friends, family, and the world; Lens Studio, an augmented reality platform that powers AR across Snapchat and other services; and its AR glasses, Spectacles.

The Data Science & Insights team seeks to leverage our massive data sets into actionable insights that deliver business value. As truth seekers and truth tellers, we relay what the data says without bias, even when inconvenient or difficult. We aim to improve decision-making quality and speed across the organization to enable a deeper understanding of our customers and products. We focus on efficient and effective analytic execution, positioning ourselves as the go-to experts with deep knowledge and expertise, constantly striving for better, faster insights from data.

We’re looking for a Manager, Business Intelligence Engineering to join Snap Inc!

What you’ll do:


 * Lead a team to establish foundational data and analytics capabilities for our ads platform and identify key insights around our ads platform.
 * Collaborate with Data Science, Product, and Engineering, and Business partners to design and build data tools/visualizations, operationalize metrics, conduct investigations, deliver actionable insights, and conduct in-depth product analysis.
 * Understand the challenges within our ads platform and help make decisions based on data driven insights by analyzing information from multiple sources in a logical and coherent data story
 * Build and maintain dashboards that communicate the performance of the various components of our ads platform with compelling data visualizations and consistency
 * Develop data pipelines that power our analytics data layer for analysis, reporting and dashboarding ensuring efficiency and reliability
 * Own the data model used to power our underlying data layer for monetization including the associated pipelines, data structures, and schemas
 * Maintain the key metric definitions and understand them at a deep level, offering recommendations for improvements and new metrics
 * Conduct exploratory and deep dive analysis to understand drivers of revenue performance and overall platform performance, developing actionable insights to Product and Engineering leadership
 * Own root-cause investigations starting from proactive identification of metric regressions to resolution including recommendations for long term product improvements
 * Proactively identify improvements to our platform or business that can be expected to drive increased revenue
   
   

Knowledge, Skills & Abilities:


 * Data driven and analytical mindset
 * Hands-on expertise with data warehousing tools and workflow automation
 * Comfortable with quantitative concepts
 * Strong attention to detail and organizational skills
 * Excellent verbal and written communication skills
 * Ability to work in an agile, dynamic environment
 * Ability to use tech to improve work-flows and create efficiencies
   
   

Minimum Qualifications:


 * BS/BA degree in Analytics, Statistics, Economics or other technical field or equivalent years of experience
 * 10+ years of post-Bachelor’s analytics experience; or a Master’s degree in a technical field + 9+ year of post-grad analytics experience; or a PhD in a related technical field + 6+ years of post-grad analytics experience
 * 1+ years relevant people management experience
   
   

Preferred Qualifications:


 * Advanced Degree in Analytics, Statistics, Economics, Computer Science or other technical field
 * Experience as a data scientist and/or managing a data team
 * Experience in the digital media space
 * A passion for Snapchat as a user and knowledge of our ad products
 * Proficiency in Looker, BigQuery, and Airflow
   
   

If you have a disability or special need that requires accommodation, please don’t be shy and provide us some information.

""Default Together"" Policy at Snap: At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office 4+ days per week.

At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets.

We are an Equal Opportunity Employer and will consider qualified applicants with criminal histories in a manner consistent with applicable law (by example, the requirements of the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, where applicable).

Our Benefits: Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid parental leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success!

Compensation

In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. The starting pay may be negotiable within the salary range for the position. These pay zones may be modified in the future.

Zone A (CA, WA, NYC):

The base salary range for this position is $209,000-$313,000 annually.

Zone B:

The base salary range for this position is $199,000-$297,000 annually.

Zone C:

The base salary range for this position is $178,000-$266,000 annually.

This position is eligible for equity in the form of RSUs.","54 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Software Development","$178,000.00/yr - $313,000.00/yr","","","15191764","https://wd1.myworkdaysite.com/en-US/recruiting/snapchat/snap/job/Los-Angeles-California/Manager\u002d\u002dBusiness-Intelligence-Engineering_R0043164-1?source=LinkedIn","EXTERNAL",""
"Data Engineer","Schaumburg, IL","1 week ago","2025-11-18","https://www.linkedin.com/jobs/view/data-engineer-at-seko-logistics-4336941875?trk=public_jobs_topcard-title","SEKO Logistics","https://www.linkedin.com/company/seko-logistics?trk=public_jobs_topcard-org-name","Job Description

About SEKO

SEKO started out in business in 1976, operating out of a single Chicago office. Since then, we have built a solid reputation throughout the world as an innovative and flexible provider of first-class logistics services. We provide complete Supply Chain Solutions, specializing in transportation, logistics, forwarding and warehousing. We also lead the industry with innovative and customizable IT solutions, which provide a seamless flow of information and give our growing customer base true supply chain visibility. With over 120 offices in 40 countries worldwide, our unique shareholder management model enables you to benefit from Global implementation experience and expertise across all industry sectors, coupled with vital in-country knowledge and service at the local level.

Key Accountabilities Include


 * Design and develop scalable data pipelines to collect, process, and store large volumes of data.
 * Collaborate with data scientists and analysts to drive scope & requirements as well as deliver strong technical design of data analytics solutions.
 * Ensure data quality and integrity through cleansing processes, validation, and automated testing.
 * Develop and maintain requirements, design documentation and test plans.
 * Implement data integration solutions to combine data from various sources.
 * Optimize data workflows for performance and reliability and reduced cloud consumption.
 * Monitor and troubleshoot data pipeline issues to ensure smooth operation.
 * Establish release management & CI/CD for data solutions.
 * Provide direction and coordination for development and support teams including globally located resources.
 * Participate in the development of a safe and healthy workplace. Comply with instructions given for their own safety and health and that of others, in adhering to safe work procedures. Co-operate with management in fulfilment of its legislative obligations.
 * Other duties as assigned by management.
   
   

REQUIREMENTS:Current industr


 * Must be a self-starter capable of independently meeting objectives and interacting with members of various teams successfully
 * Strong analytical background and mindset
 * Demonstrated expertise in SOP development, training strategy, and process improvement
 * Ability to elicit buy-in and cooperation from a variety of individuals as well as departments
 * Hands-on, flexible, and responsive to dynamic fast paced work environment
 * Capability managing several initiatives
 * Strong team player with a continuous improvement mindset
   
   

Education & Experience

Minimum


 * Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent work experience).
 * 5 years’ experience in a data engineering role.
 * 3 years’ experience building and supporting data lakehouse architectures using delta lake and change data feeds.
 * 3 years’ experience with Spark and Python.
 * 3 years’ experience writing code using OO programming.
 * 3 years’ experience designing data warehouse table architecture such as star schema or Kimball method
 * Experience developing and installing wheelhouse packages for managing dependencies and distributing code.
 * Experience creating CI/CD pipelines for analytics solutions.
   
   

Preferred


 * Hands-on experience implementing data solutions using Microsoft Fabric.
 * Experience with machine learning and data science tools.
 * Knowledge of data governance and security best practices.
 * Experience in a larger IT environment with over 3,000 users and multiple domains.
 * Option for full-time remote position
   
   

Specialist Certifications

Current industry certifications from Microsoft cloud/data platforms or equivalent certifications. One or more of the following:


 * Microsoft Certified: Fabric Data Engineer Associate
 * Microsoft Certified: Azure Data Scientist Associate
 * Microsoft Certified: Azure Data Fundamentals
 * Google Professional Data Engineer
 * Certified Data Management Professional (CDMP)
 * IBM Certified Data Architect – Big Data
   
   

Compensation And Benefits

Base salary range and benefits information for this position are being included in accordance with requirements of various state/local pay transparency legislation. Please note that base salaries may vary for different individuals in the same role based on several factors, including but not limited to location of the role, individual competencies, education/professional certifications, qualifications/experience, performance in the role and potential for revenue generation (Producer roles only).

Compensation

The base salary compensation range being offer for this role is $79,500 - $113,600 USD per year. This role is also eligible for an annual incentive bonus.

SEKO Logistics is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status.

Benefits Designed With You In Mind

At SEKO Logistics, we are committed to supporting your well-being, professional growth, and financial stability (eligibility requirements apply). Our comprehensive benefits package includes:


 * Health and Welfare Benefits: Medical (including prescription coverage), Dental, Vision, Health Savings Account, Commuter Account (IL only), Flexible Spendings Account, Health Care and Dependent Care Flexible Spending Accounts, Group Accident, Group Accident, Critical Illness and hospital indemnity program, Life Insurance, AD&D, Wellbeing Program and Work/Life Resources (including Employee Assistance Program)
 * Leave Benefits: Paid Holidays, Annual Paid Time Off (includes paid state/local paid leave where required), Short-Term Disability, Long-Term Disability, Other Leaves (e.g., Bereavement, FMLA, ADA, Jury Duty, Military Leave, and Parental and Adoption Leave)
 * Retirement Benefits: Contributory Savings Plan (401k).
   
   

SEKO Worldwide is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.","Over 200 applicants","Full-time","Entry level","Information Technology","Transportation, Logistics, Supply Chain and Storage","$79,500.00/yr - $113,600.00/yr","","","45145","https://sekologistics.wd503.myworkdayjobs.com/Seko_Logistics/job/Schaumburg-IL/Data-Engineer_R-100761?source=LinkedIn","EXTERNAL",""
"Sr. Data Engineer","Bellevue, WA","1 week ago","2025-11-25","https://www.linkedin.com/jobs/view/sr-data-engineer-at-auger-4338927447?trk=public_jobs_topcard-title","Auger","https://www.linkedin.com/company/augerinc?trk=public_jobs_topcard-org-name","Join Auger — Where Innovation Meets Real-World Impact

Imagine a place where you get the best of both worlds: the speed and energy of a startup, and the experience of leaders who’ve built systems that scale globally.Founded by 23-year Amazon veteran and serial innovator Dave Clark and backed by a $100M investment led by Oak HC/FT, Auger isn’t just rethinking how global supply chains work—we’re redefining them.

What We’re Building

Auger is creating the world’s first agentic operating system for supply chains—turning one of the planet’s most complex systems into a source of foresight, resilience, and growth.We partner with leading global enterprises to solve their toughest challenges: accelerating decision speed, reducing costs, unlocking capital, and improving service. With Auger, brittle fragments become an indestructible engine of progress, economic strength, and planetary sustainability.

Why It Matters

Supply chain problems aren’t just business problems—they’re human ones. When a supply chain breaks down, products don’t reach shelves, workers face burnout, and the environment pays the price. Auger is here to change that.At Auger, you’ll join an expert team that’s fundamentally reshaping one of the world’s most vital industries. If you’re ready to build technology that makes a real impact on people, business, and the planet—come build with us.

About The Team & Role

The Customer Solutions Data Team at Auger is on a mission to revolutionize how global supply chain information is accessed, indexed, and advanced. Supply chain data is vast and messy, but it’s also the fuel that powers efficiency, sustainability, and innovation. Our team is developing analytical approaches that turn this raw, complex data into actionable intelligence, enabling smarter decisions and better outcomes for everyone. Variety, quality, timeliness, and completeness—this is the lifeblood of our work. If you’re a passionate engineer and developer who thrives on solving hard problems, exploring new platforms, and building something the world has never seen before, we want you on our team. Key ResponsibilitiesAs a Sr. Data Engineer, you will leverage new and existing data sources in support of Auger’s core data lake and ingestion of customer data into our platform. We're seeking teammates who love data of all kinds, are masters of building efficient, scalable, operable data pipelines, and are ready to take hands-on coding ownership in the following areas:


 * Data ingestion pipelines for existing and new data sources (both batch and real-time streaming)
 * Experience with all forms of multi-modal data types
 * Monitoring frameworks to protect data quality and consistency
 * Data modeling design and data architecture skills to support reporting and analytics requirements
 * Experience in the latest generation of data lake architectures, stream and batch processing, and managed cloud services to support scale.
   
   

Qualifications


 * Degree in Computer Science, Mathematics, Statistics, or other data-intensive discipline with substantive engineering experience.
 * 5+ years demonstrated development experience using SQL, Scala, Spark, Flink, Beam, and/or Python
 * 5+ years demonstrated experience in data management (structured and unstructured) and modern database technologies
 * Demonstrated experience developing data pipelines to support machine learning, LLMs or other analytical solutions
 * Experience working with multi-cloud providers such as AWS and Azure
 * Work and collaborate in-person at our Bellevue Headquarters
 * Ability to work collaboratively through ambiguity, with urgency, patience, and good humor
   
   

Placement within the range is determined by experience and qualifications. In addition to base salary, total compensation may include eligibility for equity-awards or bonuses. Auger also offers eligible full-time employees with a comprehensive benefits package, including medical, dental and vision insurance, a 401(k) plan with Company match, paid time off (PTO), and commuter benefits. The base pay range for this role is $225,000 – $300,000 per year.

Benefits


 * Highly competitive total compensation packages
 * Top tier medical, dental, and vision insurance and wellness perks
 * 401K with Company match
 * Work with teammates who tackle complex and consequential challenges with resilience, determination, and good humor.
   
   

Auger considers all qualified applicants for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.","163 applicants","Full-time","Mid-Senior level","Information Technology","Software Development","$225,000.00/yr - $300,000.00/yr","","","104815753","https://jobs.gem.com/auger/am9icG9zdDq8l9KuUpYvHlYmGgJ0mie6?utm_source=GemJobBoardLink&utm_medium=c291cmNlOn_6Jt9NeR2Lx5muox1O82w","EXTERNAL",""
"Lead Mechanical Engineer","Tennessee, United States","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/lead-mechanical-engineer-at-lumicity-4324407134?trk=public_jobs_topcard-title","Lumicity","https://www.linkedin.com/company/lumicity?trk=public_jobs_topcard-org-name","Lead Mechanical Engineer — UHV & Laser Systems

Job Summary

We’re looking for a seasoned Lead Mechanical Engineer to drive the design and development of ultra-high vacuum (UHV) systems integrated with laser-based instrumentation. You’ll lead mechanical architecture from concept to production, mentor engineers, and coordinate across optics, electronics, and manufacturing.

Key Responsibilities

 * Lead mechanical design of UHV chambers, mounts, feedthroughs, and vacuum-laser assemblies.
 * Develop 3D CAD models and detailed drawings, ensuring manufacturability and integration.
 * Choose and evaluate materials for UHV compatibility, minimizing outgassing and matching thermal/structural constraints.
 * Run thermal and structural analysis (e.g. FEA) for components under vacuum and thermal stress.
 * Define vacuum integration processes, including bake-out protocols, alignment strategies, and contamination control.
 * Manage vendor relationships for precision machining of vacuum and optical-mechanical hardware.
 * Lead design reviews, mentor junior engineers, and manage project risk, cost, and schedules.
 * Troubleshoot and refine designs based on test data and prototype feedback.

Required Skills

 * MS or PhD in Mechanical Engineering, or a closely related field.
 * 8+ years of experience designing UHV systems and laser-integrated mechanical assemblies.
 * Strong 3D CAD skills (SolidWorks, Creo, or similar).
 * Deep understanding of vacuum materials, low-outgassing metals, and sealing techniques (e.g., CF flanges).
 * Experience with FEA, thermal analysis, and precision opto-mechanics.
 * Leadership experience and strong communication across disciplines.
 * Proven ability to take designs from concept to manufactured product.

Preferred / Nice-to-Have

 * Experience with vacuum bake-out, leak detection, and all-metal seals.
 * Familiarity with UHV-specific materials (e.g., stainless steel 304L/316L, OFHC copper, ceramics).
 * Prior work on laser-in-vacuum systems (e.g., optical cavities, cavity alignment).
 * Clearance or ability to obtain security clearance, if needed.
 * Experience with additively manufactured UHV components.","25 applicants","Full-time","Mid-Senior level","Engineering","Engineering Services","$150,000.00/yr - $200,000.00/yr","Dylan Stone","https://www.linkedin.com/in/dylan-stone-731b02236","79500056","https://www.linkedin.com/jobs/view/lead-mechanical-engineer-at-lumicity-4324407134?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Paid maternity leave
Pension plan
Paid paternity leave
Disability insurance
Child care support"
"Data Scientist","Austin, TX","15 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-scientist-at-cintra-a-ferrovial-company-4340345537?trk=public_jobs_topcard-title","Cintra, a Ferrovial company","https://es.linkedin.com/company/cintra?trk=public_jobs_topcard-org-name","Join Ferrovial: Where Innovation Meets Opportunity

Are you ready to elevate your career with a global leader in infrastructure solving complex problems and generating a positive outcome on people’s lives? At Ferrovial, we are not just a company; we are a community of innovators and trailblazers. Listed on three major stock markets: Nasdaq (US), Euronext Amsterdam (Netherlands) and IBEX 35 (Spain), we are also member of the Dow Jones Sustainability Index and FTSE4Good. We operate in more than 15 countries and have a workforce of over 24,000 professionals worldwide. Ferrovial’s activity is carried out through our business units, including Highways, Airports, Construction, and Energy.

Cintra is the highways business unit of Ferrovial, one of the world’s leading infrastructure operators committed to developing sustainable solutions. Today, its portfolio includes nearly 1,200 miles of managed highways globally, representing a total global investment in roadway improvements of over $24.8 billion.

We provide the maximum value in each project, managing all phases of the life cycle of our state-of-the-art infrastructure assets, such as the 407 ETR in Canada, the Managed Lanes LBJ and NTE in Texas, I-77 in North Carolina, I-66 in Virginia and our projects in Europe, South America, and India.

Why Ferrovial?


 * Global presence, local impact: Be part of a company that is shaping the future of infrastructure worldwide, with challenging roles and projects that make a real difference.
 * Collaborative excellence: Work alongside talented professionals in a collaborative environment where your ideas and contributions are valued.
 * Inclusive Culture: Thrive in an innovative and respectful workplace that values every voice, celebrates what makes us unique and turns differences into innovation.
 * Career growth: Benefit from global and cross-business unit mobility, with development processes designed to ensure your professional growth.
 * Compelling benefits and employee wellbeing: Enjoy a comprehensive benefits package that rewards your hard work and dedication and take advantage of initiatives designed to support your physical and psychological health.
 * Productivity tools: Utilize cutting-edge tools like Microsoft Copilot to enhance your productivity and efficiency.
   
   

Job Description:

Cintra, a Ferrovial company, develops and manages toll roads and transport infrastructure around the world. The Customer Analytics department within Cintra is responsible for exploring and identifying future sources of competitive advantage. The Data Scientist will perform data and statistical analyses to address strategic business questions posed by management. Responsibilities include communicating findings to management and supporting the work of other analytics teams. The Data Scientist is expected to stay up to date on new analytical methods, data sources, and techniques. This position is based in Austin, TX, and supports projects and teams across North America and Europe.

Essential Duties And Responsibilities


 * Execute Customer Analytics projects with three strategic goals:
 * Develop revenue optimization strategies for existing toll concessions.
 * Build models to accurately forecast traffic and revenue using existing and new data sources and analytical techniques; identify key variables affecting forecasts through machine learning and statistical analysis.
 * Design experiments and develop/execute measurement plans to evaluate new initiatives in a test & learn environment.
 * Stay informed of new developments in analytics techniques, systems, data sources, and providers, and evaluate opportunities to apply them to benefit Cintra.
   
   

Qualifications (Knowledge, Skills & Abilities)

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skills, and abilities needed to fulfill those duties. Reasonable accommodations may be provided to enable individuals with disabilities to perform the essential functions.

Key Requirements


 * Advanced degree (M.S. or Ph.D.) in quantitative fields such as Operations Research, Data Science, Statistics, Computer Science, Industrial Engineering, or a related discipline from an accredited institution.
 * 1–3 years of experience building advanced analytical models that demonstrate measurable business impact.
 * Proficiency in advanced analytical techniques such as regression, classification, clustering, tree-based methods, and optimization models.
 * Experience performing statistical analysis of controlled experiments.
 * Experience using SQL and/or Spark to process, clean, and analyze large datasets.
 * Experience with R and/or Python.
 * Experience working with Databricks.
   
   

Professional Qualities


 * A research-oriented and innovative mindset—curious, proactive, and eager to explore new ideas.
 * Strong written and verbal communication skills, particularly in technical report writing.
 * Ability to summarize, present, and explain findings and conclusions to management.
 * Strong task management skills and the ability to meet strict deadlines independently and in an organized manner.
 * Ability to collaborate effectively within a self-managed team structure.
 * Demonstrates strong problem-solving skills.
   
   

Work Environment & Physical Demands

The work environment and physical demands described here are representative of those an employee may encounter while performing the essential functions of this job. Reasonable accommodation may be provided to enable individuals with disabilities to perform these functions.


 * The noise level in the work environment is usually quiet.
 * Some travel is required, which may include air travel.
 * The employee must occasionally lift and/or move up to 10 pounds.
 * Vision requirements include the ability to adjust focus, particularly for computer use.
 * While performing the duties of this job, the employee is regularly required to talk or hear.
 * The employee is frequently required to stand, walk, and sit.
   
   

Seize the challenge. Move the world together! Innovative, creative, respectful, and diverse are some of the ways we describe ourselves. We are motivated by challenges, and we collaborate across our business units to move the world together. Your journey to a fulfilling career starts here!

Ferrovial is an equal opportunity employer.  We treat all jobs applications equally, regardless of gender, color, race, ethnicity, religion, national origin, age, disability, pregnancy, sexual orientation, gender identity and expression, covered veteran status or protected genetic information (each, a “Protected Class”), or any other protected class in accordance with applicable laws.

#WeAreFerrovial","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Civil Engineering","","","","26155","https://ferrovial.wd3.myworkdayjobs.com/Ferrovial_Career_Site/job/Austin-TX/Data-Scientist_JR15228?source=LinkedIn","EXTERNAL",""
"Corporate Solutions Engineer","San Francisco, CA","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/corporate-solutions-engineer-at-postman-4337193419?trk=public_jobs_topcard-title","Postman","https://www.linkedin.com/company/postman-platform?trk=public_jobs_topcard-org-name","Who Are We?

Postman is the world’s leading API platform, used by more than 40 million developers and 500,000 organizations, including 98% of the Fortune 500. Postman is helping developers and professionals across the globe build the API-first world by simplifying each step of the API lifecycle and streamlining collaboration—enabling users to create better APIs, faster.

The company is headquartered in San Francisco and has offices in Boston, New York, and Bangalore - where Postman was founded. Postman is privately held, with funding from Battery Ventures, BOND, Coatue, CRV, Insight Partners, and Nexus Venture Partners. Learn more at postman.com or connect with Postman on X via @getpostman.

P.S: We highly recommend reading The ""API-First World"" graphic novel to understand the bigger picture and our vision at Postman.

The Opportunity

With so many organizations using Postman, we are looking for an exceptional Corporate Solutions Engineer to join our team & help us support the growth of our customers in the corporate market. You will partner with our corporate sales team to promote an API-first development culture, nurture customer relationships, and guide Postman users in leveraging our platform to build their APIs most effectively. Ideally, we are looking for someone who lives & breathes APIs, has experience in corporate sales, is comfortable with JavaScript & is an expert Postman user already!

In addition to working with a product that customers already know and love, our sales, customer success, product, and engineering teams will support you well in this role.

What You’ll Do


 * Help drive sales by nurturing prospects & supporting customers in our corporate market
 * Conduct discovery, qualification, technical demos, & proof of value workshops with prospective customers looking to embrace Postman for their API lifecycle
 * Handle Postman technical questions or objections & provide solutions or workarounds to address customer needs
 * Produce reusable collateral that can be distributed to help our prospective customers understand how to adopt API-first practices with Postman.
 * Understand deeply our customer workflows today & how they can adopt API-first development best practices
 * Share customer feedback with appropriate teams & provide general customer advocacy
 * Remain up-to-date with the competitive landscape, current trends, & challenges in the API market
 * Create proof of concept integrations, tooling, & workflows as needed to support prospective customers
 * Maintain & develop customer sandbox environments & best practices for working with the product
 * Act as a technical intermediary between sales & other teams to best fit our customer needs
   
   

About You


 * 4+ years of corporate sales/solutions engineering experience
 * 3+ years of software development experience
 * 3+ API’s and Data platforms experience
 * Bachelor's degree in Computer Science, a related field, or relevant work experience
 * Ability to travel up to 25%
 * Loves teamwork & collaboration in a fast-paced environment
 * Customer-facing experience & comfortable engaging all levels of technologists, including individual developers, QA, product, & engineering leaders
 * Strong understanding of APIs, & experience with producing & consuming APIs across different domains
 * Strong knowledge of modern development methodologies & DevOps with an appreciation of the software development life cycle
 * Comfortable with the SaaS sales process & common security concerns of cloud services
 * Experience executing sales strategies & sales methodologies like MEDDIC, Challenger Sale, Command of the Message, etc.
 * Excellent listener who seeks to understand what a customer is trying to achieve rather than pre-supposing solutions
 * Familiar with typical developer tooling: IDEs, Git, CI/CD, monitoring services, microservices, containers, cloud computing services, etc.
 * Fast learner, excited & willing to learn new technology on an ongoing basis
 * Excellent communication skills (presentation, verbal & written)
   
   

The reasonably estimated OTE for this role is $145,000 - $175,000 plus a competitive equity package. Actual compensation is based on the candidate's skills, qualifications, and experience.

What Else?

In addition to Postman's pay-on-performance philosophy, and a flexible schedule working with a fun, collaborative team, Postman offers a comprehensive set of benefits, including full medical coverage, flexible PTO, wellness reimbursement, and a monthly lunch stipend. Along with that, our wellness programs will help you stay in the best of your physical and mental health. Our frequent and fascinating team-building events will keep you connected, while our donation-matching program can support the causes you care about. We’re building a long-term company with an inclusive culture where everyone can be the best version of themselves.

At Postman, we embrace a hybrid work model. For all roles based out of San Francisco Bay Area, Boston, Bangalore, Hyderabad, and New York, employees are expected to come into the office 3-days a week. We were thoughtful in our approach which is based on balancing flexibility and collaboration and grounded in feedback from our workforce, leadership team, and peers. The benefits of our hybrid office model will be shared knowledge, brainstorming sessions, communication, and building trust in-person that cannot be replicated via zoom.

Our Values

At Postman, we create with the same curiosity that we see in our users. We value transparency and honest communication about not only successes, but also failures. In our work, we focus on specific goals that add up to a larger vision. Our inclusive work culture ensures that everyone is valued equally as important pieces of our final product. We are dedicated to delivering the best products we can.

Equal opportunity

Postman is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. Postman does not accept unsolicited headhunter and agency resumes. Postman will not pay fees to any third-party agency or company that does not have a signed agreement with Postman.","Be among the first 25 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","","","","3795851","https://www.linkedin.com/jobs/view/corporate-solutions-engineer-at-postman-4337193419?trk=public_jobs_topcard-title","EASY_APPLY",""
"Manager, Data Platform & AI Architecture","Chicago, IL","3 days ago","2025-11-28","https://www.linkedin.com/jobs/view/manager-data-platform-ai-architecture-at-tag-the-aspen-group-4325010418?trk=public_jobs_topcard-title","TAG - The Aspen Group","https://www.linkedin.com/company/tag-the-aspen-group?trk=public_jobs_topcard-org-name","The Aspen Group (TAG) is one of the largest and most trusted retail healthcare business support organizations in the U.S. and has supported over 20,000 healthcare professionals and team members with close to 1,500 health and wellness offices across 48 states in four distinct categories: dental care, urgent care, medical aesthetics, and animal health. Working in partnership with independent practice owners and clinicians, the team is united by a single purpose: to prove that healthcare can be better and smarter for everyone. TAG provides a comprehensive suite of centralized business support services that power the impact of five consumer-facing businesses: Aspen Dental, ClearChoice Dental Implant Centers, WellNow Urgent Care, Chapter Aesthetic Studio, and Lovet Pet Health Care. Each brand has access to a deep community of experts, tools and resources to grow their practices, and an unwavering commitment to delivering high-quality consumer healthcare experiences at scale.







As a reflection of our current needs and planned growth we are very pleased to offer a new opportunity to join our dedicated team as a Manger, Data Platform & AI Architecture. The Manager will oversee teams responsible for Data Architecture, Platform and AI Ops and Readiness while shaping the future of our data platform needs to meet evolving business needs.




Key Responsibilities:




Data Architecture & AI Ops and Readiness:

 * Define the TAG line of business semantic models and data platform layer
 * Lead the adoption of modern cloud-native architectures, infrastructure-as-code practices, and data platform modernization efforts to ensure the data organization is following best in class practice from code management and repeatability.
 * Evaluate and implement technologies to enhance data accessibility, analytics capabilities, and operational efficiency.
 * Partner with the key business stakeholders to overall define the data strategy for TAG including investments with business objectives.
 * Partner with the Senior Director of Data Platform and VP of AI to define and implement roadmaps for emerging data technologies missions and values in areas such as Generative AI, advanced analytics and leading data technologies




Leadership & Team Development:

 * Build, mentor, and inspire a high-performing team of Reporting Engineering and Data Architects
 * Develop career growth pathways and training programs to upskill team members on modern data technologies.
 * Foster a culture of continuous improvement, operational excellence, and innovation.




Cross-Functional Collaboration & Delivery:

 * Collaborate with Data Engineering, Analytics, Product & Business Stakeholders to deliver scalable, data products to support TAG and brands.
 * Serve as a trusted advisor to business stakeholders, translating data platform capabilities into tangible business outcomes.
 * Lead data platform support for key company initiatives, including new product launches, analytics enhancements, and data governance.




Performance Monitoring & Continuous Improvement:

 * Define and track key performance indicators (KPIs) for platform performance, availability, and data quality across the data faculties
 * Establish feedback loops with data consumers to continuously improve platform usability and performance.
 * Drive automation and process optimization to reduce operational overhead and increase efficiency.




Qualifications & Experience:

 * 5+ years of experience of working in a data or related technical role with the management of data
 * 3+ years in a leadership role, overseeing technical teams and/or large-scale data infrastructure.
 * Commercial software development experience of implement RAG, AI, LLM, Agentic and similar tooling
 * Proven track record of leading cloud migrations, preferably on Google Cloud Platform.
 * Strong understanding of DevOps principles, including CI/CD, automation, and infrastructure as code.
 * Exceptional communication, stakeholder management, and organizational skills.







Additional Details:

Salary: $153,000-190,000 plus performance bonus

*A generous benefits package that includes paid time off, health, dental, vision, and 401(k) savings plan with match

","46 applicants","Full-time","Mid-Senior level","Health Care Provider","Hospitals and Health Care","$153,000.00/yr - $190,000.00/yr","Kaitlyn Avers","https://www.linkedin.com/in/kaitlyn-avers-571407176","79870456","https://www.linkedin.com/jobs/view/manager-data-platform-ai-architecture-at-tag-the-aspen-group-4325010418?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)"
"Data Analyst- Automation & Integration (Power Platform)","Nashua, NH","13 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/data-analyst-automation-integration-power-platform-at-amphenol-communications-solutions-4340376516?trk=public_jobs_topcard-title","Amphenol Communications Solutions","https://www.linkedin.com/company/amphenol-cs?trk=public_jobs_topcard-org-name","Location: Nashua, New Hampshire Department: Engineering Posted: 12/1/2025 Location Name: Nashua

Wage: Depends on Experience

Amphenol Communications Solutions (ACS), a division of Amphenol Corporation, is a world leader in interconnect solutions for Communications, Mobile, RF, Optics, and Commercial electronics markets. Amphenol Corporation is one of the world’s largest designers and manufacturers of electrical, electronic and fiber optic connectors and interconnect systems, antennas, sensors and sensor-based products and coaxial and high-speed specialty cable. ACS has an expansive global presence in research and development, manufacturing, and sales. We design and manufacture a wide range of innovative connectors as well as cable assemblies for diverse applications including server, storage, data center, mobile, RF, networking, industrial, business equipment, and automotive.

Amphenol High Speed Products Group is the market leader for high-speed, high-bandwidth electrical connectors, cables, and systems for the Datacom/Telecom market (AI, ML, GPUs, Servers, Switches, Routers, Storage). Our products help to enable the artificial intelligence revolution by helping major Tier 1 Hyperscale Data Centers, their OEMs and break-out AI customers to innovate globally. Our global headquarters is in Nashua, NH and we have engineering, sales, and manufacturing locations globally. We are currently seeking a Data Analyst – Automation & Integration to join our team.

The Data Analyst – Automation & Integration will eliminate manual work by building production-grade Power Apps and Power Automate workflows that connect people, data, and systems. This role will design and maintain apps/flows for NPI, ECN, RMA/8D/CAPA, approvals, and planning processes; implement secure integrations with ERP/PLM/CRM; and ensure workflow reliability, documentation, and adoption. The ideal candidate combines low-code development expertise with practical integration skills and a continuous-improvement mindset.

Responsibilities


 * Collaborate with business stakeholders to define application and workflow requirements; rapidly prototype and harden Power Apps and Power Automate solutions for high-value processes.
 * Implement and manage connectors and APIs (ERP/PLM/CRM/SharePoint/Dataverse); align with BU and Group IT on security, environments, and ALM.
 * Build and maintain robust data pipelines/transformations (Power Query/SQL; PowerShell/Python where appropriate) to ensure clean, governed data for analytics.
 * Monitor and optimize workflow performance, error handling, and run history; maintain documentation and release notes.
 * Create reusable templates and components to accelerate future automations; train super-users and support citizen-developer guardrails.
 * Partner with data analyst peers to align data capture with KPI and reporting needs.
 * Any other activities required by the business to support its data, processes and growth.
   
   

Qualifications


 * BS in Engineering, Information Systems, Computer Science, or related field.
 * 3–6+ years building production Power Apps and Power Automate solutions; experience integrating enterprise systems via connectors/REST APIs/webhooks.
 * Working knowledge of SQL and Microsoft data services (Dataverse, SharePoint, Azure SQL); understanding of Power Platform environment strategy, permissions, and governance.
 * Nice to have: Azure Functions/Logic Apps, Git-based ALM, basic scripting (PowerShell/Python).
 * Knowledge of traditional engineering and manufacturing operations processes and KPIs.
 * Travel required as needed to support global sites.
   
   

Amphenol Corporation is proud of our reputation as an excellent employer. Our main focus is to provide the highest level of support and responsiveness to both our employees and our customers, the world's largest technology companies. Amphenol Corporation offers the opportunity for career growth within a global organization. We believe that Amphenol Corporation is unique in that every employee, regardless of his or her position, has the ability to positively impact the business.

Amphenol is an “Equal Opportunity Employer” - Minority/Female/Disabled/Veteran/Sexual Orientation/Gender Identity/National Origin

For additional company information please visit our website at https://www.amphenol-cs.com/

Amphenol Corporation is proud of our reputation as an excellent employer. Our focus is to provide the highest level of support and responsiveness to both our employees and our customers, the world's largest technology companies. Amphenol Corporation offers the opportunity for career growth within a global organization. We believe that Amphenol Corporation is unique in that every employee, regardless of his or her position, has the ability to positively impact the business.

Amphenol is an “Equal Opportunity Employer” - Minority/Female/Disabled/Veteran/Sexual Orientation/Gender Identity/National Origin. For additional company information please visit our website at https://www.amphenol-cs.com/","90 applicants","Full-time","Entry level","Information Technology","Appliances, Electrical, and Electronics Manufacturing","","","","163773","https://www.linkedin.com/jobs/view/data-analyst-automation-integration-power-platform-at-amphenol-communications-solutions-4340376516?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Data Engineer","Pawtucket, RI","4 days ago","2025-11-27","https://www.linkedin.com/jobs/view/senior-data-engineer-at-hasbro-4334394012?trk=public_jobs_topcard-title","Hasbro","https://www.linkedin.com/company/hasbro?trk=public_jobs_topcard-org-name","At Hasbro, our mission is to entertain and connect generations of fans through the wonder of storytelling and exhilaration of play. We’re looking for adventurous and curious people who want to explore, experiment, and innovate to come up with the best ideas. Our culture has inspired our diverse team of highly skilled, highly creative, and highly committed individuals for 100 years and we believe the best is yet to come.

Do you have a passion for data? Then we are looking for you! We have an opportunity for a Senior Data Engineer to join our high-visibility Analytics team that is helping Hasbro better reach consumers with compelling products and entertainment! In this role use your talents in software engineering, analytics cloud platforms and business collaboration to expand our rich analytics data ecosystem. This Sr. Data Engineer will bring deep knowledge and hands-on experience working with cloud data platform technologies such as Azure, AWS, Google and scripting language like Python.

A day in the life as a Sr. Data Engineer:


 * Design, develop and optimize the data pipelines and transformations to enable analytics insights.
 * Participate in the design, architecture, and implementation of data-engineering platform infrastructure.
 * Champion engineering excellence, including software design patterns, code reviews, and automated unit/functional testing.
 * Collaborate with product managers, data scientists, and data analysts in an open, creative, and agile environment.
   
   

What you'll bring:


 * 5+ years of hands-on experience in developing and deploying data architecture strategies or engineering practices.
 * Demonstrated ability with complex SQL queries and knowledge of database technologies.
 * Proficiency in integrating AI solutions into new and existing technologies to improve efficiency, streamline operations, and elevate the consumer experience is required.
 * Self-starter with a passion and curiosity for solving unstructured data problems and ability to manipulate and optimize large data sets.
 * Knowledge of metadata management, data lineage, and principles of data governance.
 * Experience with streaming data management.
 * Excellent written and verbal communication skills – experience working with business and senior leaders.
 * Bachelor’s or master’s degree in Computer Science, Information Systems, or a related field, with equivalent experience accepted.
   
   

We are an Equal Opportunity

Hasbro is committed to equality of opportunity in all aspects of employment. We are committed to making all employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity or expression, national origin, age, marital status, or any other legally protected status.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. If you have a disability and require assistance in this application process and need to request an accommodation, please contact your recruiter or coordinator.

The base salary range for this position is $120,300.00 to $180,500.00. The hiring range will vary based on factors such as experience, skills, location and market conditions. Additionally, employees may be eligible for annual and long-term incentives as part of their overall compensation package.

Our Comprehensive Benefits Package Includes:


 * Health & Wellness: Medical, Dental, and Vision Insurance
 * Time Off to Recharge: Paid Vacation & Holidays
 * Financial Well-being: Generous 401(k) Match
 * Life & Family Support: Paid Parental Leave
 * Giving Back: Volunteer & Employee Giving Programs
 * Level Up Your Skills: Tuition Reimbursement
 * Exclusive Perks: Product Discounts & More!","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Manufacturing","$120,300.00/yr - $180,500.00/yr","","","4934","https://www.linkedin.com/jobs/view/senior-data-engineer-at-hasbro-4334394012?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer - Hybrid/Bellevue, WA","Bellevue, WA","1 week ago","2025-11-20","https://www.linkedin.com/jobs/view/data-engineer-hybrid-bellevue-wa-at-brook-health-4332827539?trk=public_jobs_topcard-title","Brook Health","https://www.linkedin.com/company/brook.ai?trk=public_jobs_topcard-org-name","Job Type

Full-time

Description

About Brook Health

Brook Health delivers care beyond the walls of the doctor’s office. Brook provides people living with chronic conditions a highly personalized experience enhanced by AI and powered by mobile apps, connected devices, and a team of health coaches and clinicians. We help people achieve their long-term health goals by supporting smart, daily decisions and partnering with their primary care physicians.

Our product suite includes continuous remote monitoring, population health management tools, and a CDC-approved diabetes prevention program.

Brook has an intentional, user-centric culture with high expectations for delivering better health outcomes for patients, providers, and health systems.

Job Overview

The Data Engineer is responsible for designing, building, and maintaining Brook’s data pipelines, warehouses, and architectures. This role transforms raw data into trusted, consumable formats that power analytics, dashboards, AI systems, and operational decision-making across the organization.

You will work closely with Product, Engineering, and Analytics teams to ensure our data infrastructure is secure, scalable, and optimized for performance—enabling our mission to deliver better health outcomes through data-driven insights.

This role is based in Bellevue, WA (Hybrid), and some travel may be required. All members of the Engineering team are based in the Pacific Time Zone to support real-time collaboration and agile development.

Requirements

Key Responsibilities


 * Data Pipeline Development: Build, maintain, and optimize ETL/ELT workflows (batch and real-time) using Python or Java and orchestration tools such as Airflow or Prefect.
 * Data Warehouse & Modeling: Design and evolve schemas in Snowflake (or similar) to ensure efficient storage, query performance, and maintainability.
 * DBT Modeling & Quality: Develop and maintain dbt models and tests to standardize data transformations and enforce data quality.
 * Infrastructure & Scalability: Plan and monitor capacity, and performance-tune data stores (PostgreSQL, MongoDB, MySQL).
 * Architecture & Solution Design: Partner with cross-functional teams to design scalable solutions and document data architecture standards.
 * Data Quality & Governance: Implement validation, reconciliation, and lineage tracking to ensure data integrity, security, and compliance with HIPAA and SOC 2.
 * Cross-Functional Collaboration: Work with analysts, product managers, and engineers to translate business needs into technical solutions.
 * Monitoring & Troubleshooting: Diagnose and resolve data-related issues to maintain high availability and reliability.
 * Continuous Improvement: Champion best practices for CI/CD, version control, and Agile/Scrum data delivery.
   
   

Knowledge, Skills, & Abilities


 * Advanced proficiency in Python and/or Java for data pipeline development.
 * Deep expertise in SQL and relational database design (PostgreSQL).
 * Strong understanding of data warehousing principles, ETL/ELT patterns, and performance tuning.
 * Hands-on experience with Snowflake (or equivalent cloud data warehouse), MongoDB, and AWS infrastructure.
 * Excellent communication skills—able to explain technical concepts to non-technical stakeholders.
 * Collaborative, analytical, and detail-oriented problem solver.
 * Passion for building scalable data systems that drive patient care and business outcomes.
   
   

Preferred Experience


 * Minimum 5 years of hands-on data engineering experience.
 * Bachelor’s degree in Computer Science, Engineering, or related field (Master’s a plus).
 * Experience in healthcare, digital health, or regulated environments. Familiarity with dbt, Airflow, or Prefect for orchestration and transformation.
 * Exposure to streaming technologies (Kafka, Kinesis) and message queues (Redis). Understanding of healthcare data standards such as FHIR.
 * Certifications in data engineering or cloud platforms (AWS, GCP) are a plus.
   
   

Working at Brook


 * Fast-paced environment – Brook operates in two of the fastest changing industries in America – Healthcare and Technology. We move quickly to design tools and protocols based on customer and industry feedback. Thriving in an environment of change and continuous improvement is a core competency for all members of our team.
 * Dynamic roles - We are a small and tight-knit team enthusiastically tackling difficult problems in an entrenched industry. All team members are expected to contribute to company protocols, provide product feedback and to generally think critically about our processes and care model.
 * High expectations - We have big goals for the future. We expect dedication and positive collaboration from all our team to achieve them.
   
   

This position is not eligible for relocation or visa sponsorship. Candidates must live within a commuting distance from the office. This is a hybrid role, onsite in the office required weekly along with remote work.

Brook is as focused on our employees’ health as we are on that of our patients. Our Benefits program reflects that. We recognize that health does not just mean physical health, but mental and financial health as well. We make every effort to cover all those areas in our plan offerings.

Benefits At Brook Health

In addition to meaningful work in a mission-driven company, Brook offers a comprehensive benefits package designed to support the medical, financial and mental health wellbeing of our employees and their families.

Healthcare Coverage


 * Employee & Child(ren): Brook pays 100% of premiums for full-time employees and their child or children for Medical, Dental, and Vision coverage. This means there are no paycheck deductions for you or your child(ren).
 * Spouse/Domestic Partner: Brook contributes 50% of premiums for coverage of a spouse or domestic partner.
 * HSA Contribution: Employees who enroll in our HSA-eligible medical plan receive a Brook-funded contribution to help cover medical expenses such as deductibles, prescriptions, and office visits.
 * Medical Concierge: Brook provides a concierge service to help employees and their families manage healthcare needs like claims, referrals, and care coordination.
   
   

Mental Health & Wellbeing


 * Mental Health Support: Brook supplements the mental health coverage included in our medical plan with additional resources. Employees have access to free therapy sessions through Spring Health, providing confidential, professional support when it’s needed most.
 * Flexible PTO: Our PTO program is truly flexible — no accruals and no preset limits. You and your manager decide what’s reasonable, so you can take the time you need to recharge. In addition, we provide dedicated sick time to support your health and well-being, and a generous holiday schedule that ensures time to rest and celebrate with family and friends.
   
   

Financial Wellness & Security


 * Income Protection: Brook provides Short-Term and Long-Term Disability insurance to all full-time employees, helping replace income during an illness or injury. Short-Term Disability works alongside any state or insurance benefits and Brook coverage to provide added financial support while you’re away from work.
 * Life Insurance: Brook provides company-paid life insurance equal to one times salary, up to a set maximum.
 * 401(k) Retirement Savings: All employees (full-time and part-time) are automatically enrolled in our 401(k) plan. Brook provides a company match to help employees grow their retirement savings.
 * Emergency Savings Account (ESA): Brook helps employees build financial resilience by supporting contributions to an emergency savings account. Brook matches a portion of employee contributions, helping the fund grow faster. The account is completely flexible — you decide what qualifies as an emergency and how to use the funds.
   
   

Recognition & Community


 * Employee Referral Bonus: Great people know great people. When you refer a candidate who is hired, you’ll receive a referral bonus.
   
   

Brook Inc is an equal opportunity employer. We are committed to building an inclusive and diverse workforce. Brook does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, marital status, age, non-disqualifying physical or mental disability, national origin or ethnic origin, military service status, citizenship or any other protected characteristic covered by appropriate law. All employment is decided on the basis of qualifications, merit, and business need.

Salary Description

$130,000-160,000 USD per year","Over 200 applicants","Full-time","Entry level","Information Technology","Hospitals and Health Care","$130,000.00/yr - $160,000.00/yr","","","10689345","https://recruiting.paylocity.com/Recruiting/Jobs/Details/3666319?src=LinkedIn","EXTERNAL",""
"GEN AI Data Scientist","Raritan, NJ","1 month ago","2025-10-27","https://www.linkedin.com/jobs/view/gen-ai-data-scientist-at-the-dignify-solutions-llc-4341935727?trk=public_jobs_topcard-title","The Dignify Solutions, LLC","https://www.linkedin.com/company/dignify-solutions?trk=public_jobs_topcard-org-name"," * Must have 12+ years of experience working in Data science, Machine learning and especially NLP technologies.
 * Exposure to various LLM technologies and solid understanding of Transformer Encoder Networks.
 * Able to apply deep learning and generative modeling techniques to develop LLM solutions in the field of Artificial Intelligence.
 * Utilize your extensive knowledge and expertise in machine learning (Client) with a focus on generative models, including but not limited to generative adversarial networks (GANs), variational autoencoders (VAEs), and transformer-based architectures.
 * Solid understanding of Model development, model serving, training/re-training techniques in a data sparse environment.
 * Very good understanding of Prompt engineering techniques in developing Instruction based LLMs.
 * Must be able to design and implement state-of-the-art generative models for natural language processing (NLP) tasks such as text generation, text completion, language translation, and document summarization.
 * Work with SAs and collaborate with cross-functional teams to identify business requirements and deliver solutions that meet the customer needs.
 * Passionate to learn and stay updated with the latest advancements in generative AI and LLM.
 * Nice to have -contributions to the research community through publications, presentations, and participation in relevant conferences or workshops.
 * Exposure to developing Guardrails for LLMs both with open source and cloud native models.
 * Nice to have- provide guidance to junior data scientists, sharing expertise and knowledge in generative AI and LLM, and contribute to the overall growth and success of the data science team.","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","75031133","https://www.linkedin.com/jobs/view/gen-ai-data-scientist-at-the-dignify-solutions-llc-4341935727?trk=public_jobs_topcard-title","EASY_APPLY",""
"Manager, Business Intelligence Engineering","Bellevue, WA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/manager-business-intelligence-engineering-at-snap-inc-4338402481?trk=public_jobs_topcard-title","Snap Inc.","https://www.linkedin.com/company/snap-inc-co?trk=public_jobs_topcard-org-name","Snap Inc is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are Snapchat, a visual messaging app that enhances your relationships with friends, family, and the world; Lens Studio, an augmented reality platform that powers AR across Snapchat and other services; and its AR glasses, Spectacles.

The Data Science & Insights team seeks to leverage our massive data sets into actionable insights that deliver business value. As truth seekers and truth tellers, we relay what the data says without bias, even when inconvenient or difficult. We aim to improve decision-making quality and speed across the organization to enable a deeper understanding of our customers and products. We focus on efficient and effective analytic execution, positioning ourselves as the go-to experts with deep knowledge and expertise, constantly striving for better, faster insights from data.

We’re looking for a Manager, Business Intelligence Engineering to join Snap Inc!

What you’ll do:


 * Lead a team to establish foundational data and analytics capabilities for our ads platform and identify key insights around our ads platform.
 * Collaborate with Data Science, Product, and Engineering, and Business partners to design and build data tools/visualizations, operationalize metrics, conduct investigations, deliver actionable insights, and conduct in-depth product analysis.
 * Understand the challenges within our ads platform and help make decisions based on data driven insights by analyzing information from multiple sources in a logical and coherent data story
 * Build and maintain dashboards that communicate the performance of the various components of our ads platform with compelling data visualizations and consistency
 * Develop data pipelines that power our analytics data layer for analysis, reporting and dashboarding ensuring efficiency and reliability
 * Own the data model used to power our underlying data layer for monetization including the associated pipelines, data structures, and schemas
 * Maintain the key metric definitions and understand them at a deep level, offering recommendations for improvements and new metrics
 * Conduct exploratory and deep dive analysis to understand drivers of revenue performance and overall platform performance, developing actionable insights to Product and Engineering leadership
 * Own root-cause investigations starting from proactive identification of metric regressions to resolution including recommendations for long term product improvements
 * Proactively identify improvements to our platform or business that can be expected to drive increased revenue
   
   

Knowledge, Skills & Abilities:


 * Data driven and analytical mindset
 * Hands-on expertise with data warehousing tools and workflow automation
 * Comfortable with quantitative concepts
 * Strong attention to detail and organizational skills
 * Excellent verbal and written communication skills
 * Ability to work in an agile, dynamic environment
 * Ability to use tech to improve work-flows and create efficiencies
   
   

Minimum Qualifications:


 * BS/BA degree in Analytics, Statistics, Economics or other technical field or equivalent years of experience
 * 10+ years of post-Bachelor’s analytics experience; or a Master’s degree in a technical field + 9+ year of post-grad analytics experience; or a PhD in a related technical field + 6+ years of post-grad analytics experience
 * 1+ years relevant people management experience
   
   

Preferred Qualifications:


 * Advanced Degree in Analytics, Statistics, Economics, Computer Science or other technical field
 * Experience as a data scientist and/or managing a data team
 * Experience in the digital media space
 * A passion for Snapchat as a user and knowledge of our ad products
 * Proficiency in Looker, BigQuery, and Airflow
   
   

If you have a disability or special need that requires accommodation, please don’t be shy and provide us some information.

""Default Together"" Policy at Snap: At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office 4+ days per week.

At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets.

We are an Equal Opportunity Employer and will consider qualified applicants with criminal histories in a manner consistent with applicable law (by example, the requirements of the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, where applicable).

Our Benefits: Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid parental leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success!

Compensation

In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. The starting pay may be negotiable within the salary range for the position. These pay zones may be modified in the future.

Zone A (CA, WA, NYC):

The base salary range for this position is $209,000-$313,000 annually.

Zone B:

The base salary range for this position is $199,000-$297,000 annually.

Zone C:

The base salary range for this position is $178,000-$266,000 annually.

This position is eligible for equity in the form of RSUs.","63 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Software Development","$178,000.00/yr - $313,000.00/yr","","","15191764","https://wd1.myworkdaysite.com/en-US/recruiting/snapchat/snap/job/Los-Angeles-California/Manager\u002d\u002dBusiness-Intelligence-Engineering_R0043164-1?source=LinkedIn","EXTERNAL",""
"Senior Data Engineer","Charlotte, NC","14 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/senior-data-engineer-at-cpi-security-4340196691?trk=public_jobs_topcard-title","CPI Security","https://www.linkedin.com/company/cpisecurity?trk=public_jobs_topcard-org-name","CPI Security, a national leader in residential and commercial security solutions, is seeking a Senior Data Engineer to join us on our data transformational journey. This is an exciting, hands-on opportunity to implement a modern enterprise data platform at a company that has fully embraced the Snowflake platform. This role will work directly with line of business leaders and technical users to design and implement our cloud data warehouse using data vault modeling and dbt. CPI will leverage the data cloud for our data warehouse, machine learning, and AI journeys. The ideal person will have extensive experience building and implementing data warehouses in the cloud with deep expertise in data vault modeling and dbt. This is an on-site position at our HQ in Charlotte, NC.

What You'll Do:

Data Vault Implementation: Design and implement data vault 2.0 modeling patterns to build a scalable, audit-friendly enterprise data platform that supports business agility and data governance.

Modern Data Engineering: Build and maintain automated data pipelines using dbt (Cloud/Core), Python, and Snowflake to transform raw data into business-ready datasets with comprehensive data quality testing.

Cloud Data Platform Development: Architect and implement an enterprise data platform on Snowflake, including automated deployment pipelines, data quality frameworks, and monitoring solutions. While we are modernizing to a cloud data platform on premises work is still needed using SSIS and MSSQL Server.

Data Mart & Dimensional Modeling: Design and build data marts using dimensional modeling techniques (Kimball methodology) to support business intelligence and analytics requirements.

ETL/ELT Pipeline Development: Design and implement robust data transformation models using dbt, SQL, and Python to build scalable ingestion and processing pipelines.

Data Quality & Testing: Implement comprehensive data quality testing frameworks using dbt tests, custom Python validations, and automated monitoring to ensure data accuracy and reliability.

External Data Integration: Integrate and operationalize data from external systems such as CRM, ERP, and third-party platforms via secure cloud data sharing, CDC, and APIs.

DataOps Implementation: Enable reliable, scalable, and automated data workflows by implementing DataOps best practices for continuous integration, testing, deployment, and monitoring across the data pipeline lifecycle.

Cloud Migration Support: Play an integral role in planning, designing, and implementing data migration strategies from legacy systems to our modern cloud platform.

What We're Looking For:

Required Experience:


 * 6+ years of data engineering experience with cloud data platforms
 * 4+ years of experience with Snowflake (required)
 * 4+ years of experience with dbt (Cloud and/or Core)
 * 4+ years of Python development experience
 * 4+ years of AWS experience (AWS Certified Developer preferred)
 * 6+ years of experience building data warehouses and data marts
 * Deep understanding of data vault 2.0 modeling methodology
 * Strong experience with dimensional modeling (Kimball methodology)
 * Proven experience with automated deployment and CI/CD pipelines
 * Experience implementing data quality testing frameworks
   
   
   

Technical Skills:


 * MSSQL Server SQL and SSIS.
 * Advanced SQL and data modeling expertise with dimensional modeling and data vault modeling
 * Strong dbt skills for data staging, cleaning, transformation, testing, and modeling
 * Proficiency in Python programming for data engineering tasks
 * Experience with agile / scrum teams for data engineering and analytics engineering.
 * AWS cloud services (S3, Lambda, IAM, CloudFormation, etc.)
 * Experience with data orchestration tools (Airflow, Prefect, or similar)
 * Understanding of modern data engineering practices and agile methodologies
 * Knowledge of data governance, security, and compliance requirements
   
   
   

Preferred Qualifications:


 * AWS Certified Developer certification
 * Snowflake certifications in data engineering and/or architecture
 * Experience with data vault automation tools (automate-dv package)
 * Knowledge of modern BI and analytics platforms
   
   
   

Soft Skills:


 * Excellent oral and written communication skills to effectively deliver messages to a wide range of audiences - from business to technical
 * Innovative and positive team member mindset
 * Strong teamwork and interpersonal skills, with the ability to deliver results working independently or in a collaborative environment
 * Agile development experience preferred
 * Solution-oriented approach with strong problem-solving abilities
   
   
   

Education:


 * Bachelor's degree in Information Systems, Computer Science, Data Science, or related field of study preferred
 * Work experience equivalent will be considered
   
   
   

What Sets You Apart:


 * Deep understanding of the complete data engineering lifecycle
 * Experience with cloud data platform implementations
 * Proven ability to work with cross-functional teams and stakeholders
 * Passion for building modern, cloud-first data solutions
 * Strong analytical and critical thinking skills
 * Commitment to data quality and best practices
   
   
   

Why Join CPI Security:


 * Opportunity to build a modern enterprise data platform from the ground up
 * Work with cutting-edge cloud technologies and data vault modeling
 * Collaborative environment with experienced data professionals
 * Competitive compensation and benefits package
 * Professional development opportunities and certification support
 * On-site position in Charlotte, NC with a dynamic, growing company
   
   
   

CPI Security is an equal opportunity employer committed to diversity and inclusion in the workplace.","28 applicants","Full-time","Mid-Senior level","Information Technology and Engineering","Construction, Software Development, and IT Services and IT Consulting","","","","73556","https://www.linkedin.com/jobs/view/senior-data-engineer-at-cpi-security-4340196691?trk=public_jobs_topcard-title","EASY_APPLY",""
"Machine Learning Engineer II (Layer 6)","New York, NY","4 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/machine-learning-engineer-ii-layer-6-at-td-securities-4340369506?trk=public_jobs_topcard-title","TD Securities","https://ca.linkedin.com/company/tdsecurities?trk=public_jobs_topcard-org-name","Work Location:

New York, New York, United States of America

Hours

40

Pay Details

$96,130 - $181,944 USD

TD is committed to providing fair and equitable compensation opportunities to all colleagues. Growth opportunities and skill development are defining features of the colleague experience at TD. Our compensation policies and practices have been designed to allow colleagues to progress through the salary range over time as they progress in their role. The base pay actually offered may vary based upon the candidate's skills and experience, job-related knowledge, geographic location, and other specific business and organizational needs.

As a candidate, you are encouraged to ask compensation related questions and have an open dialogue with your recruiter who can provide you more specific details for this role.

Line Of Business

Analytics, Insights, & Artificial Intelligence

Job Description

Department Overview:

Layer 6 is the AI research center of excellence for TD Bank Group. We develop and deploy industry-leading machine learning systems that impact the lives of over 27 million customers, helping more people achieve their financial goals and needs.

Our research broadly spans the field of machine learning with areas such as deep learning and generative AI, time series forecasting and responsible use of AI. We have access to massive financial datasets and actively collaborate with world renowned academic faculty.

Position Overview

As a Machine Learning Engineer, you will


 * Join a world-class team of AI developers with an extensive track record of shipping solutions at the cutting-edge
 * Architect scalable machine learning and Gen AI systems that integrate with existing data platform and infrastructure, focusing on automation, operation efficiency, and reliability
 * Write clean, efficient, and maintainable code for ML models to ensure efficient deployment of scalable AI application
 * Work with large-scale, real-world datasets that range from banking transactions, conversation histories, to large document collections
 * Grow by continuously learning new skills and exploring advanced topics in AI with a team that thrives on knowledge-sharing
   
   

The Machine Learning Engineer II is responsible for providing technical expertise as well as developing and maintaining technical solutions that adhere to engineering and architectural design principles while meeting business requirements. This role plays a lead role in implementing solutions with a focus on efficiency, reliability, scalability, and security; includes planning, evaluating, recommending, designing, operationalizing, and supporting machine learning engineering solutions & systems in compliance with enterprise and industry standards.

Depth & Scope


 * Expert knowledge of specific domain or range of engineering frameworks, technology, tools, processes, and procedures, as well as organization issues
 * Expert knowledge of TD applications, systems, networks, innovation, design activities, best practices, business / organization, Bank standards, and may fulfill a governance role
 * Integrates knowledge of business and functional priorities and acts as a key contributor in a complex and critical environment
 * Adept at technical project execution, strategic planning, and effective communication. Accountable for specialized knowledge in a field of AI/ML Engineering and may provide leadership to teams or projects, shares expertise
 * Applies in-depth skills and broad knowledge of the business to address complex problems and nonstandard situations
   
   

Education & Experience


 * Undergraduate degree required, advanced technical degree preferred (e.g., math, physics, engineering, finance or computer science) Graduate's degree preferred with either progressive project work experience or
 * 1 +years relevant experience (includes post graduate experience)
   
   

Preferred Qualifications


 * 3+ years of developer experience shipping code in production settings
 * Strong background in machine learning and deep learning
 * Strong coding proficiency in Python, Java, C, or C++
 * You value good software design and sweat over details in code and API design
 * You take great personal pride in building robust and scalable software
 * You are highly accountable and have a strong sense of ownership
 * You strive to communicate clearly and with empathy
 * Research experience with publication record
 * Experience with LangGraph, Pytorch, Tensorflow, Jax, or comparable library
 * Experience with building and scaling data-intensive software
 * Experience using GPUs for accelerated deep learning training
   
   

Customer Accountabilities


 * Leverages deep technology expertise for own area of specialization to deliver and ensure that all areas across the organization that provision, manage, and support various technologies have the necessary tools, processes and documentation required to effectively execute on their respective mandates
 * Executes on Engineering strategy as it relates to the introduction of tools and the automation of build, test, release and configure activities across Application, Platform and Infrastructure. Partners with the Operations team to automatically integrate with appropriate tools and processes as part of automated/self-serve Application, Platform, or Infrastructure releases
 * Works with partners across Technology and apply in depth understanding of relevant business needs to identify and leverage synergies across the various areas
 * Acts as the expert or lead innovator and agent of change for the programs and services under management.
 * Works with other teams to implement best practices for engineering and management and serve as an ambassador for ML Engineering
 * Works with vendor platform providers and engineering peers to keep abreast of trends, products, frameworks, and applications
 * Identifies and effectively manages stakeholder engagement and impacts across the enterprise
 * Interprets client needs, assess engineering related requirements, and identify solutions to non-standard requests
   
   

Shareholder Accountabilities


 * Adheres to enterprise frameworks or methodologies that relate to activities for our business area
 * Ensures respective programs / policies / practices are well managed, meets business needs, complies with internal and external requirements, and aligns with business priorities
 * Consistently exercises discretion in managing correspondence, information and all matters of confidentiality; escalates issues where appropriate.
 * Ensures business operations are in compliance with applicable internal and external requirements (e.g., financial controls, segregation of duties, transaction approvals and physical control of assets)
 * Participates in cross-functional / enterprise / initiatives as a subject matter expert helping to identify risk / provide guidance for complex situations
 * Conducts internal and external research projects; supports the development / delivery of presentations / communications to management or broader audience
 * Conducts meaningful analysis at the functional or enterprise level using results to draw conclusions, makes recommendations, assess the effectiveness of programs / policies / practices
 * Monitors service, productivity and assesses efficiency levels within own function and implement continuous process / performance improvements where opportunities exist
 * Leads / facilitates and/or implements actions / remediation plans to address performance / risk / governance issues
 * Actively manages relationships within and across various business lines, corporate and/or control functions and ensures alignment with enterprise and/or regulatory requirements
 * Keeps abreast of emerging issues, trends, and evolving regulatory requirements and assesses potential impacts
 * Maintains a culture of risk management and control, supported by effective processes in alignment with risk appetite
   
   

Employee/Team Accountabilities


 * Participates fully as a member of the team, supports a positive work environment that promotes service to the business, quality, innovation and teamwork and ensures timely communication of issues / points of interest
 * Provides thought leadership and/ or industry knowledge for own area of expertise in own area and participate in knowledge transfer within the team and business unit
 * Keeps current on emerging trends/ developments and grow knowledge of the business, related tools and techniques.
 * Participates in personal performance management and development activities, including cross training within own team
 * Keeps others informed and up to date about the status / progress of projects and/or all relevant or useful information related to day-to-day activities
 * Contributes to team development of skills and capabilities through mentorship of others, by sharing knowledge and experiences and leveraging best practices
 * Leads, motivates and develops relationships with internal and external business partners / stakeholders to develop productive working relationships
 * Contributes to a fair, positive and equitable environment that supports a diverse workforce.
 * Acts as a brand ambassador for your business area/function and the bank, both internally and/or externally
   
   

Physical Requirements

Never: 0%; Occasional: 1-33%; Frequent: 34-66%; Continuous: 67-100%


 * Domestic Travel – Occasional
 * International Travel – Never
 * Performing sedentary work – Continuous
 * Performing multiple tasks – Continuous
 * Operating standard office equipment - Continuous
 * Responding quickly to sounds – Occasional
 * Sitting – Continuous
 * Standing – Occasional
 * Walking – Occasional
 * Moving safely in confined spaces – Occasional
 * Lifting/Carrying (under 25 lbs.) – Occasional
 * Lifting/Carrying (over 25 lbs.) – Never
 * Squatting – Occasional
 * Bending – Occasional
 * Kneeling – Never
 * Crawling – Never
 * Climbing – Never
 * Reaching overhead – Never
 * Reaching forward – Occasional
 * Pushing – Never
 * Pulling – Never
 * Twisting – Never
 * Concentrating for long periods of time – Continuous
 * Applying common sense to deal with problems involving standardized situations – Continuous
 * Reading, writing and comprehending instructions – Continuous
 * Adding, subtracting, multiplying and dividing – Continuous
   
   

The above statements are intended to describe the general nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, duties and skills required. The listed or specified responsibilities & duties are considered essential functions for ADA purposes.

Who We Are

TD is one of the world's leading global financial institutions and is the fifth largest bank in North America by branches/stores. Every day, we deliver legendary customer experiences to over 27 million households and businesses in Canada, the United States and around the world. More than 95,000 TD colleagues bring their skills, talent, and creativity to the Bank, those we serve, and the economies we support. We are guided by our vision to Be the Better Bank and our purpose to enrich the lives of our customers, communities and colleagues.

TD is deeply committed to being a leader in customer experience, that is why we believe that all colleagues, no matter where they work, are customer facing. As we build our business and deliver on our strategy, we are innovating to enhance the customer experience and build capabilities to shape the future of banking. Whether you’ve got years of banking experience or are just starting your career in financial services, we can help you realize your potential. Through regular leadership and development conversations to mentorship and training programs, we’re here to support you towards your goals. As an organization, we keep growing – and so will you.

Our Total Rewards Package

Our Total Rewards package reflects the investments we make in our colleagues to help them and their families achieve their financial, physical and mental well-being goals. Total Rewards at TD includes base salary and variable compensation/incentive awards (e.g., eligibility for cash and/or equity incentive awards, generally through participation in an incentive plan) and several other key plans such as health and well-being benefits, savings and retirement programs, paid time off (including Vacation PTO, Flex PTO, and Holiday PTO), banking benefits and discounts, career development, and reward and recognition. Learn more

Additional Information

We’re delighted that you’re considering building a career with TD. Through regular development conversations, training programs, and a competitive benefits plan, we’re committed to providing the support our colleagues need to thrive both at work and at home.

Colleague Development

If you’re interested in a specific career path or are looking to build certain skills, we want to help you succeed. You’ll have regular career, development, and performance conversations with your manager, as well as access to an online learning platform and a variety of mentoring programs to help you unlock future opportunities. Whether you have a passion for helping customers and want to expand your experience, or you want to coach and inspire your colleagues, there are many different career paths within our organization at TD – and we’re committed to helping you identify opportunities that support your goals.

Training & Onboarding

We will provide training and onboarding sessions to ensure that you’ve got everything you need to succeed in your new role.

Interview Process

We’ll reach out to candidates of interest to schedule an interview. We do our best to communicate outcomes to all applicants by email or phone call.

Accommodation

TD Bank is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, status as a protected veteran or any other characteristic protected under applicable federal, state, or local law.

If you are an applicant with a disability and need accommodations to complete the application process, please email TD Bank US Workplace Accommodations Program at USWAPTDO@td.com. Include your full name, best way to reach you and the accommodation needed to assist you with the applicant process.","Be among the first 25 applicants","Full-time","Entry level","Engineering and Information Technology","Investment Banking","$96,130.00/yr - $181,944.00/yr","","","33315467","https://td.wd3.myworkdayjobs.com/en-US/TD_Bank_Careers/job/New-York-New-York/Machine-Learning-Engineer-II\u002d\u002dLayer-6-_R_1459223?source=LinkedIn","EXTERNAL",""
"Criminal Data Specialist","Nashville, TN","3 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/criminal-data-specialist-at-checkr-inc-4335411015?trk=public_jobs_topcard-title","Checkr, Inc.","https://www.linkedin.com/company/checkr-com?trk=public_jobs_topcard-org-name","About Checkr

Checkr is building the data platform to power safe and fair decisions. Established in 2014, Checkr’s innovative technology and robust data platform help customers assess risk and ensure safety and compliance to build trusted workplaces and communities. Checkr has over 100,000 customers including DoorDash, Coinbase, Lyft, Instacart, and Airtable.

We’re a team that thrives on solving complex problems with innovative solutions that advance our mission. Checkr is recognized on Forbes Cloud 100 2025 List and is a Y Combinator 2024 Breakthrough Company.

About The Team/role

We are seeking a Senior Product Operations Specialist to join our team and play a critical role in strengthening the connection between Product, Operations, and Data teams. This role is ideal for someone who thrives in fast-paced, data-driven environments and has deep knowledge of the background screening industry and the U.S. Judicial System.

You will drive process improvements, ensure data integrity, and help shape how product and operational strategies align to deliver accurate, high-quality background data to our clients.

What You’ll Do


 * Partner with Product Managers, Data, and Operations teams to identify and implement process improvements that enhance data quality, efficiency, and scalability.
 * Use analytical insights to track, monitor, and improve data accuracy across multiple systems and data sources.
 * Leverage your industry knowledge to optimize workflows related to court data, public records, and other screening data sources.
 * Act as a bridge between technical and non-technical teams, ensuring smooth communication and alignment on priorities.
 * Proactively identify gaps in data processes, propose solutions, and drive implementation.
   
   

What You Bring


 * 5+ years of experience in product operations, data operations, or process optimization, ideally within the background screening industry or a closely related field.
 * Deep understanding of the U.S. Judicial System’s processes, including court data, public records, and data sources relevant to background checks.
 * Proven track record of analyzing, tracking, and improving data quality and integrity within complex data ecosystems.
 * Experience working cross-functionally with Product Management, Engineering, Compliance, and Operations teams.
 * Team-oriented mindset, with a focus on shared success and continuous improvement.
   
   

What You’ll Get


 * A fast-paced and collaborative environment
 * Learning and development allowance
 * Competitive cash and equity compensation and opportunity for advancement
 * 100% medical, dental, and vision coverage
 * Up to $25K reimbursement for fertility, adoption, and parental planning services
 * Flexible PTO policy
 * Monthly wellness stipend, home office stipend
   
   

Pay Transparency Disclosure

One of Checkr’s core values is Transparency. To live by that value, we’ve made the decision to disclose salary ranges in all of our job postings. We use geographic cost of labor as an input to develop ranges for our roles and as such, each location where we hire may have a different range. If this role is remote, we have listed the top to the bottom of the possible range, but we will specify the target range for an exact location when you are selected for a recruiting discussion. For more information on our compensation philosophy, see our website.

On-target Earnings OR Base Salary range (Nashville, TN)

$76,000—$95,000 USD

At Checkr, we believe a hybrid work environment strengthens collaboration, drives innovation, and encourages connection. Our hub locations are Denver, CO, San Francisco, CA, and Santiago, Chile. Individuals are expected to work from the office 2 to 3 days a week. Starting January 2026, hub-based employees will be expected to work from the office 3 days per week. In-office perks are provided, such as lunch four times a week, a commuter stipend, and an abundance of snacks and beverages.

Equal Employment Opportunities at Checkr

Checkr is committed to building the best product and company, which requires hiring talented and qualified individuals with a diverse set of perspectives and lived experiences. Checkr believes in hiring people of all backgrounds, including those whose histories are impacted by the justice system in accordance with local, state, and/or federal laws, including the San Francisco’s Fair Chance Ordinance.


 * Legitimate Checkr emails will always include our official domain name after the @ symbol (e.g., name@checkr.com or name@ext.checkr.com).","52 applicants","Full-time","Entry level","Information Technology","Technology, Information and Internet, Business Consulting and Services, and Marketing Services","","","","3535535","https://www.linkedin.com/jobs/view/criminal-data-specialist-at-checkr-inc-4335411015?trk=public_jobs_topcard-title","EASY_APPLY",""
"Robotics Systems Engineer — Software/Embedded","New York, NY","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/robotics-systems-engineer-%E2%80%94-software-embedded-at-openshelf-4337103511?trk=public_jobs_topcard-title","OPENSHELF","https://www.linkedin.com/company/opshelf?trk=public_jobs_topcard-org-name","We’re looking for a Software Systems Engineer to join our small, focused team working to solve a big, real-world problem: physical inventory. You’ll work directly with the founders to design and build open-source hardware and software systems that automate storage, retrieval, and tracking. This role is central to our effort to create a flexible, small-scale AS/RS solution that can be used in a wide range of environments—not just warehouses with big budgets. 




What are we trying to solve?

We’re redefining how pharmacies operate by combining software and hardware to automate inventory management, the pick/pack process and more.

 * The Challenge: Speed, accuracy, and reliability are essential for pharmacy operations. Manual processes often lead to inefficiencies, errors, and scalability challenges that impact both operational costs and customer trust.
 * Our Solution: We’re building a fully integrated software and hardware system that automates storage, handling, and inventory management for pharmacies, ensuring faster, more accurate, and cost-effective operations.




What you’ll be doing

 * Design and develop system-level software architecture that integrates seamlessly with hardware and firmware components.
 * Write and optimize scalable, reliable software for hardware interfaces and data communication protocols.
 * Collaborate with hardware and firmware teams to ensure robust integration and end-to-end system performance.
 * Develop and maintain APIs, communication layers, and middleware to connect hardware systems with higher-level applications.
 * Implement real-time and asynchronous software systems to handle data processing, system control, and error recovery.
 * Conduct software performance testing, profiling, and debugging to meet functional and scalability requirements.
 * Define, execute, and maintain automated testing pipelines for continuous integration and deployment.
 * Document software architecture, design decisions, and system configurations comprehensively.




Requirements

 * Bachelor’s or Master’s degree in Computer Science, Software Engineering, or a related field.
 * 3+ years of experience in systems software development and architecture design.
 * Proficiency in programming languages such as Python, Rust, and Typescript or similar languages.
 * Strong knowledge of system-level programming concepts, including threading, memory management, and real-time systems.
 * Experience working with communication protocols (e.g., TCP/IP, MQTT, UART, SPI, I2C).
 * Familiarity with software development for embedded systems, cloud-based architectures, or IoT solutions.
 * Strong experience with tools and frameworks for testing, CI/CD, and version control (e.g., Jenkins, Docker, Git).
 * Excellent analytical and problem-solving skills with a focus on system-wide optimization.
 * Hardware experience: sensors, light curtains, motors, encoders, etc.




Practical details

 * You’ll get a competitive salary, and you’ll get to own part of the company via stock options.
 * We are based out of midtown Manhattan, and this is an on-site, in-person role. We believe that building the best product is the result of continuous collaboration and short feedback loops.
 * Benefits
 * Fully covered health, dental, and vision insurance
 * Flexible PTO
 * Team lunches, off-sites




Compensation

 * $80,000-$100,000 + Equity","Over 200 applicants","Full-time","Entry level","Information Technology","Automation Machinery Manufacturing","$80,000.00/yr - $100,000.00/yr","","","107389861","https://www.linkedin.com/jobs/view/robotics-systems-engineer-%E2%80%94-software-embedded-at-openshelf-4337103511?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Data Engineer","Denver, CO","1 month ago","2025-10-09","https://www.linkedin.com/jobs/view/senior-data-engineer-at-kharon-4337453474?trk=public_jobs_topcard-title","Kharon","https://www.linkedin.com/company/kharondata?trk=public_jobs_topcard-org-name","TL;DR Kharon is seeking a full-time Senior Data Engineer based in Denver, Colorado. This role requires in-office attendance at least 4 days a week. 

RESPONSIBILITIES: 

 * Help build large-scale distributed automated data processing systems and data lakes, while optimizing for both computational and storage efficiency on AWS Databricks.
 * Create data pipelines, infrastructure, and overall workflow orchestration to pull data from a diverse set of data sources into the Kharon Data Lake.
 * Build systems to track, monitor and validate the quality of data coming into or going out of Kharon Data Lake.
 * Collaborate with engineers, architects, and data scientists to implement scalable solutions to solve complex problems.
 * Interact and develop with internal and external APIs.
 * Work with product and business teams to define novel and critical metrics for the business.
 * Follow good engineering practices like documentation, diagrams, and unit/validation tests
 * Take full responsibilities for the development, deployment, adoption monitoring and maintenance of the data systems and services you build.

QUALIFICATIONS: 

 * 5+ years of experience in software or data engineering and a BS/MS in Computer Science, Engineering, or a related field preferred.
 * Experience in Python, Pandas, PySpark, and Notebooks.
 * SQL knowledge and experience working with relational databases including schema design, access patterns, query performance optimization, etc.
 * Experience setting up infrastructure and using data pipeline technologies like AWS Glue, Airflow, Kafka, or other cloud based equivalence.
 * Experience with ETL and data warehousing like Databricks, Snowflake, or equivalent.
 * Container-based deployment experience using Docker and Kubernetes.
 * Experience taking a project from inception and design to production.
 * Strong verbal and written communication skills.

NICE TO HAVE:

 * Experience working with or data modeling for graph databases like Neo4J, Neptune, etc.
 * API experience using FastAPI, Flask, Spring Boot or equivalent.
 * Understanding of Elasticsearch data and query modeling.
 * Interests or experience in Geopolitics, Sanction Compliance, or Financial Risk.

Kharon is a highly disruptive and incredibly innovative organization that navigates risk at the intersection of global security threats + international commerce.

What does that mean? Great question.

Operating at the nexus of global security, Kharon is on a mission to revolutionize the current landscape. We take really complex data as it relates to global security and empower our clients to not only understand the risk associated with their potential business relationships but to operationalize that data so that they can make the best and most informed decisions possible. From financial crimes and sanctions to export controls and threat identifications, our tools optimize protection against the types of risks that could otherwise be incredibly dangerous and excessively costly to any business. Serving many of today’s leading global financial and multinational institutions, Kharon products are the most powerful in the space with a precision and depth that is absolutely unparalleled. 

When you look at any major global crisis event, we’re providing intelligence that’s at the heart of those circumstances. We connect the dots in a way that’s meaningful. Now, we’re experiencing unprecedented growth. As the world continues to evolve in complexity, so too does the demand for our products. Given the significance of our work and the increasing global reliance on our insights, we are looking for a Senior Data Engineer to join us as we work to shape the way businesses perceive and navigate global risks. 

Reporting to the Associate Director of Data Engineering, this role is critical to driving the evolution of the data infrastructure that underpins our intelligence platform. In this senior engineering role, you will help lead in the design and implementation of scalable systems and resilient ETL pipelines that support a suite of analytic products. You’ll contribute to the architecture, tooling, and best practices that ensure structured and unstructured data is ingested, transformed, and delivered reliably, securely, and at scale. This position is ideal for an experienced data engineer who thrives on solving foundational engineering challenges, shaping data strategy and infrastructure, and mentoring engineers in building systems that are precise, performant, and built for the future.

To the right person, this will be the perfect kind of challenge. Our mission is compelling, our product is powerful, and we’re growing at a rate that makes us unstoppable. If you’re looking to be surrounded by people who will inspire you to think and challenge you to grow then look no further. Our team is made up of some of the most visionary and uncompromising individuals you will ever encounter. We don’t take ourselves seriously but we’re serious about the work we do and there is absolutely no slowing us down.  

To keep that momentum going, we do our very best to make sure that each and every team member is completely taken care of. We’re nothing without our people and we strive to offer a package that reflects that. As a Kharon team member, you can expect:

 * Fully sponsored medical, dental, and vision 
 * FSA program for both medical and dependent care
 * 401k + Roth with matching and immediate vesting
 * Paid time off + 11 paid holidays 

The base salary range at Kharon is set between $140,000 - $170,000. Please note that this figure does not necessarily include potential bonuses, commissions, benefits, or equity that may be part of the overall compensation package.

If interested in pursuing this position, please visit www.kharon.com to apply. 

Kharon is committed to cultivating and maintaining a workplace that is free from harassment and discrimination.  All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, ethnicity, gender, gender identity or expression, sexual orientation or identity, neurodiversity, appearances, age, protected veteran status, or status as a qualified individual with disability.","26 applicants","Full-time","Mid-Senior level","Sales, General Business, and Education","Wireless Services, Telecommunications, and Communications Equipment Manufacturing","$140,000.00/yr - $170,000.00/yr","","","11688499","https://app.jazz.co/apply/job/tzlDRtSIWH?source=LINKR&source=LINK&source=LINKEDIN&source=LinkedIn&src=Linkedin&gh_src=fa1195541us&LinkedIn=LinkedIn&source=LINK&source=LinkedIn","EXTERNAL",""
"Applied AI Engineer [32720]","San Francisco, CA","4 days ago","2025-11-28","https://www.linkedin.com/jobs/view/applied-ai-engineer-32720-at-stealth-startup-4347971840?trk=public_jobs_topcard-title","Stealth Startup","https://www.linkedin.com/company/stealth-startupsssss?trk=public_jobs_topcard-org-name","About Us

The company is building an AI-native platform that transforms compliance from tedious, manual work into effortless, automated workflows.




We’re the fastest growing compliance company on the market. The company helps 100s of companies save 100s of hours (e.g. Lovable, 11x, WisprFlow) by eliminating compliance busywork and helping them focus on what matters — securely supporting their customers.




Our team is a tight-knit group of builders—former founders, operators, and engineers—obsessed with solving real problems for real customers. We come from Stanford, MIT, Berkeley, OpenAI, and international olympiads. Backed by Insight Partners, General Catalyst, Y Combinator, and top-tier investors, we just raised our 32M Series A and are scaling quickly!




One step at a time, we’re on a mission to eliminate busywork for humanity.




Role Overview

As an Applied AI Engineer, you will play a pivotal role in bringing the latest AI research into production. In this role, your focus will be on turning state-of-the-art techniques into tangible products. You’ll collaborate closely with product engineers to design, implement, and deploy AI-driven features end-to-end. This is a high-impact role where you’ll own projects from idea to production, and your contributions will directly shape our product and technical trajectory.

You will collaborate with a world-class team of engineers with research background to build innovative, scalable systems. As part of our fast-paced startup, you’ll have the opportunity to influence technical direction, contribute ideas across the stack, and rapidly grow into taking more leadership as we scale. We value first-principles thinking and a get-things-done attitude – you will have broad autonomy to experiment and iterate in pursuit of the best solutions.




What you will do

 * Drive AI Innovation: Research, prototype, and build cutting-edge product, and customer facing AI Systems, pushing the state-of-the-art to solve our core technical challenges.
 * End-to-End Development: Design, implement, and deploy AI pipelines and systems—from evaluation design and benchmarking through product integration—ensuring high performance, reliable production observability, and end-to-end safety and transparency.
 * Collaborate & Iterate: Collaborate with backend engineers and product engineers to turn cutting-edge ideas into production-ready solutions—rapidly iterating on experiment data and user feedback, and applying a rigorous scientific approach to refine models and algorithms.
 * Technical Leadership: Contribute to technical decision-making and architectural discussions for AI components. Uphold high engineering standards and share best practices in code reviews and design discussions.
 * Continuous Learning: Stay up-to-date with the latest research and developments in AI. Evaluate new approaches or tools, and drive their adoption when they can advance our capabilities.




What we are looking for

 * Strong AI Fundamentals: Deep understanding of Test Time Compute Techniques, Deep Learning Frameworks, Unsupervised Scaling Methods, and Autonomous Data Collection Methods.
 * Proven Technical Excellence: Demonstrated ability to build and deploy AI solutions. This could be anything ether industry experience or exceptional project/research work (publications, open-source contributions, competition wins, etc.) – we care about quality of experience over quantity.
 * Programming Skills: Preferably extensive Python experience.
 * Problem-Solving & Math: Outstanding problem-solving skills, with a creative and analytical mindset. Strong foundation in mathematics (linear algebra, calculus, probability) and comfort with reading research papers when needed.
 * Communication & Collaboration: Excellent communication skills. You can clearly articulate complex technical concepts to team members and actively listen and incorporate feedback. You work well in a team, value open discussion, and thrive in a fast-moving, meritocratic environment where everyone is encouraged to voice ideas and concerns.




Why In-Person SF Matters

 * You’ll work shoulder-to-shoulder with an exceptional team:
 * Ex-Stanford, MIT, and Berkeley engineers with dozens of papers
 * International Olympiad winners and medalists
 * Ex-OpenAI engineers with 10+ years of domain expertise for mentorship
 * Ex-Google Deepmind engineers
 * Former founders who’ve closed $500k in revenue at 19 and hired 40+ people
 * Decisions happen live, not in backlogged async threads
 * A players work with A players. There’s a buzzing energy in the office. Hit the whiteboard with anyone here and you’ll understand why.




Why Join Us

 * Impact & Ownership: As an early employee, you’ll have a massive impact on our product and culture. You will own significant projects from day one and see your work directly affect the company’s success.
 * Learning & Growth: Work alongside some of the brightest minds in AI and software engineering. Our team’s pedigree and our culture of continuous improvement will accelerate your personal and professional growth. We challenge each other to grow every day and support learning in areas you’re passionate about.
 * Meritocratic Culture: We reward results and initiative. Hard work and innovation are recognized – high performers can expect rapid advancement in responsibility and role. You’ll have the chance to shape your role and even define new ones as the company scales.
 * Competitive Compensation: We offer a compelling salary, meaningful equity, and benefits. You’ll share in the upside of the company’s success.
 * Cutting-Edge Work: You’ll be tackling unsolved problems and using the latest techniques in AI. If you love building bold, novel solutions instead of following the status quo, you’ll fit right in.
 * Mission-Driven Team: Join a team that is passionate, driven, and believes in the positive impact of technology. We’re in this to build something that matters.




Benefits

 * 100% medical, dental & vision coverage (for you; partial for dependents)
 * 401k with employer match
 * Unlimited PTO + federal holidays
 * GrubHub stipend + all meals covered in-office
 * Gym membership covered
 * Frequent team dinners, events, and off-sites
 * The opportunity to eliminate busywork for humanity

","Over 200 applicants","Full-time","Mid-Senior level","Engineering","Technology, Information and Internet","","","","18225241","https://www.linkedin.com/jobs/view/applied-ai-engineer-32720-at-stealth-startup-4347971840?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI/Machine Learning Engineer - Python | TheLoops","San Francisco, CA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/ai-machine-learning-engineer-python-theloops-at-ifs-4338448702?trk=public_jobs_topcard-title","IFS","https://se.linkedin.com/company/ifs?trk=public_jobs_topcard-org-name","IFS is a billion-dollar revenue company with 7000+ employees on all continents. Our leading AI technology is the backbone of our award-winning enterprise software solutions, enabling our customers to be their best when it really matters–at the Moment of Service™. Our commitment to internal AI adoption has allowed us to stay at the forefront of technological advancements, ensuring our colleagues can unlock their creativity and productivity, and our solutions are always cutting-edge.



About TheLoops



TheLoops, an IFS company, is the first enterprise-grade AI Agent platform built for mission-critical applications and industries. Our AI Agents act as digital coworkers that are governed, secure, always learning, and working 24/7 to drive measurable business outcomes.



As the company grows, it is looking for mission-driven individuals to help deliver the future of AI-powered operations.



At TheLoops, they:



 * Lead with Curiosity: They ask questions, learn, and communicate with respect for each other.
 * Learn by Making: They iterate fast to deliver tangible solutions with humility.
 * Listen to the Loop: They use data and feedback to map their path to success and measure it with autonomy and empathy.

By joining our team, you will have the opportunity to be part of a global, diverse environment; you will be joining a winning team with a commitment to sustainability; and a company where we get things done so that you can make a positive impact on the world.



We’re looking for innovative and original thinkers to work in an environment where you can #MakeYourMoment so that we can help others make theirs. With the power of our AI-driven solutions, we empower our team to change the status quo and make a real difference.



If you want to change the status quo, we’ll help you make your moment. Join Team Purple. Join IFS.





Job Description



As a Software Engineer, AI/ML, you will design, build, and optimize the backend systems that power intelligent agent workflows. You will work across data pipelines, APIs, and AI/ML frameworks to create reliable, scalable, and production-ready solutions. This role emphasizes strong software engineering fundamentals, with the added dimension of applying AI/ML concepts to real-world enterprise applications.What You'll Do

Backend & Systems Engineering



 * Build and maintain Python-based services, integrations, and data pipelines that support AI agent functionality.
 * Develop reusable libraries, APIs, and frameworks to accelerate AI-driven product capabilities.
 * Ensure code quality, maintainability, and scalability through testing, CI/CD, and performance monitoring.

Applied AI/ML Engineering



 * Implement and optimize workflows leveraging LLMs, embeddings, RAG systems, and vector databases.
 * Integrate AI/ML libraries and external APIs (e.g., OpenAI, Hugging Face, LangChain, Pinecone, Weaviate).
 * Experiment with prompt engineering and fine-tuning to improve reliability and performance of deployed agents.

Collaboration & Delivery



 * Partner with product and core engineering teams to translate requirements into technical solutions.
 * Contribute to architecture decisions and internal technical documentation.
 * Support the deployment of agents into enterprise environments with a focus on stability, accuracy, and scale.
   
   

Qualifications


 * 2–5 years of professional experience as a Python Engineer / Backend Engineer (experience with AI/ML is a strong plus).
 * Strong proficiency in Python and familiarity with JavaScript/TypeScript for integrations.
 * Hands-on knowledge of AI/ML frameworks and tools (OpenAI, Hugging Face, LangChain, vector DBs, RAG).
 * Understanding of system integration patterns and comfort working with RESTful APIs, JSON, and data pipelines
 * Experience with enterprise systems (CRM, ERP, Helpdesk, Developer platforms, HR/Finance systems) is a plus.
 * Strong debugging, testing, and optimization skills.
 * Ability to write clean, maintainable, and well-documented code.

What Success Looks Like in 3–6 Months



 * Technical Depth: You’ll be proficient in the internal platform, building integrations and Python services with confidence.
 * AI/ML Impact: You’ll have delivered backend components that integrate AI/ML capabilities into enterprise workflows.
 * Engineering Excellence: You’ll contribute to reusable libraries, deployment pipelines, and system reliability practices.
 * Team Contribution: You’ll collaborate effectively with other engineers and product teams, influencing technical direction.

Why Join Us



 * Build production-grade AI/ML systems with Python at the core.
 * Work on backend challenges that bring LLMs and AI agents into real-world enterprise environments.
 * High ownership and visibility on technical projects.
 * Competitive compensation, flexible work setup, and the backing of a global enterprise (IFS).
   
   

Additional Information



What We’re Offering



 * Salary Range: $120,000 to $150,000 plus bonus potential
 * Flexible paid time off, including sick and holiday
 * Medical, dental, & vision insurance
 * Flexible spending accounts
 * Life insurance and disability benefits
 * Tuition assistance
 * Community involvement and volunteering events

M/F/Disabled/Vet VEVRAA Federal Contractor. We are a Drug-Free Workplace. Interested candidates should apply at: www.ifs.com/about/careers-at-ifs



All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. VEVRAA Federal Contractor, Equal Opportunity Employer

","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering","Software Development","$120,000.00/yr - $150,000.00/yr","","","164301","https://www.linkedin.com/jobs/view/ai-machine-learning-engineer-python-theloops-at-ifs-4338448702?trk=public_jobs_topcard-title","EASY_APPLY",""
"Business Intelligence Analyst","Columbus, OH","1 week ago","2025-11-22","https://www.linkedin.com/jobs/view/business-intelligence-analyst-at-mckesson-4333587086?trk=public_jobs_topcard-title","McKesson","https://www.linkedin.com/company/mckesson?trk=public_jobs_topcard-org-name","McKesson is an impact-driven, Fortune 10 company that touches virtually every aspect of healthcare. We are known for delivering insights, products, and services that make quality care more accessible and affordable. Here, we focus on the health, happiness, and well-being of you and those we serve – we care.

What you do at McKesson matters. We foster a culture where you can grow, make an impact, and are empowered to bring new ideas. Together, we thrive as we shape the future of health for patients, our communities, and our people. If you want to be part of tomorrow’s health today, we want to hear from you.

CoverMyMeds is seeking an experienced Business Intelligence Analyst to join our dynamic team. In this role, you'll partner with product and engineering teams to transform complex data challenges into actionable insights that directly shape our products and drive business growth. We're looking for a analytical problem-solver who thrives on uncovering meaningful patterns in data, can communicate technical findings to diverse stakeholders, and has the persistence to see complex projects through to completion. If you're energized by turning data into strategic recommendations that make a real impact, this role is for you.

We’re seeking a team member that will live our core values – a unique, self-motivated, and results-driven individual who acts with integrity and humility.

What You’ll Do:


 * Collaborate with product, engineering, UX, and operations teams to deliver data-driven insights that guide product strategy and business decisions
 * Analyze user behavior, product performance, and market trends to identify growth opportunities and optimization areas
 * Find and present insights that help provide actionable recommendations for strategic initiatives, highlighting the impact it will make on our product and for our customers.
 * Obtain a deep understanding of the capabilities and nuances of the data stack powering our analytics solutions.
 * Design, launch, and analyze experiments to validate new features and measure their business impact
 * Work cross functionally to find ways to scale our insights through better systems and automation.
 * Use Tableau, SQL, Python, and other tools to prove value and develop targeted insights that help drive our products forward.
   
   
   

Analytics Tech Stack:


 * SQL, Tableau, R, Python
   
   
   

Must be authorized to work in the U.S, now or in the future, without support from CoverMyMeds.

About You

Our ideal candidate is curious, thrives in a constantly changing environment, and loves leveraging data to tell stories. This individual will be the go-to data expert who can connect the dots for customers and colleagues. Specific qualifications include:

Minimum Qualifications:

Degree or equivalent and typically requires 4+ years of relevant experience

Critical Skills:


 * Minimum 4 years of experience in an analytics role
 * Proficiency (3+ years of experience) in visualization tools (e.g. Tableau, Power BI)
 * Proficiency (3+ years of experience) in SQL, Python, or R
 * Strong experience with data mining, analysis, and providing insights
   
   
   

Preferred Skills and Qualifications:


 * Driven, self-motivated, team player adept at working in environment with competing priorities
 * Able to communicate and manage expectations with cross functional stakeholders.
 * Curious problem solver by nature; able to quickly make sense of complex data issues
 * Awareness in how to build and execute A/B Tests and other similar experiments
 * Adept at clearly and concisely presenting findings and key takeaway to stakeholders
 * Able to “think on your feet” and respond to questions where the answer is not known or not straightforward.
   
   
   

These requirements represent the knowledge, skills, and abilities necessary to perform this job successfully. Reasonable accommodation can be made to enable individuals with disabilities to perform essential functions.

We are proud to offer a competitive compensation package at McKesson as part of our Total Rewards. This is determined by several factors, including performance, experience and skills, equity, regular job market evaluations, and geographical markets. The pay range shown below is aligned with McKesson's pay philosophy, and pay will always be compliant with any applicable regulations. In addition to base pay, other compensation, such as an annual bonus or long-term incentive opportunities may be offered. For more information regarding benefits at McKesson, please click here.

Our Base Pay Range for this position

$84,800 - $141,300

McKesson is an Equal Opportunity Employer

McKesson provides equal employment opportunities to applicants and employees and is committed to a diverse and inclusive environment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, age or genetic information. For additional information on McKesson’s full Equal Employment Opportunity policies, visit our Equal Employment Opportunity page.

Join us at McKesson!","Over 200 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Hospitals and Health Care","$84,800.00/yr - $141,300.00/yr","","","1900","https://www.linkedin.com/jobs/view/business-intelligence-analyst-at-mckesson-4333587086?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Data Engineer","San Jose, CA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/senior-data-engineer-at-tenex-ai-4347630885?trk=public_jobs_topcard-title","TENEX.AI","https://www.linkedin.com/company/tenex-ai?trk=public_jobs_topcard-org-name","Company Overview

TENEX is an AI-native, automation-first, built-for-scale Managed Detection and Response (MDR) provider. We are a force multiplier for defenders, helping organizations enhance their cybersecurity posture through advanced threat detection, rapid response, and continuous protection. Our team is composed of industry experts with deep experience in cybersecurity, automation, and AI-driven solutions.

We’re a fast-growing startup backed by Andreessen Horowitz. As an early employee, you’ll help shape our culture and have meaningful ownership over high-impact initiatives. This is a unique opportunity to join a small but well-funded team on the ground floor as we build the next-generation cybersecurity platform.

We are expanding our engineering organization and seeking a Senior Data Engineer to architect and own our data infrastructure. This role is foundational in enabling high-quality analytics, reporting, and AI-driven insights across TENEX.

Culture is one of the most important things at TENEX.AI—explore our culture deck at culture.tenex.ai to witness how we embody it, prioritizing the irreplaceable collaboration and community of in-person work. This is an in-person opportunity based in our San Jose, CA office where you will be expected to work out of 4 days a week.

Role Overview

As a Senior Data Engineer, you will design, build, and scale the data systems that power our cybersecurity platform and internal decision-making. You will own ETL/ELT architecture, develop our data warehouse, define core metrics, and enable analytics for engineering, product, security operations, and leadership teams.

You’ll work across the stack—from ingestion pipelines to transformations to reporting—ensuring our data is reliable, actionable, and trustworthy. This role blends hands-on engineering with strategic influence over how TENEX collects, processes, models, and uses data.

Job Responsibilities:

Data Architecture & Pipelines


 * Design, build, and maintain scalable ETL/ELT pipelines for ingesting and processing large volumes of cybersecurity data.
 * Develop and manage data warehouse architectures using platforms such as Snowflake, BigQuery, or Redshift.
 * Build robust data models and schemas that support analytics, product features, and machine learning workflows.
 * Ensure the reliability, scalability, and performance of data infrastructure.
   
   

Analytics Enablement


 * Define, instrument, and maintain core business and product metrics across the organization.
 * Build data marts, semantic layers, and curated datasets for use across engineering, product, operations, and customer-facing analytics.
 * Partner with stakeholders to identify data needs and translate them into high-impact data solutions.
   
   

Dashboards & Reporting


 * Develop dashboards, automated reporting, and analytics layers using modern BI tools.
 * Drive visibility into platform performance, security outcomes, and operational metrics.
 * Ensure teams have easy access to accurate, timely insights.
   
   

Data Quality & Governance


 * Establish data validation best practices, monitoring, lineage, and observability.
 * Implement automated processes to ensure accuracy, consistency, and resilience across pipelines.
 * Maintain clear documentation, metadata, and schema evolution practices.
   
   

Cross-Functional Collaboration


 * Collaborate closely with engineering, product, and security teams to support new features and data-driven capabilities.
 * Provide technical input into product design, data instrumentation, and architecture.
 * Advocate for data best practices across the organization.
   
   

Continuous Improvement


 * Evaluate and integrate tools that improve data performance, reliability, and automation.
 * Contribute to engineering excellence through tooling, CI/CD for data, testing approaches, and process improvements.
   
   

Required Skills & Qualifications:


 * 5+ years of professional experience in data engineering or equivalent.
 * Strong experience building ETL/ELT pipelines and distributed data processing systems.
 * Hands-on experience with cloud data warehouses such as Snowflake, BigQuery, or Redshift.
 * Expertise with SQL and relational databases (PostgreSQL, MySQL, etc.).
 * Proficiency in at least one data engineering language (Python, Go, Scala, etc.).
 * Experience working with cloud platforms (GCP or AWS) and cloud-native data services.
 * Experience with orchestration and workflow systems (Airflow, Dagster, Prefect, or similar).
 * Strong understanding of data modeling, warehousing principles, and performance tuning.
 * Demonstrated ability to own complex projects end-to-end with minimal oversight.
 * Excellent communication, collaboration, and problem-solving skills.
   
   

Desired:


 * Experience with modern analytics engineering frameworks.
 * Experience with real-time / streaming data systems (Kafka, Pub/Sub, Kinesis).
 * Familiarity with BI & dashboarding tools (Looker, Grafana, etc.).
 * Experience preparing datasets for AI/ML workflows, including:
    * Feature engineering
    * Vector databases
    * RAG pipelines

 * Prior experience in cybersecurity, security analytics, or security data modeling.
 * Experience working in an early-stage startup environment.
   
   

Education & Certifications


 * Bachelor’s degree in Computer Science, Engineering, or a related field (or equivalent experience).
 * Cloud certifications (GCP Data Engineer, AWS Data Analytics Specialty, or similar) are a plus.
   
   

Why Join Us?


 * Opportunity to work with cutting-edge AI-driven cybersecurity technologies and Google SecOps solutions.
 * Collaborate with a talented and innovative team focused on continuously improving security operations.
 * Competitive salary and benefits package.
 * A culture of growth and development, with opportunities to expand your knowledge in AI, cybersecurity, and emerging technologies.","152 applicants","Full-time","Mid-Senior level","Information Technology","Technology, Information and Internet","","","","106002282","https://tenex.ai/careers/?ashby_jid=92439d53-0749-4486-b50b-dc908169676f&utm_source=LinkedInJobPostings","EXTERNAL",""
"Data Scientist","Rockville, MD","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/data-scientist-at-nextonic-solutions-4324691025?trk=public_jobs_topcard-title","Nextonic Solutions","https://www.linkedin.com/company/nextonic-solutions-llc?trk=public_jobs_topcard-org-name","Nextonic Solutions is seeking a highly skilled and motivated Data Scientist to support the development of scalable state-of-the-art systems that use artificial intelligence (AI) to empower scientists and physicians. This role will focus on using AI across multiple modalities (images, text, etc) to accelerate the pace of scientific research. The successful candidate will collaborate with a multidisciplinary team of scientists, software engineers, and biologists to drive advancements in translational sciences. The ability to think critically and work independently as a part of a team is a must. A strong preference will be given to data scientists with a background in the development of data pipelines, fundamental knowledge of large language model architectures, agents, and computer vision models. A background in biology and/or medicine is preferred.

Responsibilities


 * Develop, implement, and optimize LLMs and computer vision algorithms for processing and analyzing biomedical text and image data.
 * Design and develop software tools and pipelines for automated image analysis, data integration, and visualization, leveraging machine learning and deep learning techniques.
 * Collaborate with biologists and other researchers to understand their needs and translate them into technical solutions, incorporating state-of-the-art AI methodologies.
 * Perform data mining, statistical analysis, and machine learning on large-scale biomedical imaging datasets to extract meaningful insights and improve predictive accuracy.
 * Validate and benchmark AI-driven imaging algorithms and tools to ensure their accuracy, robustness, and scalability.
 * Document software development processes, create user manuals, and provide training and support to end-users, particularly focusing on AI applications.
 * Stay up-to-date with the latest advancements in AI, computer vision, biomedical imaging, computational biology, and data science, and apply this knowledge to improve existing tools and methodologies.
 * Participate in interdisciplinary team meetings, present findings, and contribute to scientific publications and grant proposals, emphasizing AI and computer vision innovations.
 * Identify and implement new AI technologies and frameworks to enhance the capabilities of biomedical imaging tools and methodologies.
 * Knowledge of code packaging, containerization technologies, and continuous integration pipelines.
 * DevOps experience with Kubernetes and workflow automation is a plus
   
   
   

Qualifications


 * Ph.D. or Master’s degree in Data Science, Computer Science, Biomedical Engineering, Bioinformatics, or a related field.
 * Proven experience in biomedical imaging analysis, AI, and computer vision, preferably in HTS and HCS contexts.
 * Strong programming skills in languages such as Python. C++ and Rust is a plus.
 * Well versed with AI and machine learning frameworks and libraries such as TensorFlow, PyTorch, PydanticAI, and LLM observability.
 * Experience with image analysis software and libraries such as ImageJ, CellProfiler, OpenCV, or similar.
 * Knowledge of statistical analysis and data visualization techniques.
 * Familiarity with high-performance computing and cloud-based data processing environments.
 * Excellent problem-solving skills and the ability to work both independently and as part of a team.
 * Strong communication skills and the ability to convey complex technical concepts to non-technical audiences.
 * Experience in developing AI-driven software tools for biomedical research.
 * Experience with version control systems such as Git.
 * Experience with workflow automation tools.
 * Previous experience working in a collaborative, interdisciplinary research environment.","179 applicants","Full-time","Entry level","Other","Government Administration","","","","35437552","https://www.linkedin.com/jobs/view/data-scientist-at-nextonic-solutions-4324691025?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI/ML Engineer – GenAI Assistant & Experience Engineering","San Jose, CA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/ai-ml-engineer-%E2%80%93-genai-assistant-experience-engineering-at-adobe-4323606582?trk=public_jobs_topcard-title","Adobe","https://www.linkedin.com/company/adobe?trk=public_jobs_topcard-org-name","Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

About The Team

The Gen AI Experience Engineering team is defining the future of intelligent workflows across Adobe Experience Cloud with the AI Assistant. We operate like a startup within Adobe—fast, iterative, and customer-focused. Our mission is to build the intelligent systems, models, and services that power Adobe’s AI Assistant experience.

The Opportunity

We’re looking for an AI/ML Engineer who is excited to build intelligent features using whatever approach solves the problem best.

Some solutions will use LLMs and generative AI, some will rely on traditional ML, some will be heuristic or rules-based, and many will be hybrid systems that combine them.

Your job is to evaluate the problem, select the appropriate approach, and deliver high-quality, scalable solutions that improve user experiences.

In this role, you’ll build models, design prompts, develop services, run evaluations, and ship features end-to-end. This is a hands-on applied engineering role with broad ownership, where you’ll work across modeling, service development, and lightweight ops.

What You’ll Do

AI, ML & Hybrid Solution Development


 * Build and iterate on solutions using the full spectrum of approaches: LLMs, classical ML, heuristics, rules engines, retrieval systems, or combinations thereof.
 * Design, train, fine-tune, and evaluate models for generative AI, classification, search, and content understanding.
 * Develop prompting strategies, multi-step prompt workflows, and agents that power interactive AI experiences.
 * Build hybrid pipelines that combine deterministic logic with AI/ML components for predictable, reliable outcomes.
   
   

Service & Feature Engineering


 * Implement backend services and inference pipelines for the AI Assistant across Experience Cloud.
 * Build RAG systems, model-serving layers, experimentation hooks, and scalable APIs.
 * Partner with frontend engineers and product teams to turn concepts into shipped features.
   
   

Evaluation, Data, and Light Ops


 * Build automated evaluation pipelines to measure quality, safety, latency, and reliability.
 * Prepare datasets for evaluation, fine-tuning, and experimentation.
 * Deploy models and services using CI/CD, containers, and cloud workflows.
 * Monitor performance and iterate quickly based on data and user signals.
   
   

While this is not a dedicated ops role you should be able to own and operate your work end-to-end as projects require.

Cross-Functional Collaboration


 * Work closely with Product, Engineering, Design and ML teams to explore new ideas and deliver customer-facing features.
 * Help define guidelines for AI/ML development, evaluation, and hybrid system building.
 * Contribute to shared tools that accelerate experimentation and improve developer productivity.
   
   

What You Bring


 * 5+ years experience in machine learning, applied AI engineering, IR or full-stack intelligent feature development.
 * Hands-on experience with both LLM-based and traditional ML techniques, and the judgment to choose the right tool for the job.
 * Strong software engineering fundamentals and experience building production services (Node, Python, TypeScript, Go, or similar).
 * Experience building and deploying intelligent systems across cloud environments (Azure, AWS, GCP).
 * Ability to design evaluation frameworks, run experiments, and iterate rapidly.
 * Comfortable owning features from prototype → production, including monitoring and optimization.
 * Excellent communication and collaboration skills; thrives in fast-paced environments with ambiguity and autonomy.
   
   

Nice to Have


 * Experience with hybrid LLM + deterministic systems, vector search, or orchestration tools.
 * Knowledge of Adobe Experience Cloud or other enterprise SaaS ecosystems.
 * Contributions to open-source AI/ML tools, model-serving frameworks, or evaluation libraries.
 * Prior startup or high-velocity product development experience.
   
   

Our compensation reflects the cost of labor across several  U.S. geographic markets, and we pay differently based on those defined markets. The U.S. pay range for this position is $142,700 -- $257,600 annually. Pay within this range varies by work location and may also depend on job-related knowledge, skills, and experience. Your recruiter can share more about the specific salary range for the job location during the hiring process.

At Adobe, for sales roles starting salaries are expressed as total target compensation (TTC = base + commission), and short-term incentives are in the form of sales commission plans. Non-sales roles starting salaries are expressed as base salary and short-term incentives are in the form of the Annual Incentive Plan (AIP).

In addition, certain roles may be eligible for long-term incentives in the form of a new hire equity award.

State-Specific Notices:

California:

Fair Chance Ordinances

Adobe will consider qualified applicants with arrest or conviction records for employment in accordance with state and local laws and “fair chance” ordinances.

Colorado:

Application Window Notice

There is no deadline to apply to this job posting because Adobe accepts applications for this role on an ongoing basis. The posting will remain open based on hiring needs and position availability.

Massachusetts:

Massachusetts Legal Notice

It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.

Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.

Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.","170 applicants","Full-time","Entry level","Engineering and Information Technology","Advertising Services, IT Services and IT Consulting, and Software Development","$142,700.00/yr - $257,600.00/yr","","","1480","https://www.linkedin.com/jobs/view/ai-ml-engineer-%E2%80%93-genai-assistant-experience-engineering-at-adobe-4323606582?trk=public_jobs_topcard-title","EASY_APPLY",""
"Corporate Solutions Engineer","Austin, TX","6 days ago","2025-11-26","https://www.linkedin.com/jobs/view/corporate-solutions-engineer-at-postman-4338954453?trk=public_jobs_topcard-title","Postman","https://www.linkedin.com/company/postman-platform?trk=public_jobs_topcard-org-name","Who Are We?

Postman is the world’s leading API platform, used by more than 40 million developers and 500,000 organizations, including 98% of the Fortune 500. Postman is helping developers and professionals across the globe build the API-first world by simplifying each step of the API lifecycle and streamlining collaboration—enabling users to create better APIs, faster.

The company is headquartered in San Francisco and has offices in Boston, New York, and Bangalore - where Postman was founded. Postman is privately held, with funding from Battery Ventures, BOND, Coatue, CRV, Insight Partners, and Nexus Venture Partners. Learn more at postman.com or connect with Postman on X via @getpostman.

P.S: We highly recommend reading The ""API-First World"" graphic novel to understand the bigger picture and our vision at Postman.

The Opportunity

With so many organizations using Postman, we are looking for an exceptional Corporate Solutions Engineer to join our team & help us support the growth of our customers in the corporate market. You will partner with our corporate sales team to promote an API-first development culture, nurture customer relationships, and guide Postman users in leveraging our platform to build their APIs most effectively. Ideally, we are looking for someone who lives & breathes APIs, has experience in corporate sales, is comfortable with JavaScript & is an expert Postman user already!

In addition to working with a product that customers already know and love, our sales, customer success, product, and engineering teams will support you well in this role.

What You’ll Do


 * Help drive sales by nurturing prospects & supporting customers in our corporate market
 * Conduct discovery, qualification, technical demos, & proof of value workshops with prospective customers looking to embrace Postman for their API lifecycle
 * Handle Postman technical questions or objections & provide solutions or workarounds to address customer needs
 * Produce reusable collateral that can be distributed to help our prospective customers understand how to adopt API-first practices with Postman.
 * Understand deeply our customer workflows today & how they can adopt API-first development best practices
 * Share customer feedback with appropriate teams & provide general customer advocacy
 * Remain up-to-date with the competitive landscape, current trends, & challenges in the API market
 * Create proof of concept integrations, tooling, & workflows as needed to support prospective customers
 * Maintain & develop customer sandbox environments & best practices for working with the product
 * Act as a technical intermediary between sales & other teams to best fit our customer needs
   
   

About You


 * 4+ years of corporate sales/solutions engineering experience
 * 3+ years of software development experience
 * 3+ API’s and Data platforms experience
 * Bachelor's degree in Computer Science, a related field, or relevant work experience
 * Ability to travel up to 25%
 * Loves teamwork & collaboration in a fast-paced environment
 * Customer-facing experience & comfortable engaging all levels of technologists, including individual developers, QA, product, & engineering leaders
 * Strong understanding of APIs, & experience with producing & consuming APIs across different domains
 * Strong knowledge of modern development methodologies & DevOps with an appreciation of the software development life cycle
 * Comfortable with the SaaS sales process & common security concerns of cloud services
 * Experience executing sales strategies & sales methodologies like MEDDIC, Challenger Sale, Command of the Message, etc.
 * Excellent listener who seeks to understand what a customer is trying to achieve rather than pre-supposing solutions
 * Familiar with typical developer tooling: IDEs, Git, CI/CD, monitoring services, microservices, containers, cloud computing services, etc.
 * Fast learner, excited & willing to learn new technology on an ongoing basis
 * Excellent communication skills (presentation, verbal & written)
   
   

The reasonably estimated OTE for this role is $145,000 - $175,000 plus a competitive equity package. Actual compensation is based on the candidate's skills, qualifications, and experience.

What Else?

In addition to Postman's pay-on-performance philosophy, and a flexible schedule working with a fun, collaborative team, Postman offers a comprehensive set of benefits, including full medical coverage, flexible PTO, wellness reimbursement, and a monthly lunch stipend. Along with that, our wellness programs will help you stay in the best of your physical and mental health. Our frequent and fascinating team-building events will keep you connected, while our donation-matching program can support the causes you care about. We’re building a long-term company with an inclusive culture where everyone can be the best version of themselves.

At Postman, we embrace a hybrid work model. For all roles based out of San Francisco Bay Area, Boston, Bangalore, Hyderabad, and New York, employees are expected to come into the office 3-days a week. We were thoughtful in our approach which is based on balancing flexibility and collaboration and grounded in feedback from our workforce, leadership team, and peers. The benefits of our hybrid office model will be shared knowledge, brainstorming sessions, communication, and building trust in-person that cannot be replicated via zoom.

Our Values

At Postman, we create with the same curiosity that we see in our users. We value transparency and honest communication about not only successes, but also failures. In our work, we focus on specific goals that add up to a larger vision. Our inclusive work culture ensures that everyone is valued equally as important pieces of our final product. We are dedicated to delivering the best products we can.

Equal opportunity

Postman is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. Postman does not accept unsolicited headhunter and agency resumes. Postman will not pay fees to any third-party agency or company that does not have a signed agreement with Postman.","Be among the first 25 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","","","","3795851","https://www.linkedin.com/jobs/view/corporate-solutions-engineer-at-postman-4338954453?trk=public_jobs_topcard-title","EASY_APPLY",""
"SENIOR DATA ENGINEER (REMOTE)","Illinois, United States","3 weeks ago","2025-11-05","https://www.linkedin.com/jobs/view/senior-data-engineer-remote-at-compass-digital-4334403407?trk=public_jobs_topcard-title","Compass Digital","https://ca.linkedin.com/company/compass-digital-na?trk=public_jobs_topcard-org-name","Compass Digital

Salary: $130000-$140000 (to commensurate with experience)

We are Compass Digital—the digital and technology arm of Compass Group North America. We build and scale digital products and technologies to exceed the expectations of our guests and clients. Backed by research, we create remarkable user experiences with increased choice and convenience. We offer end-to-end solutions, simultaneously boosting sales and guest satisfaction.

Compass Digital was developed from within Compass Group, focusing on driving transformation and innovation in the hospitality spaces across Business & Industry, Education, and Healthcare. We power digital in the hospitality experience, ensuring that each touchpoint is optimized for guest satisfaction while leveraging data to achieve additional outcomes.

We are fully integrated into Compass Group, proudly serving its’ various clients through scalable, cutting-edge technologies and solutions.

Job Summary:

We are looking for a hands-on, collaborative Senior Data Engineer. In this role, you will have the chance to build pipelines that will deliver data solutions primarily to Levy, our restaurants and stadium sector. You will help bring best practices to the team while working with a collaborative group of data stewards. As a Senior Data Engineer, you will complete POCs, manage your time without oversight to complete tasks, and be a vocal contributor to team decisions. We are using a tech stack of primarily Snowflake and dbt, with other AWS services as needed. This role will also involve completing the scoping & discovery of the requirements of the business, identifying dependencies, and communicating those to all parties.

If you have a git repository, we would be excited to see it!

Responsibilities:


 * Lead the design, development, and deployment of scalable, resilient data pipelines using Snowflake, dbt, AWS, Fivetran, and other engineering tools.
 * Own and deliver technically complex, cross-functional data projects aligned with quarterly goals, navigating ambiguity with autonomy.
 * Collaborate with reporting, analytics, and data science teams to understand business needs, data sources, and define requirements.
 * Shape and influence architectural decisions, contribute to roadmap development, and champion best practices for ETL and engineering excellence.
 * Gather, enrich, and transform data to drive actionable insights, ensuring infrastructure changes are well-documented and pipelines are robust and performant.
 * Drive high standards for data and software quality through code reviews, documentation, and implementation of scalable, reusable solutions.
 * Mentor junior engineers and apprentices, providing technical guidance, modeling craft, and fostering a culture of growth and inclusion.
 * Proactively identify gaps in the data platform, recommend technical solutions, and advocate for improvements that enhance long-term sustainability.
 * Support testing efforts by defining and validating criteria aligned with business expectations, ensuring future-proofed deliverables.
 * Facilitate business alignment by clearly communicating the value and design of data solutions, incorporating user feedback to iterate.
 * Collaborate with third-party vendors and cross-functional stakeholders to scope requirements and deliver value across teams.
 * Take ownership of operational issues, proactively respond to incidents, and build safeguards that improve system resilience.
 * Act as a strategic partner—breaking down complex projects into executable phases, setting realistic goals, and delivering customer impact.
 * Participate in interviews and team-building efforts, helping to hire and level up a diverse, high-performing engineering team.
 * Maintain awareness of Compass Group’s organizational structure and priorities, aligning data solutions to broader business goals.
   
   

Qualifications:


 * Bachelor’s degree in Computer Science, Information Systems, Analytics, or related field
 * 3 – 5 years of experience in ETL or Data Engineering role, building and implementing data pipelines
 * AWS Data Engineering Certification, AWS Solution Architect Associate Certification, Snowpro Certification or similar
 * Solid understanding of data structures and data warehouses
 * Strong skills with SQL with the ability to write efficient queries
 * Previous experience working in a highly collaborative environment
 * Highly self-motivated and directed with an attention to detail
 * Experience designing pipelines with event driven architecture
 * Experience working in AWS
 * Experience working with Snowflake and dbt
 * Experience managing tickets in Azure DevOps or similar
 * Experience in Agile software development
 * Strong communication skills with the business & technical teams
   
   

Preferred Skills:


 * Experience in DevOps and CI/CD technologies and methodologies
 * AWS Security best practices
 * Hospitality knowledge/experience a plus
   
   

Apply to Compass Group today!

Click here to Learn More about the Compass Story

Compass Group is an equal opportunity employer. At Compass, we are committed to treating all Applicants and Associates fairly based on their abilities, achievements, and experience without regard to race, national origin, sex, age, disability, veteran status, sexual orientation, gender identity, or any other classification protected by law.

Qualified candidates must be able to perform the essential functions of this position satisfactorily with or without a reasonable accommodation. Disclaimer: this job post is not necessarily an exhaustive list of all essential responsibilities, skills, tasks, or requirements associated with this position. While this is intended to be an accurate reflection of the position posted, the Company reserves the right to modify or change the essential functions of the job based on business necessity. We will consider for employment all qualified applicants, including those with a criminal history (including relevant driving history), in a manner consistent with all applicable federal, state, and local laws, including the City of Los Angeles’ Fair Chance Initiative for Hiring Ordinance, the San Francisco Fair Chance Ordinance, and the New York Fair Chance Act.

Compass Digital maintains a drug-free workplace.

Applications are accepted on an ongoing basis.

Associates At Corporate Are Offered Many Fantastic Benefits.


 * Medical
 * Dental
 * Vision
 * Life Insurance/ AD
 * Disability Insurance
 * Retirement Plan
 * Paid Time Off
 * Holiday Time Off (varies by site/state)
 * Associate Shopping Program
 * Health and Wellness Programs
 * Discount Marketplace
 * Identity Theft Protection
 * Pet Insurance
 * Commuter Benefits
 * Employee Assistance Program
 * Flexible Spending Accounts (FSAs)
 * Paid Parental Leave
 * Personal Leave
   
   

Associates may also be eligible for paid and/or unpaid time off benefits in accordance with applicable federal, state, and local laws. For positions in Washington State, Maryland, or to be performed Remotely, click here for paid time off benefits information.

Req ID: 1479669

Compass Digital

Bankston B Williams","58 applicants","Full-time","Mid-Senior level","Information Technology","IT Services and IT Consulting","$130,000.00/yr - $140,000.00/yr","","","10782785","https://www.linkedin.com/jobs/view/senior-data-engineer-remote-at-compass-digital-4334403407?trk=public_jobs_topcard-title","EASY_APPLY",""
"GEN AI LLM Data Scientist- Onsite","Raritan, NJ","1 month ago","2025-10-27","https://www.linkedin.com/jobs/view/gen-ai-llm-data-scientist-onsite-at-the-dignify-solutions-llc-4341875744?trk=public_jobs_topcard-title","The Dignify Solutions, LLC","https://www.linkedin.com/company/dignify-solutions?trk=public_jobs_topcard-org-name"," * Must have 12+ years of experience working in Data science, Machine learning and especially NLP technologies.
 * Exposure to various LLM technologies and solid understanding of Transformer Encoder Networks.
 * Able to apply deep learning and generative modeling techniques to develop LLM solutions in the field of Artificial Intelligence.
 * Utilize your extensive knowledge and expertise in machine learning (Client) with a focus on generative models, including but not limited to generative adversarial networks (GANs), variational autoencoders (VAEs), and transformer-based architectures.
 * Solid understanding of Model development, model serving, training/re-training techniques in a data sparse environment.
 * Very good understanding of Prompt engineering techniques in developing Instruction based LLMs.
 * Must be able to design and implement state-of-the-art generative models for natural language processing (NLP) tasks such as text generation, text completion, language translation, and document summarization.
 * Work with SAs and collaborate with cross-functional teams to identify business requirements and deliver solutions that meet the customer needs.
 * Passionate to learn and stay updated with the latest advancements in generative AI and LLM.
 * Nice to have -contributions to the research community through publications, presentations, and participation in relevant conferences or workshops.
 * Evaluate and preprocess large-scale datasets, ensuring data quality and integrity, and develop data pipelines for training and evaluation of generative models.
 * Ability to articulate to business stakeholders on the hallucination effects and various model behavioral analysis techniques followed.
 * Exposure to developing Guardrails for LLMs both with open source and cloud native models.
 * Collaborate with software engineers to deploy and optimize generative models in production environments, considering factors such as scalability, efficiency, and real-time performance.
 * Nice to have- provide guidance to junior data scientists, sharing expertise and knowledge in generative AI and LLM, and contribute to the overall growth and success of the data science team.","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","75031133","https://www.linkedin.com/jobs/view/gen-ai-llm-data-scientist-onsite-at-the-dignify-solutions-llc-4341875744?trk=public_jobs_topcard-title","EASY_APPLY",""
"Business Intelligence Analyst","Columbus, OH","2 days ago","2025-11-29","https://www.linkedin.com/jobs/view/business-intelligence-analyst-at-mckesson-4335083840?trk=public_jobs_topcard-title","McKesson","https://www.linkedin.com/company/mckesson?trk=public_jobs_topcard-org-name","McKesson is an impact-driven, Fortune 10 company that touches virtually every aspect of healthcare. We are known for delivering insights, products, and services that make quality care more accessible and affordable. Here, we focus on the health, happiness, and well-being of you and those we serve – we care.

What you do at McKesson matters. We foster a culture where you can grow, make an impact, and are empowered to bring new ideas. Together, we thrive as we shape the future of health for patients, our communities, and our people. If you want to be part of tomorrow’s health today, we want to hear from you.

We are seeking a highly skilled Business Intelligence Analyst to join our Patient Support Operations Data Analytics (pSODA) team. This role plays a critical part in supporting operational reporting and data strategy for the Patient Support Center (PSC). You will work across data engineering, analytics, and business stakeholders to deliver scalable, accurate, and insightful data solutions that drive strategic decision-making.

This position is ideal for a detail-oriented, technically proficient analyst who thrives in a collaborative environment and is passionate about transforming complex data into meaningful business value.

Key Responsibilities


 * Design, develop, and maintain backend data resources and Tableau dashboards to support operational reporting.
 * Define and implement data best practices with and for the pSODA team.
 * Establish and maintain documentation for data definitions, sources, and reports.
 * Lead cross-functionally with analysts, developers, product owners, and operations to align data resources with business needs.
 * Perform quality checks on dashboards and data pipelines, investigating anomalies and resolving inconsistencies.
 * Lead deep dives into operational and efficiency questions to fuel future reporting opportunities.
 * Develop presentations and write-ups to share findings, including key reporting insights and recommendations.
   
   
   

Minimum Qualifications

Degree or equivalent and typically requires 4+ years of relevant experience

Education


 * Bachelor’s degree or equivalent experience in a related field (e.g., Computer Science, Mathematics, Statistics, Data Analytics, Information Systems).
   
   
   

Critical Skills


 * 4+ years of experience in business intelligence, data analytics, or a similar technical role.
 * Advanced (4+ years') proficiency in SQL, Tableau, Excel, R, Python, or other relevant tools.
 * Strong analytical and problem-solving skills, with the ability to translate raw data into actionable insights.
 * Solid understanding of data visualization principles and techniques.
   
   
   

Preferred Skills & Ideal Candidate Traits


 * Comfortable navigating ambiguous or unfamiliar datasets and building structure from complexity.
 * Excellent communication and presentation skills.
 * Experience working in cross-functional teams and managing multiple priorities in a fast-paced environment. Prior experience in the healthcare technology field is preferred.
 * Curious and driven to uncover insights from complex data.
 * Strategic thinker with a knack for connecting data to business logic.
 * Collaborative team player who can manage their work independently.
 * Energized by the process of inventing simple, sustainable, and scalable solutions.
 * Passionate about mentoring and supporting the growth of others through knowledge sharing and analytical best practices.
   
   
   

We are proud to offer a competitive compensation package at McKesson as part of our Total Rewards. This is determined by several factors, including performance, experience and skills, equity, regular job market evaluations, and geographical markets. The pay range shown below is aligned with McKesson's pay philosophy, and pay will always be compliant with any applicable regulations. In addition to base pay, other compensation, such as an annual bonus or long-term incentive opportunities may be offered. For more information regarding benefits at McKesson, please click here.

Our Base Pay Range for this position

$84,800 - $141,300

McKesson is an Equal Opportunity Employer

McKesson provides equal employment opportunities to applicants and employees and is committed to a diverse and inclusive environment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, age or genetic information. For additional information on McKesson’s full Equal Employment Opportunity policies, visit our Equal Employment Opportunity page.

Join us at McKesson!","Over 200 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Hospitals and Health Care","$84,800.00/yr - $141,300.00/yr","","","1900","https://www.linkedin.com/jobs/view/business-intelligence-analyst-at-mckesson-4335083840?trk=public_jobs_topcard-title","EASY_APPLY",""
"Staff Data Engineer - Store Operations","Mesquite, TX","8 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/staff-data-engineer-store-operations-at-h-e-b-4325422111?trk=public_jobs_topcard-title","H-E-B","https://www.linkedin.com/company/heb?trk=public_jobs_topcard-org-name","Responsibilities

Since H-E-B Digital Technology's inception, we've been investing heavily in our customers' digital experience, reinventing how they find inspiration from food, make food decisions, and ultimately get food into their homes. This is an exciting time to join H-E-B Digital-we're using the best available technologies to deliver modern, engaging, reliable, and scalable experiences to meet the needs of our growing audience.

As a Staff Data Engineer, you'll lead, coach, and mentor engineers and teams and provide technical direction and support. You'll collaborate with Product, Data Science, Application, and Analytics teams to develop a clear understanding of data and data infrastructure needs to resolve data-related technical issues and ensure optimal data design and efficiency.

Once you're eligible, you'll become an Owner in the company, so we're looking for commitment, hard work, and focus on quality and Customer service. 'Partner-owned' means our most important resources--People--drive the innovation, growth, and success that make H-E-B The Greatest Omnichannel Retailing Company.

Do you have a:

HEART FOR PEOPLE... ability to serve as thought leader and mentor to Partners?

HEAD FOR BUSINESS... you make sound, mature technical judgments that result in significant impact?

PASSION FOR RESULTS... you can deliver sweeping technical initiatives with minimal guidance?

We are looking for:


 * 7+ years of related experience; leadership experience
   
   

What is the work?

Design & Development:


 * Leads team in designing / developing data integrations that support application engineering and system integration
 * Leads design / development / maintenance of largescale data pipelines; may assist in diagnosing / solving complex production support issues
 * Provides operational and technical expertise to design algorithms patterns that support large/complex datasets for analytics, implement calculations, cleanse data, ensure standardization of data, and map / link data from more than one source
 * Leads engineers across one or more squads to deliver initiatives
 * Mentors / provides support to junior data engineers; coaches / mentors engineers in engineering techniques, processes, new technologies
 * Builds / supports complex data pipelines, APIs, data integrations, data streaming solutions, and predictive model implementations
 * Identifies complex data from upstream sources to enable new capabilities
 * Designs and builds large-scale batch / real-time data pipelines with big data processing frameworks
 * Architects monitoring capabilities based on business SLA and data quality
 * Maintains / streamlines existing data pipelines end to end
 * Performs full SDLC process, including planning, design, development, certification, implementation, and support on more complex projects
 * Establishes team operational plans; develops / implements new processes, standards, and operational plans that impact results; develops technical roadmaps
 * Makes recommendations for overall data platforms, work flow, design, architecture, security, scalability, reliability, and performance
 * Recommends changes to processes, tools at the group / dept level based on industry standards, patterns, and practices
 * Tests technical solutions to ensure data integrity and system functionality of own work, with consideration toward broader system, E2E
 * Designs scalable, efficient data models to support data integration, storage, and retrieval across complex systems.
 * Develops and implements data quality framework for data accuracy, consistency, and completeness across workflows.
 * Works with Product, Business, and Analyst stakeholders to confirm data quality, discuss requirements, and support data testing
 * Creates team documentation and training related to technology stacks and standards
 * Diagnoses / troubleshoots extremely complex issues independently
 * Performs data validation and quality assurance on own work and of junior engineers
 * Collaborates with external technical teams to ensure timely, high-quality solutions
 * Engages with shared services teams and vendors as needed
 * Influences others in technical decision-making / technology adoption in assigned domain
 * Knowledge in machine learning concepts
   
   

What is your background?


 * A related degree or comparable formal training, certification, or work experience
 * 7+ years of experience related to data engineering
 * Experience in team leadership
 * Experience working in large scale infrastructure, large data sets, and mission critical SLAs
   
   

Do you have what it takes to be an H-E-B Staff Data Engineer?


 * Comprehensive knowledge of Lean Startup / Agile development methodologies
 * Knowledge of business intelligence, analytics / reporting, and application integration
 * Knowledge of data architectures such as data warehouse, data lake, and data mesh and when to apply
 * Expert understanding of coding standards, design principles / patterns, and data architecture and data modeling best practices and guidelines for different data and analytic platforms
 * Advanced verbal / written communication and data presentation skills
 * Strong prioritization skills
 * Ability to deliver on ambiguous projects with incomplete information
 * Ability to act as a thought leader and mentor to junior team members
 * Ability / willingness to learn new technologies as they emerge
 * Ability to calmly work under pressure
 * Ability to work a flexible schedule as needed
 * Ability to collaborate across multiple work locations
 * Ability to work within a team, and willingness to take feedback from peers and mentors","Be among the first 25 applicants","Full-time","Mid-Senior level","Information Technology","Retail","","","","164159","https://www.linkedin.com/jobs/view/staff-data-engineer-store-operations-at-h-e-b-4325422111?trk=public_jobs_topcard-title","EASY_APPLY",""
"GEN AI LLM Data Scientist - Onsite","Raritan, NJ","1 month ago","2025-10-27","https://www.linkedin.com/jobs/view/gen-ai-llm-data-scientist-onsite-at-the-dignify-solutions-llc-4341885657?trk=public_jobs_topcard-title","The Dignify Solutions, LLC","https://www.linkedin.com/company/dignify-solutions?trk=public_jobs_topcard-org-name"," * Must have 12+ years of experience working in Data science, Machine learning and especially NLP technologies.
 * Exposure to various LLM technologies and solid understanding of Transformer Encoder Networks.
 * Able to apply deep learning and generative modeling techniques to develop LLM solutions in the field of Artificial Intelligence.
 * Utilize your extensive knowledge and expertise in machine learning (Client) with a focus on generative models, including but not limited to generative adversarial networks (GANs), variational autoencoders (VAEs), and transformer-based architectures.
 * Solid understanding of Model development, model serving, training/re-training techniques in a data sparse environment.
 * Very good understanding of Prompt engineering techniques in developing Instruction based LLMs.
 * Must be able to design and implement state-of-the-art generative models for natural language processing (NLP) tasks such as text generation, text completion, language translation, and document summarization.
 * Work with SAs and collaborate with cross-functional teams to identify business requirements and deliver solutions that meet the customer needs.
 * Passionate to learn and stay updated with the latest advancements in generative AI and LLM.
 * Nice to have -contributions to the research community through publications, presentations, and participation in relevant conferences or workshops.
 * Evaluate and preprocess large-scale datasets, ensuring data quality and integrity, and develop data pipelines for training and evaluation of generative models.
 * Ability to articulate to business stakeholders on the hallucination effects and various model behavioral analysis techniques followed.
 * Exposure to developing Guardrails for LLMs both with open source and cloud native models.
 * Collaborate with software engineers to deploy and optimize generative models in production environments, considering factors such as scalability, efficiency, and real-time performance.
 * Nice to have- provide guidance to junior data scientists, sharing expertise and knowledge in generative AI and LLM, and contribute to the overall growth and success of the data science team.","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","75031133","https://www.linkedin.com/jobs/view/gen-ai-llm-data-scientist-onsite-at-the-dignify-solutions-llc-4341885657?trk=public_jobs_topcard-title","EASY_APPLY",""
"Product Analytics Manager (Looker)","New York, NY","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/product-analytics-manager-looker-at-pinwheel-4339012846?trk=public_jobs_topcard-title","Pinwheel","https://www.linkedin.com/company/pinwheelhq?trk=public_jobs_topcard-org-name","**This is a hybrid role (3x / week) in our NYC office.**

Pinwheel - Building the future of financial services in partnership with the biggest brands

“I love my banking app!” said no one, ever.

Pinwheel is on a mission to change that. We believe banks and financial service providers represent the greatest opportunity to build 10x better experiences, especially in the AI age. We’re building the next generation of financial products alongside some of the biggest names in the market including Robinhood, DoorDash, Credit Karma, American Express, Discover, Intuit, Acorns, Visa and more.

If you’re excited by the idea of having your work touch and impact the lives of hundreds of millions of consumers, Pinwheel is the place for you.

If you get stoked about building products alongside the biggest brands in the world, Pinwheel is the place for you.

If you want to join a scrappy, hustling team that is obsessed with defining the future of financial services, Pinwheel is the place for you!

Pinwheel has raised $77M from top-tier investors such as Coatue, Notable, First Round, Upfront, Primary, American Express, Franklin Templeton, Indeed, Semper Virens and more.

Who are we looking for?

Pinwheel is looking for an Analytics Manager who will serve as a strategic partner across Product, Engineering, Design (EPD), and Go-to-Market (GTM) teams. This role goes beyond dashboards—it’s about proactively driving insights, surfacing high-impact opportunities, and shaping product and business strategy.

You’ll help Pinwheel understand not just what is happening in our products, but why, by combining quantitative and qualitative signals, and business context to guide decisions across the organization. You’ll play a critical role in influencing roadmap priorities, shaping customer best practices, and empowering our teams with clear, actionable insights.

What will you be doing?


 * Own analytics across Pinwheel’s product suite, focusing on conversion optimization and understanding customer and platform-level implementation patterns that drive success
 * Proactively identify trends, opportunities, and anomalies in product metrics—not just answering data questions; asking better ones
 * Develop metrics frameworks and KPI dashboards to monitor product performance, conversion funnels, and integration health across hundreds of partners
 * Partner with EPD and GTM teams to translate insights into action, informing product improvements and go-to-market narratives
 * Build a deep understanding of customer segments, product placement, and configuration performance to inform best practices for our partners and customers
 * Enable Sales and Marketing with case studies and metrics that highlight success factors across high-performing customers and integrations
 * Partner with Engineering and Data teams to ensure proper instrumentation, metric definitions, and data model design
 * Develop a system to ingest and synthesize qualitative feedback (e.g. Gong calls, Slack feedback, user surveys, and interviews) into unified insights about product opportunities
   
   

What experience, skills, and qualifications should you have?


 * 5+ years of experience in product analytics or a related data strategy role
 * Expert-level SQL skills and comfort with large, complex data sets
 * Deep experience with Looker / LookML
 * Strong understanding of data architecture, with the ability to ensure accuracy in metric definitions and event capture
 * Proven ability to partner cross-functionally—especially with Product, Engineering, and GTM teams—to influence strategic direction
 * Track record of proactive insights: not waiting for requests; finding patterns that drive impact
 * Excellent communicator, able to distill complexity into clear stories that drive action
 * Bonus: experience with DBT and Fintech products
   
   

Why join Pinwheel?

Best time to join - Our company is small but well-funded, meaning you are joining at a time where you can impact and shape the company.

Be a cultural builder - You will have an active hand in molding the company culture and being a part of the entrepreneurial journey.

Build something revolutionary - Help build the products on the bleeding edge of financial services!

Belong - Join a community that is passionate and relentless about building fairer financial systems for all.

Benefits included:


 * Great compensation & equity packages
 * Full medical, dental, and vision benefits
 * Life & short-term disability insurance
 * Unlimited vacation
 * Paid parental leave
 * 401K for retirement planning
 * Mentorship opportunities
 * Free Citibike membership
 * Pet friendly offices and Zoom spaces
   
   

At Pinwheel, total compensation is made up of salary + equity + benefits. We recruit motivated and high performing talent, and work to compensate people in line with the value they can bring to the organization in delivering outsized results. The talent market is competitive, and maintaining our ability to recruit and retain the best team possible is a top priority for Pinwheel. When creating an offer, we consider interview performance, candidate experience, external market competitiveness, and internal equity in thoughtfully assessing compensation. The expected cash salary range for this role is $140,000 - $168,000 base.

Diversity & Inclusion at Pinwheel

At Pinwheel, we are committed to building an environment that is diverse and inclusive. We believe that having people across different backgrounds, experiences, abilities, and perspectives enables us not only to build the best financial products, but to help us realize the best versions of ourselves. Pinwheel is an equal opportunity employer, and we aim to be an open and supportive place to work.","Be among the first 25 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Construction, Software Development, and IT Services and IT Consulting","$140,000.00/yr - $168,000.00/yr","","","30603674","https://www.linkedin.com/jobs/view/product-analytics-manager-looker-at-pinwheel-4339012846?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist","Austin, TX","1 week ago","2025-11-22","https://www.linkedin.com/jobs/view/data-scientist-at-thomson-reuters-4333249791?trk=public_jobs_topcard-title","Thomson Reuters","https://ca.linkedin.com/company/thomson-reuters?trk=public_jobs_topcard-org-name","About the role:

The Data Scientist will be responsible for managing, understanding and analyzing in-house and customer data – including text mining, developing predictive systems, risk scoring, creating efficient algorithms, data quality improvement and other related activities. This individual will work closely with the TRSS Analysts to drive, identify, evaluate, design and implement statistical analyses of gathered open source, proprietary, and customer data to create analytic metrics and tools to support TRSS analysts, customers and existing product offerings.

Successful candidates will have the opportunity to contribute directly to the features and capabilities deployed in our applications. They will work with customers to assist in gathering requirements and contributing to Statements of Work (SOWs) for new sales or POCs and executing design post sale while getting deeply involved into the delivery of the proposed solutions. The role will interface with the customer and provide continuity of technical and data-exploration expertise to ensure we are delivering a workable solution that meets the customer requirements and technical capabilities. The position requires a proactive, mission-oriented person who strives to produce the best possible work for the customer.

Job Description

Define, manipulate, aggregate and use both structured and unstructured “big data” in order to support

descriptive and predictive analytics across the businesses.


 * Collaborate with scientists, product groups and content groups to perform “big data” aggregations, symbology mapping, and manipulations of important data-sets
 * Perform statistical (and machine learned) analyses on data to serve business purposes
 * Narrate stories (sometimes to a non-technical audience) about our content and processes by data analysis and visualization
 * Define and develop software for the analysis and manipulation of large and very large data-sets
 * Guide the architecture of “big-data” business processes with an eye towards robustness, parsimony and reproducibility (at senior levels)
   
   
   

Additional Information

Are you passionate about the chance to bring your data quality improvement experience to a world class organization that is leading the way in both content and technology to serve and protect our citizens home and abroad? Do you have the skills necessary to manage, understand, and analyze inhouse

and customer data including text mining, developing predictive systems, risk scoring, creating efficient algorithms, data quality improvement and other related activities? Then Thomson Reuters Special Services (TRSS) is looking for you!

What You’ll Do: As a Data Scientist, you will be responsible for driving, identify, evaluate, design and implement statistical analyses of gathered open source, proprietary, and customer data to create analytic metrics and tools to support TRSS analysts, customers and existing product offerings. Successful

candidates will have the opportunity to contribute directly to the features and capabilities deployed in our applications. They will work with customers to assist in gathering requirements and contributing to Statements of Work (SOWs) for new sales or POCs, and executing design post sale while getting deeply

involved into the delivery of the proposed solutions. The role will interface with the customer and provide continuity of technical and data-exploration expertise to ensure we are delivering a workable solution that meets the customer requirements and technical capabilities. The position requires a proactive, mission-oriented person who strives to produce the best possible work for the customer.

As the Data Scientist, you will also contribute to a variety of areas including:


 * Working with interdisciplinary engineering and research teams on designing, building and deploying data analysis systems for large data sets.
 * Working closely with customers to apply data science to their mission specific content.
 * Creating algorithms to extract information from large data sets.
 * Establishment of scalable, efficient, automated processes for model development, model validation, model implementation, and large-scale data analysis.
 * Development of metrics and prototypes that can be used to drive business decisions.
 * Providing thought-leadership and dependable execution on diverse projects.
 * Identification of emergent trends and opportunities for future client growth and development.
 * Researching and identifying Artificial Intelligence (AI) methods – including Machine Learning (ML) and Natural Language Processing (NLP) methods.
 * Identification of new applications of AI in the context of Thomson Reuters and TRSS content sets.
 * Exploring existing data for insights, and recommends additional sources of data for improvement.
   
   
   

About You:

You’re a good fit for the role of Data Scientist if you have:


 * A bachelor’s or master’s degree in a quantitative field (e.g., statistics, computer science, mathematics physical/biological sciences, or GIS).
 * 3-5 years of experience with data cleaning, analysis, programming, and reporting of results to internal or external stakeholders (education can substitute for some years of experience)
 * Programming skills in one or more major programming languages (Python/R/Java).
 * Are creative, intellectually curious, and willing to experiment and work in dynamic organizations and situations, sometimes with little oversight or well-defined requirements.
 * The ability to take ownership for defined areas of accountability, most critically the integrity of the technical and data design in terms of meeting customer needs, design delivery and supportability.
 * A good understanding of distributed computing concepts.
 * Experience facilitating and gathering input from subject matter experts.
 * Excellent understanding of ML, NLP, and statistical methodologies.
 * The ability to test ideas and adapt methods quickly end to end from data extraction to implementation and validation.
 * Strong planning, time management, and organizational skills.
 * A team player / self-starter mentality with the ability to work using own initiative.
 * Ability to obtain and maintain a U.S. national security clearance.
   
   
   

Additional Desired Skills:


 * Big Data analytics experience (preferred, but not required).
 * Previous experience with data modeling for graphs (preferred, but not required).
 * Experience with search engines, classification algorithms, recommendation systems, and relevance evaluation methodologies (preferred, but not required).
   
   
   

What’s in it For You?


 * Hybrid Work Model: We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected.
 * Flexibility & Work-Life Balance: Flex My Way is a set of supportive workplace policies designed to help manage personal and professional responsibilities, whether caring for family, giving back to the community, or finding time to refresh and reset. This builds upon our flexible work arrangements, including work from anywhere for up to 8 weeks per year, empowering employees to achieve a better work-life balance.
 * Career Development and Growth: By fostering a culture of continuous learning and skill development, we prepare our talent to tackle tomorrow’s challenges and deliver real-world solutions. Our Grow My Way programming and skills-first approach ensures you have the tools and knowledge to grow, lead, and thrive in an AI-enabled future.
 * Industry Competitive Benefits: We offer comprehensive benefit plans to include flexible vacation, two company-wide Mental Health Days off, access to the Headspace app, retirement savings, tuition reimbursement, employee incentive programs, and resources for mental, physical, and financial wellbeing.
 * Culture: Globally recognized, award-winning reputation for inclusion and belonging, flexibility, work-life balance, and more. We live by our values: Obsess over our Customers, Compete to Win, Challenge (Y)our Thinking, Act Fast / Learn Fast, and Stronger Together.
 * Social Impact: Make an impact in your community with our Social Impact Institute. We offer employees two paid volunteer days off annually and opportunities to get involved with pro-bono consulting projects and Environmental, Social, and Governance (ESG) initiatives.
 * Making a Real-World Impact: We are one of the few companies globally that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world.
   
   
   

In the United States, Thomson Reuters offers a comprehensive benefits package to our employees. Our benefit package includes market competitive health, dental, vision, disability, and life insurance programs, as well as a competitive 401k plan with company match. In addition, Thomson Reuters offers market leading work life benefits with competitive vacation, sick and safe paid time off, paid holidays (including two company mental health days off), parental leave, sabbatical leave. These benefits meet or exceeds the requirements of paid time off in accordance with any applicable state or municipal laws. Finally, Thomson Reuters offers the following additional benefits: optional hospital, accident and sickness insurance paid 100% by the employee; optional life and AD&D insurance paid 100% by the employee; Flexible Spending and Health Savings Accounts; fitness reimbursement; access to Employee Assistance Program; Group Legal Identity Theft Protection benefit paid 100% by employee; access to 529 Plan; commuter benefits; Adoption & Surrogacy Assistance; Tuition Reimbursement; and access to Employee Stock Purchase Plan.

Thomson Reuters complies with local laws that require upfront disclosure of the expected pay range for a position. The base compensation range varies across locations.

Eligible office location(s) for this role include one or more of the following: New York City, San Francisco, Los Angeles, and/or Irvine, CA; McLean, VA; Washington, DC. The base compensation range for the role in any of those locations is $101,640 - $188,760.

For any eligible US locations, unless otherwise noted, the base compensation range for this role is $88,200 - $163,800.

This role may also be eligible for an Annual Bonus based on a combination of enterprise and individual performance.

Base pay is positioned within the range based on several factors including an individual’s knowledge, skills and experience with consideration given to internal equity. Base pay is one part of a comprehensive Total Reward program which also includes flexible and supportive benefits and other wellbeing programs.

About Us

Thomson Reuters informs the way forward by bringing together the trusted content and technology that people and organizations need to make the right decisions. We serve professionals across legal, tax, accounting, compliance, government, and media. Our products combine highly specialized software and insights to empower professionals with the data, intelligence, and solutions needed to make informed decisions, and to help institutions in their pursuit of justice, truth, and transparency. Reuters, part of Thomson Reuters, is a world leading provider of trusted journalism and news.

We are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments. At a time when objectivity, accuracy, fairness, and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward.

As a global business, we rely on the unique backgrounds, perspectives, and experiences of all employees to deliver on our business goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity Employer providing a drug-free workplace.

Thomson Reuters makes reasonable accommodations for applicants with disabilities, including veterans with disabilities, and for sincerely held religious beliefs in accordance with applicable law. If you reside in the United States and require an accommodation in the recruiting process, you may contact our Human Resources Department at HR.Leave-Expert@thomsonreuters.com. Disability accommodations in the recruiting process may include things like a sign language interpreter, making interview rooms accessible, providing assistive technology, or other relevant accommodations. Please note this email is not intended for general recruitment questions and we will promptly respond to inquiries regarding accommodations. More information on requesting an accommodation here.

Learn more on how to protect yourself from fraudulent job postings here.

More information about Thomson Reuters can be found on thomsonreuters.com.

","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Financial Services, Legal Services, and IT Services and IT Consulting","$88,200.00/yr - $188,760.00/yr","","","1400","https://careers.thomsonreuters.com/us/en/job/THTTRUUSJREQ195732EXTERNALENUS/Data-Scientist?utm_source=linkedin&utm_medium=phenom-feeds","EXTERNAL",""
"Data Engineer, Platform","New York, NY","1 week ago","2025-11-24","https://www.linkedin.com/jobs/view/data-engineer-platform-at-basis-research-institute-4338467282?trk=public_jobs_topcard-title","Basis Research Institute","https://www.linkedin.com/company/basis-ri?trk=public_jobs_topcard-org-name","About Basis

Basis is a nonprofit applied AI research organization with two mutually reinforcing goals.

The first is to understand and build intelligence. This means to establish the mathematical principles of what it means to reason, to learn, to make decisions, to understand, and to explain; and to construct software that implements these principles.

The second is to advance society’s ability to solve intractable problems. This means expanding the scale, complexity, and breadth of problems that we can solve today, and even more importantly, accelerating our ability to solve problems in the future.

To achieve these goals, we’re building both a new technological foundation that draws inspiration from how humans reason, and a new kind of collaborative organization that puts human values first.

About The Role

Data Engineers on the Platform team at Basis build trustworthy data pipelines with comprehensive provenance and quality gates, curate documented datasets for training and evaluation, and ensure data infrastructure scales reliably. You will work on both platform-specific data needs and cross-project data coordination, preventing duplicate work and facilitating shared datasets.

We are looking for people who are technically excellent and treat data quality as a first-class concern. The ideal Data Engineer has experience with ML data pipelines, understands the full lifecycle from raw data through model training and evaluation, and brings rigor to data provenance, lineage tracking, and quality assurance. You combine software engineering discipline with deep understanding of data systems and ML requirements.

This role is embedded across Platform and Research teams, working on infrastructure that supports both commercial offerings and internal research. You will help Basis scale data operations to support medium-scale models, ensure data governance as we serve external customers, and build systems that researchers can trust for reproducible experiments.

We seek individuals who aspire to do rigorous, high-quality, robust data engineering, but are not afraid to iterate, learn from real usage, and explore different approaches to achieve excellence.

Basis is a collaborative effort, both internally and with our external partners; we are looking for people who enjoy building data foundations for problems larger than ones they can tackle alone.

We expect you to:


 * Have demonstrated significant achievements in data engineering for ML/AI systems. Examples include:
    * Building data pipelines for model training or evaluation at scale
    * Developing feature stores or data platforms serving multiple teams
    * Creating data quality frameworks and implementing governance systems
    * Designing data architectures that enabled new ML capabilities

 * Possess strong proficiency in data technologies including SQL (expert level), Python for data processing, distributed computing frameworks (Spark, Dask), and workflow orchestration tools (Airflow, Dagster, Prefect).
 * Have experience with cloud data platforms including data warehouses (Snowflake, BigQuery, Redshift), data lakes, object storage (S3), and streaming systems (Kafka, Kinesis, Flink) for both batch and real-time processing.
 * Understand ML data requirements including feature engineering, training/validation/test splits, data versioning, experiment reproducibility, and the specific data needs of different model types and training procedures.
 * Be skilled at data quality and governance including implementing validation frameworks, anomaly detection, data lineage tracking, metadata management, and ensuring compliance with privacy and security policies.
 * Have knowledge of data modeling principles for both relational and NoSQL systems, understanding of schema design, normalization/denormalization tradeoffs, and performance optimization.
 * Value data provenance and documentation. You ensure data pipelines are transparent, decisions are documented, and others can understand and trust the data you deliver.
 * Progress with autonomy on complex data challenges. You can scope data projects, make sound architectural decisions, and deliver complete solutions from ingestion through consumption.
 * Be excited about enabling rigorous research through trustworthy data infrastructure that advances our ability to solve intractable problems.
   
   

In addition, the following would be an advantage:


 * Experience with feature stores (Tecton, Feast) or building feature platforms.
 * Background in ML research or research engineering providing understanding of data needs across experiment lifecycle.
 * Experience with data lineage tools (Apache Atlas, DataHub, Monte Carlo) and metadata management.
 * Knowledge of vector databases and embedding pipelines for modern AI applications.
 * Contributions to data engineering open-source projects (Airflow, dbt, Great Expectations).
 * Understanding of responsible AI and data governance practices.
   
   

Responsibilities:


 * Design and build data pipelines for training and evaluation across Basis research projects and platform offerings, ensuring reliability, performance, and scalability.
 * Implement data quality frameworks including validation rules, quality gates, anomaly detection, and monitoring that catch data issues before they impact research or production systems.
 * Develop and maintain feature stores or equivalent systems that enable consistent feature access across training and serving environments, preventing train-serve skew.
 * Ensure data provenance and lineage tracking so researchers and engineers can understand data origins, transformations applied, and dependencies, enabling reproducible experiments and debugging.
 * Curate documented datasets for model training and evaluation, including dataset versioning, comprehensive documentation, quality metrics, and metadata that enables appropriate usage.
 * Coordinate cross-project data initiatives to prevent duplicate data work, facilitate shared datasets, and ensure consistent data practices across Basis as the organization scales.
 * Optimize data infrastructure for scale as compute grows, including cost optimization, performance tuning, caching strategies, and efficient data access patterns.
 * Collaborate with research and engineering teams to understand data needs, translate requirements into technical solutions, and provide consultation on data architecture and best practices.
 * Implement data governance policies ensuring compliance with privacy regulations, security requirements, and responsible AI practices as Basis serves external customers.
 * Contribute to the culture and direction of Basis by modeling data quality rigor, documentation excellence, and focus on trustworthy data infrastructure.
   
   

Role Details

Exceptional candidates who may not meet all of the following criteria are still encouraged to apply.


 * FT/PT: Full-time.
 * In-person Policy: We are in the office four days a week. Be prepared to attend multi-day Basis-wide in-person events.
 * Location: New York City.
 * Salary range: Competitive salary.
   
   

Privacy Notice

By submitting your application, you grant Basis permission to use your materials for both hiring evaluation and recruitment-related research and development purposes. Your information may be processed in different countries, including the US. You retain copyright while providing Basis a license to use these materials for the stated purposes.

Read our full Global Data Privacy Notice here.

","Over 200 applicants","Full-time","Entry level","Information Technology","Non-profit Organizations","","","","81946321","https://www.linkedin.com/jobs/view/data-engineer-platform-at-basis-research-institute-4338467282?trk=public_jobs_topcard-title","EASY_APPLY",""
"Machine Learning Engineer","Tampa, FL","1 month ago","2025-10-31","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-cti-4338930972?trk=public_jobs_topcard-title","CTI","https://www.linkedin.com/company/ctitech?trk=public_jobs_topcard-org-name","Who we are

CTI, a Parsons Company is a high-tech software, systems engineering, and operational support corporation dedicated to providing cutting-edge engineering, and system development and support. We provide operationally-focused technology solutions for military and security applications. A veteran-owned company, CTI is committed to developing the next generation of advanced technologies in a friendly, product, and customer-focused environment. CTI specializes in developing software solutions that enable the collection, aggregation, transport, and visualization of highly complex data sets in a meaningful context to the warfighter.

We are seeking a Machine Learning Engineer (MLOps focus) who will be a key technical contributor in advancing CTI’s artificial intelligence and machine learning capabilities. This role supports United States Special Operations Command (SOCOM) programs and other advanced defense initiatives by ensuring that ML models are not only trained effectively, but also deployed, monitored, and sustained in real-world operational environments, including edge-deployed systems. We’re seeking a Machine Learning Engineer with deep expertise in MLOps, model deployment, and infrastructure automation to build scalable, secure, and production-grade ML systems. The successful candidate will be passionate about building and automating ML pipelines, implementing modern MLOps practices, and driving innovation that directly impacts mission outcomes. With hands-on experience taking ML models from concept to production deployment, this engineer will help CTI deliver highly reliable, scalable, and mission-ready ML solutions to the battlefield.

Responsibilities Include, But Are Not Limited To


 * Operationalize ML models by building robust pipelines for training, evaluation, deployment, and monitoring across diverse compute environments (cloud, on-prem, and edge).
 * Collaborate with cross-functional teams to translate mission requirements into deployable ML systems.
 * Implement CI/CD for ML workflows, enabling automated testing, packaging, and deployment of models and data pipelines
 * Manage ML infrastructure using Docker, Kubernetes, and model serving platforms like Seldon, KServe, or BentoML
 * Develop monitoring and observability systems to track model performance, data drift, and resource utilization using tools like Prometheus, Grafana, and ELK/EFK stacks
 * Contribute to security and compliance in ML pipelines, ensuring model deployments meet defense and customer requirements.
 * Explore and integrate modern MLOps technologies to improve reproducibility, scalability, and maintainability of ML capabilities.
   
   

Requirements

Location: This is a fully onsite position based at MacDill Air Force Base in Tampa, Florida. Remote work is not available for this role.

Travel requirements: Willingness and ability to travel up to 25%.

Necessary Skills And Experience


 * Bachelor’s degree in Computer Science, Electrical Engineering, Data Science, or a related technical discipline. (Master’s preferred)
 * 5+ years of professional experience in software engineering, machine learning, or related fields.
 * Experience with MLOps tools and frameworks (MLflow, Kubeflow, Airflow, DVC, etc.).
 * Proficiency in building and deploying containerized ML services (Docker, Kubernetes).
 * Strong understanding of CI/CD pipelines and DevOps practices applied to ML.
 * Familiarity with PyTorch, TensorFlow, and deployment best practices.
 * Knowledge of monitoring and logging systems (Prometheus, Grafana, ELK/EFK stacks).
 * Proficiency in Python (C, Rust, or MATLAB a plus).
 * Active U.S. Government Top Secret clearance with SCI eligibility (TS/SCI).
 * U.S. Citizenship is required as only U.S. citizens are eligible for a security clearance.
   
   

Beneficial Skills And Experience


 * Prior work on DoD programs, UAS/drone systems, or defense AI applications.
 * Experience working with diverse data types (RF signals, imagery, video, sensor feeds).
 * Experience deploying ML models to edge or constrained environments.
 * Familiarity with secure software deployment in defense environments.
 * Experience with air-gapped registries, offline updates, reproducible builds, and SBOM attestation in CI.
 * Experience with Explainable AI/ML.
   
   

Benefits

CTI is a rapidly growing company offering the following:


 * Medical, dental and vision insurance
 * H.S.A. (partially funded by CTI) and Flex Spending
 * Company-paid life insurance/AD&D and disability insurance
 * Optional supplemental life, critical illness, hospital indemnity and accident insurances
 * Paid vacation, sick leave and holidays
 * 401k plan with Safe Harbor contribution
 * Tuition reimbursement/professional training options
 * Employee Assistance Program
 * Travel Assistance
 * Financial Planning Assistance
 * Voluntary Pre-Paid Legal
 * Flexible schedules with telecommuting options
 * Service awards program
   
   

CTI is an Equal Opportunity employer and shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status.","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering","Construction, Software Development, and IT Services and IT Consulting","","","","293578","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-cti-4338930972?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Savannah, GA","2 weeks ago","2025-11-14","https://www.linkedin.com/jobs/view/data-engineer-at-colonial-group-inc-4333270224?trk=public_jobs_topcard-title","Colonial Group, Inc.","https://www.linkedin.com/company/colonial-group-inc.?trk=public_jobs_topcard-org-name","Colonial Group, Inc. is a multigenerational, family-owned parent company overseeing a diverse portfolio of subsidiaries. Through our strategic infrastructure, logistics expertise, and a broad range of products and services, we create significant value for our customers while driving innovation and operational excellence.

We are seeking a highly skilled and motivated Data Engineer to join our growing data team. The ideal candidate will have deep expertise in SQL Server Database Administration, Databricks, Microsoft Fabric, and enterprise data architecture. You will play a key role in designing, building, and maintaining scalable data solutions that support business intelligence, analytics, and operational reporting across the organization.

Key Responsibilities


 * Design, implement, and maintain robust data pipelines using Databricks and Microsoft Fabric.
 * Serve as the SQL Server DBA, managing performance tuning, backups, security, and high availability.
 * Develop and maintain data models, data lakes, and data warehouses to support analytics and reporting needs.
 * Collaborate with data architects and business stakeholders to define and implement scalable data architecture solutions.
 * Ensure data quality, integrity, and governance across all data platforms.
 * Automate data workflows and optimize ETL/ELT processes for performance and reliability.
 * Monitor and troubleshoot data systems, ensuring uptime and data accuracy.
 * Stay current with emerging technologies and best practices in data engineering and architecture.
   
   

Required Skills & Qualifications


 * Proven experience as a SQL Server DBA (administration, tuning, security, and disaster recovery).
 * Hands-on experience with Databricks (Spark, Delta Lake, notebooks, and pipelines).
 * Proficiency with Microsoft Fabric and its components (Data Factory, Synapse, Power BI integration).
 * Strong understanding of data architecture principles, including data modeling, warehousing, and lakehouse design.
 * Proficient in SQL, Python, and/or Scala for data processing.
 * Experience with cloud platforms (Azure preferred).
 * Familiarity with CI/CD pipelines and DevOps practices for data engineering.
 * Excellent problem-solving and communication skills.
   
   

Preferred Qualifications


 * Microsoft certifications (e.g., Azure Data Engineer Associate, SQL Server).
 * Experience with data governance tools and frameworks.
 * Knowledge of data security and compliance standards (e.g., GDPR, HIPAA).
   
   

Physical Requirements

Job conditions require standing, walking, sitting, twisting, stooping, crouching, kneeling, lifting or carryings, pushing or pulling up to 50 lbs., climbing up to 15ft, working in confined spaces, talking or hearing, making visual inspections, making precise hand and finger movements, reaching or grasping; perceiving color differences; ability to wear personal protective equipment.

Eligibility Requirements: Hiring is contingent upon eligibility to work in the United States.

Colonial Group, Inc. is committed to creating an environment that values and supports diversity and inclusiveness across our organizations. We encourage applications from qualified individuals who will help us achieve this mission. Colonial Group, Inc. prohibits discrimination of and will receive consideration for employment without regard to race, color, religion, sex, age, sexual orientation, gender identity, religion, national origin, disability, veteran status, or other legally protected status.","Over 200 applicants","Full-time","Entry level","Information Technology","Oil and Gas","","","","113373","https://www.linkedin.com/jobs/view/data-engineer-at-colonial-group-inc-4333270224?trk=public_jobs_topcard-title","EASY_APPLY",""
"AWS Data Engineer - Remote","New Jersey, United States","1 month ago","2025-10-27","https://www.linkedin.com/jobs/view/aws-data-engineer-remote-at-the-dignify-solutions-llc-4341985688?trk=public_jobs_topcard-title","The Dignify Solutions, LLC","https://www.linkedin.com/company/dignify-solutions?trk=public_jobs_topcard-org-name","AWS data Engineer

Remote

12 month contract. This can be extended depending on the work load.


 * Location - Remote , but candidates from US/Central timezone preferred
   
   

The ideal candidate will have expert knowledge of Python and SQL and demonstrable experience developing cloud-based data pipelines. Experience with our specific stack including AWS services (S3, EC2, Lambda, SNS, Datapipeline), Linux/Unix, Snowflake, and Tableau is a plus.

Responsibilities:


 * Create AWS data pipelines, build data models and test/deploy code
 * Work with a variety of APIs to create ETL workflows.
 * Ensure that we meet delivery SLAs and adhere to Agile principles.
 * Develop a deep understanding of SVOD/AVOD business data model.
 * Create Snowflake objects, stored procedures, and tasks for modifying and storing data
 * Identify areas of improvement and optimize data storage, processing, and utilization of cloud resources
   
   

Requirements:


 * Undergrad or higher degree in a field such as computer science, software engineering, or equivalent
 * 3+ years experience of hands on as a data engineering
 * 3+ years experience with Python and SQL
 * 2+ years experience in AWS
 * Experience working with large data sets
 * Experience working with Business Intelligence tools
 * Excellent written and oral communication skills
 * Must be a detail-oriented self-starter, able to work independently as well as in a team environment
   
   

Primary Skill:

Application Development, Graphic Design, IDX, Lighting","Be among the first 25 applicants","Full-time","Mid-Senior level","Other","IT Services and IT Consulting","","","","75031133","https://www.linkedin.com/jobs/view/aws-data-engineer-remote-at-the-dignify-solutions-llc-4341985688?trk=public_jobs_topcard-title","EASY_APPLY",""
"Business Intelligence Analyst","Birmingham, AL","1 week ago","2025-11-18","https://www.linkedin.com/jobs/view/business-intelligence-analyst-at-landing-4336121126?trk=public_jobs_topcard-title","Landing","https://www.linkedin.com/company/hellolanding?trk=public_jobs_topcard-org-name","We make living flexible for everyone.

We are a data-driven company seeking an experienced Business Intelligence Senior Analyst (BI) to join our team. This role is pivotal in shaping and executing our company-wide BI strategy, directly impacting our long-term success by enabling data-driven decision-making across all functions. In this position, you will lead the creation of end-to-end data products for Landing, manage data from multiple sources, and develop flexible, clean data models that support strategic insights and guide our vision.

Our ideal candidate embodies our Landing Leadership principles: They are hands-on, passionate about auditing data at the source, simplifying complex issues, and focusing on details that drive customer-centric outcomes. They have a radical long-term mindset, ensuring that our BI initiatives are scalable, sustainable, and aligned with the company’s future growth.

About the Role:

Landing is seeking a motivated data enthusiast to join our Business Intelligence team and help bring visibility and actionable insights to the business. This is a highly cross-functional role where you will help drive the data agenda throughout all departments in order to solve critical business challenges. Landing employees depend on data to make effective decisions - over 3000 data queries are run each day! This role reports directly to the Head of Data and Strategy.

What You'll Do:


 * Architect data models to provide visibility and self-service analytics for the business
 * Help manage team priorities, ensuring that our time is spent on the highest impact projects
 * Become a subject matter expert of Landing’s data to ensure accurate and proper interpretation of core business metrics
 * Act as a trusted partner for stakeholders, helping guide decision making and strategy
 * Perform ad-hoc analysis and present recommended actions to improve company performance
 * Create insightful dashboards for the business via our Looker platform
 * Automate manual reporting processes to make the organization more productive
 * Execute light advanced analytics techniques including regressions and segmentations
 * Help deepen our supply and corporate demand partnerships through data insight and storytelling
   
   

What You'll Need:


 * 3-5 years in Business Intelligence, Analytics Engineering, Data Product, or similar
 * Ability to work successfully in a remote role, or in our Birmingham, AL office
 * Strong SQL skills, experience building ETL processes and architecting data models
 * Experience creating data visualizations in Looker (preferred), Tableau, or a similar
 * A strong business acumen with the ability to apply data skills to solve business problems
 * Comfort in managing multiple projects and stakeholders, as well as changing priorities
 * Experience with Snowflake or a similar data warehouse (Redshift, GBQ, or Vertica) is a plus
 * Familiarity applying statistics and advanced analytic methods (e.g. regression, cluster analysis)
 * Alignment with Landing’s Leadership Principles
 * Experience with Sigma
   
   

Benefits & Perks:

Landing aims to create a workplace that fosters both personal and professional growth. We offer a competitive benefits package we are proud to share with you!


 * Solid compensation package + stock options
 * Comprehensive benefits - Medical, Dental, Vision, Life and AD&D, Disability, Mental Health, Pet, Commuter, and FSA or HSA
 * We’ve got you covered with a 401(k) plan and access to ImmediatePay
 * Feel relaxed with super generous PTO policy
 * Opportunities for upward mobility - we want you to grow with us!
 * Explore and travel comfortably with 7 free nights in a Landing home per year
 * Employee perks for temporary or indefinite stays when you choose to live with Landing
   
   

Landing provides equal opportunities for everyone that works for us and everyone that applies to join our team, without regard to sex or gender, gender identity, gender expression, age, race, religious creed, color, national origin, ancestry, pregnancy, physical or mental disability, medical condition, genetic information, marital status, sexual orientation, any service, past, present, or future, in the uniformed services of the United States (military or veteran status), or any other consideration protected by federal, state, or local law. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.","Over 200 applicants","Full-time","Mid-Senior level","Sales, General Business, and Education","Wireless Services, Telecommunications, and Communications Equipment Manufacturing","","","","51661738","https://www.linkedin.com/jobs/view/business-intelligence-analyst-at-landing-4336121126?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist - Agentic AI Systems - The Loops","San Francisco, CA","1 month ago","2025-10-24","https://www.linkedin.com/jobs/view/data-scientist-agentic-ai-systems-the-loops-at-ifs-4336639240?trk=public_jobs_topcard-title","IFS","https://se.linkedin.com/company/ifs?trk=public_jobs_topcard-org-name","TheLoops, an IFS company, is the first enterprise-grade AI Agent platform built for mission-critical applications and industries. Our AI Agents act as digital coworkers that are governed, secure, always learning, and working 24/7 to drive measurable business outcomes.

As we grow, we’re looking for driven, collaborative and ambitious individuals to help us deliver the future of AI-powered operations

By joining our team, you will have the opportunity to be part of a global, diverse environment; you will be joining a winning team with a commitment to sustainability; and a company where we get things done so that you can make a positive impact on the world.

We’re looking for innovative and original thinkers to work in an environment where you can #MakeYourMoment so that we can help others make theirs. With the power of our AI-driven solutions, we empower our team to change the status quo and make a real difference.

If you want to change the status quo, we’ll help you make your moment. Join Team Purple. Join IFS.

Job Description

We’re seeking a Data Scientist with a strong research mindset to help shape the future of agentic AI systems. This role blends deep analytical thinking with fast-paced experimentation and model development, where your insights will directly inform how AI agents reason, plan, and act in dynamic environments.

You’ll work on a cross-functional team exploring how AI agents learn from real-world data, adapt to user intent, and interact autonomously—or collaboratively—with users and systems. If you’re a self-starter who thrives on ambiguity, builds fast, and can bridge theory with practical outcomes, this role is for you.

Responsibilities


 * Design and run applied research initiatives that inform the behavior and learning loops of AI agents
 * Build and evaluate models for planning, memory, retrieval, reasoning, or tool use in agentic systems
 * Develop internal tools and pipelines to test agent behavior across different environments
 * Analyze structured and unstructured data from user-agent interactions, logs, and experiments
 * Rapidly prototype and test hypotheses to improve agent performance and reliability
 * Collaborate with engineering, product, and design to translate insights into deployable features
 * Communicate findings clearly and concisely to both technical and non-technical audiences
   
   

Qualifications

Minimum Qualifications


 * Masters or PhD in Computer Science, Applied Math, Statistics, or related quantitative field
 * 4+ years of experience in data science, applied ML, or AI research
 * Strong Python and SQL skills; experience with libraries like scikit-learn, PyTorch, LangChain or any similar agentic framework
 * Familiarity with LLMs, retrieval-augmented generation (RAG), Reinforcement Learning, Fine-Tuning
 * Comfort with ambiguity, fast iteration cycles, and self-directed research
 * Excellent communication and storytelling skills — you can explain complex models to others clearly
   
   

Preferred Qualifications


 * Experience working with agent frameworks (AutoGen, OpenAgents, LangGraph, etc.)
 * Background in decision-making models, memory systems, or multi-agent coordination
 * Exposure to vector databases, embeddings, and custom RAG pipelines
 * Experience building evaluation frameworks or simulators for agent performance
 * Experience with LLM Post Training – SFT, DPO, RLHF, GRPO
   
   

Who You Are


 * Curious – You explore the edges of what’s possible with AI agents
 * Action-biased – You ship prototypes quickly and iterate based on evidence
 * Scientific – You bring structure to messy problems and back claims with data
 * Independent – You operate autonomously and drive projects end-to-end
 * Collaborative – You thrive in cross-functional teams and open discussion
   
   

Additional Information

What We’re Offering


 * Salary Range: $240,000-280,000 + bonus
 * Flexible paid time off, including sick and holiday
 * Medical, dental, & vision insurance
 * 401K with Company contribution
 * Flexible spending accounts
 * Life insurance and disability benefits
 * Tuition assistance
 * Community involvement and volunteering events
   
   

M/F/Disabled/Vet VEVRAA Federal Contractor. We are a Drug-Free Workplace. Interested candidates should apply at: www.ifs.com/about/careers-at-ifs

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. VEVRAA Federal Contractor, Equal Opportunity Employer","Be among the first 25 applicants","Full-time","Mid-Senior level","Production, Distribution, and Engineering","Software Development and IT Services and IT Consulting","$240,000.00/yr - $280,000.00/yr","","","164301","https://www.linkedin.com/jobs/view/data-scientist-agentic-ai-systems-the-loops-at-ifs-4336639240?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Columbus, OH","3 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/data-engineer-at-covermymeds-4335490532?trk=public_jobs_topcard-title","CoverMyMeds","https://www.linkedin.com/company/covermymeds?trk=public_jobs_topcard-org-name","McKesson is an impact-driven, Fortune 10 company that touches virtually every aspect of healthcare. We are known for delivering insights, products, and services that make quality care more accessible and affordable. Here, we focus on the health, happiness, and well-being of you and those we serve – we care.

What you do at McKesson matters. We foster a culture where you can grow, make an impact, and are empowered to bring new ideas. Together, we thrive as we shape the future of health for patients, our communities, and our people. If you want to be part of tomorrow’s health today, we want to hear from you.

CoverMyMeds’ Data & Analytics is looking for a Specialist, Data Engineering to join our Data Engineering team. Of note, our Data Engineering Team is a highly technical group of results driven Engineers, Analysts and Architects focused on providing our internal and external clients with high quality, repeatable and scalable data solutions. Together with our various business units, the work our Data Engineering team does ultimately helps get more people the medicine they need to live healthier lives. 

 

What You'll Do 

The Specialist, Data Engineering will support and expand the data platforms that process, store, organize the data critical for the Data and Analytics team. This role will participate in the technical strategy and execution to provide trusted, stable, reliable, responsive, and secure solutions and proactively inform business partners on Data & Analytics platform and product health, and problem resolution. The Specialist, Data Engineering will work collaboratively with our Data Systems Analysts as well as our Analytics and Technology partners to solve business problems and deliver solutions.

Position Description


 * Design and develop solutions and commissions of complex data across systems for McKesson/CoverMyMeds internal and external customers.
 * Develop Data Ingestion and Integration pipelines from various sources to Data Warehouse
 * Work with databases, files and unstructured data to identify, transport and quality test the data required to drive our data synchronization tasks to perform regular and incremental loads of data.
 * Write program/code in SQL and / or cloud based tools such as Snowflake or Databricks to cleanse, apply business logic and standardize the data according to business rules, enabling more effective data governance along with clear and efficient end-user reporting.
 * Design conceptual data model based on business reporting requirements, interacting with business partners to understand the business logic and end-use of the data.
 * Work with the application development teams to determine data flow in the source system and architect an appropriate flow into the data warehouse.
   
   

Minimum Qualifications

Degree or equivalent and typically requires 4+ years of relevant experience

Education


 * Bachelor's degree in. Computer Science, Information Systems, or related field.
   
   

Critical Skills


 * 4+ years of technical and professional experience as a data engineer
 * Strong (4+ years'), hands-on experience as a technologist working with data warehouse solutions, cloud technology, relational databases and dashboarding tools such as Databricks, Oracle, MySQL, Qlik, Tableau, SQL Server, etc. 
 * 4 years' experience working with structured and unstructured data and within batch and real-time data streaming environments.
 * Experience supporting Reporting and Analytics, Real time Analytics, Systems Integration, and Data Governance.
 * Demonstrated expertise in database design and modeling.
 * Expert knowledge of cloud data technologies (MS Azure)
 * Experience with business-critical applications.
 * Experience on large-scale implementation programs.
   
   

Preferred Skills


 * Excellent written and verbal communication skills; timely communication with clear expectations. An active listener and clear communicator; can lead by influence.
 * Ability to find creative solutions to complex problems.
 * Exhibit a strong sense of urgency and ownership for task/project completion.
 * Highly adept at working collaboratively across multiple business and technical functions to achieve results.
   
   

We are proud to offer a competitive compensation package at McKesson as part of our Total Rewards. This is determined by several factors, including performance, experience and skills, equity, regular job market evaluations, and geographical markets. The pay range shown below is aligned with McKesson's pay philosophy, and pay will always be compliant with any applicable regulations. In addition to base pay, other compensation, such as an annual bonus or long-term incentive opportunities may be offered. For more information regarding benefits at McKesson, please click here.

Our Base Pay Range for this position

$105,500 - $175,900

McKesson is an Equal Opportunity Employer

McKesson provides equal employment opportunities to applicants and employees and is committed to a diverse and inclusive environment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, age or genetic information. For additional information on McKesson’s full Equal Employment Opportunity policies, visit our Equal Employment Opportunity page.

Join us at McKesson!","Over 200 applicants","Full-time","Entry level","Information Technology","IT Services and IT Consulting","$105,500.00/yr - $175,900.00/yr","","","1741261","https://www.linkedin.com/jobs/view/data-engineer-at-covermymeds-4335490532?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr. Analytics Engineer (Amazon Marketplace)","San Diego, CA","2 weeks ago","2025-11-18","https://www.linkedin.com/jobs/view/sr-analytics-engineer-amazon-marketplace-at-luminize-4347015178?trk=public_jobs_topcard-title","Luminize","https://www.linkedin.com/company/luminize-marketing?trk=public_jobs_topcard-org-name"," Help Brands Win on Amazon - and Love Where You Work

 Role: eCommerce Sr Analytics Engineer
 Location: San Diego, CA 92101 (Onsite at Symphony Towers)
 Compensation Range: $120,000-$140,000 DOE

At Luminize, we help brands win, and as one of the top 5 Amazon sellers in the US, we're looking for top performers to grow with us.

Our people are the heartbeat of our success, and we're looking for a strategic and experienced Senior Analytics Engineer with deep ecommerce and financial data expertise to join our growing team. This role is perfect for a data-driven problem solver who thrives on building scalable pipelines for inventory management, financial reporting, and marketplace analytics, delivering actionable insights that directly impact profitability and operational efficiency.

We believe data is more than numbers - it's the story that drives smarter inventory decisions, financial performance, and meaningful client growth. Come help us tell that story.

 What You'll Be Doing
 * Build & Optimize – Design, develop, and manage advanced data pipelines for inventory  tracking,  financial reporting, and marketplace performance analytics for internal and client use.
 * Drive eCommerce Intelligence – Transform complex inventory data, advertising spend, and sales performance metrics into actionable insights that optimize stock levels, improve margins, and maximize  ROI.
 * Financial Data Mastery – Build comprehensive financial dashboards, interactive reports, and executive visualizations tracking COGS, profit margins, advertising efficiency (ACOS/TACOS), inventory turns, and Amazon selling metrics.
 * Inventory Analytics Leadership – Develop sophisticated models, visualizations, and automated  reports for demand forecasting, reorder point optimization, and trend analysis to prevent stockouts and overstock situations.
 * Champion eCommerce Data Governance – Develop and uphold data standards specifically for SKU management, financial reconciliation, and marketplace data integrity across the organization.
 * Mentor & Collaborate – Guide junior team members on ecommerce analytics best practices and foster a high-performing, collaborative environment.
 * Innovate & Communicate – Identify process improvements in inventory management and financial reporting workflows, stay current on eCommerce industry trends, and clearly present complex financial and operational concepts to all audiences.

 What We're Looking For
 * Education & Experience – Bachelor's or Master's degree in Computer Science, Engineering, Finance, or related field (or equivalent experience) with 5+ years specifically in ecommerce analytics/data engineering with inventory and financial data focus.
 * eCommerce Data Expertise – Proven experience working with marketplace data, inventory management systems, ERP integrations, and financial reporting platforms. Deep understanding of ecommerce KPIs, unit economics, and inventory metrics. Strong background in creating client-facing dashboards and executive reporting.
 * Financial Analytics Background – Strong experience with COGS tracking, margin optimization, advertising spend analysis, and financial reconciliation processes. Familiarity with accounting principles and financial statement analysis. Proven ability to translate financial data into clear visualizations and actionable reports.
 * Inventory Management Systems – Hands-on experience with inventory planning software, demand forecasting tools, warehouse management systems (WMS), and supply chain analytics. Understanding of inventory accounting methods and valuation. Experience building automated inventory reports and performance dashboards.
 * Visualization & Reporting Expertise – Strong proficiency in data visualization tools (Tableau, Power BI, Looker, or similar) with experience creating compelling dashboards, automated reports, and executive presentations that drive business decisions.
 * Technical Mastery – Expert in SQL and Python (or similar languages) for building scalable, efficient data solutions specifically for eCommerce and financial data pipelines.
 * dbt + BigQuery Expertise – Proven experience using dbt for transformations and deploying solutions on Google BigQuery or similar ( AWS or Azure).
 * Data Engineering Skills – Strong knowledge of data modeling, warehousing concepts, and ETL/ELT pipelines with specific experience in ecommerce data schemas, marketplace APIs, and financial data integration.
 * Modern Development Practices – Familiar with Git, version control, and Agile methodologies.
 * Leadership & Communication – Excellent at mentoring, presenting insights, and explaining complex concepts to technical and non-technical audiences, including C-level executives and brand managers.

 Benefits & Perks
Our people are our #1 priority. Our benefits include:
 * Multiple medical plan options through Anthem Blue Cross
 * Dental & vision insurance (including orthodontia and annual exams)
 * Pet benefit program with savings on vet care, products, and services
 * Paid vacation (accruing up to 120+ hours/year with rollover and cap)
 * Paid holidays annually
 * Coverage for spouses/domestic partners and dependents under 26
 * Benefits begin on the first of the month after your hire date

 Compensation Transparency
We've listed a broad base salary range of $120,000-$140,000/year to account for varying levels of experience, skill sets, and leadership depth in eCommerce and financial analytics. Where you land in the range will depend on how your background aligns with this role and your specific expertise.

We're committed to compensating based on value and impact, not just years on paper, and we're happy to have open conversations throughout the process.

 Growth & Career Opportunities at Luminize
At Luminize, growth isn't just something we drive for our clients; it's our mindset and a big priority for our people.

We offer clear career paths and leveling guidelines so you always know where you stand, what's next, and what skills and experience you need to get there. From day one, you'll have visibility into advancement opportunities and what it takes to grow into leadership, specialization, or other cross-functional roles.

We're proud of our strong track record of promoting from within. Many of our team leads and managers started in independent contributor roles and grew by consistently showing initiative, curiosity, and impact. We only hire externally when needed, because we believe the best future leaders are often already here.

You'll also benefit from:

 * Mentorship from experienced managers during 1:1s and annual performance reviews
 * Cross-functional exposure to departments including content, brand management, software, supply chain, operations, and catalog
 * Learning resources, including Udemy course access, and additional training programs and courses.
 * A culture that encourages asking questions, trying new things, and leveling up together

If you're excited to take ownership and grow, both in your craft and your career, you'll be in good company here.

 About Luminize
Luminize is a full-service Amazon growth partner helping brands achieve next-level success in a competitive digital marketplace. From creative strategy to advertising and analytics, we combine expertise and hustle to fuel results for brands in CPG, health, wellness, beauty, and Beyond.

We’re not your typical agency, and we like it that way. We operate with transparency, celebrate wins often, and treat every brand like it’s our own.

If you’re ready to work with great people, do work that matters, and keep growing, we’d love to meet you!
","Be among the first 25 applicants","Full-time","Mid-Senior level","Sales, General Business, and Education","Wireless Services, Telecommunications, and Communications Equipment Manufacturing","$120,000.00/yr - $140,000.00/yr","","","70392521","https://www.linkedin.com/jobs/view/sr-analytics-engineer-amazon-marketplace-at-luminize-4347015178?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr. Data Engineer I (6154)","Herndon, VA","3 weeks ago","2025-11-10","https://www.linkedin.com/jobs/view/sr-data-engineer-i-6154-at-metrostar-4339713196?trk=public_jobs_topcard-title","MetroStar","https://www.linkedin.com/company/metrostar-systems?trk=public_jobs_topcard-org-name","As a Sr. Data Engineer I, you’ll work with team members to build, deploy, and operate data pipelines and data engineering components to enable data brokering and exchange capabilities across a diverse range of producers and consumers. In this role, you will be responsible for building robust, scalable data pipelines while working collaboratively with cross-functional teams to ensure seamless integration, optimized performance, and efficient delivery of solutions.

What you’ll do: 

 * Work with team members to operationalize data pipelines and supporting cloud infrastructure
 * Collaborate with external data producers and consumers to obtain and provide data through interfaces such as REST APIs and S3
 * Provide day-to-day support of deploying Python-native data pipelines and performing data engineering tasks to enable data brokering and exchange capabilities
 * Provide Tier 2/3 troubleshooting and incident resolution support for data pipelines in Production

What you’ll need to succeed: 

 * Active TS/SCI with the ability to obtain and maintain a CI polygraph required
 * 4+ years of proven experience in data engineering, with expertise in designing, developing, and maintaining data ingestion, transformation, and loading pipelines and components
 * Demonstrated experience in designing and deploying data pipelines leveraging AWS cloud infrastructure across multiple classification domains (e.g., IL5 to IL6+)
 * Experience with Infrastructure-as-Code (IaC) tools, including Terraform, CloudFormation, or Ansible, to automate deployment of data pipeline cloud infrastructure
 * Understanding of RMF security principles and hands-on experience implementing security controls for data pipelines in cloud environments
 * Strong scripting and programming skills in languages such as Go, Python, and Bash
 * Experience with data pipeline tools and technologies such as Nifi, Hadoop, HDFS, and Kafka. Experience implementing data pipelines in the Cloudera Data Platform environment is highly preferred.
 * Strong communication skills, with the ability to clearly convey complex technical concepts

SALARY RANGE: $126,000 - $147,000

The salary range for this position is determined based on qualifications, skills, and relevant experience. The final salary offered will be determined based on several factors including: 

 * The candidate's professional background and relevant work experience
 * The specific responsibilities of the role and organizational needs
 * Internal equity and alignment with current team compensation
 * This role is also eligible for additional compensation, subject to the terms and policies of MetroStar, which may include:
    * Performance-based bonuses
    * Company-paid training and/or certifications
    * Referral bonuses

 

To apply for this position, please submit your resume via the form below or through our careers page: https://www.metrostar.com/jobs/

Application Deadline:  Applications will be accepted on a rolling basis until the position is filled; candidates are encouraged to apply as early as possible for full consideration.

Additional Compensation: This role may also be eligible for bonuses and/or additional incentives based on individual and company performance.

Benefits: All full-time employees are eligible to participate in our benefits programs:

 * Health, dental, and vision insurance
 * 401(k) retirement plan with company match
 * Paid time off (PTO) and holidays
 * Parental Leave and dependent care
 * Flexible work arrangements
 * Professional development opportunities
 * Employee assistance and wellness programs

Like we said, we are big fans of our people. That’s why we offer a generous benefits package, professional growth, and valuable time to recharge. Learn more about our company culture code and benefits. Plus, check out our accolades.

Commitment to Non-Discrimination
All qualified applicants will receive consideration for employment based on merit and without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, status as a protected veteran, or any other status protected by applicable federal, state, local, or international law.

 What we want you to know:

In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.

 Not ready to apply now? 

Sign up to join our newsletter here.","Be among the first 25 applicants","Full-time","Mid-Senior level","Information Technology","Technology, Information and Internet","$126,000.00/yr - $147,000.00/yr","","","83745","https://www.linkedin.com/jobs/view/sr-data-engineer-i-6154-at-metrostar-4339713196?trk=public_jobs_topcard-title","EASY_APPLY",""
"ETL Developer/Data Engineer","Greenwood Village, CO","1 week ago","2025-11-24","https://www.linkedin.com/jobs/view/etl-developer-data-engineer-at-meritore-technologies-4324109723?trk=public_jobs_topcard-title","Meritore Technologies","https://www.linkedin.com/company/meritore-technologies?trk=public_jobs_topcard-org-name","Role: ETL Developer/Data Engineer



Job Type: Contract on W2



Location: Greenwood Village, Colorado



 



Must have: ETL, SQL, Tableau, data pipelines



   
   
 * We are seeking a highly skilled and experienced ETL Developer/Data Engineer to join our dynamic team.
   
   
 * The ideal candidate will have a strong background in SQL, Python, and large-scale data processing, with hands-on experience in cloud platforms.
   
   
 * This role involves leading data engineering initiatives, optimizing data workflows, and contributing to the development of scalable data solutions.
   
   



 



Required Skills & Qualifications:



   
   
 * 7+ years of professional experience in data engineering and analytics.
   
   
 * 3+ years of hands-on experience creating interactive dashboards and visualizations using Tableau.
   
   
 * Strong proficiency in SQL, with the ability to write and optimize queries for Big Data environments.
   
   
 * Hands-on experience with AWS services such as EMR, Lambda, S3, Step Functions, and Athena.
   
   
 * Advanced programming skills in Python and PySpark for building scalable data solutions.
   
   
 * Proven experience in designing and managing ETL workflows and data pipelines.
   
   
 * Expertise in data visualization tools, preferably Tableau, to present insights effectively.
   
   
 * Experience working with large datasets and distributed systems.
   
   
 * Solid understanding of data modelling techniques including star and snowflake schemas.
   
   


Familiarity with Heavy AI for accelerated analytics (preferred).","Be among the first 25 applicants","Full-time","Entry level","Business Development and Sales","Software Development","","","","78993015","https://www.linkedin.com/jobs/view/etl-developer-data-engineer-at-meritore-technologies-4324109723?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Analyst","Schenectady, NY","2 weeks ago","2025-11-13","https://www.linkedin.com/jobs/view/data-analyst-at-healthy-alliance-4336023971?trk=public_jobs_topcard-title","Healthy Alliance","https://www.linkedin.com/company/healthyalliance?trk=public_jobs_topcard-org-name","Full-time Description

Life at Healthy Alliance

At Healthy Alliance, our purpose is to improve health and empower communities facing barriers. Every community has its own needs, affecting the health of those who live, learn, work, and play within them. Our network brings together organizations, big and small, to coordinate and collaborate so that all communities have reliable access to the resources they need. Why? Because every New Yorker deserves the same opportunity to be healthy.

Designated as the Social Care Network (SCN) Lead Entity for the Capital Region, Central NY, and North Country under New York’s 1115 Waiver Amendment’s SCN & Health-Related Social Needs (HRSN) Program, we are responsible for ensuring that there is a seamless, consistent end-to-end process for screening, navigation, and the delivery of services – including food, housing, and transportation to thousands of Medicaid Members. Transformative in nature, this novel Program will further sustain our vision of cultivating a world wherein everyone has a fair and just opportunity to be as healthy as possible.

As a 2019-2024 Albany Business Review’s Best Places to Work and a 2021-2025 Modern Healthcare’s Best Places to Work in Health Care award recipient, we strive to maintain a culture wherein high-performing, mission-driven team members collectively work toward better health for all. Dedicated to promoting a culture built upon autonomy, mastery, and purpose, we believe our differences in strengths and perspectives play an integral role in propelling us forward, while our core values ground us, serving as the common thread that unites our team.

Why You Should Join Healthy Alliance

Benefits

We offer amenities, professional development opportunities, events, and programming that support the interests of our teams while expanding and enriching our culture. Some of the benefits you can expect when you join Healthy Alliance include:


 * Competitive compensation package
 * Comprehensive insurance benefits available the 1st of the month after hire, including but not limited to medical, dental and vision, group short-term disability and life insurance with buy-up options, flexible spending and HSA company-contributed accounts, and more
 * 401K with a company match
 * Unlimited paid time off after 90 days of employment
 * Company-sponsored training and certification opportunities
 * Hybrid employer with flexible work schedules
 * A workplace that values safety, respect, employee engagement, recognition, and diversity
 * Salary range: $68,800-$79,120 per year, commensurate with experience
   
   

Who You Are

The Data Analyst is responsible for establishing and maintaining data analysis processes that support Healthy Alliance’s mission, strategic initiatives, contractual obligations, and data quality standards. The Data Analyst collaborates closely with business and technical teams in supporting data-driven decisions.

We are looking to fill this position with someone who currently resides in the North Country, Capital or Central New York Regions.

What You’ll Do


 * Work with key business partners to understand business priorities and develop effective and timely analytic solutions.
 * Query, link, validate, and analyze data across multiple databases with a keen eye on data integrity.
 * Analyze data and calculate metrics, including health outcomes and costs savings.
 * Present and explain results of analyses, internally and externally.
 * Identify and address expected and unforeseen data complexities to mitigate its impact on reporting and analytic outcomes.
 * Look for new data correlations to illustrate additional value to partners.
 * Investigate and analyze data to identify trends that could benefit both internal and external clients.
 * Identify data discrepancies and opportunities for improved data capture.
 * Ensure constant compliance with data standards and data sharing regulations and guidelines with an emphasis on continuous quality control and process improvements.
 * Translate business requirements into data and report technical specifications.
 * Design and develop reports (ongoing and/or ad-hoc) and dashboards for internal and external clients, ensuring timeliness and accuracy of data.
 * Conduct data and reporting testing, when appropriate.
 * Support data technical team by participating in design sessions.
 * Provide data management documentation, inclusive of reporting and analytics platforms.
 * Embody Healthy Alliance’s vision, mission, and goals.
   
   

This job description is not designed to cover or contain a comprehensive listing of task activities and/or duties that are required of the employee for this job. Responsibilities and activities may change at any time with or without notice.

Requirements

What You’ll Need

Education


 * Bachelor’s degree in mathematics, statistics, computer science, engineering, or related field required. Equivalent work experience in a related field may be considered in lieu of degree requirements.
   
   

Professional Work Experience


 * Minimum of 3-5 years data analysis experience using large diverse data sets.
 * Experience in health care and/or social care service industries.
   
   

Knowledge, Skills, And Abilities


 * Experience in performance tuning of reporting queries.
 * Experience developing advanced SQL queries.
 * Experience analyzing and conducting critical analysis to derive business insights.
 * Experience developing reports and dashboards in a Business Intelligence (BI) tool (i.e., Power BI, Tableau).
 * Experience and proficiency in Microsoft Office suite of products with advanced knowledge in Excel a plus.
 * Experience with programming tools and languages (e.g., SAS, Python, JavaScript, Ruby, etc.) a plus.
 * Experience with Azure a plus.
 * Experience in supporting non-technical end users in the proper compilation and submission of data using standard file formats.
 * Strong communication skills and ability to transform data into information, information into complex analytics, and analytics into actionable plain language to drive business decisions.
 * Strong verbal and written communication skills with the ability to communicate methods and results to a non-technical audience.
 * Perform all work in accordance with Healthy Alliance core competencies and values.
   
   

Your next career opportunity is at Healthy Alliance!

This position involves sedentary work that primarily involves sitting/standing, use of typical office equipment such as a computer, laptop, and cell phone. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Equal Opportunity Employer

Healthy Alliance is an Equal Opportunity Employer and does not discriminate against any employee or applicant on the basis of age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We adhere to these principles in all aspects of employment, including recruitment, hiring, training, compensation, promotion, benefits, social and recreational programs, and discipline. If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to hr@healthyalliance.org.

Privacy Requirement

This job function involves potential access / interaction with protected health information. Position will be required to abide by company policies and procedures that support federal, state, and local HIPAA regulations. Any violations will be subject to company policy which includes disciplinary actions up to and including separation of employment.

Healthy Alliance is an At-Will Employer.

Salary Description $68,800-$79,120 per year","Over 200 applicants","Full-time","Entry level","Information Technology","Non-profit Organizations","$68,800.00/yr - $79,120.00/yr","","","10148384","https://www.adzuna.com/details/5492750874?v=72E0FDE001EFCC1E4FAFE6F1CD42B8875494DAD7&r=20758277&frd=1afd8ed363d8b2e2d4e7fc63148de3c3&ccd=a3160043a947ea7b5b733a89344cc3c9&utm_source=linkedin7&utm_medium=organic&chnlid=1931&title=Data%20Analyst&a=e","EXTERNAL",""
"Manager, Data & Analytics","New York, NY","1 week ago","2025-11-22","https://www.linkedin.com/jobs/view/manager-data-analytics-at-terraform-power-4347131757?trk=public_jobs_topcard-title","TerraForm Power","https://www.linkedin.com/company/terraform-power?trk=public_jobs_topcard-org-name","Location: New York City Office / Remote

Reports To: Director of Technology

Department: Technology

Company: TerraForm Power (Brookfield Renewable)

Type: Full-Time, Permanent

About Us

TerraForm Power (“TERP”), a platform company of Brookfield, attracts high-performing individuals who are driven to make an impact in a fast-paced and collaborative environment. We offer unparalleled opportunities to lead and manage one of the largest renewable energy businesses with decades of history, while contributing to the global need for sustainable energy.

The company is committed to employee development, encouraging curiosity, ownership, and continuous learning. You’ll be empowered to take initiative, contribute ideas, and grow your career within a supportive and ambitious organization. This position will be based in remote.

Job Summary

TerraForm Power is seeking an experienced and visionary Data & Analytics Manager to lead and scale our enterprise data program, integrating IT and OT data to deliver actionable insights across Finance, Operations, Asset Management, and Development. This role combines strategic leadership with hands-on execution, driving adoption of modern analytics practices, and fostering a data-driven culture across the organization.

You will own the data platform strategy, govern end-to-end pipelines, and manage both internal resources and external vendors to enable trusted decision-making and AI readiness. The ideal candidate brings expertise in cloud data architecture, governance, analytics delivery, and team leadership in a hybrid IT/OT environment.

Responsibilities

Leadership & Strategy


 * Build and lead a high-performing Data & Analytics team, providing mentorship and career development.
 * Define and communicate the enterprise data strategy, aligning priorities with business objectives.
 * Champion a data-driven culture through executive engagement and stakeholder education.
 * Manage resource allocation, intake, and prioritization for analytics initiatives.
   
   

Data Platform & Architecture


 * Design and evolve a hybrid analytics platform leveraging Microsoft Fabric, Databricks, and Power BI.
 * Architect secure, scalable data lakes and lakehouses integrating IT systems and OT telemetry (SCADA, historians).
 * Implement CI/CD practices for data pipelines using GitHub, Azure DevOps, or Fabric pipelines.
   
   

Data Engineering & Integration


 * Oversee ingestion, transformation, and modeling workflows from ERP, Salesforce, Procore, and OT systems.
 * Implement robust ETL/ELT pipelines using Fabric Dataflows, Spark, or Synapse integrations.
 * Ensure data normalization and enrichment for unified reporting and forecasting.
   
   

Analytics & BI Delivery


 * Deliver governed Power BI dashboards and datasets with defined KPIs and business logic.
 * Enable self-service analytics while maintaining centralized governance through semantic models.
 * Drive adoption of deployment pipelines and certified datasets across business units.
   
   

Data Governance & Compliance


 * Implement enterprise-wide governance with Microsoft Purview (cataloging, lineage, classification).
 * Enforce data quality policies, role-based access, and sensitive data tagging.
 * Ensure compliance with SOX, SOC 2, and internal audit requirements.
 * OT Data Reliability & Edge Integration
 * Guarantee reliable, time-synced telemetry flows for wind and solar operations.
 * Collaborate with OT and cybersecurity teams to secure edge-to-cloud ingestion (Modbus, OPC UA, data diodes).
   
   

AI/ML Readiness


 * Prepare curated datasets for predictive analytics and optimization initiatives.
 * Support development of MLOps pipelines for model versioning and monitoring.
 * Stakeholder & Vendor Engagement
 * Manage external vendors, SLAs, and delivery for analytics and integration services.
 * Communicate roadmap, usage metrics, and value delivery to executive leadership.
   
   

Qualifications


 * Bachelor’s or Master’s in Computer Science, Engineering, Information Systems, Data Science, or related field.
 * 7–10+ years in data engineering, analytics, or BI, with 2–5+ years in a leadership role.
 * Proven success delivering modern data platforms using Microsoft Fabric, Databricks, Power BI, Azure Synapse.
 * Experience with Microsoft Purview for governance and compliance.
 * Familiarity with OT environments (SCADA, historians, Modbus/OPC UA) is a strong asset.
 * Strong SQL, Python, DAX, and Git-based workflows.
 * Excellent communication and stakeholder management skills.
   
   

Compensation: $115,000-142,000 USD, bonus eligible","26 applicants","Full-time","Mid-Senior level","Information Technology","Renewable Energy Power Generation","$115,000.00/yr - $142,000.00/yr","","","5277111","https://www.linkedin.com/jobs/view/manager-data-analytics-at-terraform-power-4347131757?trk=public_jobs_topcard-title","EASY_APPLY",""
"Backend Engineer","San Francisco Bay Area","3 weeks ago","2025-11-10","https://www.linkedin.com/jobs/view/backend-engineer-at-indent-4334587236?trk=public_jobs_topcard-title","Indent","https://www.linkedin.com/company/indent-com?trk=public_jobs_topcard-org-name","About You:

 * You will be working on our backend built with Python/FastAPI (with lots of asyncio), Postgres, and Redis. You should be immediately productive coming into a codebase on this stack.
 * You understand how to build resilient applications with LLMs: managing tool calls, prompts, cost/latency tradeoffs, etc.
 * You have clear likes and dislikes about AI coding tools you have tried, and know what should be better. We dogfood a lot and at the end of the day, we’re building for software engineers like ourselves.




About Us:

 * Indent is building the platform that every software engineer begins and ends their day in. Our customers are large engineering teams who use Indent for everything from incident response to code review to data analysis. Indent is built to handle these tasks in the real world (think analyzing a 30,000 table warehouse, not vibe querying a tiny Postgres instance) with minimal setup.
 * We are a small, engineering-focused team. We come from a background of systems and infrastructure engineering, working on things like the Swift Compiler, distributed data orchestration software, and scaled video conferencing systems. We think that rigor is an advantage in this get-rich-quick market.
 * We are taking an ambitious approach to a massive market. At Indent, one engineer can own a product like the Incident Response Agent that outperforms entire companies solving the same problem.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Software Development","","","","105004277","https://www.linkedin.com/jobs/view/backend-engineer-at-indent-4334587236?trk=public_jobs_topcard-title","EASY_APPLY",""
"Staff Process Engineer, Thin Film","Fremont, CA","2 weeks ago","2025-11-13","https://www.linkedin.com/jobs/view/staff-process-engineer-thin-film-at-western-digital-4335885223?trk=public_jobs_topcard-title","Western Digital","https://www.linkedin.com/company/western-digital?trk=public_jobs_topcard-org-name","Salary Range: 115,200.00-153,600.00

Company Description

At Western Digital, our vision is to power global innovation and push the boundaries of technology to make what you thought was once impossible, possible.

At our core, Western Digital is a company of problem solvers. People achieve extraordinary things given the right technology. For decades, we’ve been doing just that—our technology helped people put a man on the moon and capture the first-ever picture of a black hole.

We offer an expansive portfolio of technologies, HDDs, and platforms for business, creative professionals, and consumers alike under our Western Digital®, WD®, WD_BLACK™ Professional brands.

We are a key partner to some of the largest and highest-growth organizations in the world. From enabling systems to make cities safer and more connected, to powering the data centers behind many of the world’s biggest companies and hyperscale cloud providers, to meeting the massive and ever-growing data storage needs of the AI era, Western Digital is fueling a brighter, smarter future.

Today’s exceptional challenges require your unique skills. Together, we can build the future of data storage.

Job Description

Provide engineering support to the thin film deposition processes in manufacture lines in order to meet manufacturing objectives with high quality, high productive and low cost products, as well as support the development of future generation products.

Essential Duties And Responsibilities


 * Lead thin-film deposition manufacture process team, to sustain the production line, monitor processes and equipment to ensure minimal deviations, meeting quality and quantity specifications.
 * Develop and optimize process control methods and procedures to guarantee the quality, and prevent damage excursion.
 * Improve processes in sigma, cycle time, throughput, defects, and cost of ownership.
 * Performing wafer failure analysis, troubleshooting, and implement corrective and preventive actions.
 * Collaborate with cross-function team on the projects to improve overall product yield and element yield.
 * Collaborate with integration, research and development plus other modules on new products development and transfer into production lines.
 * Evaluate novel equipment to meet process requirement in future generation products
 * Driving project planning, execution, summary, presentation, and delivery on time.
 * Set up and improve automation systems, and working instruction documents. Provide the training instruction to the operators.
 * Working with Characterization, Reliability and Failure Analysis teams to develop test methodologies, understand failure modes and identify improvement opportunities.
 * Working with the Program, Modeling Process and Characterization teams to understand product requirements, defining development targets and plans.
   
   

Qualifications

Education, Certifications, and/or Licenses and Experience (Minimum Requirements)


 * Academic background in Material Science, Physics, Chemistry, or related engineering fields
 * Ph.D 1-2 year or MS with 4+ year of experience in wafer fab processes. Experience in thin film magnetic head is a plus.
   
   

Knowledge/Skills/ Abilities


 * Familiar with thin film deposition processes (PVD, CVD, IBD, etc), and equipment.
 * Solid background on correlation of process and equipment hardware
 * Deep understanding of material characterization techniques. Knowledge of Magnetic material process and characterization is a plus.
 * Knowledge of DOE and data analysis using JMP
 * Understanding of SPC.
 * Good trouble shooting and problem solving skill.
 * Leadership and communication skill, and good team player.
 * Being self-motivation, and good project management skill
   
   

Additional Information

Western Digital is committed to providing equal opportunities to all applicants and employees and will not discriminate against any applicant or employee based on their race, color, ancestry, religion (including religious dress and grooming standards), sex (including pregnancy, childbirth or related medical conditions, breastfeeding or related medical conditions), gender (including a person’s gender identity, gender expression, and gender-related appearance and behavior, whether or not stereotypically associated with the person’s assigned sex at birth), age, national origin, sexual orientation, medical condition, marital status (including domestic partnership status), physical disability, mental disability, medical condition, genetic information, protected medical and family care leave, Civil Air Patrol status, military and veteran status, or other legally protected characteristics. We also prohibit harassment of any individual on any of the characteristics listed above. Our non-discrimination policy applies to all aspects of employment. We comply with the laws and regulations set forth in the ""Know Your Rights: Workplace Discrimination is Illegal” poster. Our pay transparency policy is available here.

Western Digital thrives on the power and potential of diversity. As a global company, we believe the most effective way to embrace the diversity of our customers and communities is to mirror it from within. We believe the fusion of various perspectives results in the best outcomes for our employees, our company, our customers, and the world around us. We are committed to an inclusive environment where every individual can thrive through a sense of belonging, respect and contribution.

Western Digital is committed to offering opportunities to applicants with disabilities and ensuring all candidates can successfully navigate our careers website and our hiring process. Please contact us at jobs.accommodations@wdc.com to advise us of your accommodation request. In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying.

Based on our experience, we anticipate that the application deadline will be (3 months from posting), although we reserve the right to close the application process sooner if we hire an applicant for this position before the application deadline. If we are not able to hire someone from this role before the application deadline, we will update this posting with a new anticipated application deadline.

LI-JS1","59 applicants","Full-time","Mid-Senior level","Engineering","Computer Hardware Manufacturing, Computers and Electronics Manufacturing, and Semiconductor Manufacturing","$115,200.00/yr - $153,600.00/yr","","","4593","https://www.linkedin.com/jobs/view/staff-process-engineer-thin-film-at-western-digital-4335885223?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior AI/ML Architect, Applied Field Engineering","New York, NY","23 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/senior-ai-ml-architect-applied-field-engineering-at-snowflake-4340183077?trk=public_jobs_topcard-title","Snowflake","https://www.linkedin.com/company/snowflake-computing?trk=public_jobs_topcard-org-name","Snowflake is about empowering enterprises to achieve their full potential — and people too. With a culture that’s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology — and careers — to the next level.

Our Sales Engineering organization is seeking an AI Specialist who can provide hands-on expertise and support while working with technical decision makers and data scientists to design and architect AI solutions built on the Snowflake AI Data Cloud.

This is a strategic role that works closely with cross-functional teams, including product, engineering, and the broader field organization to ensure successful execution and customer adoption of Snowflake’s AI & ML solutions.

IN THIS ROLE YOU WILL GET TO:


 * Be the technical expert in the room that positions Snowflake’s AI and ML features and value to technical stakeholders at Snowflake’s customers across the Americas.
 * Partner with Snowflake account team teams and customer champions to scope and drive POCs to success and technical wins that prove the value of Snowflake’s capabilities, including executive readouts and business value cases.
 * Collaborate with Snowflake’s product and engineering teams to influence Snowflake’s AI and ML roadmaps based on customer feedback.
 * Publish content that helps the team and company scale beyond your individual efforts, like blog posts, presentations at conferences, or technical collateral like notebooks and demos.
 * Influence, tailor and maintain Sales Engineering AI and ML selling assets, including customer presentations, demonstrations, and customer stories.
   
   
   

ON DAY ONE, WE WILL EXPECT YOU TO HAVE:


 * 5+ years of experience building and deploying machine learning and generative AI solutions in the cloud.
 * Familiarity and associated knowledge of generative AI techniques like RAG, few shot learning, prompt engineering, or fine-tuning that are used to operationalize enterprise AI use cases like interactive chat applications or text processing.
 * Deep knowledge of Python and common ML packages (such as LangChain, pandas, sklearn, and PyTorch) as well as data engineering tools and technologies like dbt, Airflow, and Spark.
 * Strong presentation skills to both technical and executive audiences, whether whiteboarding sessions or formal readouts and demos.
 * Bachelor’s Degree required, Masters Degree in computer science, engineering, mathematics or related fields, or equivalent experience preferred.
   
   
   

BONUS POINTS FOR EXPERIENCE WITH THE FOLLOWING:


 * Working knowledge of tools in the LLM ecosystem such as LangChain, LlamaIndex, or other OSS packages.
 * Experience and understanding of large-scale infrastructure-as-a-service platforms (e.g. AWS, Microsoft Azure, GCP, etc.)
 * 1+ years of practical Snowflake experience.
 * Knowledge of and experience with large-scale database technology (e.g. Snowflake, Netezza, Exadata, Teradata, Greenplum, etc.)
   
   
   

Every Snowflake employee is expected to follow the company’s confidentiality and security standards for handling sensitive data. Snowflake employees must abide by the company’s data security plan as an essential part of their duties. It is every employee's duty to keep customer information secure and confidential.

Snowflake is growing fast, and we’re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.

How do you want to make your impact?

For jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com

The following represents the expected range of compensation for this role:


 * This role is eligible to participate in Snowflake's commission plan and it is common for employees in this role to receive total on-target earnings of $220,000 - $288,750. The estimated base salary for this role is $165,000 - $216,562.
 * Additionally, this role is eligible to participate in Snowflake’s equity plan.
   
   
   

The successful candidate’s starting salary will be determined based on permissible, non-discriminatory factors such as skills, experience, and geographic location. This role is also eligible for a competitive benefits package that includes: medical, dental, vision, life, and disability insurance; 401(k) retirement plan; flexible spending & health savings account; at least 12 paid holidays; paid time off; parental leave; employee assistance program; and other company benefits.

To comply with pay transparency requirements and other statutes, you can notify us if you believe that a job posting is not compliant by completing this form.","36 applicants","Full-time","Mid-Senior level","Design, Art/Creative, and Information Technology","Software Development","$165,000.00/yr - $288,750.00/yr","","","3653845","https://www.linkedin.com/jobs/view/senior-ai-ml-architect-applied-field-engineering-at-snowflake-4340183077?trk=public_jobs_topcard-title","EASY_APPLY",""
"Software Development Engineer","San Jose, CA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/software-development-engineer-at-adobe-4323560201?trk=public_jobs_topcard-title","Adobe","https://www.linkedin.com/company/adobe?trk=public_jobs_topcard-org-name","Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

The Opportunity

Join Adobe as a Software Development Engineer and work on our world-class Adobe Unified Platform team! You will work closely with Solution Architects, Product & other engineering teams across multiple geographies to deliver solutions to strategic priorities. You will play a pivotal role in driving strategic priorities at the intersection of data engineering, analytics, and AI innovation. We are looking for candidates who are passionate about continuous learning, mentoring, and innovative thinking. This is an outstanding opportunity to contribute to high-impact projects and help compose the future of Adobe’s technological landscape.

What you'll Do


 * Participate in all aspects of software development, including design, coding, code review, testing, bug fixing, and documentation.
 * Design, build, and maintain data pipelines and data models that scale well with growth of data.
 * Build and fine-tune specialized AI agents for Data Engineering.
 * Implement prompt engineering strategies, memory handling, resource management and tool-calling integrations.
 * Improve developer efficiency, automate tasks, and enhance customer experience using AI tools and capabilities.
   
   

What you need to succeed


 * BS in Computer Science, Engineering, or a related field with 3+ years of experience in data engineering.
 * Experience in SQL and Python for data transformation, automation, and analysis.
 * Solid understanding of data modeling, warehousing concepts, and ETL/ELT pipeline development.
 * Experience with Azure, Databricks, and Airflow (or similar modern data stack tools).
 * Strong proficiency with LLM frameworks (e.g., OpenAI APIs, LangChain/LangGraph, RAG pipelines) and comfort with prompt composition, vector databases, and memory handling strategies.
 * Experience building conversational agents or workflow bots in production environments.
 * Analytical approach with a focus on attention to detail and problem-solving skills.
 * Effective communication abilities and a cooperative and positive approach.
   
   

Our compensation reflects the cost of labor across several  U.S. geographic markets, and we pay differently based on those defined markets. The U.S. pay range for this position is $93,200 -- $170,600 annually. Pay within this range varies by work location and may also depend on job-related knowledge, skills, and experience. Your recruiter can share more about the specific salary range for the job location during the hiring process.

At Adobe, for sales roles starting salaries are expressed as total target compensation (TTC = base + commission), and short-term incentives are in the form of sales commission plans. Non-sales roles starting salaries are expressed as base salary and short-term incentives are in the form of the Annual Incentive Plan (AIP).

In addition, certain roles may be eligible for long-term incentives in the form of a new hire equity award.

State-Specific Notices:

California:

Fair Chance Ordinances

Adobe will consider qualified applicants with arrest or conviction records for employment in accordance with state and local laws and “fair chance” ordinances.

Colorado:

Application Window Notice

If this role is open to hiring in Colorado (as listed on the job posting), the application window will remain open until at least the date and time stated above in Pacific Time, in compliance with Colorado pay transparency regulations. If this role does not have Colorado listed as a hiring location, no specific application window applies, and the posting may close at any time based on hiring needs.

Massachusetts:

Massachusetts Legal Notice

It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.

Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.

Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Advertising Services, IT Services and IT Consulting, and Software Development","$93,200.00/yr - $170,600.00/yr","","","1480","https://www.linkedin.com/jobs/view/software-development-engineer-at-adobe-4323560201?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Solutions Engineering Manager","Lenexa, KS","1 week ago","2025-11-18","https://www.linkedin.com/jobs/view/data-solutions-engineering-manager-at-kiewit-4319215863?trk=public_jobs_topcard-title","Kiewit","https://www.linkedin.com/company/kiewit?trk=public_jobs_topcard-org-name","Requisition ID: 178289

Job Level: Senior Level

Home District/Group: Kiewit Industrial & Water Engineering

Department: Estimating

Market: Industrial

Employment Type: Full Time

Position Overview

In this role, you will lead a small team of data analysts and solution engineers, acting as a central coordinator and problem-solver, interfacing between various data and technology groups to ensure smooth data operations and project delivery. You’ll work closely with the Kiewit Technology Group (KTG), Kiewit Data Services (KDS), and other internal teams to identify and resolve data issues, guide analysts, and develop tools that improve our workflows. Because this role operates with minimal oversight, you must be a self-starter who can independently identify high-value problems to solve, prioritize your time effectively, and confidently determine what’s worth pursuing without being told.

District Overview

Kiewit Engineering Group, Inc is a full-service consulting and engineering firm serving the infrastructure and engineering markets. Our combined staff of more than 1,700 engineers and design professionals have expertise that spans all major engineering disciplines to serve transportation, power, water/wastewater, mining, building, and oil, gas & chemical markets. Backed by 130 years of construction experience, our construction-driven engineering focuses on constructability and safety in the earliest phases of projects to ensure on-time and on-budget project delivery.

Our rapidly growing Industrial Design Group, which includes process, electrical, controls, structural, architectural, geotechnical, and civil disciplines, is a multi-faceted and leading-edge division of Kiewit with best-in-class technical expertise focused on EPC and design-build delivery of industrial projects in markets such as Food & Beverage, Consumer Products, Heavy Manufacturing, Industrial Buildings Industrial Water and Utilities.

Location

This position is based out of Lenexa, Kansas.

Responsibilities


 * Leadership: Lead a small technical team (2-4+) with clear goals, ownership, and delivery expectations. Serve as direct manager or functional lead (dotted line) for some existing Industrial Data team members.
 * Data Coordination and Issue Resolution: Serve as the go-to person for identifying data issues and finding the right contacts in KTG and KDS to get them resolved. This includes investigating with SQL scripts, guiding platform teams to the source of data errors, and ensuring the corrections are implemented.
 * Project and Tool Development: Manage and program tools (often in Python) to support our teams. Build utilities like civil estimation tools and machine learning POCs. Design and improve tools while evaluating buy vs. build decisions.
 * Guiding and Mentoring Analysts: Mentor analysts in using Python, APIs, and transitioning legacy Excel data into more robust structures. Foster a culture of curiosity and problem-solving.
 * Process Improvement and Strategic Planning: Evaluate and find ways to improve estimation workflows to accelerate delivery and increase accuracy. Reduce friction and improve collaboration across teams.
 * Data Modeling and Analytical Insight: Work independently to source, structure, and clean data from a wide range of systems using SQL and Python. With limited direction, analyze that data to generate actionable business insights — including forming and testing hypotheses, uncovering correlations, and identifying opportunities. You’ll be expected to connect technical findings to their real-world business impact and communicate your recommendations effectively.
   
   
   

Qualifications


 * Bachelor's degree in Engineering, Computer Science, Data Science, or a related field
 * Experience leading a small technical including setting direction, giving feedback, and coordinating delivery.
 * 5+ years experience in analytics, tool-building, or data coordination
 * Strong working knowledge of Python, SQL, APIs
 * Experience collaborating across business and technical teams
 * Familiarity with cloud tools (Snowflake, Power BI, etc.) a plus
   
   
   

Technical Skills


 * Python programming for automation, prototyping, and utilities
 * SQL for data investigation and transformation
 * Familiarity with data visualization tools (Power BI, Streamlit)
 * Comfortable reading and debugging legacy code
 * Knowledge of basic ML/AI concepts a plus
   
   
   

Soft Skills


 * Excellent communication and collaboration skills
 * Curiosity and drive to solve problems independently
 * Ability to explain technical topics to non-technical audiences
 * Patience and gentle persistence when working across teams
 * Strategic thinking and proactive mindset
   
   
   

Other Requirements:


 * Regular, reliable attendance
 * Work productively and meet deadlines timely
 * Communicate and interact effectively and professionally with supervisors, employees, and others individually or in a team environment.
 * Perform work safely and effectively. Understand and follow oral and written instructions, including warning signs, equipment use, and other policies.
 * Work during normal operating hours to organize and complete work within given deadlines. Work overtime and weekends as required.
 * May work at various different locations and conditions may vary.
   
   
   

We offer our fulltime staff employees a comprehensive benefits package that’s among the best in our industry, including top-tier medical, dental and vision plans covering eligible employees and dependents, voluntary wellness and employee assistance programs, life insurance, disability, retirement plans with matching, and generous paid time off.

Equal Opportunity Employer, including disability and protected veteran status.

","71 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Construction and Civil Engineering","","Kelsey Strobel","https://www.linkedin.com/in/kelsey-strobel","9585","https://www.linkedin.com/jobs/view/data-solutions-engineering-manager-at-kiewit-4319215863?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Python Engineer | Hedge Fund | $400k","New York City Metropolitan Area","3 weeks ago","2025-11-06","https://www.linkedin.com/jobs/view/senior-python-engineer-hedge-fund-%24400k-at-orbis-group-4334406575?trk=public_jobs_topcard-title","Orbis Group","https://uk.linkedin.com/company/weareorbis?trk=public_jobs_topcard-org-name","Python Software Engineer | Hedge Fund | NYC | $400k




I'm partnered with a global hedge fund who are looking for a Quant/Software Engineer to join their new multi-asset systematic trading team in New York.




What you’ll be doing:

 * Designing, building and optimising high-performance systems that support data ingestion, research, backtesting and live trading.
 * Working closely with quantitative researchers to bring research ideas into production.
 * Maintaining and improving Python-based infrastructure in a cloud and Linux environment.




What we’re looking for:

 * Strong software engineering experience, ideally within a trading, systematic or data-driven environment.
 * Advanced Python programming skills and a strong grasp of software design principles.
 * Experience working in Linux and cloud-based environments (AWS, GCP or Azure).
 * A degree in Computer Science or a related technical field from a leading university.
 * Bonus points for C# experience




This is a hands on engineering role within a fast moving trading environment and huge earning potential.




At this time, we cannot accept anyone that requires H1-b transfer.","Over 200 applicants","Full-time","Mid-Senior level","Finance and Engineering","Financial Services and IT Services and IT Consulting","$200,000.00/yr - $300,000.00/yr","Joe Davies","https://uk.linkedin.com/in/joedavies1","3522089","https://www.linkedin.com/jobs/view/senior-python-engineer-hedge-fund-%24400k-at-orbis-group-4334406575?trk=public_jobs_topcard-title","EASY_APPLY",""
"Backend Engineer, Data Products","San Francisco, CA","2 weeks ago","2025-11-14","https://www.linkedin.com/jobs/view/backend-engineer-data-products-at-alembic-technologies-4335968304?trk=public_jobs_topcard-title","Alembic Technologies","https://www.linkedin.com/company/getalembic?trk=public_jobs_topcard-org-name","About Alembic

Alembic is where top engineers are solving marketing's hardest problem: proving what actually works. If you're looking for frontier technical challenges at an applied science company, this is the place.

At Alembic, we're not just building software—we're decoding the chaos of modern marketing. Join Alembic to build trusted systems that Fortune 100 companies use to make multimillion-dollar decisions. We're backed by leading tech luminaries including WndrCo (founded by DreamWorks founder Jeffrey Katzenberg), Jensen Huang, Joe Montana, and many more.

About The Role

We're looking for a Senior Backend Engineer to architect and operate our backend platform that delivers scalable, high-performance insights for Fortune 500 clients. You'll build the core systems that power our causation analytics—from data processing pipelines to the APIs that serve insights to our customers.

This role offers significant technical ownership and the opportunity to work on complex distributed systems at enterprise scale.

What You'll Do


 * Design and build scalable backend services and APIs that process massive marketing datasets with high reliability
 * Architect distributed systems that can handle 10x growth in data volume and customer workloads
 * Optimize database performance and data models to support complex analytical queries at scale
 * Build robust data processing pipelines that transform raw marketing data into actionable insights
 * Collaborate with frontend engineers to design clean, efficient API contracts
 * Establish backend engineering best practices and mentor other engineers on the team
   
   

What Will Help You Succeed

Backend Engineering Excellence


 * 8+ years backend engineering experience with significant ownership of production systems
 * Expert-level Python (FastAPI, Flask, or similar frameworks)
 * Working proficiency in Node.js (comfortable reading and contributing when needed)
 * Strong database knowledge (PostgreSQL, Elasticsearch (can be learned), data modeling, query optimization)
 * System design expertise (distributed systems, scalability patterns, performance optimization)
 * AWS/GCP experience with modern DevOps tooling (Docker, Kubernetes, Terraform, CI/CD pipelines)
   
   

Problem Solving & Collaboration


 * Ability to translate ambiguous requirements into well-defined technical designs
 * Strong cross-functional communication and collaboration skills
 * Early-stage or high-growth startup experience with fast-paced, evolving environments
 * Proven track record building scalable APIs and data processing pipelines
 * Experience with data-intensive applications and large-scale data systems
 * Background collaborating with frontend engineers on API contracts and interface design
   
   

Nice to Have


 * AI/ML infrastructure experience or familiarity with analytics platforms
 * Stream processing knowledge (Kafka, Kinesis, Redis Streams)
 * Lakehouse architectures (Iceberg) or ELT pipeline experience
 * Experience mentoring engineers and contributing to technical culture at scale
   
   

Why You Might Be Excited About Alembic


 * Hard problems with real impact: You'll tackle the hardest challenges in marketing analytics while building systems that influence multimillion-dollar decisions at Fortune 100 companies
 * Technical autonomy: You want ownership over technical decisions and the freedom to solve complex problems your way
 * Cutting-edge technology: Work with advanced AI/ML algorithms, composite AI solutions, private NVIDIA DGX clusters, and the latest in data processing at scale
 * Elite team: Join top engineers who thrive on challenging problems and high-impact work
 * Startup upside: Early-stage equity opportunity with experienced leadership and proven product-market fit
   
   

Why You Might Not Be Excited


 * If you only want to tell people what to build instead of building and coding alongside them, we're not the environment for you
 * You prefer company practices with 100% built-out process for every detail
 * You prefer static over dynamic. Projects, priorities, and roles will adapt to your skill set and goals. Though we have real paying customers and a playbook for growth, we proudly remain an early-stage startup
   
   

Compensation Range: $179K - $200K

","Be among the first 25 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","$179,000.00/yr - $200,000.00/yr","","","18958653","https://www.linkedin.com/jobs/view/backend-engineer-data-products-at-alembic-technologies-4335968304?trk=public_jobs_topcard-title","EASY_APPLY",""
"Deep Learning Scientist, LLM Training Datasets","Santa Clara, CA","1 week ago","2025-11-22","https://www.linkedin.com/jobs/view/deep-learning-scientist-llm-training-datasets-at-nvidia-4338369838?trk=public_jobs_topcard-title","NVIDIA","https://www.linkedin.com/company/nvidia?trk=public_jobs_topcard-org-name","NVIDIA is looking for a dedicated Deep Learning Scientist specializing in LLM training datasets engineering. This is a highly technical role requiring deep expertise in machine learning, data science and data engineering to develop innovative solutions that address the unique challenges of training foundation models. This role involves addressing innovative machine learning challenges through building and improving our data ecosystem.

What You'll Be Doing


 * Develop datasets for LLM pre-training and post training (fine-tuning and reinforcement learning), optimize models and evaluate performance.
 * Design and implement data strategies for model training and evaluation that includes data collection, cleaning, labeling, augmentation, RL verifier datasets to improve model performance. Actively identify and manage data issues such as outliers, noise, and biases.
 * Generate high-quality synthetic data to augment existing datasets, especially for domain-specific or safety-critical use cases and multi-modal use cases (text, image, video, etc)
 * Define data annotation guidelines and curate high-quality labeled datasets for model alignment, including reinforcement learning with human feedback (RLHF).
 * Conduct experiments to optimize Large Language Models with SFT and RL techniques.
 * Design and develop systems for reasoning, tool calling, multi-modal processing, RL verifiers.
 * Implement post-training tasks for LLMs, including fine-tuning, RL, distillation, and performance evaluation, and adjust hyperparameters to improve model quality.
 * Partner with ML researchers, data scientists, and infrastructure teams to understand data needs, integrate datasets, and deploy efficient ML workflows.
   
   

What We Need To See


 * You have a Master’s or PhD in Computer Science, Electrical Engineering or related field - or equivalent experience.
 * 3+ years of work experience in developing datasets and training large language models or other generative AI models.
 * Hands-on programming expertise in python.
 * Solid understanding of machine learning concepts and algorithms for managing data and experiments, including multi-modal datasets.
 * Experience with synthetic data generation techniques, and evaluation strategies.
 * Background with high-performance data processing libraries and machine learning frameworks like PyTorch, Data Loader, TensorFlow Data.
 * Experience with alignment/fine-tuning of LLMs, VLMs (img-to-text, vid-to-text)or any-to-text large models.
 * Familiarity with distributed training paradigms and optimization techniques.
 * Good at problem solving and analytical ability as well as excellent collaboration and communication skills.
 * Demonstrates behaviors that build trust: humility, transparency, respect, intellectual integrity.
   
   

Ways To Stand Out From The Crowd


 * Strong track record of contributions to open-source data tools or research publications.
 * Experience with cloud platforms (e.g., AWS, GCP, Azure) and data storage systems (e.g., S3, Google Cloud Storage).
 * Stay ahead of research: Continuously evaluate new tools, techniques, and methodologies in data engineering and generative AI to improve training data infrastructure.
 * Passion for AI and a demonstrated commitment to advancing the field through innovative research, prior scientific research and publication experience.
   
   

With highly competitive salaries and a comprehensive benefits package, NVIDIA is widely considered to be one of the technology industry's most desirable employers. We have some of the most forward-thinking and hardworking people in the world working with us and our engineering teams are growing fast in some of the hottest state of the art fields: Deep Learning, Artificial Intelligence, and Large Language Models. If you're a creative engineer with a real passion for robust and enjoyable user experiences, we want to hear from you.

Your base salary will be determined based on your location, experience, and the pay of employees in similar positions. The base salary range is 148,000 USD - 235,750 USD for Level 3, and 184,000 USD - 287,500 USD for Level 4.

You will also be eligible for equity and benefits .

Applications for this job will be accepted at least until November 24, 2025.NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.

JR2003826

","77 applicants","Full-time","Entry level","Engineering","Computer Hardware Manufacturing, Software Development, and Computers and Electronics Manufacturing","$148,000.00/yr - $287,500.00/yr","","","3608","https://nvidia.wd5.myworkdayjobs.com/NVIDIAExternalCareerSite/job/US-CA-Santa-Clara/Machine-Learning-Engineer\u002d\u002dLLM-Training-Datasets_JR2003826?source=jobboardlinkedin","EXTERNAL",""
"Distinguished Software Engineer (Data Security - Distributed Systems, Big Data & AI )","Santa Clara, CA","2 weeks ago","2025-11-13","https://www.linkedin.com/jobs/view/distinguished-software-engineer-data-security-distributed-systems-big-data-ai-at-palo-alto-networks-4335963627?trk=public_jobs_topcard-title","Palo Alto Networks","https://www.linkedin.com/company/palo-alto-networks?trk=public_jobs_topcard-org-name","Our Mission

At Palo Alto Networks®, we’re united by a shared mission—to protect our digital way of life. We thrive at the intersection of innovation and impact, solving real-world problems with cutting-edge technology and bold thinking. Here, everyone has a voice, and every idea counts. If you’re ready to do the most meaningful work of your career alongside people who are just as passionate as you are, you’re in the right place.

Who We Are

We believe collaboration thrives in person. That’s why most of our teams work from the office full time, with flexibility when it’s needed. This model supports real-time problem-solving, stronger relationships, and the kind of precision that drives great outcomes.

Job Description

The Team

You’ll be working in a top tier cybersecurity company and collaborating with some of the brightest minds in technology. Our team doesn’t shy away from tackling big problems. You will help build and support the tools and infrastructure enabling our developers to release the products that our customers depend on to defend against cyberattacks. Joining this dynamic and fast-paced team will give you the opportunity and thrill of resolving the technical and process gaps that hold back productivity.

Job Summary

At Palo Alto Networks, we are redefining cybersecurity. As a Distinguished Engineer on the Enterprise DLP team, you will be the foremost technical leader responsible for architecting and scaling the data platform that underpins our industry-leading cloud-delivered DLP service. Your mission is to establish the standards and systems necessary to process and analyze massive volumes of sensitive data, leveraging cutting-edge AI/ML, to ensure our customers' data remains protected across all network, cloud, and user vectors.

Key Responsibilities

As a Distinguished Engineer, you will own the long-term technical direction and execution for all data and analytics infrastructure within Saas Data Security and AI.

I. Architecture & Strategic Vision


 * Define Architectural Roadmap: Set the 3-5 year technical strategy and architectural vision for the Enterprise DLP data platform, emphasizing scalability, performance, security, and cost-efficiency
 * Big Data & AI Foundation: Drive the design, implementation, scaling, and evangelism of the core BigQuery, Vertex AI, Nvidia Triton, Kubeflow platform components that enable high-velocity data ingestion, transformation, and Machine Learning model serving for DLP detections
 * Real-time Decisioning: Architect and implement ultra-low latency data ingestion and processing systems (utilizing Kafka, Pub/Sub, Dataflow) to enable real-time DLP policy enforcement and alert generation at massive enterprise scale
 * Cross-Functional Influence: Act as the technical voice of the DLP data platform, collaborating with Engineering VPs, Product Management, and Data Science teams to align platform capabilities with product innovation
   
   

II. High-Scale Data Platform Engineering


 * Big Data Pipeline Mastery: Architect and Lead the design and implementation of highly resilient, optimized batch and real-time data pipelines (ETL/ELT) to transform raw data streams into high-quality, actionable datasets
 * Optimized Datasets: Expertly design and optimize clean, well-structured analytical datasets within BigQuery, focusing on partitioning, clustering, and schema evolution to maximize query performance for both operational analytics and complex data science/ML feature generation
 * Database Strategy: Provide deep, hands-on expertise in both SQL and NoSQL databases like MongoDB, Spanner, BigQuery, advising on the optimal data persistence layer for diverse DLP data use cases (e.g., policy configurations, high-speed telemetry, analytical fact tables)
 * MLOps Implementation: Establish robust MLOps practices model deployment & execution pipelines like Vertex AI, Nvidia Triton for DLP models, including automated pipelines for continuous training, versioning, deployment, and monitoring of model drift
 * Performance Engineering: Debug, optimize, and tune the most challenging performance bottlenecks across the entire data platform, from initial data ingestion to final analytics query execution, often dealing with PBs of data
   
   

III. Mentorship & Operational Excellence


 * Technical Mentorship: Mentor and develop Principal and Staff-level engineers, raising the bar for engineering craftsmanship and data platform development across the organization
 * Operational Health: Define and implement advanced observability, monitoring, and alerting strategies to ensure the end-to-end health and SLOs of the mission-critical DLP data service
   
   

Qualifications

Preferred Qualifications


 * 12+ years of experience in a high-scale data-intensive environment, with a minimum of 3+ years operating as a Distinguished or Principal-level Engineer/Architect
 * Mastery of Google Cloud Platform (GCP) with extensive, hands-on experience architecting and scaling solutions using BigQuery and Vertex AI or equivalent AWS, Azure, or other Big Data & AI services
 * Expertise in Big Data processing frameworks and managed services, specifically with building and scaling data and analytics pipelines using Dataflow, Pub/Sub, and GKE (or equivalent technologies like Apache Spark/Kafka)
 * Strong experience in SQL & NoSQL databases (e.g., MongoDB, Cassandra, Spanner), with an understanding of their respective architectural trade-offs for distributed systems
 * Demonstrated ability to design scalable data models and systems that enable high-precision
 * Proven ability to build and optimize clean, well-structured analytical datasets for large-scale business and data science use cases
 * Demonstrated experience in implementing and supporting Big Data solutions for both batch (scheduled) and real-time (streaming) analytics
 * Prior experience in the security domain (especially DLP, Data Security, or Cloud Security) is a significant advantage
 * Exceptional ability to influence technical and business leaders, translating ambiguous problems into clear, executable technical designs
 * BS/MS in Computer Science or Electrical Engineering or equivalent experience or equivalent military experience required
   
   

Additional Information

Salary Disclosure

The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $230,000/YR - $300,000/YR. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.

Our Commitment

We’re problem solvers that take risks and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.

We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.

Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.

All your information will be kept confidential according to EEO guidelines.

","26 applicants","Full-time","Mid-Senior level","Engineering","Computer and Network Security","","","","30086","https://www.linkedin.com/jobs/view/distinguished-software-engineer-data-security-distributed-systems-big-data-ai-at-palo-alto-networks-4335963627?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr BI Developer - Data Engineering ETL","Diamond Bar, CA","2 weeks ago","2025-11-14","https://www.linkedin.com/jobs/view/sr-bi-developer-data-engineering-etl-at-niagara-bottling-4323977254?trk=public_jobs_topcard-title","Niagara Bottling","https://www.linkedin.com/company/niagara-bottling?trk=public_jobs_topcard-org-name","At Niagara, we’re looking for Team Members who want to be part of achieving our mission to provide our customers the highest quality most affordable bottled water.

Consider Applying Here, If You Want To


 * Work in an entrepreneurial and dynamic environment with a chance to make an impact.
 * Develop lasting relationships with great people.
 * Have the opportunity to build a satisfying career.
   
   

We offer competitive compensation and benefits packages for our Team Members.

Sr BI Developer - Data Engineering ETL

As a key member of our team, the Senior Business Intelligence (BI) Developer will be responsible for designing, developing, implementing, and supporting essential enterprise Business Intelligence solutions. The ideal candidate will possess a strong background in data integration, ETL processes, and business intelligence to deliver scalable and efficient data solutions. This role involves collaborating with cross-functional teams to gather requirements and leveraging skills and experience to create end-to-end solutions, from data acquisition and data modelling to support reporting and visualization. The candidate will continuously assess and adopt new technologies, methodologies and practices to enhance data processing capabilities. This position is crucial in ensuring high-quality data operations and providing valuable insights to support the organization’s decision-making processes.


 * Design, build, and maintain robust ETL/ELT pipelines using Incorta and Databricks (PySpark, SQL, Delta Lake).
 * Develop and optimize Spark transformations for processing large-scale datasets.
 * Enhance Databricks SQL performance by troubleshooting and tuning slow-running queries and reports.
 * Optimize data storage, partitioning, and retrieval for scalability and performance using Z-Ordering, OPTIMIZE, Auto Compaction, and file size tuning.
 * Configure and manage Databricks infrastructure components, including Serverless SQL Warehouses and Interactive Clusters.
 * Collaborate with BI developers and analysts to design and implement data models supporting reporting and analytical nee
 * Maintain data quality and integrity through validation, cleansing, and transformation routines.
 * Enforce data governance, access controls, and compliance standards using Unity Catalog.
 * Ensure proper configuration management and change control processes are followed.
 * Partner with offshore teams and actively participate in scrum calls for coordinated delivery.
 * Work closely with Oracle ERP analysts to identify and resolve data quality or integration issues.
 * Participate in and manage activities across the entire Software Development Life Cycle (SDLC).
   
   

Please note that this job description is not designed to contain a comprehensive list of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without prior notice

Qualifications


 * Minimum Qualifications:
    * 7-10 years – Proven experience in data engineering or enterprise data platform development, including the design and implementation of complex data pipelines and integration frameworks
    * 7-10 years – Strong expertise in advanced SQL development, including complex transformations, query tuning, and performance optimization across large datasets.
    * 7-10 years – Experience in troubleshooting and resolving ETL/ELT failures, performance bottlenecks, and end-to-end BI solution issues.
    * 7-10 years – Expertise in data modeling, dimensional modeling (Star/Snowflake), data mart design, and semantic layer development to support enterprise BI and analytics.
    * 5-7 years – Hands-on experience in PySpark, Spark SQL, and Databricks SQL, building scalable data transformations and lakehouse solutions.
    * 5-7 years – Proven ability to process and optimize large-scale datasets (terabytes to petabytes) with a focus on partitioning, Z-ordering, and data compaction.
    * 5-7 years – Experience with cloud platforms like Microsoft Azure, Google Cloud and OCI Platform
    * 5-7 years – Experience with Finance, Supply Chain, Manufacturing, Procurement, EAM processes and data elements
    * 3-5 years – Hands-on experience implementing data quality frameworks, schema evolution handling, and data validation controls in Databricks or similar ecosystems.
    * 3-5 years – Hands-on experience with Azure Databricks, including cluster management, workflows, and SQL performance tuning.
    * 0-2 year(s) – Experience in Oracle Analytics Cloud Services (OACS) or PowerBI
      
      

 * experience may include a combination of work experience and education
 * Preferred Qualifications:
    * 10+ years – Proven experience in data engineering or enterprise data platform development, including the design and implementation of complex data pipelines and integration frameworks
    * 10+ years – Strong expertise in advanced SQL development, including complex transformations, query tuning, and performance optimization across large datasets
    * 10+ years – Expertise in data modeling, dimensional modeling (Star/Snowflake), data mart design, and semantic layer development to support enterprise BI and analytics.
    * 10+ years – Experience in troubleshooting and resolving issues in ETL jobs and BI solutions
    * 7-10 years – Experience in understanding Finance, Supply Chain, Manufacturing, Procurement and EAM modules of an ERP application
    * 5-7 years – Experience in understanding Fusion ERP cloud, OTM cloud, WMS (Manhattan)
    * 2-4 years – Experience with Incorta
    * 2-4 years – Experience in Oracle Hyperion/EPM
    * 2-4 years – Experience in Oracle Analytics Cloud Services (OACS) or PowerBI

 * experience may include a combination of work experience and education
   

Additionally, The Sr. IT Developer Is Expected To Demonstrate


 * Strong analytical and problem-solving skills with the ability to troubleshoot complex issues
 * Excellent communication and interpersonal skills to work with cross-functional teams and business stakeholders
 * Ability to manage multiple tasks and priorities in a fast-paced environment
 * Attention to detail and a commitment to delivering high-quality, error-free data solutions
 * A strong sense of ownership and accountability, promptly notifying management of any issues that affect his/her ability to accomplish planned goals
   
   

Education


 * Minimum Required:
    * Bachelor's Degree in Computer Science or Engineering
      
      

 * Preferred:
    * Master's Degree in Computer Science or Engineering
      

Certification/License


 * Required: NA
 * Preferred: Databricks, Azure Cloud
   
   

Typical Compensation Range

Pay Rate Type: Salary

$111,766.36 - $159,267.07 / Yearly

Benefits

Our Total Rewards package is thoughtfully designed to support both you and your family:

Regular full-time team members are offered a comprehensive benefits package, while part-time, intern, and seasonal team members are offered a limited benefits package.


 * Paid Time Off for holidays, sick time, and vacation time
 * Paid parental and caregiver leaves
 * Medical, including virtual care options
 * Dental
 * Vision
 * 401(k) with company match
 * Health Savings Account with company match
 * Flexible Spending Accounts
 * Expanded mental wellbeing benefits including free counseling sessions for all team members and household family members
 * Family Building Benefits including enhanced fertility benefits for IVF and fertility preservation plus adoption, surrogacy, and Doula reimbursements
 * Income protection including Life and AD&D, short and long-term disability, critical illness and an accident plan
 * Special discount programs including pet plans, pre-paid legal services, identity theft, car rental, airport parking, etc.
 * Tuition reimbursement, college savings plan and scholarship opportunities
 * And more!
   
   

https://careers.niagarawater.com/us/en/benefits


 * *Los Angeles County applicants only** Qualified applicants with arrest or conviction records will be considered for employment in accordance with the Los Angeles County Fair Chance Ordinance for Employers, the California Fair Chance Act, and any other applicable local and state laws.
   
   

Any employment agency, person or entity that submits a résumé into this career site or to a hiring manager does so with the understanding that the applicant's résumé will become the property of Niagara Bottling, LLC. Niagara Bottling, LLC will have the right to hire that applicant at its discretion without any fee owed to the submitting employment agency, person or entity.

Employment agencies that have fee agreements with Niagara Bottling, LLC and have been engaged on a search shall submit résumé to the designated Niagara Bottling, LLC recruiter or, upon authorization, submit résumé into this career site to be eligible for placement fees.

Niagara Plant Name

CORP-MAIN","181 applicants","Full-time","Mid-Senior level","Information Technology","Food and Beverage Services","$111,766.36/yr - $159,267.06/yr","","","120859","https://careers.niagarawater.com/us/en/job/NBLLUSR51407EXTERNALENUS/Sr-BI-Developer-Data-Engineering-ETL?utm_source=linkedin&utm_medium=phenom-feeds","EXTERNAL",""
"Fullstack Engineer, Intelligence Systems","San Francisco, CA","2 weeks ago","2025-11-13","https://www.linkedin.com/jobs/view/fullstack-engineer-intelligence-systems-at-openai-4340442217?trk=public_jobs_topcard-title","OpenAI","https://www.linkedin.com/company/openai?trk=public_jobs_topcard-org-name","About The Team

The Intelligence and Investigations team seeks to rapidly detect and disrupt abuse in AI technologies to ensure their safe use. We are dedicated to identifying emerging abuse trends, analyzing risks, and working with our internal partners to implement effective mitigation strategies to protect against misuse. Our efforts contribute to OpenAI's overarching goal of developing AI that benefits all of humanity.

About The Role

As an Intelligence Systems Engineer, you’ll be focused on advancing our Intelligence & Investigations efforts at OpenAI, ensuring the safe and responsible use of AI across our products and services.

We are seeking a self-starter to prototype, develop, and maintain new tools and processes that integrate OpenAI’s models and infrastructure to enable internal teams to make sense of large, open-domain datasets, fight abuse, and inform high-stakes decisions.

You will be a crucial technical bridge between our data scientists and subject matter experts and technical teams like Platform Integrity, Safety Systems, and Research by leading the development of innovative tools and processes that bolster goals in scaled collections, investigations, and analysis.

The ideal candidate has strong analytical and data skills, with a background in both prototyping and building scalable systems that can swiftly detect emerging threats, process vast amounts of information, and deliver insights to stakeholders. We value professionals with outstanding communication skills, a commitment to continuous learning, and who are dedicated to promoting the responsible use of AI.

This role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.

In This Role, You Will


 * Prototype, build, and maintain at-scale intelligence systems that detect, triage, and monitor targeted signals from both open-source and internal data
 * Analyze requirements and deliver end-to-end solutions that address complex intelligence challenges while ensuring code quality and scalability
 * Be a crucial technical bridge between our Intelligence needs and technical teams like Platform Integrity, Safety Systems, and Research
 * Contribute to shaping the team’s technical strategy and design user interfaces for non-technical investigators and analysts
 * Prototype new applications to automate team workflows and route leads
 * Report on scaled impact using advanced data analysis and visualization products
 * Work closely with internal stakeholders and address their technical intelligence needs
   
   

You might thrive in this role if you have / are:


 * Experience in engineering and project management, ideally with a focus on security, intelligence, or data analysis products.
 * Strong technical background and proven track record of building and maintaining systems that enable users to make sense of large, open-domain datasets, fight abuse, and inform high-stakes decisions.
 * Proficiency in data analysis, SQL / Python, and application of novel AI techniques for problem-solving.
 * Demonstrated ability to leverage cross-functional teams, manage complex product ecosystems, and deliver results in a fast-paced and sometimes ambiguous environment.
 * Strong belief in & passion for the value of AI in enabling humans to better understand the complexity of the world
   
   

About OpenAI

OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.

We are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.

For additional information, please see OpenAI’s Affirmative Action and Equal Employment Opportunity Policy Statement.

Background checks for applicants will be administered in accordance with applicable law, and qualified applicants with arrest or conviction records will be considered for employment consistent with those laws, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act, for US-based candidates. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.

To notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.

We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.

OpenAI Global Applicant Privacy Policy

At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.

Compensation Range: $220K - $320K","162 applicants","Full-time","Entry level","Engineering and Information Technology","Research Services","$220,000.00/yr - $320,000.00/yr","","","11130470","https://jobs.ashbyhq.com/openai/52c72cb9-7c44-4cba-b440-e05262a38491/application","EXTERNAL",""
"JR Software Developer","Chantilly, VA","3 weeks ago","2025-11-05","https://www.linkedin.com/jobs/view/jr-software-developer-at-probity-inc-4334620505?trk=public_jobs_topcard-title","Probity Inc.","https://www.linkedin.com/company/probityrocks?trk=public_jobs_topcard-org-name","PLEASE NOTE: This position requires an ACTIVE Top Secret/SCI Clearance with Polygraph. To be considered for this position, you MUST have an ACTIVE Clearance Level of Top Secret/SCI with Polygraph

Position Code: 20-SO1002-1

Position Description:

Seeking a highly motivated, self-directed professional to fill a Software Developer role in Chantilly, VA, to provide developer support for systems and tools that process a large volume of data from a variety of sources. The tools are used by analysts and data scientists in support of the customer’s mission. Specifically seeking candidates with experience in software development and data engineering.

Required Qualifications:


 * A master’s degree in Computer Science, Information Systems, Engineering, or additional years of specialized experience in a scientific or technical discipline.
 * Demonstrated experience with Python programming language and its ecosystem (e.g. NumPy, pandas, scikit-learn).
 * Demonstrated experience with Java or Scala programming languages for building scalable data pipelines.
 * Demonstrated experience with SQL, (e.g. MySQL, PostgreSQL, Hive).
 * Familiarity with Apache Hadoop ecosystem (e.g. HDFS, MapReduce, YARN).
 * Knowledge of Apache Spark and its APIs (e.g. Spark SQL, Spark Streaming, Mllib).
 * Experience working in cloud-based data platforms like AWS Glue, Google Cloud Dataflow, or Azure Data Factory.
 * Experience with containerization technologies (e.g. Docker)
 * Experience working with orchestration tools (e.g. Kubernetes, Apache Airflow)
 * Proven experience working in a dynamic working environment.
 * Proven experience working in an Agile scrum teamwork environment.
   
   
   

Additional Qualifications:


 * Excellent communication and collaboration skills.
 * Analytical, critical, and creating thinking and problem-solving skills.
 * Excellent time management skills.
 * Attention to detail.","Be among the first 25 applicants","Full-time","Entry level","Engineering and Information Technology","Information Technology & Services","","","","2310148","https://probity.com/careers-listing/?gnk=job&gni=8a7885a89a31edcc019a556271703dbd&gns=LinkedIn%2BLimited","EXTERNAL",""
"Engineering Innovation Program Leader","Wyoming, MN","13 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/engineering-innovation-program-leader-at-polaris-inc-4340306939?trk=public_jobs_topcard-title","Polaris Inc.","https://www.linkedin.com/company/polarisinc?trk=public_jobs_topcard-org-name","At Polaris Inc., we have fun doing what we love by driving change and innovation. We empower employees to take on challenging assignments and roles with an elevated level of responsibility in our agile working environment. Our people make us who we are, and we create incredible products and experiences that empower us to THINK OUTSIDE.

Position Summary

This Engineering Innovation Leader supports the innovation pipeline – from problem discovery and ideation through evaluation, proof-of-concept, and hand-off into development. It combines strategic portfolio management with hands-on leadership of the innovation process, design-thinking workshops, rapid prototyping, and cross-functional collaboration to accelerate concept maturation and de-risk early-stage initiatives. The position requires strong analytical and storytelling skills to translate insights into ideas, influence evidence-based decisions, and align innovation efforts with overarching business strategy. Success is measured by portfolio throughput, strategic impact, and fostering a culture of innovation across the enterprise.

Responsibilities


 * Own the innovation pipeline and governance: Govern the gate system with clear entry/exit criteria, disciplined review cadence, and crisp go/kill decisions; drive progression from ideation through proof-of-concept to development hand-off.
 * Drive rigorous evaluation and portfolio decisions: Apply standardized scoring against the Innovation Review rubric (IP, income, peak sales, market readiness, risk, strategic alignment, investment) and deliver investable recommendations to leadership forums.
 * Accelerate concept creation and maturation: Lead design-thinking workshops and white-paper sprints, orchestrate rapid prototyping across engineering functions; drive to shorten cycles and de-risk early.
 * Ensure smooth integration to development: Define “definition-of-ready” for Pre-Development and PDP insertion, align requirements with Engineering for clean hand-offs.
 * Build and sustain an innovation culture: Run charrettes/challenges; codify fast-fail learning; align efforts with strategic themes to maximize business impact.
 * Partner externally and internally: Lead make/buy/partner analyses; engage suppliers and universities for feasibility accelerators and benchmarking; maintain strong ties across product and engineering teams
 * Measure what matters: Establish and track portfolio health and impact metrics (idea throughput, ARL cycle time, kill rate, number of charters, innovation vs. pre-dev investment mix, program stability/speed), and publish transparent, actionable readouts.
 * Support end-to-end innovation pipeline: Drive problem discovery, ideation, evaluation, proof-of-concept, and seamless hand-off into development to ensure disciplined progression from concept to execution.
 * Champion adherence to the innovation process: Model best practices and actively coach teams to follow established frameworks, reinforcing consistency and rigor across initiatives.
 * Mentor and develop innovation capabilities: Build organizational competency through coaching, training, and hands-on engagement, fostering a sustainable innovation ecosystem across Polaris Inc.
 * Apply critical thinking and analytics: Leverage structured analysis and data-driven insights to evaluate opportunities, mitigate risk, and optimize portfolio outcomes.
 * Facilitate cross-functional collaboration: Orchestrate technology roadmapping, ideation sessions, and portfolio reviews to align innovation efforts with enterprise priorities and accelerate decision-making.
 * Align innovation with business strategy: Ensure initiatives support overarching objectives and strategic themes, maximizing impact on growth, profitability, and competitive advantage.
   
   

Qualifications


 * Bachelor’s degree in Engineering, STEM, Business, or Strategy; advanced degree a plus.
 * 7+ years in product development/engineering with demonstrated early-stage delivery (concept through proof-of-concept) and prior ownership of stage-gate or ARL processes.
 * Ability to translate customer insights and competitive/macro scans into high-potential problem statements and investable charters; excellence in technical storytelling/white papers.
 * Portfolio judgment using the standard Innovation Review rubric; comfortable facilitating teams to make evidence-based go/kill calls and presenting to leadership.
 * Track record building cross-functional coalitions and running charrettes/white-paper sprints that result in prototypes and charters.
 * Excellent communication and interpersonal skills
 * Experience with start-ups, partnerships, and/or university initiatives and co-development exposure.
 * Prior leadership in running company-wide innovation challenges or innovation ideation initiatives.
 * Execution of engineering design projects, specifically innovation or early product design
   
   

The starting pay range for Minnesota is $104,000 to $137,000 per year. Individual salaries and positioning within the range are determined through a wide variety of factors including but not limited to education, experience, knowledge, skills, and geography. While individual pay could fall anywhere in the range based on these factors, it is not common to start at the high end or top of the range.

To qualify for this position, former employees must be eligible for rehire, and current employees must be in good standing.

We are an ambitious, resourceful, and driven workforce, which empowers us to THINK OUTSIDE. Apply today!

At Polaris we put our employees first, by offering a holistic approach to their health and financial wellbeing. Polaris is proud to offer competitive compensation, including a market-leading profit-sharing plan that is fundamental to our pay-for-performance culture. At Polaris, employees are owners of the company through company contributions to our Employee Stock Ownership Plan and discounted employee stock purchases plan. Employees receive a generous matching contribution to 401(k), financial wellness education and consultation to plan for their financial future. In addition to competitive pay, Polaris provides a comprehensive suite of benefits, including health, dental, and vision insurance, wellness programs, paid time off, gym & personal training reimbursement, life insurance and disability offerings. Through the Polaris Foundation and our Polaris Gives paid volunteer time off, we support employees who actively volunteer their time, efforts, and passions to improve the health and wellbeing of the communities in which they live, play and work. Employees at Polaris drive our success and are rewarded for their commitment.

About Polaris

As the global leader in powersports, Polaris Inc. (NYSE: PII) pioneers product breakthroughs and enriching experiences and services that have invited people to discover the joy of being outdoors since our founding in 1954. Polaris' high-quality product line-up includes the Polaris RANGER®, RZR® and Polaris GENERAL™ side-by-side off-road vehicles; Sportsman® all-terrain off-road vehicles; military and commercial off-road vehicles; snowmobiles; Indian Motorcycle® mid-size and heavyweight motorcycles; Slingshot® moto-roadsters; Aixam quadricycles; Goupil electric vehicles; and pontoon and deck boats, including industry-leading Bennington pontoons. Polaris enhances the riding experience with a robust portfolio of parts, garments, and accessories. Proudly headquartered in Minnesota, Polaris serves more than 100 countries across the globe. www.polaris.com

EEO Statement

Polaris Inc. is an Equal Opportunity Employer and will make all employment-related decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, age, disability, marital status, familial status, status with regard to public assistance, membership or activity in a local commission, protected veteran status, or any other status protected by applicable law. Applicants with a disability that are in need of an accommodation to complete the application process, or otherwise need assistance or an accommodation in the recruiting process, should contact Human Resources at 800-765-2747 or Talent.Acquisition@Polaris.com. To read more about employment discrimination protection under U.S. federal law, see: Know Your Rights: Workplace Discrimination is Illegal (eeoc.gov).

EEO/AA/M/F/Vets/Disabled

","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Motor Vehicle Manufacturing, Manufacturing, and Armed Forces","$104,000.00/yr - $137,000.00/yr","","","8885","https://www.linkedin.com/jobs/view/engineering-innovation-program-leader-at-polaris-inc-4340306939?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr. Data Engineer","Greater Birmingham, Alabama Area","4 weeks ago","2025-11-04","https://www.linkedin.com/jobs/view/sr-data-engineer-at-oakworth-capital-bank-4334321072?trk=public_jobs_topcard-title","Oakworth Capital Bank","https://www.linkedin.com/company/oakworth-capital-bank?trk=public_jobs_topcard-org-name","Job Details

Job Location

Central Alabama - Birmingham, AL

Position Type

Full Time

Job Shift

Day

Job Category

Information Technology

Description

Oakworth Capital Bank is expanding and has an excellent opportunity for someone to join our team in Birmingham, AL! We are looking for a full-time Sr. Data Engineer that will play a vital role in supporting our current & future clients. An ideal candidate would meet the qualifications listed below, and more importantly, be able to demonstrate that they live by Oakworth Core Values (Golden Rule, Character, Innovative Spirit, Professionalism, Work Ethic).

Summary

The Senior Data Engineer is responsible for building and maintaining a reliable, scalable data platform that supports analytics, reporting, and operational needs across the business. This is a hands-on, execution-focused role grounded in practical data engineering by owning data pipelines, transformations, and infrastructure that can support growth and evolve with the organization’s needs.

Key Roles/Responsibilities


 * Design, build, and maintain secure, observable ELT pipelines using Python and SQL, supporting structured ingestion from internal systems and external vendors.
 * Lead the transition of legacy, on-prem data flows into a scalable, cloud-based architecture aligned with current and future business needs.
 * Own transformation logic and data modeling patterns to support BI, regulatory reporting, and operational analytics—using tools like dbt where appropriate.
 * Define and enforce structure including naming, documentation, testing and implement monitoring across pipeline health, job failures, and data quality.
 * Collaborate with stakeholders to translate business needs into structured data assets and contribute to broader architectural decisions, including tooling and modeling strategy, while aligning all work with data governance and security expectations.
   
   

Responsibility Details


 * Own the design and execution of core data pipelines that are structured, testable, and observable.
 * Model datasets to support Power BI and other downstream analytics tools.
 * Manage transformations using Python and/or SQL-based modeling tools (e.g., dbt).
 * Contribute to architectural decisions such as storage, orchestration, and modeling patterns as the platform evolves.
 * Interface with application owners, analysts, and business users to translate needs into structured data models.
 * Maintain operational documentation and pipeline transparency for continuity and support.
 * Ensure pipelines and assets align with governance expectations, including access, retention, and classification.
   
   

Qualifications And Skills


 * Bachelor’s degree in computer science, information systems, or a related technical field
 * 5+ years in data engineering, including experience in a cloud environment
 * Deep SQL expertise across platforms (e.g., PostgreSQL, SQL Server, cloud-native warehouse platforms)
 * Strong Python skills for data processing and integration (pandas, polars, etc.)
 * Experience with dbt or similar modeling frameworks preferred
 * Familiarity with orchestration and deployment tooling (e.g., Dagster, Airflow, Azure Data Factory, GitHub Actions)
 * Proven ability to support and scale data infrastructure in a business-facing environment
 * Financial services experience is preferred
   
   

Oakworth has been recognized as a Best Bank to Work For by American Banker Magazine for the last eight years, with six of those holding the top spot & ranking #2 in 2024. To learn more about our story and what makes Oakworth unique, visit https://www.oakworth.com/.

If you are interested in this excellent opportunity, please send your resume to brooke.kline@oakworth.com.","39 applicants","Full-time","Mid-Senior level","Information Technology","Financial Services","","","","1752456","https://www.linkedin.com/jobs/view/sr-data-engineer-at-oakworth-capital-bank-4334321072?trk=public_jobs_topcard-title","EASY_APPLY",""
"Manager, Applied Data Science","Oakland, CA","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/manager-applied-data-science-at-pacific-gas-and-electric-company-4324681087?trk=public_jobs_topcard-title","Pacific Gas and Electric Company","https://www.linkedin.com/company/pacificgasandelectric?trk=public_jobs_topcard-org-name","Requisition ID # 168813

Job Category: Accounting / Finance

Job Level: Manager/Principal

Business Unit: Operations - Other

Work Type:

Job Location: Oakland

Department Overview

The aim of the Applied Data Science team in the Wildfire Mitigation organization is to enhance the risk practices of PG&E’s Electric Operation business and thereby address changing external conditions such as climate change. To this end the Applied Data Science team integrates predictive models into PG&E’s work planning processes. These models and tools provide a multi-layered view of risk and risk reduction across the electric system so that decision-making processes include and empower employees at all levels of the company to manage risk appropriately.

Sample activities include:


 * Development of tools to monitor wildfire mitigation program performance on the distribution and transmission electric system.
 * Development of tools and dashboards to track electric system risk and risk reduction.
 * Support for regulatory filings like the Wildfire Mitigation Plan (WMP).
   
   

Position Summary

Oversees the data science function, which uses predictive modeling, machine learning (ML), optimization, simulation and artificial intelligence (AI) solutions to provide future-focused data driven decisions used by the enterprise. Leads the development of expertise and knowledge in data science, machine learning, mathematics, and statistics to solve specific problems, as well as technology development of large data sets from multiple systems as related to solving those problems. Actively participates in the larger, external community of data science and risk management by monitoring emerging trends and leading strategies to capitalize impact and lower risk.

This position is hybrid, working from your remote office and your assigned location based on business need.

PG&E is providing the salary range that can reasonably be expected for this position at the time of the job posting. This salary range is specific to the locality of the job. The actual salary paid to an individual will be based on multiple factors, including, but not limited to, internal equity, specific skills, education, licenses or certifications, experience, market value, and geographic location. The decision will be made on a case-by-case basis related to these factors. This job is also eligible to participate in PG&E’s discretionary incentive compensation programs.

Bay Area – $159,000 - $236,500

Job Responsibilities


 * Manages data scientist teams to accomplish results through effective recruitment and selection, training and development, performance management and coaching, and rewards and recognition.
 * Works with enterprise leaders to identify and solve business problems requiring the implementation of data science, machine learning and risk management.
 * Utilizes deep understanding of business drivers and financial levers, along with instrumental data science techniques, to prioritize work and provide strategic decision support.
 * Ensures compliance with standards and processes to improve quality and timeliness of predictive models and risk optimization tools.
 * Acts as peer reviewer for code scripts and model development for narrow scope projects. Reviews and approves the maturity for release of technical features in data science products.
 * Conducts risk-evaluation studies of model impact on business outcomes.
 * Assesses business implications associated with modeling assumptions, types of inputs, statistical methodologies, programming approach, etc.
 * Monitors the development of data science, machine learning, artificial intelligence, mathematical modeling and optimization, and similar emerging technologies to continuously assess their impact on business strategies. Participates with peers in risk and maturity assessment of data science and decision tools.
 * Develops budget (expense, capital, and expenditures) and monitor, forecast and report on budget performance.
   
   

Qualifications

Minimum:


 * Bachelor's degree in Statistics, Mathematics, Applied Science, Data Science, Engineering, Physics, Economics, or equivalent field
 * 2 years hands-on experience in data science (or no experience, if possess Advanced Degree, as described above)
 * 2 years of leadership experience in data science
   
   

Desired:


 * Advanced degree in Statistics, Mathematics, Applied Science, Data Science, Engineering, Physics, Economics, or equivalent field.
 * Utility industry experience, electric or gas, or other job-related, 3 years
 * Experience with data science and machine learning algorithms (supervised, unsupervised), ML domains (computer vision, NLP, etc.).
 * Experience with the following:
    * a) Statistics: statistical modeling, experimental design, sampling, clustering, data reduction, confidence intervals, testing, modeling, predictive modeling and other related techniques;
    * b) Artificial Intelligence: machine learning, predictive analytics, as they collect, analyze and extract value out of data; simulation;
    * c) Software Engineering: programming languages, big data wrangling packages, cloud services, APIs, and related tools.

 * Making sense of complex, high quantity, and sometimes contradictory information to effectively solve problems.
 * Ability to clearly and concisely communicate and present complex analysis to both quantitative and non-quantitative audiences.
 * Ability to apply project management theories, concepts, methods, best practices, and techniques as needed to perform at the job level. Domain expertise: familiarity with one or more line of business (electric, customer, generation, procurement, gas, risk, etc.) and ability to identify areas where data science can improve processes and inform decision making (this may also include familiarity with the datasets/databases that support these lines of business)","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Utilities","","","","3895","https://www.linkedin.com/jobs/view/manager-applied-data-science-at-pacific-gas-and-electric-company-4324681087?trk=public_jobs_topcard-title","EASY_APPLY",""
"Business Intelligence Analyst","Columbus, OH","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/business-intelligence-analyst-at-mckesson-4334327757?trk=public_jobs_topcard-title","McKesson","https://www.linkedin.com/company/mckesson?trk=public_jobs_topcard-org-name","McKesson is an impact-driven, Fortune 10 company that touches virtually every aspect of healthcare. We are known for delivering insights, products, and services that make quality care more accessible and affordable. Here, we focus on the health, happiness, and well-being of you and those we serve – we care.

What you do at McKesson matters. We foster a culture where you can grow, make an impact, and are empowered to bring new ideas. Together, we thrive as we shape the future of health for patients, our communities, and our people. If you want to be part of tomorrow’s health today, we want to hear from you.

As a Business Intelligence Analyst on the Reporting & Performance Analytics Team, you will play a pivotal role in partnering with data engineering to transform raw data into structured, reliable, and actionable insights that power one of the most ambitious product launches in CoverMyMeds’ history.

You will be responsible for building the data foundation that supports internal product development, external provider engagement, and biopharma customer reporting. Your work will directly impact how quickly patients access life-saving therapies, how effectively providers engage with the platform, and how biopharma clients measure success.

Key Responsibilities

Data Integration & Normalization


 * Collaborate with data engineering and product teams to ingest and normalize data from multiple sources (EHRs, 3rd party aggregators, benefit verification systems, etc.).
 * Ensure data quality, consistency, and completeness across all reporting pipelines.
   
   
   

Data Modeling & Infrastructure


 * Working with the data engineering team, design and maintain scalable data models that support evolving reporting needs across MVP and future phases.
   
   
   

Analytical Support


 * Partner with the Senior Reporting Leader to define KPIs and metrics aligned with strategic goals (e.g., time to therapy, BI/BV/PA approval and accuracy rates, user engagement).
 * Prepare datasets for visualization and advanced analytics, ensuring they are accurate, timely, and well-documented.
   
   
   

Cross-Functional Collaboration


 * Serve as the connective tissue between data engineering, product, and commercial teams to ensure data is usable and aligned with business needs.
 * Support ad hoc data requests and exploratory analysis to inform product decisions and customer conversations.
   
   
   

What Makes This Role Unique


 * Strategic Impact: You will be the data engine behind a platform that could define the future of medical benefit drug access—an area with no current industry leader.
 * Greenfield Opportunity: With no legacy systems to constrain you, you’ll help build the data architecture from the ground up.
 * High Visibility: Your work will directly support executive decision-making and be showcased to top-tier biopharma clients.
 * Collaborative Innovation: You’ll work alongside a senior analytics leader and, soon, a visualization specialist to create a best-in-class insights engine—not just dashboards.
   
   
   

Candidate must be based in the metropolitan area of our hub city Columbus, OH. Position will primarily allow for remote working.

We are unable to provide sponsorship now or in the future for this position.

Minimum Qualifications:

Degree or equivalent and typically requires 4+ years of relevant experience

Education:

Bachelor’s or Master’s degree in Data Science, Computer Science, Information Systems, or a related field.

Critical Skills:


 * 3+ years of experience in data engineering, analytics, or a similar role.
 * Strong proficiency in SQL and data modeling; experience with Python or R is a plus.
 * Familiarity with cloud data platforms (e.g., Snowflake, Azure, FHIR).
 * Experience working with healthcare or biopharma data is highly desirable.
 * Strong communication skills and a collaborative mindset.
   
   
   

We are proud to offer a competitive compensation package at McKesson as part of our Total Rewards. This is determined by several factors, including performance, experience and skills, equity, regular job market evaluations, and geographical markets. The pay range shown below is aligned with McKesson's pay philosophy, and pay will always be compliant with any applicable regulations. In addition to base pay, other compensation, such as an annual bonus or long-term incentive opportunities may be offered. For more information regarding benefits at McKesson, please click here.

Our Base Pay Range for this position

$84,800 - $141,300

McKesson is an Equal Opportunity Employer

McKesson provides equal employment opportunities to applicants and employees and is committed to a diverse and inclusive environment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, age or genetic information. For additional information on McKesson’s full Equal Employment Opportunity policies, visit our Equal Employment Opportunity page.

Join us at McKesson!","Over 200 applicants","Full-time","Mid-Senior level","Research, Analyst, and Information Technology","Hospitals and Health Care","$84,800.00/yr - $141,300.00/yr","","","1900","https://www.linkedin.com/jobs/view/business-intelligence-analyst-at-mckesson-4334327757?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Director Data Center Engineering","Texas, United States","2 weeks ago","2025-11-17","https://www.linkedin.com/jobs/view/senior-director-data-center-engineering-at-oracle-4287188275?trk=public_jobs_topcard-title","Oracle","https://www.linkedin.com/company/oracle?trk=public_jobs_topcard-org-name","Job Description

Oracle Cloud Infrastructure (OCI) is seeking an accomplished Senior Director of Data Center Engineering to lead advanced engineering initiatives that enable OCI’s hyperscale data centers to support the next generation of cloud and AI workloads. This leader will oversee critical functions including computational fluid dynamics (CFD) modeling, dynamic power distribution analysis, on-site generation (OSG) integration, grid stability studies, infrastructure telemetry, and service-level engineering for compute, storage and network hardware. The ideal candidate will combine deep technical expertise with strong leadership skills to drive innovation, efficiency, and resiliency across OCI’s global data center portfolio.

Why Join OCI? As the Senior Director of Data Center Engineering, you will play a pivotal role in advancing the performance, resiliency, and sustainability of OCI’s global infrastructure. This is a unique opportunity to shape the engineering foundation for the cloud and AI workloads that define the future of technology.

Responsibilities

Key Responsibilities:


 * Lead a global engineering team supporting OCI’s data center design and operations through advanced analysis, modeling, and validation.
 * Oversee CFD modeling of airflow and thermal performance to optimize facility and IT cooling strategies.
 * Direct dynamic power distribution modeling, including integration of on-site generation systems, grid interconnection, and stability analysis.
 * Establish engineering standards and simulation methodologies to validate design intent and operational performance.
 * Develop and implement telemetry and data analytics frameworks for IT equipment (ITE) and infrastructure to improve efficiency and resiliency.
 * Act as the primary engineering interface with OCI hardware development and architecture teams, ensuring alignment between ITE requirements and data center capabilities.
 * Partner with data center design, construction, and operations teams to ensure engineered solutions scale reliably and sustainably.
 * Provide technical leadership in evaluating emerging technologies, renewable integration, and AI/ML-driven optimization strategies.
 * Present engineering strategies, risk assessments, and performance metrics to senior executives and stakeholders.
 * Mentor and grow a high-performing team of engineers, fostering innovation, technical excellence, and collaboration.
   
   
   

Minimum Requirements:


 * Bachelor’s degree in Electrical/Mechanical Engineering, Computer Engineering, or a related technical field (Master’s degree preferred).
 * 10+ years of experience in data center engineering, design, or operations, with at least 5 years in a senior leadership role.
 * Proven expertise in CFD modeling, power distribution modeling, and electrical grid/OSG integration.
 * Strong knowledge of IT hardware requirements, infrastructure systems, and service-level engineering practices.
 * Experience with telemetry systems, data collection, and analytics for performance optimization.
 * Demonstrated success in leading complex, large-scale engineering programs in fast-paced environments.
 * Excellent communication, collaboration, and leadership skills with the ability to influence cross-functional and executive stakeholders.
   
   
   

Preferred Qualifications:


 * Master’s or PhD in Engineering, Applied Physics, or a related technical discipline.
 * Experience with hyperscale cloud or AI-driven data center infrastructure.
 * Expertise in renewable energy integration, OSG microgrids, and advanced energy storage technologies.
 * Familiarity with AI/ML-based predictive modeling, automation, and optimization in data centers.
 * Strong vendor and partner management experience in engineering services and technology development.
 * Background in both greenfield and retrofit/expansion data center projects.
   
   
   

Qualifications

Disclaimer:

Certain US customer or client-facing roles may be required to comply with applicable requirements, such as immunization and occupational health mandates.

Range and benefit information provided in this posting are specific to the stated locations only

US: Hiring Range in USD from: $161,700 - $338,500 per year. May be eligible for bonus, equity, and compensation deferral.

Oracle maintains broad salary ranges for its roles in order to account for variations in knowledge, skills, experience, market conditions and locations, as well as reflect Oracle’s differing products, industries and lines of business.

Candidates are typically placed into the range based on the preceding factors as well as internal peer equity.

Oracle US offers a comprehensive benefits package which includes the following:


 * Medical, dental, and vision insurance, including expert medical opinion
 * Short term disability and long term disability
 * Life insurance and AD&D
 * Supplemental life insurance (Employee/Spouse/Child)
 * Health care and dependent care Flexible Spending Accounts
 * Pre-tax commuter and parking benefits
 * 401(k) Savings and Investment Plan with company match
 * Paid time off: Flexible Vacation is provided to all eligible employees assigned to a salaried (non-overtime eligible) position. Accrued Vacation is provided to all other employees eligible for vacation benefits. For employees working at least 35 hours per week, the vacation accrual rate is 13 days annually for the first three years of employment and 18 days annually for subsequent years of employment. Vacation accrual is prorated for employees working between 20 and 34 hours per week. Employees working fewer than 20 hours per week are not eligible for vacation.
 * 11 paid holidays
 * Paid sick leave: 72 hours of paid sick leave upon date of hire. Refreshes each calendar year. Unused balance will carry over each year up to a maximum cap of 112 hours.
 * Paid parental leave
 * Adoption assistance
 * Employee Stock Purchase Plan
 * Financial planning and group legal
 * Voluntary benefits including auto, homeowner and pet insurance
   
   
   

The role will generally accept applications for at least three calendar days from the posting date or as long as the job remains posted.

Career Level - M5

About Us

As a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle today’s challenges. We’ve partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity.

We know that true innovation starts when everyone is empowered to contribute. That’s why we’re committed to growing an inclusive workforce that promotes opportunities for all.

Oracle careers open the door to global opportunities where work-life balance flourishes. We offer competitive benefits based on parity and consistency and support our people with flexible medical, life insurance, and retirement options. We also encourage employees to give back to their communities through our volunteer programs.

We’re committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation-request_mb@oracle.com or by calling +1 888 404 2494 in the United States.

Oracle is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans’ status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law.","27 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","IT Services and IT Consulting","$161,700.00/yr - $338,500.00/yr","","","1028","https://eeho.fa.us2.oraclecloud.com/hcmUI/CandidateExperience/en/job/305804/?utm_medium=jobboard&utm_source=LinkedIn","EXTERNAL",""
"Machine Learning Scientist","New York, NY","3 weeks ago","2025-11-07","https://www.linkedin.com/jobs/view/machine-learning-scientist-at-the-new-york-times-4334653304?trk=public_jobs_topcard-title","The New York Times","https://www.linkedin.com/company/the-new-york-times?trk=public_jobs_topcard-org-name","The mission of The New York Times is to seek the truth and help people understand the world. That means independent journalism is at the heart of all we do as a company. It’s why we have a world-renowned newsroom that sends journalists to report on the ground from nearly 160 countries. It’s why we focus deeply on how our readers will experience our journalism, from print to audio to a world-class digital and app destination. And it’s why our business strategy centers on making journalism so good that it’s worth paying for.

About The Role

The New York Times is a technology company committed to producing the world's most reliable and highest quality journalism. Our ability to do so relies on a talented team of expert technologists who help NYT learn from a tremendous abundance of data unique to this company.

The Algorithmic Recommendations and Audience Data Science team aims to help users discover content across the Times' website, apps and emails by applying algorithms that make use of information about our readers' behavior and our editorial judgment. We also build internal tools for the newsroom to better understand story performance and coverage trends. We are a group of machine learning scientists and data analysts that partner with teams across The New York Times. We are looking for a Machine Learning Scientist to join the team and apply machine learning methods to meet this challenge. You will report to a Lead Machine Learning Scientist, and collaborate with partners across the company.

Responsibilities


 * You will reframe business and newsroom goals as machine learning tasks that deliver accurate predictions, relevant insights, and optimization
 * You will adapt or develop machine learning algorithms in cases when existing algorithms are insufficient, while implementing simple approaches when appropriate
 * You will implement and deploy machine learning research with robustness and reproducibility, with consideration of risks and trade-offs
 * You will turn models into data products, collaborate with engineering teams, and integrate into processes throughout The Times
 * You will communicate complex ideas in machine learning while collaborating with technical and non-technical colleagues in in engineering, analytics, product management, marketing, editorial, and executive leadership groups
 * Demonstrate support and understanding of our value of journalistic independence and a strong commitment to our mission to seek the truth and help people understand the world.
   
   

Basic Qualifications


 * PhD, MS + 2 years experience, or 3+ years work experience in machine learning, statistics, computational social science, applied mathematics, or another quantitative/computational discipline
 * 2+ years experience with open source machine learning or statistical analysis tools
 * 2+ years coding experience in Python
 * 2+ years experience in SQL and manipulating large structured or unstructured datasets for analysis
   
   

Preferred Qualifications


 * 1+ year of experience with recommendation systems, including content-based methods using natural language processing
 * 1+ years of experience with deep learning architectures, including embedding methods and Pytorch or Tensorflow
 * 1+ years of experience translating ambiguous business questions into machine learning problems
 * 1+ years of experience building data products, either internal or consumer-facing
   
   

REQ-019073

The annual base pay range for this role is between:

$121,000 - $131,000 USD

The New York Times Company is committed to being the world’s best source of independent, reliable and quality journalism. To do so, we embrace a diverse workforce that has a broad range of backgrounds and experiences across our ranks, at all levels of the organization. We encourage people from all backgrounds to apply.

We are an Equal Opportunity Employer and do not discriminate on the basis of an individual's sex, age, race, color, creed, national origin, alienage, religion, marital status, pregnancy, sexual orientation or affectional preference, gender identity and expression, disability, genetic trait or predisposition, carrier status, citizenship, veteran or military status and other personal characteristics protected by law. All applications will receive consideration for employment without regard to legally protected characteristics. The U.S. Equal Employment Opportunity Commission (EEOC)’s Know Your Rights Poster is available here.

The New York Times Company will provide reasonable accommodations as required by applicable federal, state, and/or local laws. Individuals seeking an accommodation for the application or interview process should email reasonable.accommodations@nytimes.com. Emails sent for unrelated issues, such as following up on an application, will not receive a response.

The Company encourages those with criminal histories to apply, and will consider their applications in a manner consistent with applicable ""Fair Chance"" laws, including but not limited to the NYC Fair Chance Act, the Los Angeles Fair Chance Initiative for Hiring Ordinance, the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act.

For information about The New York Times' privacy practices for job applicants click here.

Please beware of fraudulent job postings. Scammers may post fraudulent job opportunities, and they may even make fraudulent employment offers. This is done by bad actors to collect personal information and money from victims. All legitimate job opportunities from The New York Times will be accessible through The New York Times careers site. The New York Times will not ask job applicants for financial information or for payment, and will not refer you to a third party to do so. You should never send money to anyone who suggests they can provide employment with The New York Times.

If you see a fake or fraudulent job posting, or if you suspect you have received a fraudulent offer, you can report it to The New York Times at NYTapplicants@nytimes.com. You can also file a report with the Federal Trade Commission or your state attorney general.","Over 200 applicants","Full-time","Mid-Senior level","Other","Newspaper Publishing","$121,000.00/yr - $131,000.00/yr","","","4236","https://www.linkedin.com/jobs/view/machine-learning-scientist-at-the-new-york-times-4334653304?trk=public_jobs_topcard-title","EASY_APPLY",""
"SQL Database Administrator","St Louis, MO","5 days ago","2025-11-26","https://www.linkedin.com/jobs/view/sql-database-administrator-at-veridian-tech-solutions-inc-4324545192?trk=public_jobs_topcard-title","Veridian Tech Solutions, Inc.","https://www.linkedin.com/company/veridian-tech-solutions-inc.?trk=public_jobs_topcard-org-name","Role: PostgreSQL DBA

Location: St Louis, MO (Onsite)




Job Description

PostgreSQL




Overview

• Represent Database Engineering team as a subject matter expert in EDB Postgres, Postgres Distributed (PGD), and AWS relational database services. Expectation is Level 3 and above with good AWS Experience

• Continuously seek opportunities to improve efficiency and integrate technologies and platforms within the Postgres and related domains.

• Provide leadership and contribute to technology roadmaps supporting vision for Postgres and other relational database technologies.

• Possess experience with data migration and integration across multiple systems.




Roles and Responsibilities

• Excellent interpersonal and communication skills.

• Strong collaboration skills to work effectively across cross-functional teams.

• Forward-thinking approach to infrastructure automation and scripting.

• Ability to work with global teams across multiple time zones.

• Self-motivated with the ability to work independently and seek guidance when needed.

• Ability to understand application data requirements and recommend appropriate database solutions.

• Responsible for designing, deploying, and maintaining EDB Postgres, PGD and AWS RDS database clusters to support large-scale platforms and applications.

• Create and manage fully functional database clusters across development, QA, and production environments, with experience in performance tuning.

• Review existing configurations and recommend improvements.

• Assist with planning and executing Postgres database upgrades and migrations.

• Provide day-to-day administrative support and maintenance for Postgres and AWS Aurora databases.

• Participate in production support and on-call rotations as needed.

• Collaborate with Postgres and cloud vendors and utilize their support channels.

• Develop and implement backup strategies, perform upgrades, and apply patches.

• Identify inefficiencies and implement optimized solutions.

• Design and execute data and database migrations to new hardware or platforms.

• Lead best practices and database solution strategies

• Work with management to plan and implement new tools and data services.

• Represent Database Engineering in strategic planning and long-term direction.

• Support both internal and future cloud-managed Postgres systems, define best practices, and drive automation and innovation.

• Collaborate with multiple application teams and developers.

• Assist in defining lon g-term strategic goals for database development in alignment with stakeholders.




Required Skills:

• Experience in the design, maintenance, and administration of EDB Postgres, Postgres Distributed and AWS RDS.

• Deep understanding of EDB Postgres architecture and internals.

• Expertise in Table Partitioning on Large Data sets

• Proficient in PostgreSQL installation and configuration, especially PostgreSQL Plus Advanced Server and Postgres Distributed from EnterpriseDB.

• Skilled in PostgreSQL monitoring and alerting tools, particularly PEM. Familiarity with observability tools like Splunk and Dynatrace is a plus.

• Experienced in setting up, configuring, and monitoring PostgreSQL binary and logical replication (e.g., Binary Streaming, Bi-Directional Replication - BDR).

• Strong skills in collecting diagnostics and tuning PostgreSQL and SQL performance.

• Proficient in PostgreSQL procedural languages (PL/pgSQL, PL/Tcl, PL/Perl, PL/Python) and SQL.

• Excellent troubleshooting and debugging skills.

• Experience in performance tuning and automation for Postgres and AWS platforms.

• Proficient in Linux, especially Oracle Linux Enterprise.

• Familiarity with scripting languages such as Bash, KSH, and Perl.","65 applicants","Full-time","Mid-Senior level","Information Technology","IT Services and IT Consulting","$100,000.00/yr - $100,000.00/yr","","","33125878","https://www.linkedin.com/jobs/view/sql-database-administrator-at-veridian-tech-solutions-inc-4324545192?trk=public_jobs_topcard-title","EASY_APPLY",""
"AI & Cloud Engineer - Remote","Phoenix, AZ","17 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/ai-cloud-engineer-remote-at-coreai-consulting-4340315142?trk=public_jobs_topcard-title","CoreAi Consulting","https://www.linkedin.com/company/core-ai-consulting?trk=public_jobs_topcard-org-name","We are seeking a highly skilled Mid–Senior Level Engineer with strong expertise in Python, AWS cloud services, containerization, and modern AI/ML technologies. The ideal candidate has hands-on experience designing scalable data ingestion pipelines, deploying GenAI/LLM solutions, and building retrieval-augmented and agentic systems for enterprise use cases. This role involves end-to-end solution design—data, infrastructure, orchestration, and model integration—across cloud-native environments.




Key Responsibilities

 * Design, develop, and deploy scalable applications and microservices using Python and AWS services (Lambda, ECS/EKS, S3, DynamoDB, API Gateway, Bedrock, CloudFormation, etc.).
 * Build and maintain containerized workloads using Docker, GitHub workflows, and CI/CD automation.
 * Develop robust data ingestion and processing pipelines integrating structured/unstructured data sources.
 * Implement GenAI solutions using LLMs, embeddings, vector databases (Pinecone, FAISS, Redis, etc.), and RAG architectures.
 * Build and manage knowledge bases, embedding pipelines, and context-retrieval systems optimized for real-world performance.
 * Design and orchestrate agentic workflows using modern agentic frameworks and multi-agent patterns for automation and decision-making.
 * Work with AWS Bedrock to integrate foundation models, manage guardrails, tune prompts, and optimize model performance.
 * Implement secure, scalable infrastructure using CloudFormation, IAM, VPC, and AWS networking best practices.
 * Collaborate with cross-functional teams (data, product, engineering) to translate requirements into technical designs.
 * Monitor, troubleshoot, and optimize production AI/ML workloads, including inference performance, latency, cost, and reliability.
 * Maintain strong code quality standards through GitHub version control, documentation, and automated testing.




Required Skills & Experience

 * 8+ years of professional experience in software engineering, cloud engineering, or ML/AI development.
 * Expert-level programming skills in Python (FastAPI, Flask, Async frameworks preferred).
 * Deep experience with AWS services, including serverless and container architectures.
 * Hands-on experience with Docker, CI/CD, and IaC tools like CloudFormation or CDK.
 * Proven experience building RAG pipelines, vector store integrations, and embedding workflows.
 * Strong understanding of LLMs, prompt engineering, model evaluation, and generative AI development.
 * Experience with agentic orchestration (LangChain, LlamaIndex, custom agent frameworks, or AWS Agents).
 * Experience integrating with AWS Bedrock or similar foundation model platforms.
 * Solid understanding of distributed systems, API development, security, and cloud-native patterns.
 * Strong problem-solving abilities and the ability to work independently in fast-paced environments.

","115 applicants","Full-time","Mid-Senior level","Information Technology","Financial Services","","","","102685873","https://www.linkedin.com/jobs/view/ai-cloud-engineer-remote-at-coreai-consulting-4340315142?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Analyst - Enterprise Systems & Business Intelligence","Herndon, VA","4 days ago","2025-11-28","https://www.linkedin.com/jobs/view/data-analyst-enterprise-systems-business-intelligence-at-kda-consulting-inc-4347861624?trk=public_jobs_topcard-title","KDA CONSULTING INC","https://www.linkedin.com/company/kda-consulting-inc?trk=public_jobs_topcard-org-name","We’re seeking a mission-aligned, strategically-minded Data Analyst to support enterprise-wide visibility and decision intelligence across business, engineering, operations, cost, performance, and security data.

In this role, you’ll lead the analysis, visualization, and interpretation of data from enterprise platforms like Splunk IT Service Intelligence (ITSI) and ServiceNow, transforming raw inputs into powerful insights and executive dashboards using Power BI and Tableau.

The ideal candidate understands the end-to-end data engineering lifecycle, and brings rigor to the testing, verification, and validation (V&V) of data pipelines and collections to ensure accuracy, reliability, and trust.

Core Position Responsibilities


 * Analyze and interpret complex data sets across enterprise domains—cost, performance, service operations, engineering workflows, and cybersecurity.
 * Leverage Splunk ITSI to develop and manage KPIs, service definitions, glass tables, and episode dashboards to provide real-time insights and visibility.
 * Design and deliver dynamic, intuitive dashboards in Power BI and Tableau that communicate key metrics to both technical and executive audiences.
 * Collaborate with stakeholders across IT, business, and finance to translate mission needs into analytical solutions and forecast models.
 * Partner with data engineering teams to understand data flows, support validation processes, and ensure quality across source systems and downstream products.
 * Perform and document testing, verification, and validation (V&V) of data pipelines and collections to ensure integrity and trustworthiness.
 * Contribute to data governance and data quality frameworks across enterprise systems.
   
   

Required Skills & Experience


 * Position requires an Active Top Secret/SCI with Full Scope Polygraph
 * Bachelor's Degree required, Master's preferred
 * 12+ years of related work experience
 * Demonstrated experience analyzing business, engineering, cost, and security data across enterprise platforms.
 * Hands-on expertise in Splunk ITSI, including configuration of services, KPIs, and service health monitoring tools.
 * Strong skills in Power BI, Tableau, SQL, and Excel for analysis, modeling, and executive reporting.
 * Familiarity with ServiceNow data models, workflows, and reporting structures.
 * Understanding of the data engineering lifecycle and collaboration with data pipeline teams.
 * Experience with data validation and V&V processes to ensure the accuracy, completeness, and consistency of data used in decision-making.
   
   

Preferred Qualifications


 * Experience in Agile, Scrum, or ITIL-aligned operational environments.
 * Familiarity with modern data platforms (data lakes, cloud data environments) and structured/unstructured data management.
 * Ability to create multi-layered dashboards that serve business, operations, and technical audiences.
 * Clear communicator with a strong ability to translate complex analysis into actionable insights aligned to mission objectives.
 * Curiosity-driven and impact-oriented—driven to uncover the “why,” not just the “what.","Be among the first 25 applicants","Full-time","Mid-Senior level","Information Technology","IT Services and IT Consulting","","","","15749701","https://www.linkedin.com/jobs/view/data-analyst-enterprise-systems-business-intelligence-at-kda-consulting-inc-4347861624?trk=public_jobs_topcard-title","EASY_APPLY",""
"Sr Data Scientist, Manufacturing Science and Technology","Bedford, MA","2 weeks ago","2025-11-14","https://www.linkedin.com/jobs/view/sr-data-scientist-manufacturing-science-and-technology-at-ultragenyx-4340519674?trk=public_jobs_topcard-title","Ultragenyx","https://www.linkedin.com/company/ultragenyx?trk=public_jobs_topcard-org-name","Why Join Us?

Be a hero for our rare disease patients

At Ultragenyx, we fundamentally believe that taking real impactful action to care for the needs of patients and our people is always the right thing to do. To achieve this goal, our vision is to lead the future of rare disease medicine. For us, this means going where other biopharma companies won’t go – challenging the status quo and creating a new model that advances our field so more patients and caregivers can benefit from life-changing treatments. We do this by following the science, applying a novel rapid development approach, making innovative medicines at fair and reasonable prices, and creating a collaborative ecosystem to reach patients in ways that are most meaningful for them.

Our commitment and care for patients extends to our people, so culture is an essential cornerstone for Ultragenyx. We remain continuously focused on creating a supportive and inclusive environment of profound learning and growth – so employees can thrive in all areas of their lives, in and outside of work. Ultimately, we want to be an organization where we would be proud for our family, friends and children to work.

If you want to have a meaningful impact, do the best work of your career, and grow a lot, both professionally and personally, come join our team.

Position Summary:

ultrafocused – Work together to fearlessly uncover new possibilities

The Sr Data Scientist, Manufacturing Science and Technology (MSAT) will provide technical leadership to support both early- and late-stage AAV GMP manufacturing at internal and contract gene therapy facilities. Reporting to the Sr. Director of MSAT, this role will focus on developing data management solutions to enable monitoring the ongoing GMP production and drive process improvements for future lifecycle management. The ideal candidate will bring a strong foundation in biologics/AAV process knowledge combined with statistical expertise. Success in this role requires a high degree of professionalism, cross-functional collaboration, and an innovative mindset.

Work Model:

Core Lab & Ops: This role typically requires that the majority of the work be conducted on-site.

Responsibilities:


 * Build and implement the Continued Process Verification (CPV) framework for AAV programs, including online/offline data management solutions, data integrity verification process, statistical tools and predictive models to monitor and improve batch performance.
 * Establish and oversee systems for data collection, monitoring, and analysis systems for early and late-stage programs, ensuring compliance with 21 CFR Part 11 and alignment with regulatory expectations.
 * Develop and apply advanced statistical data modeling approaches (e.g., multivariate analysis, regression, machine learning techniques) to enable predictive modeling, deviation investigations and continuous improvement.
 * Support data review and report writing with data trending and statistical models, for proactively actionable recommendations
 * Support deviation investigations and tech transfer activities by leveraging statistical expertise to analyze historical data, and to set or revise in-process control limits.
 * Lead initiatives to develop platform process models (HEK vs. HeLa) across multiple GMP manufacturing sites to support proactive process monitoring; stay current with the AAV manufacturing technology innovations, and support implementation of process improvements for life cycle management.
 * Collaborate with Global CMC Development, external CDMOs, Manufacturing, Quality Assurance, Quality Control, and other stakeholders to enable robust CPV strategy execution.
 * Contribute to regulatory filings by authoring CPV-related content, responding to agency inquiries, and authoring sections of briefing books and submissions.
 * Author and maintain technical documentation, including CPV protocols and reports, statistical models, SOPs for data management, and lifecycle management protocols and reports.
   
   

Requirements:


 * Master’s degree in Virology, Molecular Biology, Genetics, Biochemistry, Chemical Engineering, Bioinformatics, Biostatistics or an equivalent discipline preferred
 * 5+ years in biopharma industry. Biologics, Gene / Cell therapy experience preferred
 * Understanding of biologics/AAV manufacturing process is required and experience in manufacturing technical support, process development, and/or MSAT roles is preferred
 * Demonstrated experience in data management, process modeling, and predictive analytics, preferred with GMP environment
 * Proficiency in biostatistics and data management tools (e.g., DOE, multivariate analysis, regression, Python/R/SAS).
 * Experience with regulatory filing is a plus
 * Proven ability to deliver results successfully, collaborating with multi-cultural and geographically diverse teams
 * Demonstrated ability to work in a team and in a fast-paced environment. Proven ability to independently manage multiple competing priorities, while working on multiple projects simultaneously
 * Excellent communication and presentation skills
 * May require up to 15% travel when necessary.
   
   

The typical annual salary range for this full-time position is listed below. This range reflects the characteristics of the job, such as required skills and qualifications and is based on the office location noted in this job posting. The range may also be adjusted based on applicant's geographic location.This position is eligible for annual bonus and equity incentives. Actual individual pay is determined by demonstrated experience and internal equity alignment.

Pay Range: $169,200 USD - $209,000 USD

Full Time employees across the globe enjoy a range of benefits, including, but not limited to:


 * Generous vacation time and public holidays observed by the company
 * Volunteer days
 * Long term incentive and Employee stock purchase plans or equivalent offerings
 * Employee wellbeing benefits
 * Fitness reimbursement
 * Tuition sponsoring
 * Professional development plans
 * Benefits vary by region and country
   
   

Ultragenyx Pharmaceutical is an equal opportunity employer and prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, disability, marital and veteran status, and any other status or classification protected by applicable federal, state, and/or local laws. Reasonable accommodation will be provided for all protected statuses or classifications protected by applicable law, including individuals with disabilities, disabled veterans, for pregnancy, childbirth, and related medical conditions, and based on sincerely held religious beliefs. Applicants can request an accommodation prior to accepting a job offer. If you require reasonable accommodation in completing this application, or in any part of the recruitment process, you may contact Talent Acquisition by emailing us at talentacquisition@ultragenyx.com.

See our CCPA Employee and Applicant Privacy Notice.

See our Privacy Policy.

It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.

Note to External Recruiters: All candidate activity and open positions are managed strictly through our Human Resources Department. Our Human Resources Department kindly requests that recruiters not contact employees/hiring managers directly in an attempt to solicit business and present candidates. Please note that failure to comply with this request will be a factor in determining a professional relationship with our organization. Submission of unsolicited resumes prior to an agreement set in place between the Human Resources Department and the recruiting agency will not create any implied obligation. Inquiries on developing a recruiting relationship with us, may be directed to: talentacquisition@ultragenyx.com.

","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Biotechnology Research","$169,200.00/yr - $209,000.00/yr","","","1218233","https://www.linkedin.com/jobs/view/sr-data-scientist-manufacturing-science-and-technology-at-ultragenyx-4340519674?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist - Mid","Fort George G. Meade, MD","6 days ago","2025-11-26","https://www.linkedin.com/jobs/view/data-scientist-mid-at-cherokee-federal-4324468463?trk=public_jobs_topcard-title","Cherokee Federal","https://www.linkedin.com/company/cherokee-federal?trk=public_jobs_topcard-org-name","Job Description

Data Scientist – Mid

***This position requires an active TS/SCI with the ability to obtain a Counterintelligence Polygraph.***

Cherokee Analytics is seeking a Data Scientist to design, implement, and operate data management systems for intelligence needs.

Compensation & Benefits

Estimated starting salary range: $140,000-$155,000. Pay commensurate with experience.

Full time benefits include Medical, Dental, Vision, 401K and other possible benefits as provided.Benefits are subject to change with or without notice.

Data Scientist – Mid Responsibilities Include


 * Conduct data analytics, data mining, exploratory analysis, predictive analysis, and statistical analysis, and uses scientific techniques to correlate data into graphical, written, visual and verbal narrative products, enabling more informed analytic decisions
 * Proactively retrieve information from various sources, analyzes it for better understanding about the data set, and builds AI tools that automate certain processes
 * Supports program evaluation with system assessments, statistical and data analysis, apply data mining techniques, and build high quality prediction systems.
 * Design how data will be stored, accessed, used, integrated, and managed by different data regimes and digital systems.
 * Work with data users to determine, create, and populate optimal data architectures, structures, and systems.
 * Plans, designs, and optimizes data throughput and query performance.
 * Provides modeling/ visualization , machine learning, statistic, data engineering, pattern recognition/learning support to organization as needed.
 * Use data science approaches to identify anomalies, patterns, or relationships that can support organization’s assessments.
 * Performs other job-related duties as assigned
   
   

Data Scientist – Mid Experience, Education, Skills, Abilities Requested


 * Current TS/SCI security clearance with the ability to obtain a Counterintelligence polygraph
 * Minimum of four (4) years of related experience
 * Bachelor’s degree preferred
 * Skilled in data visualization and use of graphical applications, including Microsoft Office (Power BI) and Tableau
 * Skilled in major data science languages, such as R and Python
 * Experience in managing and merging of disparate data sources, preferably through R, Python, or SQL
 * Experience with statistical analysis and data mining algorithms
 * Experience with large data Multi-INT analytics, ML, and automated predictive analytics
 * Comprehensive mission knowledge and skills that affirms completion of all developmental training
 * Ability to communicate understanding from information that may be incomplete, indirect, highly complex, seemingly unrelated, and / or technically advanced
 * Ability to structure analysis based on trends in reporting and a range of analytic perspectives from other analysts, organizations, and intelligence disciplines
 * Ability to work independently with minimal oversight and direction
 * Ability to collaborate and work with other IC members on information Sharing, driving collection, and addressing analytic disputes and conflict resolution.
 * Ability to develop concise, insightful. and comprehensive products for defense intelligence.
 * Ability to lead teams in researching multifaceted or critical problems.
 * Must pass pre-employment qualifications of Cherokee Federal
   
   

Company Information

Cherokee Analytics (CA) provides support, services, and solutions to federal and commercial customers.The company takes a personalized approach to solving our clients' toughest challenges, helping you make the most of your skills.CA is part of Cherokee Federal – a team of tribally owned federal contracting companies.For more information, visit cherokee-federal.com.

#CherokeeFederal #IntelCareers

Similar searchable job titles


 * Data Engineer
 * Data Architect
 * Data Analyst
 * Data Solutions Manager
 * Business Intelligence Analyst
   
   

Keywords


 * Data management systems
 * Data architecture
 * Database technologies (SQL, NoSQL, HPC)
 * Data analysis
 * Data optimization
   
   

Legal Disclaimer: All qualified applicants will receive consideration for employment without regard to protected veteran status, disability or any other status protected under applicable federal, state or local law. Many of our job openings require access to government buildings or military installations. Candidates must pass pre-employment qualifications of Cherokee Federal.

Many of our job openings require access to government buildings or military installations. Candidates must pass pre-employment qualifications of Cherokee Federal.

As required by our governmental client, this position requires being a US Citizen AND an active TS/Sensitive Compartmental Information (SCI) clearance.

","88 applicants","Full-time","Entry level","Engineering and Information Technology","Business Consulting and Services","$140,000.00/yr - $155,000.00/yr","","","35651393","https://www.linkedin.com/jobs/view/data-scientist-mid-at-cherokee-federal-4324468463?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)"
"Lead Data Analyst","Beverly Hills, CA","3 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/lead-data-analyst-at-alo-4339992050?trk=public_jobs_topcard-title","ALO","https://www.linkedin.com/company/aloyoga?trk=public_jobs_topcard-org-name","WHY JOIN ALO?

Mindful movement. It’s at the core of why we do what we do at ALO—it’s our calling. Because mindful movement in the studio leads to better living. It changes who yogis are off the mat, making their lives and their communities better. That’s the real meaning of studio-to-street: taking the consciousness from practice on the mat and putting it into practice in life.

OVERVIEW

We are seeking a Lead Data Analyst with a sharp strategic mindset, and a passion for turning data into business impact. This role goes beyond traditional analytics—you're not just crunching numbers; you're actively shaping the business. Acting as a close partner to the team leader, you’ll serve as both a thought leader and execution driver, helping translate complex data into persuasive narratives and strategic action. You’ll independently engage with cross-functional business stakeholders, influence high-impact decisions, and help build a scalable analytics function. You’ll also manage junior team members and contribute to AI-driven initiatives, empowering the business with smarter, faster insights. If you're a proactive, influential communicator who thrives at the intersection of business, data, and AI innovation, this is the role for you.

RESPONSIBILITIES


 * Partner directly with business stakeholders at all levels to define success metrics, lead strategic analyses, and guide decision-making across e-commerce, retail, marketing, and customer strategy.
 * Translate complex data into clear, actionable insights that drive growth and operational efficiency.
 * Design and lead high-impact A/B and multivariate tests.
 * Build and scale dashboards and automated reporting to enable data democratization.
 * Ensure data quality and partner with Data Engineering to validate end-to-end data implementation, from tracking to reporting.
 * Collaborate with AI and data science teams to integrate AI tools (e.g., LLMs, recommendation engines) into business workflows and decision support systems.
 * Leverage generative AI tools to accelerate insight generation, automate repetitive analysis, and enhance stakeholder communication.
 * Mentor junior analysts and foster a high-performance culture through best practices and coaching.
 * Support as the analytical right hand to the Senior Director of Analytics, helping prioritize and drive high-value data initiatives across the company.
   
   

QUALIFICATIONS


 * 7–8 years of professional experience in data analytics, with a track record of using insights to shape business strategy in high-growth e-commerce or digitally enabled retail environments.
 * Minimum of 2 years of professional experience managing and developing junior team members.
 * Strong e-commerce domain expertise, including digital funnel optimization, omnichannel performance, customer segmentation, and merchandising analytics.
 * Strong business acumen and executive presence, with the ability to influence senior stakeholders through data storytelling.
 * Advanced SQL and proficiency in Python or R; strong grasp of experimentation design, statistics, and data modeling.
 * Proficiency in BI tools like Tableau or Thoughtspot; able to build scalable, intuitive dashboards from the ground up.
 * Experience collaborating with Data Science teams to build, deploy, and evaluate predictive models (e.g., forecasting, churn, LTV).
 * Familiarity with AI/ML applications in analytics, including generative AI (e.g., prompt engineering, LLMs), and AI-based tools for business decision support.
 * Self-starter with excellent communication and prioritization skills; comfortable managing projects with ambiguity and shifting priorities.
   
   

The base salary range for this position is $170,000-$190,000 per year which represents the current range for the base salary for this exempt position. Please note that actual salaries will vary based on factors including but not limited to location, experience, and performance. As such, on occasion and when applicable, there is the possibility that the final, agreed-upon base salary may be outside of the upper end of the range. Please also note the range listed is just one component of the company’s total rewards package for exempt employees. Other rewards may include performance bonuses, long term incentives, a PTO policy, and many other progressive benefits.

For CA residents, Job Applicant Privacy Policy HERE.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Retail Apparel and Fashion","$170,000.00/yr - $190,000.00/yr","","","3555747","https://boards.greenhouse.io/aloyoga/jobs/5684572004?gh_jid=5684572004","EXTERNAL",""
"Data Platform and Engineering Lead","Home, KS","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/data-platform-and-engineering-lead-at-kirklees-council-4337123157?trk=public_jobs_topcard-title","Kirklees Council","https://uk.linkedin.com/company/kirklees-council?trk=public_jobs_topcard-org-name","We adopt a ‘name blind’ approach to shortlisting. Recruiting managers will not have access to personal information, including your name and contact details, until a shortlisting decision has been made - please note that this also includes any CV uploaded. Equality monitoring information is not accessible by recruiting managers at any stage.

Organisation

Kirklees

Directorate

Public Health and Corporate Resources

Service Area

Strategy and Innovation

Hours

37

Number of Jobs

1

Location(s)

Hybrid - Home working and Kirklees offices

Position type

Permanent

Grade

Grade 16

Salary

£57,457 - £58,462

Advert Wording

About The Role

You will be leading a team of Data Engineers, Developers and Business Analysts responsible for the design, development and delivery of data services and products that improve how Kirklees Council manages and uses data.

In this pivotal role, you’ll lead the creation of a new council-wide data platform, using modern architecture and engineering practices within a modern technology stack. You will shape and develop the council’s data engineering capabilities, providing people, process, and technology leadership, and setting the standards for data engineering across the council.

This is a unique opportunity to make an impact and unlock new opportunities for how the council uses data.

About You

We’re looking for someone who shares our passion for using data to drive positive change.

You’ll Bring


 * A strong background in data architecture, engineering, and modelling.
 * Experience delivering enterprise-scale data platforms using Microsoft cloud technologies (e.g. Fabric, Azure, Purview) within large and complex organisations.
 * A deep understanding of data management concepts, principles, and practices with demonstrable experience of applying this knowledge.
 * A track record of leading and mentoring high-performing teams.
 * Excellent communication and stakeholder engagement skills.
 * A commitment to continuous improvement and innovation.
   
   

If you’re ready to lead with purpose and help shape the future of data at Kirklees, we’d love to hear from you.

Mike Henry is the manager for this role, please contact them on 01484 221000 for an informal discussion, or if you need any more information.

We know there’s a wealth of talent among people who have a disability and we encourage applications from people with all differing abilities. So, if you need any support completing an application form, or any other format for the application or Job Description please contact the Recruitment Team for help by email:or phone: 01484 221000 and ask for ‘Recruitment’.

We are committed to safeguarding and promoting the welfare of vulnerable adults and children and young people and expect all staff and volunteers to share this commitment.

Closing date

07 December 2025, 11:55 PM

Important Information","Be among the first 25 applicants","Full-time","Mid-Senior level","Information Technology","Government Relations Services","$57,457.00/yr - $58,462.00/yr","","","75134","https://kirklees.tal.net/vx/lang-en-GB/mobile-0/appcentre-1/brand-4/xf-e1ad51606ebc/candidate/so/pm/1/pl/4/opp/16543-Data-Platform-and-Engineering-Lead/en-GB","EXTERNAL",""
"Senior Data Scientist, Research, Operations Data Science","New York, NY","5 days ago","2025-11-27","https://www.linkedin.com/jobs/view/senior-data-scientist-research-operations-data-science-at-google-4337975007?trk=public_jobs_topcard-title","Google","https://www.linkedin.com/company/google?trk=public_jobs_topcard-org-name","Applicants in San Francisco: Qualified applications with arrest or conviction records will be considered for employment in accordance with the San Francisco Fair Chance Ordinance for Employers and the California Fair Chance Act.

Note: By applying to this position you will have an opportunity to share your preferred working location from the following: San Francisco, CA, USA; New York, NY, USA; Sunnyvale, CA, USA.Minimum qualifications:


 * Master's degree in Statistics, Data Science, Mathematics, Physics, Economics, Operations Research, Engineering, a related quantitative field, or equivalent practical experience.
 * 5 years of work experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or 3 years of work experience with a PhD degree.
   
   

Preferred qualifications:


 * 8 years of work experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or 6 years of work experience with a PhD degree.
 * Experience in designing and building optimization, simulation, and probabilistic decision-making models.
 * Experience in designing and building statistical models or physical models for energy consumption.
 * Experience in the computer hardware industry.
   
   

About The Job

Operations Data Science (ODS) is a team of Data Science and Business Analysis experts, who provide model-based decision support to scale Google's Technical Infrastructure optimally.

In this role, you will lead data modeling and estimation efforts for our Google Cloud Carbon Footprint product. You will collaborate with internal teams to gather, analyze, and interpret data related to Google Cloud software usage, resource consumption, energy consumption, and carbon emissions. You will work to enhance the value of the Google Cloud Carbon Footprint by more accurately estimating the energy consumption and carbon emissions of customers' workloads and projects. You will build problem-solving tools to clearly identify energy and carbon-savings opportunities for customers. Additionally, you will quantify the opportunity size of potential Cloud carbon-efficiency projects and prioritize these to build Cloud features that help customers reduce their emissions.

The AI and Infrastructure team is redefining what’s possible. We empower Google customers with breakthrough capabilities and insights by delivering AI and Infrastructure at unparalleled scale, efficiency, reliability and velocity. Our customers include Googlers, Google Cloud customers, and billions of Google users worldwide.

We're the driving force behind Google's groundbreaking innovations, empowering the development of our cutting-edge AI models, delivering unparalleled computing power to global services, and providing the essential platforms that enable developers to build the future. From software to hardware our teams are shaping the future of world-leading hyperscale computing, with key teams working on the development of our TPUs, Vertex AI for Google Cloud, Google Global Networking, Data Center operations, systems research, and much more.

The US base salary range for this full-time position is $166,000-$244,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .

Responsibilities


 * Collaborate with stakeholders in cross-projects and team settings to identify and clarify business or product questions to answer. Provide feedback to translate and refine business questions into tractable analysis, evaluation metrics, or mathematical models.
 * Gather information, business goals, priorities, and organizational context around the questions to answer, as well as the existing and upcoming data infrastructure.
 * Own the process of gathering, extracting, and compiling data across sources via relevant tools (e.g., SQL, R, Python). Format, re-structure, or validate data to ensure quality, and review the dataset to ensure it is ready for analysis.
 * Collaborate with subject matter experts to combine hardware insights with energy and emissions data to prioritize carbon-reduction efforts in Cloud.
 * Develop, maintain, support, and enhance models and estimation tools for the energy-use and carbon-footprint of Google Cloud customer workloads.
   
   
   

Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .","60 applicants","Full-time","Mid-Senior level","General Business, Strategy/Planning, and Consulting","Information Services and Technology, Information and Internet","$166,000.00/yr - $244,000.00/yr","","","1441","https://careers.google.com/jobs/results/128476089239380678-senior-data-scientist/?src=Online/LinkedIn/linkedin_us&utm_source=linkedin&utm_medium=jobposting&utm_campaign=contract","EXTERNAL",""
"Marketing Analytics Engineer","New York, NY","2 weeks ago","2025-11-18","https://www.linkedin.com/jobs/view/marketing-analytics-engineer-at-datadog-4336754922?trk=public_jobs_topcard-title","Datadog","https://www.linkedin.com/company/datadog?trk=public_jobs_topcard-org-name","Datadog is looking for a Marketing Analytics Engineer with strong data architecture and modeling skills to build the foundation of reliable, scalable, and well-structured marketing data. In this role, you’ll design and maintain the data pipelines, models, and source tables that power analytics across our global marketing organization. You’ll partner closely with Data Engineering, RevOps, and GTMOps to translate complex data flows into streamlined, analysis-ready assets. This is an ideal opportunity for someone who thrives on building robust backend systems that make actionable insights possible at scale.

At Datadog, we place value in our office culture - the relationships and collaboration it builds and the creativity it brings to the table. We operate as a hybrid workplace to ensure our Datadogs can create a work-life harmony that best fits them.

What You’ll Do:


 * Design, build, and maintain scalable dbt models and SQL transformations to support global marketing analytics
 * Collaborate with Marketing Operations and RevOps to map data from platforms like Marketo, Salesforce, and advertising tools into the warehouse
 * Partner with Data Engineering and GTMOps to optimize data architecture, align schemas, and improve governance
 * Troubleshoot data pipelines to ensure attribution accuracy, campaign tracking integrity, and lead lifecycle measurement
 * Build semantic layers and reusable models that power dashboards in Metabase, Tableau, or Looker
 * Establish and maintain best practices for model versioning, documentation, testing, and data lineage
   
   

Who You Are:


 * 3–5 years of experience in analytics engineering, data engineering, or marketing data architecture—ideally in a B2B SaaS environment
 * Advanced SQL skills and hands-on experience developing in dbt (Data Build Tool)
 * Proficient in working with cloud data warehouses such as Snowflake, BigQuery, or Redshift
 * Familiar with marketing systems like Marketo, Salesforce, and ad platforms, and how their data maps to pipelines and attribution models
 * Experience with data quality testing, documentation standards, and pipeline monitoring practices
 * Comfortable with BI tools (Metabase, Tableau, or Looker), with a strong focus on building underlying data structures
   
   

Datadog values people from all walks of life. We understand not everyone will meet all the above qualifications on day one. That's okay. If you’re passionate about technology and want to grow your skills, we encourage you to apply.

Benefits and Growth:


 * Generous and competitive benefits package
 * New hire stock equity (RSUs) and employee stock purchase plan
 * Continuous career development and pathing opportunities
 * Employee-focused best in class onboarding
 * Internal mentor and cross-departmental buddy program
 * Friendly and inclusive workplace culture
   
   

Benefits and Growth listed above may vary based on the country of your employment and the nature of your employment with Datadog.

Datadog offers a competitive salary and equity package, and may include variable compensation. Actual compensation is based on factors such as the candidate's skills, qualifications, and experience. In addition, Datadog offers a wide range of best in class, comprehensive and inclusive employee benefits for this role including healthcare, dental, parental planning, and mental health benefits, a 401(k) plan and match, paid time off, fitness reimbursements, and a discounted employee stock purchase plan.

The reasonably estimated yearly salary for this role at Datadog is:

$94,000—$125,000 USD

About Datadog:

Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability. We are on a mission to break down silos and solve complexity in the cloud age by enabling digital transformation, cloud migration, and infrastructure monitoring of our customers’ entire technology stacks. Built by engineers, for engineers, Datadog is used by organizations of all sizes across a wide range of industries. Together, we champion professional development, diversity of thought, innovation, and work excellence to empower continuous growth. Join the pack and become part of a collaborative, pragmatic, and thoughtful people-first community where we solve tough problems, take smart risks, and celebrate one another. Learn more about #DatadogLife on Instagram, LinkedIn, and Datadog Learning Center.

Equal Opportunity at Datadog:

Datadog is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and other characteristics protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. Here are our Candidate Legal Notices for your reference.

Datadog endeavors to make our Careers Page accessible to all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please complete this form. This form is for accommodation requests only and cannot be used to inquire about the status of applications.

Privacy and AI Guidelines:

Any information you submit to Datadog as part of your application will be processed in accordance with Datadog’s Applicant and Candidate Privacy Notice. For information on our AI policy, please visit Interviewing at Datadog AI Guidelines.","182 applicants","Full-time","Entry level","Information Technology","Software Development","$94,000.00/yr - $125,000.00/yr","","","1066442","https://careers.datadoghq.com/detail/7369285/?gh_jid=7369285&gh_src=8363eca61","EXTERNAL",""
"Senior AI/ML Architect, Applied Field Engineering","Menlo Park, CA","23 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/senior-ai-ml-architect-applied-field-engineering-at-snowflake-4340173238?trk=public_jobs_topcard-title","Snowflake","https://www.linkedin.com/company/snowflake-computing?trk=public_jobs_topcard-org-name","Snowflake is about empowering enterprises to achieve their full potential — and people too. With a culture that’s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology — and careers — to the next level.

Our Sales Engineering organization is seeking an AI Specialist who can provide hands-on expertise and support while working with technical decision makers and data scientists to design and architect AI solutions built on the Snowflake AI Data Cloud.

This is a strategic role that works closely with cross-functional teams, including product, engineering, and the broader field organization to ensure successful execution and customer adoption of Snowflake’s AI & ML solutions.

IN THIS ROLE YOU WILL GET TO:


 * Be the technical expert in the room that positions Snowflake’s AI and ML features and value to technical stakeholders at Snowflake’s customers across the Americas.
 * Partner with Snowflake account team teams and customer champions to scope and drive POCs to success and technical wins that prove the value of Snowflake’s capabilities, including executive readouts and business value cases.
 * Collaborate with Snowflake’s product and engineering teams to influence Snowflake’s AI and ML roadmaps based on customer feedback.
 * Publish content that helps the team and company scale beyond your individual efforts, like blog posts, presentations at conferences, or technical collateral like notebooks and demos.
 * Influence, tailor and maintain Sales Engineering AI and ML selling assets, including customer presentations, demonstrations, and customer stories.
   
   
   

ON DAY ONE, WE WILL EXPECT YOU TO HAVE:


 * 5+ years of experience building and deploying machine learning and generative AI solutions in the cloud.
 * Familiarity and associated knowledge of generative AI techniques like RAG, few shot learning, prompt engineering, or fine-tuning that are used to operationalize enterprise AI use cases like interactive chat applications or text processing.
 * Deep knowledge of Python and common ML packages (such as LangChain, pandas, sklearn, and PyTorch) as well as data engineering tools and technologies like dbt, Airflow, and Spark.
 * Strong presentation skills to both technical and executive audiences, whether whiteboarding sessions or formal readouts and demos.
 * Bachelor’s Degree required, Masters Degree in computer science, engineering, mathematics or related fields, or equivalent experience preferred.
   
   
   

BONUS POINTS FOR EXPERIENCE WITH THE FOLLOWING:


 * Working knowledge of tools in the LLM ecosystem such as LangChain, LlamaIndex, or other OSS packages.
 * Experience and understanding of large-scale infrastructure-as-a-service platforms (e.g. AWS, Microsoft Azure, GCP, etc.)
 * 1+ years of practical Snowflake experience.
 * Knowledge of and experience with large-scale database technology (e.g. Snowflake, Netezza, Exadata, Teradata, Greenplum, etc.)
   
   
   

Every Snowflake employee is expected to follow the company’s confidentiality and security standards for handling sensitive data. Snowflake employees must abide by the company’s data security plan as an essential part of their duties. It is every employee's duty to keep customer information secure and confidential.

Snowflake is growing fast, and we’re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.

How do you want to make your impact?

For jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com

The following represents the expected range of compensation for this role:


 * This role is eligible to participate in Snowflake's commission plan and it is common for employees in this role to receive total on-target earnings of $220,000 - $288,750. The estimated base salary for this role is $165,000 - $216,562.
 * Additionally, this role is eligible to participate in Snowflake’s equity plan.
   
   
   

The successful candidate’s starting salary will be determined based on permissible, non-discriminatory factors such as skills, experience, and geographic location. This role is also eligible for a competitive benefits package that includes: medical, dental, vision, life, and disability insurance; 401(k) retirement plan; flexible spending & health savings account; at least 12 paid holidays; paid time off; parental leave; employee assistance program; and other company benefits.

To comply with pay transparency requirements and other statutes, you can notify us if you believe that a job posting is not compliant by completing this form.","Be among the first 25 applicants","Full-time","Mid-Senior level","Design, Art/Creative, and Information Technology","Software Development","$165,000.00/yr - $288,750.00/yr","","","3653845","https://www.linkedin.com/jobs/view/senior-ai-ml-architect-applied-field-engineering-at-snowflake-4340173238?trk=public_jobs_topcard-title","EASY_APPLY",""
"Product Development Engineer - 158984","New York, NY","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/product-development-engineer-158984-at-atrium-4336985982?trk=public_jobs_topcard-title","Atrium","https://www.linkedin.com/company/atrium?trk=public_jobs_topcard-org-name","Our client is a start-up biotech company that aims to improve lives through their research and products. They are looking to add a Product Development Engineer to their team.

Salary/Hourly Rate

$110k - $140k

Position Overview

The Product Development Engineer will work to bring products from lab concept to commercial manufacturing. This role supports prototyping, process development, and GMP readiness while working closely with R&D, Quality, Regulatory, and Operations teams.

Responsibilities Of The Product Development Engineer


 * Lead product and process development activities that move technologies from laboratory testing to commercial scale.
 * Build prototypes, run feasibility studies, and refine designs using data-driven engineering.
 * Manage risk analyses, verification/validation testing, and controlled documentation.
 * Create and execute GLP/GMP qualification protocols and support tech transfer to manufacturing.
 * Develop test methods, conduct characterization studies, and apply statistical tools (DOE, analysis, modeling).
 * Partner with Quality and Supply Chain on supplier qualification and GMP material readiness.
 * Support regulatory documentation, investigations, and updates to SOPs and technical files.
   
   

Required Experience/Skills for the Product Development Engineer:


 * 3+ years of experience in medical devices.
 * Strong experience with design control.
 * Direct experience moving medical device or biotech products from lab development to commercial production.
 * Strong regulatory documentation experience and knowledge.
 * Excellent communication, organization, and ability to manage multiple technical projects.
   
   

Preferred Experience/Skills for the Product Development Engineer:


 * Demonstrated success supporting commercialization or scale-up activities.
 * Hands-on work in GLP/GMP labs or manufacturing environments.
   
   

Education Requirements:


 * Bachelor's degree in Engineering or Life Sciences is required.
   
   

Benefits:


 * Fully covered medical, dental, vision insurance, 401k, paid time off, and more.
   
   

By applying to this job, you agree to receive calls, AI-generated calls, text messages, and/or emails from Atrium and its affiliates, and contracted partners. Frequency varies for text messages. Message and data rates may apply. Carriers are not liable for delayed or undelivered messages. You can reply STOP to opt out on any message you receive. For more details, please review our Terms of Use and Privacy Policy .

As a woman-owned firm, we value diversity. We are an equal opportunity and affirmative action employer and will consider all applications without regard to race, sex (including gender, pregnancy, sexual orientation and gender identity), age, color, religion or creed, national origin or ancestry, veteran status, disability (physical or mental), genetic information, citizenship or any other characteristic protected by law. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Candidates who apply for roles through the Atrium website will be added to our candidate pool and may be considered for additional roles of a similar title. Please contact us to request an accommodation.

EOE/M/F/D/V/SO

Position ID: 158984","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Staffing and Recruiting","$110,000.00/yr - $140,000.00/yr","","","19534","https://www.linkedin.com/jobs/view/product-development-engineer-158984-at-atrium-4336985982?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Data Engineer","New York, United States","2 weeks ago","2025-11-13","https://www.linkedin.com/jobs/view/senior-data-engineer-at-synechron-4340205783?trk=public_jobs_topcard-title","Synechron","https://www.linkedin.com/company/synechron?trk=public_jobs_topcard-org-name","We are

At Synechron, we believe in the power of digital to transform businesses for the better. Our global consulting firm combines creativity and innovative technology to deliver industry-leading digital solutions. Synechron s progressive technologies and optimization strategies span end-to-end Artificial Intelligence, Consulting, Digital, Cloud & DevOps, Data, and Software Engineering, servicing an array of noteworthy financial services and technology firms. Through research and development initiatives in our FinLabs we develop solutions for modernization, from Artificial Intelligence and Blockchain to Data Science models, Digital Underwriting, mobile-first applications and more. Over the last 20+ years, our company has been honored with multiple employer awards, recognizing our commitment to our talented teams. With top clients to boast about, Synechron has a global workforce of 14,500+, and has 58 offices in 21 countries within key global markets.







Our Challenge:

Looking for skilled senior data engineer with comprehensive experience in designing, developing, and maintaining scalable data solutions within the financial and regulatory domains. Proven expertise in leading end-to-end data architectures, integrating diverse data sources, and ensuring data quality and accuracy.




Additional Information*

The base salary for this position will vary based on geography and other factors. In accordance with law, the base salary for this role if filled within New York, NY is $135k - $155k/year & benefits (see below).




Work location: New York City, NY (Hybrid, 3 days in a week)







The Role

Responsibilities:

 * Advanced proficiency in Python, SQL Server, Snowflake, Azure Databricks, and PySpark.
 * Strong understanding of relational databases, ETL processes, and data modeling.
 * Expertise in system design, architecture, and implementing robust data pipelines.
 * Hands-on experience with data validation, quality checks, and automation tools (Autosys, Control-M).
 * Skilled in Agile methodologies, SDLC processes, and CI/CD pipelines.
 * Effective communicator with the ability to collaborate with business analysts, users, and global teams.







Requirements:

 * Overall 12+ years of IT experience is required
 * Collaborate with business stakeholders to gather technical specifications and translate business requirements into technical solutions.
 * Develop and optimize data models and schemas for efficient data integration and analysis.
 * Lead application development involving Python, Pyspark, SQL, Snowflake and Databricks platforms.
 * Implement data validation procedures to maintain high data quality standards.
 * Strong experience in SQL (Writing complex queries, Join, Tables etc.)
 * Conduct comprehensive testing (UT, SIT, UAT) alongside business and testing teams.
 * Provide ongoing support, troubleshooting, and maintenance in production environments.
 * Contribute to architecture and design discussions to ensure scalable, maintainable data solutions.
 * Experience with financial systems (capital markets, credit risk, and regulatory compliance applications).










We offer:

 * A highly competitive compensation and benefits package.
 * A multinational organization with 58 offices in 21 countries and the possibility to work abroad.
 * 10 days of paid annual leave (plus sick leave and national holidays).
 * Maternity & paternity leave plans.
 * A comprehensive insurance plan including medical, dental, vision, life insurance, and long-/short-term disability (plans vary by region).
 * Retirement savings plans.
 * A higher education certification policy.
 * Commuter benefits (varies by region).
 * Extensive training opportunities, focused on skills, substantive knowledge, and personal development.
 * On-demand Udemy for Business for all Synechron employees with free access to more than 5000 curated courses.
 * Coaching opportunities with experienced colleagues from our Financial Innovation Labs (FinLabs) and Center of Excellences (CoE) groups.
 * Cutting edge projects at the world’s leading tier-one banks, financial institutions and insurance firms.
 * A flat and approachable organization.
 * A truly diverse, fun-loving, and global work culture.







S YNECHRON’S DIVERSITY & INCLUSION STATEMENT




Diversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative ‘Same Difference’ is committed to fostering an inclusive culture – promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more.




All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant’s gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.

","143 applicants","Full-time","Mid-Senior level","Analyst, Finance, and Information Technology","Banking, Investment Banking, and Financial Services","$135,000.00/yr - $155,000.00/yr","Fizza Abid","https://in.linkedin.com/in/fizza-abid-7ba37833","15506","https://www.linkedin.com/jobs/view/senior-data-engineer-at-synechron-4340205783?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Paid maternity leave
Paid paternity leave
Disability insurance"
"Artificial Intelligence Engineer","San Francisco Bay Area","3 weeks ago","2025-11-04","https://www.linkedin.com/jobs/view/artificial-intelligence-engineer-at-stealth-ai-startup-4334035648?trk=public_jobs_topcard-title","Stealth AI Startup","https://www.linkedin.com/company/stealthaistartup?trk=public_jobs_topcard-org-name","About the Company

We're an early-stage Fintech + AI startup backed by seasoned investors from the financial and technology sectors. Our mission is to reinvent how users interact with modern financial tools by combining AI-driven intelligence with high-performance trading and investment infrastructure.




We're assembling our founding engineering team — a small, world-class group of builders ready to shape the company’s technology, product, and culture from day one.




Role Overview

As a Founding Engineer, you'll be responsible for designing and building the backbone of our platform — from data pipelines and trading infrastructure to AI-powered analytics and user interfaces. This role is ideal for someone who loves autonomy, technical depth, and fast iteration.




What You' ll Do

 * Architect and develop scalable backend systems in Python, Go, Node or Rust.
 * Build and manage cloud infrastructure on AWS (EC2, Lambda, S3, RDS, CloudWatch, etc.) for speed, reliability, and scalability.
 * Design APIs and data services that power real-time financial insights and trading systems.
 * Collaborate with product and design to build high-impact user experiences.
 * Prototype and deploy AI/ML models in production environments.
 * Define engineering best practices and help grow the early tech team.




Ideal Candidate

 * Strong academic background or proven hands-on experience — whether from a top school, or from building real things that matter.
 * Prior experience at fintech, trading, or AI companies such as J.P. Morgan, Goldman Sachs, Citadel, Robinhood, TradingView, Webull, Futu, or similar.
 * Strong technical foundation in distributed systems, data engineering, or backend architecture.
 * Hands-on experience with AWS cloud infrastructure.
 * Comfortable in fast-paced startup environments; bias for action and ownership.




Nice to Have

 * Familiarity with Docker, Kubernetes, Terraform, or modern DevOps stacks.
 * Experience deploying AI/ML or quantitative trading systems.
 * Previous leadership or mentorship experience.
 * Interest in financial innovation, crypto, or DeFi (optional).




Location

 * Based in or open to relocating to the Bay Area / San Francisco.
 * Hybrid or flexible work arrangements are possible.




Compensation Package

 * Base salary (depending on experience and seniority)
 * Equity: 0.25 – 1.0 %
 * Bonus: up to 10–20 % of base (cash and equity)
 * 401k
 * Medical Insurance




*This is a hybrid working arrangement, however candidates do have to be based out of San Francisco.*

","Over 200 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Technology, Information and Internet and Financial Services","$180,000.00/yr - $250,000.00/yr","","","96670793","https://www.linkedin.com/jobs/view/artificial-intelligence-engineer-at-stealth-ai-startup-4334035648?trk=public_jobs_topcard-title","EASY_APPLY","401(k)
Medical insurance
Dental insurance
Vision insurance
Pension plan"
"AI Developer","McLean, VA","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/ai-developer-at-steampunk-inc-4347600845?trk=public_jobs_topcard-title","Steampunk, Inc.","https://www.linkedin.com/company/steampunk-inc?trk=public_jobs_topcard-org-name","We are looking for a highly skilled Senior AI Developer to design, build, and optimize advanced AI solutions across predictive, generative, and autonomous system domains. This role requires strong hands-on engineering capabilities, deep familiarity with modern AI architectures, and the ability to translate mission needs into robust, production-ready AI capabilities. The Senior AI Developer will work across the full stack of AI development , from data ingestion and model experimentation to application integration, orchestration, and deployment , and will collaborate closely with product teams, LLMOps engineers, designers, and mission stakeholders.

Contributions


 * Develop end-to-end AI solutions including LLM-powered applications, predictive ML models, multi-agent workflows, RAG pipelines, and specialized AI microservices.
 * Implement reusable AI components, libraries, and APIs that streamline application development and accelerate delivery across programs.
 * Integrate AI models with enterprise systems, APIs, data platforms, vector databases, and cloud-native services to deliver scalable mission capabilities.
 * Drive iterative experimentation, prototyping, and model improvement cycles in collaboration with Data Scientists and AI Evaluation Scientists.
 * Design and implement advanced prompt strategies, context management layers, retrieval systems, and LLM orchestration logic.
 * Build scalable inference services, optimize model performance, and collaborate with LLMOps to enable robust deployment, monitoring, and continuous improvement.
 * Translate user needs and mission workflows into intuitive, reliable AI-powered features through active partnership with designers and product teams.
 * Implement secure-by-design and trustworthy AI practices, including safety guardrails, input sanitization, content filtering, and integration of evaluation metrics.
 * Contribute to internal AI frameworks, code patterns, and shared accelerators that raise delivery quality across the AI & Data Exploitation Practice.
 * Mentor junior developers, conduct code reviews, and support engineering excellence across multi-disciplinary AI delivery teams.
 * Stay current with emerging AI techniques, libraries, foundation models, and agent frameworks, evaluating their applicability to client missions.
 * You will contribute to the growth of our AI & Data Exploitation Practice!
   
   

Qualifications


 * Ability to hold a position of public trust with the U.S. government.
 * Bachelor’s degree and 2 years of experience.
 * 5+ years of hands-on software engineering experience, with at least 2+ years focused on AI/ML, generative AI, or LLM-driven application development.
 * Strong proficiency in Python and modern AI frameworks such as PyTorch , TensorFlow, Hugging Face Transformers, LangChain , LlamaIndex , or similar.
 * Demonstrated ability to design and develop production-grade AI applications, including APIs, back-end services, orchestration logic, and front-end integrations (when needed).
 * Experience implementing RAG architectures , embeddings, vector stores, and context retrieval patterns.
 * Familiarity with multi-agent orchestration frameworks, prompt engineering strategies, and advanced LLM interaction design.
 * Strong understanding of cloud platforms (AWS, Azure, GCP), including compute , serverless services, and security fundamentals for AI workloads.
 * Working knowledge of containerization (Docker), orchestration (Kubernetes), and CI/CD pipelines for AI-based systems.
 * Experience with structured and unstructured data, document processing, and application integration with existing enterprise systems.
 * Understanding of responsible AI principles including safety, fairness, privacy, and model risk mitigation.
 * Strong analytical and communication skills with the ability to collaborate across engineering, design, and mission domains.
 * Proven experience mentoring teammates and raising the technical bar of development teams.
   
   

About Steampunk

Steampunk relies on several factors to determine salary, including but not limited to geographic location, contractual requirements, education, knowledge, skills, competencies, and experience. The projected compensation range for this position is $140,000 to $190,000. The estimate displayed represents a typical annual salary range for this position. Annual salary is just one aspect of Steampunk’s total compensation package for employees. Learn more about additional Steampunk benefits here.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Steampunk is a Change Agent in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our Human-Centered delivery methodology , we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an employee owned company , we focus on investing in our employees to enable them to do the greatest work of their careers – and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com .

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.","71 applicants","Full-time","Entry level","Engineering and Information Technology","IT Services and IT Consulting","$140,000.00/yr - $190,000.00/yr","","","23690866","https://www.linkedin.com/jobs/view/ai-developer-at-steampunk-inc-4347600845?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Emeryville, CA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/data-engineer-at-premier-nutrition-the-good-energy-people-4323840538?trk=public_jobs_topcard-title","Premier Nutrition: The Good Energy People","https://www.linkedin.com/company/premier-nutrition?trk=public_jobs_topcard-org-name","Here’s What All The Hype Is About…

Premier Nutrition Company (PNC) is one of the fastest-growing companies in the proactive wellness space showing clear leadership in the category of protein shakes and powders. We make the brands Premier Protein and Dymatize, and are part of our publicly traded holding company, BellRing Brands (NYSE: BRBR).

We have a simple, yet powerful, formula for our success, which we’ve been nailing since our founding in 1997. We start with an organization powered by our company purpose—Changing Lives with Good Energy. Then our purpose-driven people are given the support and autonomy to develop and grow. Next, we are super-intentional about designing a culture where everyone feels like they truly connect and belong, which is one of our five company core values. Purpose-driven, connected employees deliver amazing business results. And winning companies with remarkable people and thriving cultures attract and retain top talent, so the cycle becomes self-reinforcing or what we call our regenerative culture.

We don’t mind sharing our formula, since we believe the world would be a better place if more workplaces treated adults like adults and gave them the platform to do the best work of their lives—alongside some truly amazing colleagues. Why don’t more companies do this? It takes deep-in-your-bones conviction to your people, products, and purpose to pull it off. It also takes resisting the urge to try to control people, and instead, trusting them to make the right decisions. The result of our vibrant culture speaks for itself: We were certified as a Great Place to Work™ for the 9 th year-running in 2025. And we currently rank #8 on Fortune Magazine’s Best Workplaces in our category and were in the top 12 for each of the last 7 years.

We have a long list of ways we take care of our people, but here are some crowd-pleasers that our employees often say they love most: Year-round ½ day Fridays, in-office massages, free lunches & snacks, dogs in the office, culture of belonging celebrations, engaging in-office events like bring your kids to work day, 6% 401k match after 1 year, generous paid family leave regardless of gender, all positions bonus-eligible, company-wide volunteer days, company-matched charitable donations, no employee handbook, no dress code, coaching conversations instead of performance reviews, and walking meetings.

PNC seeks individuals who will flourish in this type of work environment and will add to our culture and help build this high-growth company for the next phase in our amazing journey. Does this sound like you? Then read on…

We believe in the power of mindset, and specifically what we call the Challenger Mindset. Do you take smart, bold risks, display relentless hunger, and see yourself as a builder? We’re looking for individuals who choose action over analysis paralysis—those who start before they feel completely ready, make calculated moves based on the best information available, and build momentum through decisive action rather than perfect planning. You should have an insatiable drive that keeps you agile and forward-thinking, always challenging assumptions, seeking new opportunities, and focusing on long-term impact over short-term wins. Above all, you’re a builder—someone who transforms the status quo, finds smarter, simpler, faster ways to get things done, and inspires others to do the same.

The role you’re interested in…

As a Data Engineer, you will help our company solve their most challenging problems and drive decisions with data. As a member in our Enterprise Data Intelligence team, you will be at the center of data and analytical innovation and adoption. In this role, you will drive value by migrating, acquiring, maintaining, and evolving our data integration process and platform. Activities range from data acquisition and validation, designing and implementing ETL/ELT data pipelines, designing and implementing databases, job suite execution and monitoring, support testing, troubleshooting, and system analysis. You will be collaborating with all our departments to build end-to-end data infrastructure and pipelines that promote reporting and advanced analytics and further business process evaluation.

The work environment…

So, what’s it like to work here? If you’re based in the greater Bay Area, you’ll walk into our Emeryville office each Tuesday morning and start the in-person portion of our hybrid work week at our weekly all-company meeting and find close to 200 of your colleagues, some sitting with their dogs, talking excitedly through the week ahead and watching a newer teammate tell their personal life and career journey followed by a quick update on any hot topics that might be relevant to the week ahead.

We are a dynamic, HYBRID workplace so every employee who lives within 100 miles of our offices is expected to come in Tuesday through Thursday. We are very intentional about connecting in person for things like innovation, impromptu collaboration, having respectful challenges to get to better decisions, leadership role-modeling, and culture building. Great work cultures are built on stories about what great looks like in practice, and great stories during virtual meetings just don’t happen. The expected pay scale for this role is $145k to $155k, which may vary based on relevant experience, qualifications, geographic area (if applicable), and internal equity for the role.

At the beginning of 2026, we will move into our massive modern 133,000 square foot headquarters in Emeryville, California, complete with spacious personal workspaces, gym with rock-climbing wall, a café, free onsite parking, tons of greenery, and many transportation options.

You’re excited about this opportunity because your time will be filled with…

Design, Develop, and Maintain Data Infrastructure and Pipelines: 60% of your time


 * Design, build, and maintain cloud-native data pipelines and infrastructure to support analytics, reporting, and data science use cases in a SaaS-based environment.
 * Perform all stages of the data lifecycle: requirements gathering, design, ingestion, transformation, modeling, testing, deployment, monitoring, and production support.
 * Implement and manage ELT pipelines using tools such as Fivetran, dbt, and Python, delivering reliable and scalable data solutions.
 * Develop and maintain data models, data marts, APIs, and automation scripts to streamline analytics workflows.
 * Design and deploy database schemas, tables, and views in Snowflake across multiple environments (DEV, QA/UAT, PROD).
 * Collaborate with stakeholders to translate business requirements into robust technical designs.
 * Support documentation, training, and enablement to drive adoption of enterprise data assets.
   
   

Enhance and Optimize DataOps Operational Excellence: of your time 30%


 * Protect the data pipeline! Your mission is to monitor the production schedule, troubleshoot any failures, and ensure that the processes are running smoothly.
 * Monitor data quality and dig in deep to find solutions to problems when they arise.
 * Administer Snowflake security strategy and database management.
 * Fine-tune and optimize databases, queries, and pipelines for improved performance and efficiency.
 * Proactively identify processes that would benefit from system automation to improve the Enterprise Data Intelligence team effectiveness and increase operating efficiencies.
 * Research and test new technology solutions, assist in vetting architectural changes/database design that would have to occur to support enterprise adoption and determine impacts.
   
   

Data Warehouse Administration: 10% of your time


 * Follow documented procedures for configuring, maintaining, upgrading, testing, and deploying as a database administrator. Ensure best technical practices are followed for all enterprise database administration for the best user experience and sustainable design.
   
   

What are we looking for?

Education


 * Bachelor’s degree in Computer Science, Engineering, Information Systems, or related technical disciplines.
   
   

Experience


 * 5+ years of experience as a Data Engineer working within cloud-native and SaaS-based environments, supporting enterprise data platforms built on data warehouses, data lakes, and application databases (e.g., Snowflake, Oracle, SQL Server).
 * 5+ years of SQL experience with proven ability to write, optimize, and maintain complex queries and stored procedures.
 * Programming experience in Python, Scala, or other scripting languages for automation, data transformation, and integration.
 * Hands-on experience designing, building, and maintaining ELT/ETL data pipelines, dimensional models, and data marts using modern tools such as dbt, Fivetran, or equivalent cloud-based frameworks.
 * Demonstrated experience working with SaaS data sources and APIs, integrating data from cloud-based systems such as ERP (e.g., NetSuite), CRM, and planning tools (e.g., Oracle EPM, O9, or Salesforce).
 * Exposure to or hands-on experience with AI/LLM frameworks (e.g., Snowflake Cortex, MCP, or similar technologies) to enhance automation and data intelligence.
 * Experience with data integration and orchestration tools (e.g., Dell Boomi, Airflow, Azure Data Factory, or equivalent).
 * Strong understanding of data governance, observability, lineage, and data quality management in a cloud environment.
 * Experience using Git-based version control systems (e.g., GitHub, GitLab) and CI/CD workflows for deployment across multi-environment pipelines (DEV, QA, PROD).
 * Working knowledge of cloud platforms (preferably Azure, with exposure to AWS or GCP) and secure data exchange mechanisms (APIs, SFTP).
 * Excellent communication and collaboration skills, with the ability to work cross-functionally in a distributed SaaS organization.
   
   

Preferred Qualifications


 * Master’s degree in Computer Science, Engineering, Information Systems, or related technical disciplines preferred.
 * Hands on knowledge with at least one key BI market tool (Tableau, SAP BO, Oracle BI, MS Power BI) is a plus.
 * Must be willing to be on call for night/weekend production support.
 * Ability to think strategically about tools and technologies that enable analytics.
 * Experience working in CPG industry.
   
   

Skills


 * Problem-Solving: Ability to analyze complex data challenges and develop innovative solutions that align with business objectives.
 * Get Things Done: Great work ethic and moves with a sense of urgency.
 * Drives Continuous Improvement: Always focusing on effective and efficient work and ways to get better.
 * Obsesses over the Details and committed to paying attention to the details
 * Demonstrated excellent verbal/written communication skills.
 * Life long learner: A passion for staying up-to-date with the latest trends and advancements in data engineering and related technologies.
 * Provocative thinker who is courageous to share his or her thoughts regardless of the level of the audience
 * Self-motivated individual who can identify issues/opportunities for improvement and be proactive in addressing them
 * Able to wear many hats and multitask as priorities evolve and change
 * Demonstrates ownership of outcomes vs being an order taker of tasks
 * Manage the forward progress on multiple projects and determine priority order
 * Bring a sense of fun, passion and positive attitude to every day
   
   

So, if after reading through this long list you’re thinking—I’m not sure I meet 100% of these requirements, should I still apply? YES—if you embody a growth mindset, see challenges as opportunities to develop, and find innovative ways to get the real work that matters done, you sound like our kind of candidate!

The 5 capabilities or mindsets most relevant to this role:


 * Challenger Mindset—bias for action, hungry to get after it, comfortable taking smart risks
 * Be a builder by creating for the future
 * Enterprise strategic view—take the full company perspective over departments or channels
 * Challenge ideas respectfully by sharing your real opinion with conviction; disagree in a way people feel heard
 * Bring people along by providing context and cascading information; share openly and inclusively
   
   

You will thrive here and may just do the best work of your life if…


 * You are hungry, are comfortable with smart risks,
 * You like to get sh*t, I mean—stuff done
 * You can be both clear and kind—empathetic yet hold people accountable
 * You want to be an integral part of shaping an amazing work culture and being a culture-add
 * You are comfortable being natural, casual, open, and even a bit playful at work
   
   

This may not be your ideal next career move if you like…


 * …a lot of structure, rules, and uniformity
 * …a lot of command and control management
 * …a “big company” impersonal, cog-in-the-machine vibe—that ain’t us
 * …to build a beautiful, orderly bureaucracy
 * … things to not change much (we suggest the elevator business for that)
   
   

Here’s the deal with our not-so-standard, um…standard interview process because we know you are the curious type, which is why you’re still reading this…


 * Quick 30 min phone chat with a high energy member of our Talent Acquisition team to do a quick overview of your background and answer any burning questions you have
 * Team interviews are kept to a minimum to foster a more efficient, candidate-friendly process (too many interviewers yields little value and drags out the process for you—and who wants that, right?):
    * A short series of in-person or video interviews in a 1:1 setting; these are usually with the hiring manager, one or two other team members, and a person from another team to get broader perspectives (note: we don’t do panel interviews because they don’t give interviewers a chance to ask you unique questions, and we assign interviewers different roles so we’re probing different capabilities)

 * A case study or job task to simulate what you’d actually be doing in the role might be included (since your job is not actually to be interviewed for a living, why is that the thing companies rely on so much?) Yes, there will be a small panel for this one so you don’t have to do it more than once, and yes, they might ask you some kind yet probing questions at the end after the raucous applause stops.
 * Once your interview concludes, the team will meet for an in-depth consultative process to ensure we are hiring the right person for the right job. Interviewers must come in with a strong yes or no vote beforehand to avoid groupthink with supporting reasons. The collective thoughts on your candidacy will be discussed in an environment of safety to challenge ideas respectfully, debate. and be open to all important qualifications of the candidates. A trained, disinterested bias blocker will be present to help mitigate bias so the team can make a sound hiring decision. The moment of truth arrives when the hiring manager makes the big decision. If you nailed the interviews and the case study was brilliant, guess what? The offer is all yours! And the ball is in your court. Will you accept? We sure hope so, because this place is the real deal, and don’t just believe us—just ask the 91% of our people who said this is a great place to work in our most recent employee survey.
   

We strive to create an equitable and inclusive environment to contribute to the success of our organization. Premier Nutrition provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, genetic information, marital status, status as a covered veteran and any other category protected under applicable federal, state, provincial and local laws.","Over 200 applicants","Full-time","Entry level","Information Technology","Manufacturing","$145,000.00/yr - $155,000.00/yr","","","84201","https://www.linkedin.com/jobs/view/data-engineer-at-premier-nutrition-the-good-energy-people-4323840538?trk=public_jobs_topcard-title","EASY_APPLY",""
"Software Engineer","McLean, VA","18 hours ago","2025-12-02","https://www.linkedin.com/jobs/view/software-engineer-at-ascendion-4325117520?trk=public_jobs_topcard-title","Ascendion","https://www.linkedin.com/company/ascendion?trk=public_jobs_topcard-org-name","About Ascendion

Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next.

Ascendion | Engineering to elevate life

We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:

 * Build the coolest tech for world’s leading brands
 * Solve complex problems – and learn new skills
 * Experience the power of transforming digital engineering for Fortune 500 clients
 * Master your craft with leading training programs and hands-on experience

Experience a community of change makers!

Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.

About the Role:



Job Title: Java Developer



Job Summary

We are seeking a highly skilled Java Backend Engineer with strong expertise in building scalable microservices and cloud-native solutions. The ideal candidate is experienced with Java, Spring Boot, AWS services, serverless architecture, and modern DevOps practices. This role involves designing, developing, and deploying backend components that support high-performance, reliable, and secure applications.

Key Responsibilities

 * Design, develop, and maintain backend applications using Java and Spring Boot
 * Build and optimize microservices for performance, scalability, and security
 * Develop and deploy serverless solutions using AWS Lambda, Step Functions, and related AWS services
 * Integrate applications with AWS cloud components such as API Gateway, DynamoDB, S3, SNS/SQS, and CloudWatch
 * Implement CI/CD pipelines and follow DevOps best practices to ensure smooth deployments
 * Collaborate with cross-functional teams including architecture, QA, DevOps, and product
 * Troubleshoot and resolve performance, reliability, and scalability issues
 * Ensure best practices in coding, testing, automation, and cloud configuration
 * Participate in code reviews and contribute to continuous improvement initiatives

Must-Have Skills

 * Strong proficiency in Java (Java 8+)
 * Hands-on experience with Spring Boot and building REST APIs
 * Deep understanding of Microservices architecture
 * Practical experience with AWS Cloud, including:
 * Lambda
 * Step Functions
 * API Gateway
 * DynamoDB / RDS
 * S3
 * CloudWatch
 * Experience building serverless applications
 * Familiarity with DevOps and CI/CD pipelines (Jenkins, GitHub Actions, GitLab, CodePipeline, etc.)
 * Experience with containerization (Docker; Kubernetes is a plus)
 * Strong understanding of distributed systems and event-driven patterns

Nice-to-Have

 * Experience with Terraform or AWS CloudFormation
 * Knowledge of messaging systems (Kafka, Kinesis, SQS/SNS)
 * Familiarity with monitoring tools (Prometheus, Grafana, CloudWatch dashboards)
 * Experience with unit testing frameworks (JUnit, Mockito)
 * Exposure to Agile/Scrum development environments

Soft Skills

 * Strong problem-solving and analytical abilities
 * Excellent communication and teamwork skills
 * Ability to work in a fast-paced, cloud-first environment





Location: Mclean, VA



Salary Range: The salary for this position is between $109,480 – $128,520 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience and other qualifications of the successful candidate.





Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [12-15 days of paid vacation time] [6-8 weeks of paid parental leave after a year of service] [9 paid holidays and 2 floating holidays per calendar year] [Ascendion Learning Management System] [Tuition Reimbursement Program]



Want to change the world? Let us know.

Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk!","Over 200 applicants","Full-time","Mid-Senior level","Finance","Banking and Financial Services","$109,480.00/yr - $128,520.00/yr","Muskan Khatun","https://www.linkedin.com/in/muskan-khatun-793a651b2","86694680","https://www.linkedin.com/jobs/view/software-engineer-at-ascendion-4325117520?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)"
"Data Engineer","Alpharetta, GA","1 week ago","2025-11-24","https://www.linkedin.com/jobs/view/data-engineer-at-infor-4324320578?trk=public_jobs_topcard-title","Infor","https://www.linkedin.com/company/infor?trk=public_jobs_topcard-org-name","Infor is hiring a Data Engineer to join our Cloud Operations Machine Learning (COML) team. This position will play a pivotal role in deploying models and analyses into production on AWS, building and maintaining ETL (Extract, Transform, Load) pipelines, and optimizing SQL queries for performance. The Data Engineer will lead projects and initiatives, write and debug analytical code, translate business problems into mathematical models, monitor and maintain production systems, and ensure the analytical integrity of deployed solutions. Infor’s customers rely on our cloud infrastructure for critical business operations—from payroll processing to customer communications. Any disruption can significantly impact their business. The COML team leverages vast operational data to develop and deploy AI/ML solutions that improve system performance, uptime, and ultimately, customer satisfaction and retention.

A Day in The Life Typically Includes:

* Build and deploy scalable data pipelines and ML models in AWS.
* Review and debug analytical code to ensure production stability.
* Optimize SQL queries for performance across large datasets.
* Maintain and monitor deployed models and ETL workflows.
* Collaborate with stakeholders to translate business needs into data solutions.
* Align with team goals and track progress on initiatives.
* Coordinate cross-functionally to meet project timelines.
* Define data requirements and design efficient queries.
* Support data needs of scientists and business partners.

Basic Qualifications:

* Corporate experience in data engineering or software development.
* Experience writing and maintaining Python code for data processing, automation, or application development.
* Experience using SQL for complex queries, data modeling, and performance tuning in enterprise-scaled databases.
* Experience deploying time series data ETL pipelines in a corporate environment.
* Experience working in a cloud environment.
* Legal authorization to work permanently in the United States for any employer without requiring a visa transfer or visa sponsorship now or in the future.

Preferred Qualifications:

* Bachelor’s degree in Computer Science, Data Science, Mathematics, Statistics, Economics, Physics, or Engineering.
* Experience with InfluxDB, AWS Redshift, Athena, Lambda, and Apache DataFusion.
* Experience with Git and Docker.
* Knowledge of Sumo Logic.
* Understanding of AWS ecosystem (Athena, Lambda, S3, etc.).
* Experience designing and deploying data pipelines and data science solutions in the cloud.
* Experience in data transformation and algorithm development.
* Data Engineering Certifications.

About Infor

Infor is where ambition meets impact. Join a global community of bold thinkers and innovators, where your expertise doesn’t just solve problems. it shapes industries, unlocks opportunities, and creates real-world impact for billions of people. At Infor, you’re not just building a career. you’re helping to build what’s next.

Infor is a global leader in business cloud software products for companies in industry specific markets. Infor builds complete industry suites in the cloud and efficiently deploys technology that puts the user experience first, leverages data science, and integrates easily into existing systems. Over 60,000 organizations worldwide rely on Infor to help overcome market disruptions and achieve business-wide digital transformation.

For more information visit [1] www.infor.com


References

Visible links
1. https://www.infor.com/

Our Values

At Infor, we strive for an environment that is founded on a business philosophy called [1] Principle Based Management™ (PBM™) and eight Guiding Principles: integrity, stewardship & compliance, transformation, principled entrepreneurship, knowledge, humility, respect, self-actualization.

We have a relentless commitment to a culture based on PBM™. Informed by the principles that allow a free and open society to flourish, PBM™ prepares individuals to innovate, improve, and transform while fostering a healthy, growing organization that creates long-term value for its clients and supporters and fulfillment for its employees.

Infor is an Equal Opportunity Employer. We are committed to creating a diverse and inclusive work environment. Infor does not discriminate against candidates or employees because of their sex, race, gender identity, disability, age, sexual orientation, religion, national origin, veteran status, or any other protected status under the law. If you require accommodation or assistance at any time during the application or selection processes, please submit a request by following the directions located in the [2] FAQ section.

Fraud Awareness

We have been made aware of unauthorized individuals posing as Infor recruiters, including some who have made fraudulent offers of employment. Please read our [3] guidelines and protect yourself from recruitment scams.

Fraud Privacy Policy

We value your privacy at Infor. You may access our privacy policy [4] here.


References

Visible links
1. http://https//www.kochind.com/about/business-philosophy
2. https://www.infor.com/about/careers/faq
3. https://dam.infor.com/api/public/content/b45f298e1ab44b84ac898d759b2c21f7?v=3994f5e9
4. https://www.infor.com/about/privacy","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Software Development","","","","1711","https://www.linkedin.com/jobs/view/data-engineer-at-infor-4324320578?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","Richmond, VA","2 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/data-engineer-at-marketview-education-partners-4335478615?trk=public_jobs_topcard-title","MARKETview Education Partners","https://www.linkedin.com/company/marketvieweducationpartners?trk=public_jobs_topcard-org-name","Company Overview

MARKETview gives colleges and universities an analytical advantage in achieving their goals. Using higher education’s only aggregated, real-time student data set, we provide insights that are customized to address each partner’s key objectives. We then follow that up with actionable steps they can use to make better, more informed enrollment, marketing, and financial aid decisions. 

Headquartered in Richmond, Virginia, the company serves a rapidly growing number of partners nationwide, helping them navigate the shifting landscape of higher education.

Position Overview

MARKETview Education Technology is seeking a skilled and motivated mid-level Data Engineer with 3–5 years of experience to help build and manage the data infrastructure that powers our insights platform. You’ll play a key role in supporting complex data systems and ETL pipelines, working alongside a collaborative team of experienced professionals in a fast-growing, mission-driven environment.

Individuals will support and maintain complex data storage systems and will be responsible for all aspects of development, performance tuning, and monitoring.

Responsibilities


 * Develop and maintain robust ETL processes using Microsoft Azure tools (ADF, Data Lake, SQL) and Python.
 * Support ingestion and normalization of large, complex data sets from higher education institutions.
 * Collaborate with analytics and client service teams to ensure smooth client onboarding and data delivery.
 * Monitor and optimize data workflows for performance, scalability, and reliability.
 * Ensure data quality, integrity, and security using best-in-class BI tools and practices.
 * Create and maintain technical documentation to support internal knowledge sharing and client communications.
 * Contribute to the design and development of data models and data warehouse solutions.
   
   

Minimum Requirements


 * Bachelor’s degree in computer science, information technology or related field or a database certification
 * 3–5 years of professional experience in data engineering or a related role.
 * Hands-on experience with Microsoft Azure cloud services (ADF, Databricks, Function Apps, SQL)
 * Proficiency in Python for data manipulation and ETL development.
 * Solid understanding of structured and unstructured data storage.
 * Strong troubleshooting and problem-solving skills.
 * Impressive interpersonal and verbal communication skills
 * Ability to multitask and prioritize tasks appropriately
   
   

Preferred Qualifications


 * Exposure to working with large databases and developing data warehouses
 * Exposure to designing and developing dimensional models
 * Understanding of programmatic languages such as python for managing complex data
   
   

Bonus Points


 * Microsoft developer certifications
   
   

Why MARKETview Education Partners?

The MARKETview team is united by a common passion to increase higher education access while improving the performance of colleges and universities and the educational outcomes for students and families. This is the spirit that drives every client partner relationship, as we serve the mission of each with an unwavering commitment to their goals and success. We are looking for equally passionate team members with a similar disposition and willingness to put the success of others – partners and teammates – before their own. If this is you, you’ll fit right in.

Job Type: Full-time, on-site

Location: Richmond, VA

Equal Opportunity

MARKETview Education Technology is an equal opportunity employer. We are committed to building a diverse and inclusive environment for our employees and do not discriminate on the basis of any status protected under federal, state, or local law. Qualified candidates must be legally authorized to work in the United States without employer sponsorship for a work visa, both currently and in the future.","184 applicants","Full-time","Entry level","Information Technology","Education Administration Programs","","","","35583771","https://www.linkedin.com/jobs/view/data-engineer-at-marketview-education-partners-4335478615?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Data Engineer, RegTech","New York, NY","2 weeks ago","2025-11-17","https://www.linkedin.com/jobs/view/senior-data-engineer-regtech-at-drivewealth-4336732715?trk=public_jobs_topcard-title","DriveWealth","https://www.linkedin.com/company/drivewealth?trk=public_jobs_topcard-org-name","DriveWealth is a global B2B financial technology organization dedicated to democratizing access to financial independence around the world. Our mission is realized through an API-based platform, empowering our partners to offer seamless investing and trading experiences to clients worldwide, all from their mobile devices.

Our technology provides partners with a modern, extensible toolkit, enabling traditional investment workflows and innovative techniques like fractional share ownership. DriveWealth has evolved into a global platform offering trading of US equities, mutual funds, ETFs, fixed income, and options.

We seek enthusiastic professionals to contribute diverse perspectives and experiences to our Brokerage-as-a-Service platform. Our culture blends the pace and opportunity of a tech start-up with the impact, stability, and significance of Wall Street. We encourage creativity and experimentation while ensuring institutional-grade execution and regulatory compliance in everything we do. We value diversity and inclusion, celebrating the unique differences of our employees as we scale and grow together. We’re guided by operating principles grounded in accountability, teamwork, integrity, and solutions built to scale. Join us!

About The Role:

The Regulatory Technology (RegTech) team at DriveWealth develops data products to support the Compliance organization in its supervisory reporting responsibilities and external regulatory requirements. We are looking for a Senior Data Engineer to take ownership of regulatory-related data products. The role entails end-to-end automation of data ingestion, transformation, orchestration, and delivery of best-of-class data products to internal and external stakeholders. The end product may be a BI report, data mart, bulk raw data delivery, or REST API endpoints.

The ideal candidate is excited about working in an automated, modular, and testable environment and will work closely with the broader Data Platform, Analytics Engineers, Product Management, and Compliance professionals to ensure that requirements are met with scalable technical designs developed with strong engineering principles.

What You'll Do:


 * Assist in creatively solving compliance and regulatory needs at DriveWealth
 * Establish unit and regression testing practices for end-to-end CI/CD using declarative languages such as YAML and Terraform to ensure environmental parity
 * Work with business partners, compliance, and product managers on requirements using an AGILE framework
 * Work to establish an open and scalable data culture through documentation, constructive code reviews, and clear explanations of priorities and pain points
 * Provide thought leadership, best practices on architecture and tooling, and standards for designing and implementing scalable data analytics solutions
 * Provide mentorship and guidance to analytics engineers and analysts
   
   

What You'll Need:


 * 5+ years of experience solving data problems with internal and external stakeholders
 * 3+ years working on data ingestion (CSV, JSON, REST), data transformation (DBT), and orchestrating data pipelines (Databricks and/or Airflow)
 * 2+ years of experience working with trading and/or regulatory reports, such as best execution, CAT, OATS, trade monitoring, EBS, and regulatory inquiries
 * Experience working within a larger data team: CI/CD process leveraging GitHub and AGILE development where possible
 * Programming Languages: Python, SQL, Spark (PySpark, Spark SQL)
 * Declarative Languages: YAML, Terraform
 * Databases: DynamoDB, Unity Catalog, PostgreSQL, SQL Server
 * BS in Computer Science or equivalent program
   
   

Nice To Have, But Not Required:


 * Experience with business intelligence reporting (Sigma)
   
   

Applicants must be authorized to work for any employer in the U.S. DriveWealth is unable to sponsor or take over sponsorship of an employment Visa at this time.

Compensation

Compensation package offerings are based on candidate experience and technical qualifications, as it relates to the role. These are identified and determined throughout your interviewing experience.

Please note: this role is expected to come into our office on a cadence set by the Hiring Manager/Team.

New York, NY (Hybrid) Pay Range

$150,000—$180,000 USD

Benefits


 * Competitive medical, dental, and vision insurance options
 * Mental health resources
 * Generous paid time off with observed holidays (varies per country)
 * Paid parental leave for biological and adoptive parents
 * Up to $2,500 or local equivalent each year to invest in continued education and personal development
 * Up to $900 each year or local equivalent for fitness and wellness reimbursement
 * Company-provided phone (varies by country)
 * For HQ in-office employees, a daily lunch stipend, unlimited snacks, and engaging office space in the Financial District
 * Pre-tax commuter benefits (US only)
 * Employer 401K match (US only)
   
   

Benefit offerings vary based on country and are subject to change.

Equal Employment Opportunity

To build technology and products that are used and loved by people and solve real-world problems, we need to build a team with many different perspectives and experiences. We are an equal opportunity employer. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We encourage candidates from all backgrounds to apply. Applicants in need of special assistance or accommodation during the interview process or in accessing our website may contact us at recruiting@drivewealth.com.

Agency Disclaimer

DriveWealth does not accept agency resumes. Please do not forward resumes to our jobs alias, employees, or any other organization location. DriveWealth is not responsible for any fees related to unsolicited resumes.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology","Financial Services","$150,000.00/yr - $180,000.00/yr","","","5004213","https://www.linkedin.com/jobs/view/senior-data-engineer-regtech-at-drivewealth-4336732715?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Analytics Engineer","San Francisco, CA","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/senior-analytics-engineer-at-world-4337252598?trk=public_jobs_topcard-title","World","https://www.linkedin.com/company/worldofficial?trk=public_jobs_topcard-org-name","About The Company

World is building a real human network designed to accelerate people in the age of AI. As bots and autonomous agents reshape the internet, people, institutions, and applications need a trusted way to confirm who is a real human while preserving privacy. Our products make this possible: the Orb verifies real people, World ID proves it privately, and World App enables and distributes the new applications made possible by this technology. Together, they form a new layer for AI internet.

We’re one of the fastest-growing networks in tech. More than 17 million people across 160 countries have verified with World ID, and we complete over 350,000 verifications each week. World App is already among the most used wallets globally. Developers are integrating World ID to build safer online experiences and create spaces where real people can participate, earn, and be recognized in ways AI simply can’t replicate.

World was founded in 2019 and launched globally in 2023. We are more than 400 people across hardware, software, AI, cryptography, mobile engineering, and global operations. Our teams come from OpenAI, Tesla, SpaceX, Apple, Google, Stripe, Meta, Coinbase, Palantir and MIT Media Lab. We’re backed by leading investors, including a16z, Khosla Ventures, Bain Capital Crypto, Blockchain Capital, Variant, Tiger Global, and Coinbase Ventures, as well as prominent operators and founders across fintech and AI.

World has been featured on the cover of TIME Magazine, highlighted in Fast Company’s Next 5 in Fintech, and explored in a Bloomberg deep dive. The New York Times, Bankless and TechCrunch have all recognized our progress in identity, cryptography, AI, and global-scale hardware deployment. Our leadership is also named to the Time AI 100.

About The Team

The Analytics Engineering team bridges the gap between data engineering and data analysis. We're responsible for building and maintaining data infrastructure, designing efficient data pipelines, and developing robust data models that power Data Science across the organization. Our team transforms raw data into reliable, accessible datasets that enable data-driven decision making throughout the organization.

Due to our unique growth model, we need a high-performing Analytics Engineering team capable of managing the vast amounts of complex data generated by our products and operations. World’s privacy-maximizing approach imposes unique restrictions on how data is collected, stored, and used, making analytics engineering innovations critical to provide the team with useful data models. We have earned a reputation for our technical expertise, hands-on approach, responsiveness, precision, and impactful solutions.

About The Role

We're looking for a talented and motivated Senior Analytics Engineer to join our Analytics Engineering team. You'll focus on understanding business requirements, developing and maintaining dbt models, assisting stakeholders with BI queries, enhancing data model performance, and documenting and refactoring existing pipelines.

In addition to working closely with the Data Engineering and Data Science teams, you will collaborate with teams across the broader organization, including Economic Operations, Fraud & Risk Analytics, Product, Engineering, Blockchain Protocol, etc. Your work will directly shape the quality and speed of data-driven decision-making at World.

This is an ideal opportunity for candidates with at least 4 years of experience who are ready to grow professionally, take ownership of projects, and excel in a dynamic environment that offers both autonomy and significant impact.

In This Role, You Will


 * Develop and maintain performant dbt models in Snowflake for all departments across the company.
 * Collaborate closely with a high-performing team of data scientists, data engineers, blockchain engineers, statisticians and economists.
 * Work with an exciting, massive dataset, including product (e.g., user in-app behavior, notifications, experiments), blockchain transactions, operations, fraud models, and customer support data.
 * Write and support SQL queries in Metabase used by teams across the company
 * Monitor and improve performance of analytical queries and pipelines
   
   

About You


 * Bachelor’s or Master’s degree in Engineering, Physics, Mathematics, Statistics, Computer Science, or a related quantitative field
 * 4+ years of experience in analytics engineering or data engineering
 * Strong SQL skills, and experience working with Snowflake
 * Hands-on experience with dbt and GitHub workflows
 * Ability to learn quickly, work independently, and take ownership of tasks
 * Clear communicator with a knack for writing clean, maintainable code and documentation
 * Start-up experience or experience working in lean, fast-paced environments
   
   

Location:

Onsite in San Francisco

By submitting your application, you consent to the processing and internal sharing of your CV within the company, in compliance with the GDPR.

Pay Transparency Statement (for CA Based Roles)

The reasonably estimated base salary for this role at TFH ranges from $204,000 - $220,000 plus a competitive long term incentive package. Actual compensation is based on factors such as the candidate's skills, qualifications, and experience. In addition, TFH offers a wide range of best in class, comprehensive and inclusive employee benefits for this role including healthcare, dental, vision, a 401(k) plan and match, life insurance, flexible time off, commuter benefits, professional development stipend and much more!","138 applicants","Full-time","Mid-Senior level","Information Technology","Technology, Information and Internet","$204,000.00/yr - $220,000.00/yr","","","76499266","https://www.linkedin.com/jobs/view/senior-analytics-engineer-at-world-4337252598?trk=public_jobs_topcard-title","EASY_APPLY",""
"Machine Learning Engineer","Denver, CO","1 month ago","2025-10-24","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-zvst-cloud-technologies-inc-4331161960?trk=public_jobs_topcard-title","ZVST Cloud Technologies, Inc.,","https://www.linkedin.com/company/zvst-cloud-technologies?trk=public_jobs_topcard-org-name","Machine Learning Engineer Denver, CO

Type:Contract Duration:12 Months Rate:Negotiable Mode of Interview:Telephonic / Skype

Job Description


 * 3-5 years of data engineering expertise
 * Experience with ML, clustering, neural networks, AI training
 * Experience in data analysis and data science
 * Experience with Spark, Spark ML, Lucene
 * Adept at learning and applying new technologies and solving new problems
 * Work remotely but be willing to periodically travel for team meetings
   
   

Apply Form

Resume Upload*

Description


 * 
 * 3-5 years of data engineering expertise
 * Experience with ML, clustering, neural networks, AI training
 * Experience in data analysis and data science
 * Experience with Spark, Spark ML, Lucene
 * Adept at learning and applying new technologies and solving new problems
 * Work remotely but be willing to periodically travel for team meetings
   
   

"" title=""Share on Facebook"" target=""_blank"">


 * 
 * 3-5 years of data engineering expertise
 * Experience with ML, clustering, neural networks, AI training
 * Experience in data analysis and data science
 * Experience with Spark, Spark ML, Lucene
 * Adept at learning and applying new technologies and solving new problems
 * Work remotely but be willing to periodically travel for team meetings
   
   

"" target=""_blank"" title=""Share on LinkedIn"">","120 applicants","Full-time","Entry level","Engineering and Information Technology","IT Services and IT Consulting","","","","13238554","https://www.linkedin.com/jobs/view/machine-learning-engineer-at-zvst-cloud-technologies-inc-4331161960?trk=public_jobs_topcard-title","EASY_APPLY",""
"Senior Technical Program Manager, Data Center - Engineering Operations","Santa Clara, CA","1 week ago","2025-11-22","https://www.linkedin.com/jobs/view/senior-technical-program-manager-data-center-engineering-operations-at-nvidia-4338520315?trk=public_jobs_topcard-title","NVIDIA","https://www.linkedin.com/company/nvidia?trk=public_jobs_topcard-org-name","We are looking for a Senior Technical Program Manager (TPM) to join NVIDIA’s Server Engineering Operations Team. You will be the cross-section between execution and strategy, driving impactful programs and delivering measurable results across many functions of R&D Engineering Operations. NVIDIA’s enterprise server platforms have made a major impact to various fields and are universally used across leading CSPs and industry datacenters, including the world’s largest Internet companies. We need passionate, hard-working, with a can-do attitude and creative people to help us take on more of these unique opportunities in data-center solutions.

What You Will Be Doing


 * The Technical Program Manager will have strong skills and experience in program management and engineering operations. The Technical Program Manager is encouraged to be an analytical, meticulous, effective communicator. We expect you to have the ability to work across multiple engineering teams to understand our product roadmap, as well as limitations we may encounter.
 * Your ability to use historical trends, generate meaningful metrics, and stay tuned into rapid changes in product development plans will play a key role in helping Nvidia succeed by bringing world class enterprise products to market at the speed of light!
 * Lead coordination, planning and execution activities for our Datacenter Server product deployments in internal development data centers. In this role you will develop and lead end-to-end project plans to improve infrastructure stability, observability, and uptime; help define and drive KPIs. Be at the intersection of engineering, operations and lab administration teams helping streamline overall engineering operations.
 * Provide hands-on program management during analysis, design, development, testing, implementation, and post implementation phases.
 * Opportunity to interact with diverse technical groups, spanning all organizational levels.
   
   

What We Need To See


 * Proven experience and successful record of accomplishment handling sophisticated infrastructure deployments. We need solid Service Management or Engineering Operations experience.
 * 10+ years of experience as a TPM or hands-on leader in a similar collaborative role involving multiple engineering teams, developing enterprise hardware products.
 * Bachelor's degree in a related field, or equivalent experience
 * Experience leading cross-organizational programs, effectively influencing partners and holding them accountable to goals, timelines, and deliverables
 * Analytical and problem-solving experience including experience defining and collecting key metrics across projects
 * We are a matrix organization. We need to see experience communicating effectively across the organization with interpersonal skills, including relationship building and collaboration within a cross-functional team!
   
   

Ways To Stand Out From The Crowd


 * Understanding of software engineering principles, enterprise system architecture and parallel computing. Prior experience in hardware or software QA best practices
 * Experience with productivity tools and process automation.
 * Experience with engineering operations tools, triage, and overall methodology
   
   

NVIDIA is considered one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people in the world working for us. Are you creative and autonomous? Do you love a challenge? If so, we want to hear from you. Come, join our Deep Learning Enterprise Server Platform team and help build the real-time, cost-effective computing platform driving our success in this exciting and quickly growing field.

Your base salary will be determined based on your location, experience, and the pay of employees in similar positions. The base salary range is 160,000 USD - 253,000 USD for Level 4, and 192,000 USD - 304,750 USD for Level 5.

You will also be eligible for equity and benefits .

Applications for this job will be accepted at least until November 25, 2025.NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.

JR2001987

","48 applicants","Full-time","Mid-Senior level","Project Management and Information Technology","Computer Hardware Manufacturing, Software Development, and Computers and Electronics Manufacturing","$160,000.00/yr - $304,750.00/yr","Bella Yanovsky","https://www.linkedin.com/in/bella-yanovsky-4a17ba3","3608","https://nvidia.wd5.myworkdayjobs.com/NVIDIAExternalCareerSite/job/US-CA-Santa-Clara/Senior-Technical-Program-Manager\u002d\u002dData-Center\u002d\u002d-Engineering-Operations_JR2001987-1?source=jobboardlinkedin","EXTERNAL",""
"Applied Data Scientist, Unit Economics Understanding","San Francisco, CA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/applied-data-scientist-unit-economics-understanding-at-openai-4331495307?trk=public_jobs_topcard-title","OpenAI","https://www.linkedin.com/company/openai?trk=public_jobs_topcard-org-name","About The Role

This role focuses on building the strategic unit economics understanding of OpenAI, guiding sustainable growth to make it the most impactful company of our generation and beyond.

You will lead the development of foundational causal inference and data science models and frameworks to predict and quantify the drivers of customer lifetime value (LTV), translating deep data insights into strategic decisions and growth levers. The role requires both technical depth and executive-level communication.

This position is based in our San Francisco HQ with a hybrid work model (three days in office per week). Relocation assistance is available.

The Vision


 * Build causal inference and predictive analytics capabilities to measure and forecast LTV across customer segments (B2C and B2B), and quantify the incremental impact of different actions or product features on customer LTV.
 * Design customer “happy paths” by identifying adoption journeys that maximize lifetime value while ensuring customers gain the most from our ecosystem.
 * Analyze price elasticity to guide product packaging, monetization, and pricing strategies.
   
   

In This Role, You Will


 * Partner with cross-functional teams (Finance, Product, Data Engineering, GTM, and other DS teams) to build causal inference and predictive models that drive business decisions.
 * Develop and maintain LTV models across product lines and customer cohorts.
 * Architect scalable frameworks and models that democratize economic insights for leadership and functional teams.
 * Support strategic pricing and investment decisions with robust analytical and causal evidence.
 * Lead cross-functional data science initiatives, ensuring analytical rigor, clarity, and timely delivery.
   
   

You Might Thrive In This Role If You


 * Executive communication — ability to distill complex analysis into clear, actionable recommendations for leadership.
 * Technical breadth — comfort spanning ROI analysis, causal inference, statistical modeling, and ML predictive models; strong experience with Python and SQL.
 * Strategic judgment — ability to connect analytical insights to business impact, delivering the “so what” that informs leadership decisions.
 * Collaboration and ownership — thrive in a fast-paced, cross-functional environment and proactively take projects from concept to delivery.
   
   

Qualifications


 * MS or PhD in a quantitative field (Statistics, Economics, Applied Math, Operations Research, Computer Science, etc.).
 * 7+ years of experience in applied data science, causal inference, or quantitative strategy.
 * Proven record of delivering high-impact insights to executive leadership.
 * Experience building scalable analytical frameworks and models that inform business decision-making.
   
   

About OpenAI

OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.

We are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.

For additional information, please see OpenAI’s Affirmative Action and Equal Employment Opportunity Policy Statement.

Background checks for applicants will be administered in accordance with applicable law, and qualified applicants with arrest or conviction records will be considered for employment consistent with those laws, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act, for US-based candidates. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.

To notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.

We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.

OpenAI Global Applicant Privacy Policy

At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.

Compensation Range: $255K - $405K","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Research Services","$255,000.00/yr - $405,000.00/yr","","","11130470","https://jobs.ashbyhq.com/openai/9f69106f-c2c9-4f14-9938-f38eb42cab50/application","EXTERNAL",""
"Data Scientist, People","San Francisco, CA","2 weeks ago","2025-11-15","https://www.linkedin.com/jobs/view/data-scientist-people-at-doordash-4340663704?trk=public_jobs_topcard-title","DoorDash","https://www.linkedin.com/company/doordash?trk=public_jobs_topcard-org-name","About The Team

The People Data Science team is part of DoorDash’s People Intelligence organization, a multidisciplinary group that combines data science, business intelligence, analytics engineering, and data engineering to power our people decisions with trusted, scalable insights. Together, we enable DoorDash to unlock the full potential of our talent and drive measurable improvements in organizational effectiveness.

As the advanced analytics arm of People Intelligence, the People Data Science team applies statistical modeling, machine learning, and AI-driven analysis to uncover trends and patterns across the employee lifecycle — from hiring to engagement to retention. By transforming people data into meaningful insights, we help DoorDash foster a thriving, high-performing workforce and make data-informed decisions that elevate the employee experience and organizational impact.

About The Role

As a Data Scientist on the People Team at DoorDash, you will shape the future of people analytics by building and deploying AI and LLM-based models that deliver insights from both quantitative and qualitative employee data. You’ll design intelligent systems and agents that leverage large-scale employee experience, performance, and organizational data — integrating structured and unstructured signals to uncover trends that inform talent strategy and business outcomes.

This role blends deep expertise in statistical modeling, natural language processing, and applied machine learning with a strong understanding of people analytics and business context. You’ll collaborate with data engineers, applied scientists, and People Business Partners to develop scalable insight-generation systems that help leaders make more informed, data-backed decisions.

You're Excited About This Opportunity Because You Will...


 * Build AI-powered people analytics tools — develop LLM- or agent-based systems that summarize employee sentiment, extract insights from qualitative feedback, and surface trends in quantitative data.
 * Apply advanced statistical and ML techniques to understand drivers of engagement, retention, and performance.
 * Design, test, and deploy scalable models and pipelines that analyze large volumes of survey, feedback, and HR data.
 * Collaborate cross-functionally with People, Engineering, and Product partners to design AI solutions that support business strategy and improve the employee experience.
 * Translate data into action — tell compelling stories with data that shape leadership decisions and organizational priorities.
 * Explore cutting-edge GenAI and NLP approaches — from embeddings and topic modeling to fine-tuning LLMs for people analytics applications.
 * Contribute to the evolution of People Data Science at DoorDash — shaping our approach to scalable, AI-driven insights for the future of work.
   
   

We’re Excited About You Because You Have...


 * Master’s or Ph.D. in Data Science, Computer Science, Statistics, Applied Mathematics, Economics, Industrial-Organizational Psychology (quantitative track), or a related field.
 * 3+ years of experience applying data science methods to real-world problems (1–2+ years in People Analytics preferred).
 * Proficiency in Python and SQL, with experience using ML and NLP libraries (e.g., scikit-learn, statsmodels).
 * Proven experience building or applying large language models (LLMs) and NLP-based systems for text summarization, sentiment analysis, or insight extraction.
 * Strong foundation in statistical modeling, causal inference, and experimental design (e.g., regression, clustering, A/B testing, time-series).
 * Experience designing and scaling data pipelines using Snowflake, dbt, Databricks.
 * Familiarity with LLM orchestration tools (e.g., LangChain, LlamaIndex, or similar frameworks) and vector databases (e.g., Postgres with pgvector).
 * Ability to distill complex analyses into actionable insights through clear communication, visualization, and storytelling.
 * Experience creating data visualizations and dashboards using tools such as Sigma, Tableau, or Looker to communicate insights effectively.
 * Passion for building AI solutions that empower people leaders and improve organizational decision-making through ethical and responsible applications of data science.
   
   

Nice-to-have


 * Experience building or contributing to AI analytics assistants or chatbots that enable natural language access to insights.
 * Experience with data science python packages such as PyTorch, TensorFlow, and Hugging Face Transformers.
 * Experience in survey analytics, employee engagement research, or text analytics using large-scale feedback data.
 * Familiarity with HRIS systems (e.g., Workday) and core workforce metrics such as attrition and engagement.
 * Exposure to fine-tuning foundation models and evaluating LLM performance for reliability and bias.
 * Experience with graph databases (e.g., Neo4j) for modeling organizational networks.
 * Background in applied behavioral science, organizational research, or people analytics experimentation.
   
   

Notice to Applicants for Jobs Located in NYC or Remote Jobs Associated With Office in NYC Only

We use Covey as part of our hiring and/or promotional process for jobs in NYC and certain features may qualify it as an AEDT in NYC. As part of the hiring and/or promotion process, we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound from August 21, 2023, through December 21, 2023, and resumed using Covey Scout for Inbound again on June 29, 2024.

The Covey tool has been reviewed by an independent auditor. Results of the audit may be viewed here: Covey

Compensation

The successful candidate’s starting pay will fall within the pay range listed below and is determined based on job-related factors including, but not limited to, skills, experience, qualifications, work location, and market conditions. Base salary is localized according to an employee’s work location. Ranges are market-dependent and may be modified in the future.

In addition to base salary, the compensation for this role includes opportunities for equity grants. Talk to your recruiter for more information.

DoorDash cares about you and your overall well-being. That’s why we offer a comprehensive benefits package to all regular employees, which includes a 401(k) plan with employer matching, 16 weeks of paid parental leave, wellness benefits, commuter benefits match, paid time off and paid sick leave in compliance with applicable laws (e.g. Colorado Healthy Families and Workplaces Act). DoorDash also offers medical, dental, and vision benefits, 11 paid holidays, disability and basic life insurance, family-forming assistance, and a mental health program, among others.

To learn more about our benefits, visit our careers page here.

See Below For Paid Time Off Details


 * For salaried roles: flexible paid time off/vacation, plus 80 hours of paid sick time per year.
 * For hourly roles: vacation accrued at about 1 hour for every 25.97 hours worked (e.g. about 6.7 hours/month if working 40 hours/week; about 3.4 hours/month if working 20 hours/week), and paid sick time accrued at 1 hour for every 30 hours worked (e.g. about 5.8 hours/month if working 40 hours/week; about 2.9 hours/month if working 20 hours/week).
   
   

The national base pay range for this position within the United States, including Illinois and Colorado.

$124,100—$182,500 USD

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

Our Commitment to Diversity and Inclusion

We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on “protected categories,” we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.

Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.

If you need any accommodations, please inform your recruiting contact upon initial connection.","164 applicants","Full-time","Entry level","Engineering and Information Technology","Software Development","","","","3205573","https://job-boards.greenhouse.io/doordashusa/jobs/7398398","EXTERNAL",""
"Senior Data Scientist","Irvine, CA","1 week ago","2025-11-21","https://www.linkedin.com/jobs/view/senior-data-scientist-at-finfare-4333147794?trk=public_jobs_topcard-title","Finfare","https://www.linkedin.com/company/finfare?trk=public_jobs_topcard-org-name","About Snowpeak AI

Are you eager to make a significant impact in the ever-evolving AI landscape? Join Snowpeak AI, a dynamic leader in AI innovation, as a Senior Data Scientist. You’ll work alongside a top-tier AI team to harness data, advanced analytics, and cutting-edge models to fuel strategic growth and deliver real-world impact. This is your chance to lead data-driven transformation, build intelligent systems, and push the boundaries of conversational AI and automation.

We seek a versatile expert with deep proficiency in conversational AI, LLMs, agentic AI, retrieval systems, and end-to-end ML development, combined with a relentless drive to learn, experiment, and solve complex problems. From designing RAG-powered chatbots to securing data pipelines, you’ll own critical initiatives that power our AI-enabled operators and customer solutions. Please note that we are a fully on-site environment based in Irvine, CA. For the right candidate, we are open to potentially considering remote/hybrid arrangements and visa sponsorship opportunities.

Key Responsibilities:

 * Design, build, and refine conversational AI systems using retrieval-augmented generation (RAG), combining large language models (LLMs) with vector search and retrieval.
 * Develop data ingestion and embedding pipelines to support scalable, efficient information retrieval.
 * Fine-tune and adapt LLMs for domain-specific use cases, covering prompt engineering, instruction tuning, and low-rank adaptation (LoRA).
 * Integrate AI models into CRMs, workflow platforms and vendor management systems.
 * Own the end-to-end development of machine learning algorithms, from data collection and feature engineering to model training, validation, and performance tuning.
 * Research and prototype emerging ML architectures and retrieval strategies to enhance performance.
 * Resolve and rerank RAG’s training material data for a single source of truth.
 * Translate business requirements into robust, data-driven technical solutions with measurable outcomes.
 * Collaborate with engineering teams to deploy, scale, and monitor AI systems across the organization.
 * Identify new opportunities to embed machine learning into business processes and workflows.
 * Partner with Product, Marketing, Finance, Risk, and Operations to define and track key performance metrics.
 * Continuously improve data pipelines for accuracy, accessibility, and scalability.
 * Support cross-functional data science initiatives and perform additional duties as needed.
 * Other duties as assigned.

 

Qualifications & Requirements:

 * Education: Bachelor’s degree in a quantitative or technical field; Master’s or Ph.D. preferred.
 * 8+ years of professional experience in data science, AI, or applied machine learning.
 * Proven experience in designing and building Voice AI systems and/or chatbots, including speech recognition, conversational agents, and real-time dialogue models.
 * Hands-on proficiency with leading machine learning and deep learning frameworks, such as LangChain, Hugging Face, TensorFlow, PyTorch, Keras, scikit-learn, and pandas.
 * 7+ years of strong programming expertise in Python/Pyspark and SQL, with proven experience deploying AI solutions in cloud environments (AWS or Google Cloud Platform).
 * 2+ years of practical experience working with MCP, LLMs, generative AI, and conversational AI frameworks (e.g., LangChain, LangGraph, RAG, Vector Databases, AutoGen, CrewAI).
 * 5+ years of specialization in at least one area of advanced modeling - predictive analytics, recommendation engine, reinforcement learning, natural language processing (NLP), or causal inference.
 * 4+ years of experience translating complex AI and data science concepts into tangible business outcomes, including stakeholder engagement and value quantification.
 * 4+ years leading end-to-end AI solution delivery, from data architecture and model orchestration to front-end integration and user adoption.
 * Demonstrated excellence in communication, storytelling, and customer engagement, with the ability to present technical insights in a clear and impactful manner.
 * Experience developing agentic AI systems for conversational analytics, autonomous reporting, or intelligent decision support.
 * Proven ability to design, train, and deploy machine learning models for real-world applications.
 * Strong expertise in data acquisition, preprocessing, and quality assurance for enterprise or industry-scale use cases.

Bonus Points:

 * Strong data analysis and visualization skills.
 * Practical knowledge of data engineering.
 * A proactive and open mindset with a willingness to learn and adapt to emerging technologies and techniques.

Compensation

The compensation for this position is $130k - $190k+ (depending on experience).

Benefits at Snowpeak AI

 * Competitive health, vision, and dental benefits (covering 100% premium for employee and all dependent(s))
 * 401K (with employer matching) 
 * Health and wellness reimbursement
 * Catered lunches 5x times a week
 * Work sponsorship (if applicable)
 * Other employee perks

As part of our dedication to the diversity of our workforce, Snowpeak AI is committed to a policy of Equal Employment Opportunity and will not discriminate against an applicant or employee on the basis of race, color, religion, creed, national origin or ancestry, sex, gender, gender identity, gender expression, sexual orientation, age, physical or mental disability, medical condition, marital/domestic partner status, military and veteran status, genetic information or any other legally recognized protected basis under federal, state or local laws, regulations or ordinances.","26 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Financial Services","$130,000.00/yr - $190,000.00/yr","","","81003123","https://www.linkedin.com/jobs/view/senior-data-scientist-at-finfare-4333147794?trk=public_jobs_topcard-title","EASY_APPLY",""
"Artificial Intelligence/Machine (AI/ML) Learning Engineer","La Mirada, CA","2 weeks ago","2025-11-13","https://www.linkedin.com/jobs/view/artificial-intelligence-machine-ai-ml-learning-engineer-at-living-spaces-furniture-4335778818?trk=public_jobs_topcard-title","Living Spaces Furniture","https://www.linkedin.com/company/living-spaces-furniture?trk=public_jobs_topcard-org-name","Position Summary

The Artificial Intelligence/Machine (AI/ML) Learning Engineer plays a vital role in designing, building, and implementing enterprise-grade Artificial Intelligence and Machine Learning solutions. This position focuses on leveraging the Microsoft and Azure stack to create and deploy intelligent automation, predictive analytics, and other AI-powered tools. This role will collaborate closely with business units to gather requirements and scope projects, and drive them to resolution, while also helping to establish and build out the company's AI Center of Excellence (COE).

Position Description

Essential Duties and Responsibilities include the following. Other duties may be assigned.


 * Design and implement end-to-end AI and Machine Learning solutions, platforms, and tools.
 * Develop solutions focused on Intelligent Automation and Predictive Analytics.
 * Build and deploy models predominantly within the Microsoft and Azure Stack (e.g., Azure ML, Cognitive Services, Azure Databricks).
 * Leverage the Google Vertex AI Stack(e.g., BigQuery, VertexAI, Imagen, Veo, Gemini API and Agentic Platform) where the toolset meets the business need.
 * Collaborate with business stakeholders to gather user requirements, define project scope, and translate needs into technical specifications.
 * Assist in the development, documentation, and governance of the AI Center of Excellence (COE).
 * Drive AI/ML projects from initial conception and design through to deployment, monitoring, and resolution.
 * Design and conduct experiments and tests with a focus on model performance, scalability, and accuracy.
 * Collaborate with data engineers, developers, and other IT personnel to design and integrate compatible solutions.
 * Evaluate existing systems and provide advice on integrating new AI/ML capabilities.
 * Stay current with the latest advancements in AI, machine learning, and the Azure ecosystem.
   
   

Qualifications

Education/Experience: Bachelor's degree (B. S.) or equivalent from four-year college in Computer Science, Data Science, Artificial Intelligence, or related field preferred. 3-5+ years of hands-on experience in data science, machine learning, or AI engineering. Demonstrable experience with the Microsoft and Azure AI stack (e.g., Azure ML, Azure Cognitive Services, Azure Databricks, Power BI). Equivalent combination of education and experience will be considered.

Computer Skills: To perform this job successfully, an individual must have the following core capabilities. Proficiency in programming languages such as Python or R. Deep experience with the Microsoft Azure AI stack: Azure Machine Learning, Cognitive Services, Azure Databricks, Azure Data Factory. Experience with ML frameworks and libraries (e.g., Scikit-learn, TensorFlow, PyTorch). Strong understanding of data modeling, data warehousing, and predictive analytics. Knowledge of MLOps principles and tools for model deployment and management.

Certificates and Licenses: CCNA / CCNP preferred but not required.

Supervisory Responsibilities: This position will not have supervisory responsibilities.

Position Hiring Range

The hiring pay range provides a guide for what we would reasonably pay for the position. Pay will be determined by several factors, including but not limited to: applicant’s education, relevant work experience, knowledge, skills and abilities, as well as internal equity and alignment with geographic market data. Living Spaces reserves the right to modify this pay range at any time. Pay is determined by various factors including market demand, applicable skills, work experience and education, location, company budget, and in-demand skill sets.

Compensation: $90,000.00 - $120,000.00

Retail, Guest Services, and Distribution Center Team Members are eligible to receive team bonus based on meeting specific goals and KPI’s.

Benefits Include


 * Medical
 * Dental
 * Vision
 * 401(k) (full and part time eligible)
 * Vacation
 * Sick Time
 * Flex Spending Account
 * Employee Assistance Program
   
   

For more details, please visit our website at: Careers (livingspaces.com)

Equal Opportunity Employer

It is our policy to abide by all federal, state, and local laws prohibiting employment discrimination based solely on a person’s race, color, religious creed, sex, national origin, ancestry, citizenship status, pregnancy, physical disability, mental disability, age, military status, or status as a Vietnam-era or special disabled veteran, marital status, registered domestic partner or civil union status, gender (including sex stereotyping and gender identity or expression), medical condition (including but not limited to, cancer related or HIV/AIDS related), sexual orientation, or any other protected status except where a reasonable, bona fide occupational qualification exists.

E-Verify

Living Spaces participates in E-Verify. All newly-hired team members are queried through this electronic system established by the Department of Homeland Security (DHS) and the Social Security Administration (SSA) to verify their identity and employment eligibility.

Applicant Privacy

#corporate","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Furniture and Home Furnishings Manufacturing, Retail, and Manufacturing","$90,000.00/yr - $120,000.00/yr","","","2183946","https://www.linkedin.com/jobs/view/artificial-intelligence-machine-ai-ml-learning-engineer-at-living-spaces-furniture-4335778818?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist","Marietta, GA","3 days ago","2025-11-28","https://www.linkedin.com/jobs/view/data-scientist-at-accion-labs-4324361097?trk=public_jobs_topcard-title","Accion Labs","https://www.linkedin.com/company/accionlabs?trk=public_jobs_topcard-org-name","The IT Data Senior Scientist will leverage advanced analytics, machine learning, and statistical methods to extract meaningful insights from complex datasets. In this role, they will develop and implement data models, conduct in-depth analysis, and collaborate with cross-functional teams to drive data-driven decision-making. They will work with large datasets to identify patterns, build predictive models, and provide actionable recommendations that support business strategies. This position offers the opportunity to work with cutting-edge technologies and mission-critical AI-based business cases, and solve key challenges through data innovation.




Must have skills:

-Machine Learning Model Development and Deployment

-Industrial Data Science and IoT/Time Series (Critical for working with sensor data from manufacturing sources (IoT/Industry 4.0)

-Computer Vision (CV): Specific experience with AI-driven solutions like computer vision for automate product inspection and identifying defects, which requires technical familiarity with CV libraries like OpenCV and deep learning frameworks like TensorFlow/PyTorch.

-Working with ""large datasets"" and deploying cutting-edge AI requires a scalable, cloud-based infrastructure.







Key Responsibilities

 * Gather, preprocess, and clean data from various manufacturing sources (e.g., sensors, production systems) to ensure high-quality, accurate datasets for analysis.
 * Develop machine learning models to predict equipment failures, enabling proactive maintenance and minimizing downtime on the manufacturing floor.
 * Implement AI-driven solutions such as computer vision and statistical models to automate product inspection, identify defects, and maintain product quality.
 * Analyze production processes to identify inefficiencies, bottlenecks, and opportunities for optimization, recommending data-driven strategies to improve throughput and reduce costs.
 * Use data analytics to optimize supply chain operations by forecasting demand, improving inventory management, and enhancing logistics to reduce lead times and costs.
 * Build and refine predictive models to forecast production schedules, optimize resource allocation, and improve capacity planning based on historical data and trends.
 * Design and deploy anomaly detection algorithms to monitor production systems, identifying unusual patterns or failures in real-time to prevent costly errors.
 * Work closely with production, engineering, and IT teams to understand business needs, develop solutions, and integrate data science tools into manufacturing workflows.
 * Create dashboards, visualizations, and reports to effectively communicate insights and trends to stakeholders and support data-driven decision-making.
 * Stay updated on emerging data science techniques and technologies, driving continuous improvements in manufacturing processes and introducing innovative solutions to enhance productivity.

Required Education, Experience, and Skills

Minimum Education Level: Bachelor's

Specialized Degree: Software Engineering, Applied Computer Science, Statistics.

Years of Experience: 5-7 years

Field of Expertise: Manufacturing, ioT, Industry 4.0, Cybersecurity,

Preferred Education, Experience, and Skills

Minimum Education Level: Master's

Certificates: GCP, AW, S, or Azure certified

Years of Experience: 8-11 years

Preferred Field of Expertise: Manufacturing in Wire & Cable","Over 200 applicants","Full-time","Mid-Senior level","Consulting","IT Services and IT Consulting","","Sheetal Correia","https://www.linkedin.com/in/sheetal-correia-2471115a","2680000","https://www.linkedin.com/jobs/view/data-scientist-at-accion-labs-4324361097?trk=public_jobs_topcard-title","EASY_APPLY",""
"Business Data Specialist","Fort Worth, TX","2 weeks ago","2025-11-14","https://www.linkedin.com/jobs/view/business-data-specialist-at-textron-4336301921?trk=public_jobs_topcard-title","Textron","https://www.linkedin.com/company/textron?trk=public_jobs_topcard-org-name","Description

We’re more than aviation experts, we’re pioneers. We challenge what’s possible. From breaking the sound barrier to advanced tiltrotor systems. Today, Bell is shaping the future of aviation through specialized engineering. And we want you.

Enterprise Digital Systems

Bring your skills and experience to the Enterprise Digital Systems department at Bell who maintains cross-functional alignment and long-term strategy for tools in engineering design, manufacturing, and product lifecycle management. The team advocates for the business need of engineering analytical tools, aligns tool development with program needs short and long-term, and orchestrates evaluation of new methods and tools. The team also has responsibility to drive data governance, enable data domain ownership, and support adoption of data mesh principles. What you’ll be doing as a Business Data Specialist


 * Develop advanced analytics solutions using tools like Power BI, R, and Python to consume and visualize data from existing data products
 * Create dashboards, reports, and visualizations that provide actionable insights for business and engineering teams as well as define and maintain data products that ensure trusted, high-quality data for analytics and decision-making
 * Utilize and improve data governance policies, standards, and stewardship practices across engineering and associated manufacturing domains to enable data product quality sustainment and analytics output viability (not in the job role to create data governance outside of the EDP and analytics team)
 * Understand technical analytics needs of business stakeholders and provide documentation of sourcing, transformation, and quality expectations to data product architects and development teams
 * Explain technical implications of systems like structured databases, the Databricks cloud data, and API endpoint integrations to business stakeholders as well as analyze and document existing data architecture to identify gaps and opportunities for improvement
 * Work with IT Data Architecture team to ensure alignment of data architecture with business goals and objectives as well as enable domain experts with templates, tools, and processes to manage their data products effectively
 * Oversee the migration of existing Power BI reports to new data medallions, operating within the Databricks lakehouse environment
 * Advocate for data quality, consistency, and security across the enterprise, as well as educate teams on data mesh principles, governance best practices, and modern analytics capabilities
 * Provide training and support to teams on data tools, systems, and processes
   
   

Qualifications

Skills You Bring To this Role


 * Strong understanding of data governance, stewardship, and data mesh principles
 * Designer and developer skills in analytics toolsets such as Power BI, Tableau, SQL, Python, R, and Databricks
 * Understanding of ETL processes and data pipeline development
 * Ability to translate business needs into technical requirements and vice versa
 * Skilled in rolling out stewardship programs to organizations primarily oriented to product design, engineering, and manufacturing
 * Ability in interpreting organizational hierarchies to anticipate both technical and labor management expectations
 * Ability to work collaboratively across teams and manage multiple priorities
 * Agility to utilize in-person and virtual communications to coordinate numerous stakeholders What you need to be successful
 * 10 years overall experience with Information Technology (IT)/ Operations Technology (OT) networking, programming, and/or other role relevant to IT/OT
 * Bachelor’s degree in information systems, engineering, engineering management, business administration or other related field What we offer you in return
 * You’ll be off every other Friday with our 9/80 work schedule
 * 80 hours of Personal Time Off (PTO)
 * 120 hours Vacation time
 * 12-13 paid holidays per year
 * 6 weeks parental leave
 * Tuition reimbursement
 * Competitive salary
 * Comprehensive health insurance
 * On-site clinic, pharmacy, physical therapy, and licensed counselor
 * Access to more than 11 Employee Resource Groups
 * And so much more
   
   

It’s time to make your mark on the future of aviation. Join us on this mission, and let’s make history together. We are on a journey to amplify innovation, cultivate purpose and bridge experiences by fostering a culture that is driven by unique perspectives, voices and values.

EEO Statement

Textron is committed to providing Equal Opportunity in Employment, to all applicants and employees regardless of race, color, religion, age, national origin, military status, veteran status, disability, sex (including pregnancy and sexual orientation), genetic information or any other characteristic protected by law.

This position requires use of information which is subject to the International Traffic in Arms Regulations (ITAR) and/or the Export Administration Regulations (EAR)., Non-U.S. persons selected must meet eligibility requirements for access to export-restricted information. , The ITAR/EAR defines a U.S. person as a U.S. Citizen, U.S. Permanent Resident (i.e. 'Green Card Holder'), Political Asylee, or Refugee.

Recruiting Company: Bell Textron Inc.

Primary Location: US-Texas-Fort Worth

Job Function: Information Technology

Schedule: Full-time

Job Level: Individual Contributor

Job Type: Standard

Shift: First Shift

Relocation: Available

Job Posting: 11/14/2025, 8:37:08 AM

Job Number: 337461","51 applicants","Full-time","Entry level","Information Technology","Aviation and Aerospace Component Manufacturing","","","","3335","https://www.linkedin.com/jobs/view/business-data-specialist-at-textron-4336301921?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineer","San Francisco, CA","5 days ago","2025-11-27","https://www.linkedin.com/jobs/view/data-engineer-at-motion-recruitment-4339242356?trk=public_jobs_topcard-title","Motion Recruitment","https://www.linkedin.com/company/motion-recruitment-partners?trk=public_jobs_topcard-org-name","We’re working with a company who’s seeking a top-tier data engineer to help build the data infrastructure that explains and models how work happens inside Fortune 500 organizations. This is not a conventional data role. You’ll be solving problems with no existing solutions, processing terabytes of workflow data per customer in real time, and mapping the full operational “genome” of large enterprises. You’ll be inventing new data primitives, designing novel data structures, and building pipelines that handle billions of events per day.

You’ll work directly with the founders and core engineering team on unprecedented challenges: real-time processing at massive scale, creating a universal taxonomy for work across industries, and architecting systems capable of handling the most complex enterprise data environments in the world.

Required Skills & Experience


 * Strong programming knowledge, Python preferred
 * Software engineering fundamentals - APIs, backend services
 * SQL + DBT (or SQLMesh) proficiency
 * Infrastructure as code: Terraform (or equivalent)
 * Datalake experience (Iceberg, Databricks, etc
 * Familiarity with Datalake Technology (Databrick, Iceberg, Etc.)
   
   

Desired Skills & Experience


 * Has trained models before (even personal projects count, perhaps especially)
 * You have interesting personal projects
 * Pytorch or similar framework experience
 * Kubernetes
 * Understand ML/DL systems from an infra perspective
   
   

What You Will Be Doing

Tech Breakdown


 * 75% Data Engineering
 * 25% Building APIs
   
   

The Offer


 * $150K - $250K salary, depending on candidate and experience
 * Bonus eligible
   
   

You Will Receive The Following Benefits


 * Substantial equity
 * Vacation Time
   
   

Applicants must be currently authorized to work in the US on a full-time basis now and in the future.

Posted By: Charles Deuter

","154 applicants","Full-time","Entry level","Information Technology","Staffing and Recruiting","","","","5887","https://motionrecruitment.com/tech-jobs/san-francisco-/direct-hire/data-engineer/800449?utm_source=linkedin&utm_medium=feed&utm_campaign=paid-20210428","EXTERNAL",""
"Senior Data Engineer","New York, NY","2 weeks ago","2025-11-12","https://www.linkedin.com/jobs/view/senior-data-engineer-at-genentech-4335399466?trk=public_jobs_topcard-title","Genentech","https://www.linkedin.com/company/genentech?trk=public_jobs_topcard-org-name","The Position

A healthier future. It’s what drives us to innovate. To continuously advance science and ensure everyone has access to the healthcare they need today and for generations to come. Creating a world where we all have more time with the people we love. That’s what makes us Roche.

Advances in AI, data, and computational sciences are transforming drug discovery and development. Roche’s Research and Early Development organisations at Genentech (gRED) and Pharma (pRED) have demonstrated how these technologies accelerate R&D, leveraging data and novel computational models to drive impact. Seamless data sharing and access to models across gRED and pRED are essential to maximising these opportunities. The new Computational Sciences Center of Excellence (CoE) is a strategic, unified group whose goal is to harness this transformative power of data and Artificial Intelligence (AI) to assist our scientists in both pRED and gRED to deliver more innovative and transformative medicines for patients worldwide.

The Opportunity

At Genentech and Roche, we're at the forefront of a revolutionary transformation in drug discovery powered by AI and machine learning. Our ""lab in the loop"" strategy processes massive quantities of experimental data to train AI models that accelerate the discovery of new medicines. To enable this vision, we're seeking an exceptional Senior Data Engineer to be part of the team building and maintaining our next-generation Therapeutic Molecule Registration (TMR) platform - a foundational component of our AI-driven drug discovery infrastructure, Lab-in-the-Loop (https://www.youtube.com/watch?v=cN1PxxQWoEc). This platform will serve as the central nervous system for managing and integrating molecular data across our global research organization, handling hundreds of billions of records and enabling unprecedented scale in virtual molecule design and testing. As the volume of AI-generated molecular designs grows exponentially, our TMR platform must evolve to become a high-performance, cloud-native system capable of supporting rapid iteration cycles between computational design and experimental validation. You will be instrumental in consolidating our molecule registration systems into a single, harmonized environment, unlocking the full potential of our data and accelerating the development of life-changing therapies. The ideal candidate has a proven record of standing up, migrating, and scaling databases with experience in chemical and/or biological registration systems. You will work on implementing scalable solutions for molecular data management and contribute to the architecture of our cloud-native platform.

You will work closely with our machine learning for drug development team, Genentech Research & Early Development (gRED) Drug Discovery teams including the Antibody Engineering division, and other teams across the Roche family of companies to identify, strategize, and productionalize high-impact applications from across the drug discovery and development pipeline. Genentech provides a dynamic and challenging environment for cutting-edge, multidisciplinary research in AI and drug discovery including access to rich sources of data, close links to top academic institutions around the world, as well as internal Genentech and Roche partners and research units.

In this role, you will:


 * Design and implement features of our TMR data model
 * Oversee cloud data migration to TMR and production deployment
 * Contribute to technical design discussions and architecture decisions
 * Write high-quality, testable code for chemical registration workflows
 * Support and mentor junior team members
 * Collaborate with scientists and other engineers to implement business requirements
   
   

Who You Are


 * You have 7+ years of data engineering experience
 * You have expert knowledge of Postgres SQL and experience with Oracle
 * Skilled with at least one modern data toolkit (Glue, dbt, Databricks,...)
 * Experience with cloud platforms (preferably AWS)
 * Python programming skills
 * Strong testing practices and test automation
 * Understanding of CI/CD pipelines
 * Experience with agile development methodologies
   
   

Preferred


 * Open source cheminformatics experience (e.g., RDKit, chemfp, Indigo, HELM toolkit)
 * Chemical database cartridge expertise
 * Familiarity with biological sequence alignment
 * Chemical & biological structure notation expertise
 * Familiarity with chemical structure canonicalization
 * Molecular structure searching algorithm expertise
 * Experience with scientific software development
 * Familiarity with Docker and Kubernetes
 * Experience with event-driven architectures
 * Knowledge of security best practices
   
   

Relocation benefits are available for this job posting

The expected salary range for this position, based on the primary location of New York is $141,100 - 262,200. Actual pay will be determined based on experience, qualifications, geographic location, and other job-related factors permitted by law. A discretionary annual bonus may be available based on individual and Company performance. This position also qualifies for the benefits detailed at the link provided below.

Benefits

#ComputationCoE

#tech4lifeComputationalScience

Genentech is an equal opportunity employer. It is our policy and practice to employ, promote, and otherwise treat any and all employees and applicants on the basis of merit, qualifications, and competence. The company's policy prohibits unlawful discrimination, including but not limited to, discrimination on the basis of Protected Veteran status, individuals with disabilities status, and consistent with all federal, state, or local laws.

If you have a disability and need an accommodation in relation to the online application process, please contact us by completing this form Accommodations for Applicants.","Over 200 applicants","Full-time","Mid-Senior level","Information Technology and Engineering","Biotechnology Research","","","","2276","https://www.linkedin.com/jobs/view/senior-data-engineer-at-genentech-4335399466?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Scientist","Plymouth Meeting, PA","2 weeks ago","2025-11-17","https://www.linkedin.com/jobs/view/data-scientist-at-towne-park-4336102692?trk=public_jobs_topcard-title","Towne Park","https://www.linkedin.com/company/towne-park?trk=public_jobs_topcard-org-name","At Towne Park, it’s more than a job, you can make an impact.

A career with us is rewarding in more ways than one.

As a hospitality services company, our commitment is to create smiles by delivering exceptional experiences. When you work with us, you have an opportunity to impact the millions of patients, visitors and guests we proudly serve. Whether providing compassionate service that eases the anxiety of a patient and their family, creating a memorable experience for a guest in a new city, or helping a colleague, every day is a new opportunity to brighten someone else’s day and make an impact. When we see a customer, a client or one of our own team members smile, we know we made an impact. It’s why we do what we do.

Towne Park is a place where you can make a difference and create smiles every day.

Click here for important notices that may be applicable to you.

For more information about our privacy policy, please click here.

Job Details

Compensation: Towne Park is committed to offering competitive, fair, and commensurate compensation. Actual compensation will be based on a candidate’s job-related skills, experience, education or training, and location. The annual base pay range for this position is $135,000 - $150,000.

Benefits: Employees are eligible to enroll in medical, dental, and vision insurance, accident insurance, critical illness insurance, hospital indemnity insurance, and telemedicine benefits. Employees are provided company-paid basic life and AD&D insurance as well as short-term and long-term disability. Employees are also able to enroll in the company’s 401k retirement savings plan.

Paid Time Off: Employees accrue 0.0654 hours of PTO per hour worked up to a maximum of 136 hours per calendar year. Employees receive 6 paid holidays throughout the calendar year and employees accrue up to a maximum of 4 paid floating holidays per calendar year.

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

Summary

We are looking for a Data Scientist with expertise in predictive modeling, time series analysis, and optimization techniques to support our dynamic pricing initiatives. In this role, you will build and refine models to predict parking demand and optimize pricing for commercial lots (e.g., downtown city lots) and hotel parking facilities. You will collaborate with a team of data scientists and engineers to deliver actionable insights and improve parking management efficiency across multiple locations.

Essential Functions

Reasonable accommodations may be made to enable individuals with disabilities to perform all functions.

Descriptive Statement(s)

% of Time

Develop ML models to forecast parking demand

20%

Build and optimize dynamic pricing models that adjust prices based on predicted demand and other relevant factors

20%

Implement machine learning algorithms and statistical models to predict demand accurately.

20%

Analyze historical data and market trends to identify patterns and inform pricing strategies.

10%

Work closely with product teams and business stakeholders to deliver actionable insights and help shape business decisions.

5%

Monitor and evaluate model performance over time, making improvements as needed

10%

Communicate findings and insights through clear and compelling data visualizations and reports.

10%

Stay up to date with industry best practices in data science and machine learning.

5%

The total amount of time for all functions of the job

100%

Qualifications

Education:


 * Bachelor’s or master’s degree in computer science, Data Science, Statistics, Economics, Engineering, or a related field
   
   

Work Experience


 * 3+ years of professional experience in data science or a related role, with a strong emphasis on predictive modeling and optimization
   
   

Knowledge & Skills


 * Solid experience with machine learning algorithms (e.g., regression, classification, time series forecasting) and statistical techniques
 * Proficiency in Python (or R) and SQL
 * Strong knowledge of data manipulation, analysis, and visualization tools
 * Experience with cloud computing platforms (e.g., Azure, Snowflake, AWS, GCP) and data storage solutions (e.g., SQL, NoSQL).
 * Excellent communication skills, both written and verbal, with the ability to present technical concepts to non-technical stakeholders.
 * Strong problem-solving skills and the ability to work independently and collaboratively.
 * Experience building Streamlit or Shiny apps
   
   

Preferred Skills (not Required)


 * Experience with A/B testing and experimentation
 * Ability to write production-ready code
 * Experience building and deploying dynamic pricing models in production
   
   

SCOPE

Authority To Act

Job is fairly routine. Incumbent follows established practices and procedures. Duties are performed with specific directions given and work is checked or verified on a frequent basis. Decisions are made within specific operational instructions and departmental guidelines. Errors in judgment could affect the smooth and efficient operation of the department.

Budget Responsibility

The employee has control over resources available only.

WORKING CONDITIONS & PHYSICAL DEMANDS

The working conditions and physical demands described here are representative of those that must be met by an associate to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Physical Requirements

While performing the duties of this job, the employee is regularly required to talk or hear. The employee frequently is required to sit or stand for extended periods of time and may be required to run; walk; handle or feel objects, tools or controls; reach with hands and arms; climb stairs; balance; stoop, kneel, crouch or crawl. Specific vision abilities required by the job include close vision, distance vision, color vision, peripheral vision, depth perception, and the ability to adjust focus.

Lifting Requirements

Exerting up to 50 pounds of force occasionally, and/or up to 25 pounds of force frequently, and/or greater than 10 pounds of force constantly to move objects.

Working Environment

The majority of work will be performed in climate-controlled environment, but may be exposed to inclement weather and varying degrees of temperatures on occasion.

Travel

Travel of up to 20% may be required.","Over 200 applicants","Full-time","Entry level","Engineering and Information Technology","Hospitals and Health Care and Hospitality","$135,000.00/yr - $150,000.00/yr","","","20071","https://townepark.wd5.myworkdayjobs.com/ext/job/Field-Support-Center\u002d\u002d-Plymouth-Meeting-PA/Data-Scientist_REQ25-65026","EXTERNAL",""
"Sr. Manager, Data Engineering","Englewood Cliffs, NJ","1 week ago","2025-11-19","https://www.linkedin.com/jobs/view/sr-manager-data-engineering-at-nbcuniversal-4337062424?trk=public_jobs_topcard-title","NBCUniversal","https://www.linkedin.com/company/nbcuniversal-inc-?trk=public_jobs_topcard-org-name","We create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.



Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.





Job Description



As part of the global Operations & Technology organization, the Data & Analytics team (D&A) is focused on data and analytics strategies for the future. We support NBCU’s vast portfolio of brands - from broadcast, cable, news, and sports networks to film studios, world-renowned theme parks and a diverse suite of digital properties.



As the Sr. Manager of Data Engineering, you'll lead exciting technical projects and manage budgets from start to finish, while transforming our internal engineering teams into efficient, scalable, and reliable forces. You're perfect for this role if you have a background in proactively removing impediments from the group, understanding the importance of clear communication, and is able to provide relevant reporting at both the team and executive level. Here you can create the extraordinary. Join us!



Responsibilities:



 * Thinking like a Data Engineer to help discover, design & build Data Engineering initiatives
 * Manage and mentor a team of data engineers and managers to foster a culture of collaboration, innovation, and continuous learning.
 * Manage budgets, vendors, resources & delivery of large, high-impact programs aimed at improving operational efficiencies for Data Engineering.
 * Develop close working relationships with stakeholders to identify functional requirements for the data lakes, data warehouse, reports, and final data products.
 * Ensure all technical projects are understood, documented, and progressing with complete visibility of all budgets, timelines, status, progress, dependencies, risks, opportunities, etc.
 * Ensure all work is captured, vetted, planned, and tracked within JIRA, according to established practices
 * Help the product teams and development teams achieve their goals aligned with program roadmaps and initiatives
 * Lead development teams in self-organization, time, budget management and workload balance
 * Define project roadmaps: ensure all milestones are met, risk is communicated, and data quality is never compromised.
 * Prioritize department project work, delegate responsibilities effectively and ensure accountability
 * Leverage prototyping methodologies to propose and design creative business solutions that exploit our broad toolset of technologies.
 * Collaborate with the IT platform, infrastructure, and architecture teams in introducing and integrating new analytics/data tools into the organization.
 * Participate in the department’s data governance initiatives: assist in developing, promoting, and enforcing documentation, data standards and quality in the Data & Analytics programs.
 * Organize and socialize metadata resources, such as data lineage documents, data mappings, data dictionaries, training documents, knowledge base/wiki, etc.
 * Coordinate final production releases with project team, platform teams, business team ensuring communications, release notes
   
   

Qualifications


 * Bachelor's degree in engineering, Computer Science, Information Systems, or related field with Strong Computer Science/Engineering/Information Systems background
 * 8+ years of progressive experience in solution development building of data Engineering products
 * 8+ years in data warehousing projects with at least 6 years of full life cycle experience in implementation and support of DW Solutions
 * 8+ years of experience with SQL or other data discovery/analysis platforms in a capacity supporting day-to-day operations.
 * 8+ years of experience in a business-facing data engineering role and proven track record of related success
 * 6+ years of work experience in system design and development using various tools and technologies.
 * Demonstrated experience in the following: Python, SQL, AWS, Snowflake, Big query, S3, Glue catalogue, Athena, airflow, etc.,
 * Experience in Data Modelling, Data Architecture, Data Quality, Metadata, ETL and Data Warehouse methodologies and technologies.
 * Proven ability to architect and design a large-scale data solution that allow rapid ingest, processing and responsive interaction with massive data sets.
 * Experience leading and managing multiple teams – preferably in the data engineering space.
 * Experienced with leading projects in highly collaborative, multi-disciplinary development teams.

Desired Characteristics:



 * 6+ years of experience directly managing and developing workflow, Agile, or ITSM management systems.
 * Experience with data visualization tools (Tableau, Power BI, etc.)
 * Know about the value of metrics and incremental delivery.
 * Communicator – You have excellent verbal and written skills with the ability to communicate ideas effectively across all levels of the organization, both technical and non-technical
 * Action-oriented – You're constantly figuring out new problems and are regularly showing results with a positive attitude, always displaying ethical behaviour, integrity, and building trust
 * Strong understanding of Agile principles and best practices
 * You’ve dealt with ambiguity and can make quality decisions in a dynamic, fast-paced environment
 * Strong analytical focus, results-oriented and execution driven, with the ability to align technology developments with the generation of potential competitive business advantage.
 * Ability and desire to work within a cross-functional team environment with people from multiple business units, vendors, countries, and cultures.
 * Demonstrates good personal time management skills, including punctuality, time reporting and completion of assigned tasks within agreed time frames
 * Committed and solution focused with the ability to perform under pressure and meeting targets

Additional Requirements:



 * Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee’s residence.

This position is eligible for company sponsored benefits, including medical, dental and vision insurance, 401(k), paid leave, tuition reimbursement, and a variety of other discounts and perks. Learn more about the benefits offered by NBCUniversal by visiting the Benefits page of the Careers website. Salary range: $140,000 - $180,000 (bonus eligible)



We are accepting applications for this position on an ongoing basis.





Additional Information



As part of our selection process, external candidates may be required to attend an in-person interview with an NBCUniversal employee at one of our locations prior to a hiring decision. NBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law.



If you are a qualified individual with a disability or a disabled veteran and require support throughout the application and/or recruitment process as a result of your disability, you have the right to request a reasonable accommodation. You can submit your request to AccessibilitySupport@nbcuni.com.



For LA County and City Residents Only: NBCUniversal will consider for employment

qualified applicants with criminal histories, or arrest or conviction records, in a manner

consistent with relevant legal requirements, including the City of Los Angeles' Fair Chance

Initiative For Hiring Ordinance, the Los Angeles' County Fair Chance Ordinance for Employers, and the California Fair Chance Act, where applicable.

","29 applicants","Full-time","Mid-Senior level","Engineering","Entertainment Providers","$140,000.00/yr - $180,000.00/yr","","","1828","https://www.linkedin.com/jobs/view/sr-manager-data-engineering-at-nbcuniversal-4337062424?trk=public_jobs_topcard-title","EASY_APPLY",""
"Operations Manager","Colorado Springs, CO","6 days ago","2025-11-25","https://www.linkedin.com/jobs/view/operations-manager-at-the-job-store-staffing-4339131533?trk=public_jobs_topcard-title","The Job Store Staffing","https://www.linkedin.com/company/the-job-store-staffing?trk=public_jobs_topcard-org-name","Operations Manager – Medical Manufacturing

Location: Colorado Springs, CO

Employment Type: Full-Time

Industry: Medical Device Manufacturing (ISO 13485)

Salary Range: $100-120K annually plus benefits

About the Role

We are seeking a hands-on Operations Manager to lead day-to-day manufacturing operations in a fast-paced, ISO 13485–certified environment. This leader will drive production efficiency, oversee planning activities, strengthen quality and compliance, and actively support our warehouse and production teams. If you thrive in a regulated environment, enjoy solving problems on the floor, and use data to make decisions, this role is for you.

Key Responsibilities

 * Oversee daily manufacturing, warehouse, and production operations to ensure safety, quality, and on-time delivery goals are met.
 * Lead and mentor production teams by working closely on the warehouse floor — modeling best practices and operational excellence.
 * Manage production planning, scheduling, and resource allocation to meet customer demand and optimize workflow.
 * Drive continuous improvement initiatives aligned with ISO 13485 standards and support upkeep of the quality management system.
 * Leverage data analytics, Excel, and ERP tools to monitor performance, forecast needs, and improve operational efficiency.
 * Partner cross-functionally with Quality, Supply Chain, and Engineering to support compliance, resolve issues, and improve processes.
 * Ensure adherence to regulatory and quality standards; experience with ISO 9001 is a strong plus.

Must-Have Qualifications

 * Strong experience in ISO 13485 medical manufacturing operations.
 * Knowledge of or experience with ISO 9001 (preferred).
 * Proven background in production planning and scheduling.
 * Hands-on leadership style — comfortable spending significant time on the production/warehouse floor.
 * Advanced skills in Excel, data analytics, and ERP system utilization.
 * Excellent communication skills and ability to lead diverse teams.

","39 applicants","Full-time","Mid-Senior level","Management and Manufacturing","Manufacturing and Medical Equipment Manufacturing","$100,000.00/yr - $120,000.00/yr","Lynnette Hardy","https://www.linkedin.com/in/lynnette-hardy-9a778487","69073","https://www.linkedin.com/jobs/view/operations-manager-at-the-job-store-staffing-4339131533?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Paid paternity leave
Paid maternity leave
Disability insurance"
"Software Engineer","New York, United States","2 weeks ago","2025-11-13","https://www.linkedin.com/jobs/view/software-engineer-at-evolve-group-4340444902?trk=public_jobs_topcard-title","Evolve Group","https://uk.linkedin.com/company/evolvegrp?trk=public_jobs_topcard-org-name","Software Engineer – High-Ownership Role at a Fast-Growing Healthcare Technology Company




We’re supporting a rapidly scaling healthcare technology company that is building modern software and AI systems to simplify some of the most complex operational workflows in the industry. The team is hiring product-focused engineers who want to work across the stack, own major problem areas, and help define the foundation of a platform that supports patients, clinicians, and partners at scale.




This is a role for someone who enjoys deep product understanding, high autonomy, and end-to-end responsibility. You’ll work closely with leadership, engineering, and operations to bring new capabilities from concept to production, ensuring your work delivers measurable impact on user experience, operational efficiency, and business outcomes.

It’s a demanding environment, ideal for someone who thrives in early-stage, mission-driven teams and wants to take on meaningful ownership from day one.




What You’ll Do

 * Own major areas of the product and drive the corresponding technical roadmaps
 * Lead zero-to-one product development, collaborating with cross-functional teams
 * Build features end-to-end across front-end, back-end, system architecture, debugging, and testing
 * Work directly with customers and internal teams to translate real-world challenges into elegant software solutions
 * Improve engineering processes, infrastructure, and standards as the company scales
 * Partner with leadership to make decisions balancing rapid execution with long-term platform durability




Key Technical & Product Challenges

You’ll contribute to solving challenges such as:

 * Automating complex, multi-step healthcare workflows that involve branching logic and external systems
 * Applying AI/ML to classify documents, extract unstructured clinical data, interpret policy rules, and support high-accuracy decision-making
 * Building automation that interacts with third-party platforms that vary widely in reliability and structure
 * Designing state-driven systems that orchestrate intricate, interdependent processes
 * Scaling the platform across new therapeutic areas, patient groups, and provider networks
 * Building resilient data and ML pipelines to handle inconsistent clinical documentation and other heterogeneous healthcare data sources
 * Creating intuitive, consumer-grade user experiences that incorporate AI-powered workflows for patients, providers, and operational users
 * Turning large volumes of healthcare, operational, and behavioral data into reliable insights that guide decision-making
 * Developing predictive models to forecast clinical, operational, or adoption outcomes
 * Powering real-time engagement workflows to help connect the right patients, physicians, and programs at the right time




What They’re Looking For

 * Strong engineering fundamentals with experience working across the stack
 * Ability to own projects end-to-end and deliver independently
 * Product intuition and eagerness to deeply understand healthcare workflows and user needs
 * Comfort operating in fast-paced, ambiguous environments
 * High-agency, low-ego mindset and appetite for impactful, mission-driven work
 * Interest in the intersection of healthcare, automation, and AI/ML




Why Join

 * Rapid growth: The product has seen strong organic adoption, with usage and customer demand increasing at a fast pace
 * Strong funding: Backed by top-tier investors with substantial capital raised to support scaling
 * Healthcare impact: Meaningful opportunity to improve patient access, streamline clinical processes, and reduce systemic friction
 * High ownership: You’ll directly shape core systems that define the platform’s future
 * AI-native environment: The company is designed around data, automation, and intelligence from the ground up
 * Early-stage trajectory: Exceptional opportunity for accelerated learning, career progression, and influence

","Over 200 applicants","Full-time","Mid-Senior level","Engineering","Medical Practices and IT Services and IT Consulting","","Jake Bushell","https://uk.linkedin.com/in/jake-bushell-811607225","5085557","https://www.linkedin.com/jobs/view/software-engineer-at-evolve-group-4340444902?trk=public_jobs_topcard-title","EASY_APPLY","Medical insurance
Vision insurance
Dental insurance
401(k)
Pension plan
Child care support
Paid maternity leave
Paid paternity leave
Commuter benefits
Disability insurance"
"Senior Director Data Center Engineering","Santa Clara, CA","2 weeks ago","2025-11-15","https://www.linkedin.com/jobs/view/senior-director-data-center-engineering-at-oracle-4287185392?trk=public_jobs_topcard-title","Oracle","https://www.linkedin.com/company/oracle?trk=public_jobs_topcard-org-name","Job Description

Oracle Cloud Infrastructure (OCI) is seeking an accomplished Senior Director of Data Center Engineering to lead advanced engineering initiatives that enable OCI’s hyperscale data centers to support the next generation of cloud and AI workloads. This leader will oversee critical functions including computational fluid dynamics (CFD) modeling, dynamic power distribution analysis, on-site generation (OSG) integration, grid stability studies, infrastructure telemetry, and service-level engineering for compute, storage and network hardware. The ideal candidate will combine deep technical expertise with strong leadership skills to drive innovation, efficiency, and resiliency across OCI’s global data center portfolio.

Why Join OCI? As the Senior Director of Data Center Engineering, you will play a pivotal role in advancing the performance, resiliency, and sustainability of OCI’s global infrastructure. This is a unique opportunity to shape the engineering foundation for the cloud and AI workloads that define the future of technology.

Responsibilities

Key Responsibilities:


 * Lead a global engineering team supporting OCI’s data center design and operations through advanced analysis, modeling, and validation.
 * Oversee CFD modeling of airflow and thermal performance to optimize facility and IT cooling strategies.
 * Direct dynamic power distribution modeling, including integration of on-site generation systems, grid interconnection, and stability analysis.
 * Establish engineering standards and simulation methodologies to validate design intent and operational performance.
 * Develop and implement telemetry and data analytics frameworks for IT equipment (ITE) and infrastructure to improve efficiency and resiliency.
 * Act as the primary engineering interface with OCI hardware development and architecture teams, ensuring alignment between ITE requirements and data center capabilities.
 * Partner with data center design, construction, and operations teams to ensure engineered solutions scale reliably and sustainably.
 * Provide technical leadership in evaluating emerging technologies, renewable integration, and AI/ML-driven optimization strategies.
 * Present engineering strategies, risk assessments, and performance metrics to senior executives and stakeholders.
 * Mentor and grow a high-performing team of engineers, fostering innovation, technical excellence, and collaboration.
   
   
   

Minimum Requirements:


 * Bachelor’s degree in Electrical/Mechanical Engineering, Computer Engineering, or a related technical field (Master’s degree preferred).
 * 10+ years of experience in data center engineering, design, or operations, with at least 5 years in a senior leadership role.
 * Proven expertise in CFD modeling, power distribution modeling, and electrical grid/OSG integration.
 * Strong knowledge of IT hardware requirements, infrastructure systems, and service-level engineering practices.
 * Experience with telemetry systems, data collection, and analytics for performance optimization.
 * Demonstrated success in leading complex, large-scale engineering programs in fast-paced environments.
 * Excellent communication, collaboration, and leadership skills with the ability to influence cross-functional and executive stakeholders.
   
   
   

Preferred Qualifications:


 * Master’s or PhD in Engineering, Applied Physics, or a related technical discipline.
 * Experience with hyperscale cloud or AI-driven data center infrastructure.
 * Expertise in renewable energy integration, OSG microgrids, and advanced energy storage technologies.
 * Familiarity with AI/ML-based predictive modeling, automation, and optimization in data centers.
 * Strong vendor and partner management experience in engineering services and technology development.
 * Background in both greenfield and retrofit/expansion data center projects.
   
   
   

Qualifications

Disclaimer:

Certain US customer or client-facing roles may be required to comply with applicable requirements, such as immunization and occupational health mandates.

Range and benefit information provided in this posting are specific to the stated locations only

US: Hiring Range in USD from: $161,700 - $338,500 per year. May be eligible for bonus, equity, and compensation deferral.

Oracle maintains broad salary ranges for its roles in order to account for variations in knowledge, skills, experience, market conditions and locations, as well as reflect Oracle’s differing products, industries and lines of business.

Candidates are typically placed into the range based on the preceding factors as well as internal peer equity.

Oracle US offers a comprehensive benefits package which includes the following:


 * Medical, dental, and vision insurance, including expert medical opinion
 * Short term disability and long term disability
 * Life insurance and AD&D
 * Supplemental life insurance (Employee/Spouse/Child)
 * Health care and dependent care Flexible Spending Accounts
 * Pre-tax commuter and parking benefits
 * 401(k) Savings and Investment Plan with company match
 * Paid time off: Flexible Vacation is provided to all eligible employees assigned to a salaried (non-overtime eligible) position. Accrued Vacation is provided to all other employees eligible for vacation benefits. For employees working at least 35 hours per week, the vacation accrual rate is 13 days annually for the first three years of employment and 18 days annually for subsequent years of employment. Vacation accrual is prorated for employees working between 20 and 34 hours per week. Employees working fewer than 20 hours per week are not eligible for vacation.
 * 11 paid holidays
 * Paid sick leave: 72 hours of paid sick leave upon date of hire. Refreshes each calendar year. Unused balance will carry over each year up to a maximum cap of 112 hours.
 * Paid parental leave
 * Adoption assistance
 * Employee Stock Purchase Plan
 * Financial planning and group legal
 * Voluntary benefits including auto, homeowner and pet insurance
   
   
   

The role will generally accept applications for at least three calendar days from the posting date or as long as the job remains posted.

Career Level - M5

About Us

As a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle today’s challenges. We’ve partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity.

We know that true innovation starts when everyone is empowered to contribute. That’s why we’re committed to growing an inclusive workforce that promotes opportunities for all.

Oracle careers open the door to global opportunities where work-life balance flourishes. We offer competitive benefits based on parity and consistency and support our people with flexible medical, life insurance, and retirement options. We also encourage employees to give back to their communities through our volunteer programs.

We’re committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation-request_mb@oracle.com or by calling +1 888 404 2494 in the United States.

Oracle is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans’ status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law.","86 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","IT Services and IT Consulting","$161,700.00/yr - $338,500.00/yr","","","1028","https://www.linkedin.com/jobs/view/senior-director-data-center-engineering-at-oracle-4287185392?trk=public_jobs_topcard-title","EASY_APPLY",""
"Data Engineering Manager","Addison, TX","1 month ago","2025-10-24","https://www.linkedin.com/jobs/view/data-engineering-manager-at-nexus-cognitive-4331102460?trk=public_jobs_topcard-title","Nexus Cognitive","https://www.linkedin.com/company/composable-intelligence?trk=public_jobs_topcard-org-name","Description

The Data Engineering Manager will lead distributed teams responsible for designing, modernizing, and operating large-scale data pipelines on the NexusOne platform — an open-source-based data and AI control plane for regulated enterprise environments.

This leader combines hands-on technical depth with strategic delivery management, ensuring that complex data workloads are refactored, migrated, and optimized using modern, composable frameworks.

The role requires strong architectural intuition, proven leadership, and fluency in modern data-engineering technologies.

Core Responsibilities

Must-Have Core Skills


 * Distributed Data Systems: Deep expertise in Apache Spark (core, SQL, streaming) and Airflow orchestration.
 * Open-Source Data Stack: Hands-on with Iceberg, Trino/Presto, Hive, NiFi, and Kafka.
 * Data Modeling & Transformation: Strong command of SQL, DBT, and schema-on-read design principles.
 * Programming & Scripting: Proficiency in Python, Scala, and Java for data pipeline development.
 * Infrastructure & Automation: Practical experience with Kubernetes, Terraform, Helm, GitLab CI/Jenkins, and Linux-based environments.
 * Governance & Security: Familiarity with Ranger, DataHub, RBAC, and enterprise IAM/SSO integration.
 * Data Quality & Testing: Working knowledge of Great Expectations or similar validation frameworks.
 * Delivery Leadership: Proven ability to manage distributed engineering teams in Agile/DevOps settings.
   
   

Ideal Background


 * 8–12 years of experience in data engineering or platform modernization, including 3+ years leading technical teams.
 * Strong foundation in open-source and hybrid-cloud data ecosystems.
 * Demonstrated success leading migration or modernization programs at enterprise scale.
 * Excellent communication and stakeholder-management skills; capable of bridging executive vision and technical execution.
   
   

Success Criteria


 * Delivery of high-performing, production-ready data pipelines on the NexusOne platform.
 * Consistent adherence to governance, quality, and performance SLAs.
 * Adoption of standardized frameworks and automation across engineering teams.
 * Measurable improvement in pipeline reliability, cost efficiency, and developer productivity.
 * High engagement, retention, and growth within the data-engineering team.
   
   

Requirements

Must-Have Core Skills


 * Distributed Data Systems: Deep expertise in Apache Spark (core, SQL, streaming) and Airflow orchestration.
 * Open-Source Data Stack: Hands-on with Iceberg, Trino/Presto, Hive, NiFi, and Kafka.
 * Data Modeling & Transformation: Strong command of SQL, DBT, and schema-on-read design principles.
 * Programming & Scripting: Proficiency in Python, Scala, and Java for data pipeline development.
 * Infrastructure & Automation: Practical experience with Kubernetes, Terraform, Helm, GitLab CI/Jenkins, and Linux-based environments.
 * Governance & Security: Familiarity with Ranger, DataHub, RBAC, and enterprise IAM/SSO integration.
 * Data Quality & Testing: Working knowledge of Great Expectations or similar validation frameworks.
 * Delivery Leadership: Proven ability to manage distributed engineering teams in Agile/DevOps settings.
   
   

Ideal Background


 * 8–12 years of experience in data engineering or platform modernization, including 3+ years leading technical teams.
 * Strong foundation in open-source and hybrid-cloud data ecosystems.
 * Demonstrated success leading migration or modernization programs at enterprise scale.
 * Excellent communication and stakeholder-management skills; capable of bridging executive vision and technical execution.
   
   

Success Criteria


 * Delivery of high-performing, production-ready data pipelines on the NexusOne platform.
 * Consistent adherence to governance, quality, and performance SLAs.
 * Adoption of standardized frameworks and automation across engineering teams.
 * Measurable improvement in pipeline reliability, cost efficiency, and developer productivity.
 * High engagement, retention, and growth within the data-engineering team.","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","IT Services and IT Consulting","","","","15083214","https://dc1prodrecruiting.paylocity.com/Recruiting/Jobs/Details/3668312/Nexus-Cognitive-Technologies?source=LinkedIn_Feed","EXTERNAL",""
"Applied AI Engineer - Cybersecurity Focus - Fully Cleared","Annapolis Junction, MD","3 weeks ago","2025-11-11","https://www.linkedin.com/jobs/view/applied-ai-engineer-cybersecurity-focus-fully-cleared-at-intelliforce-it-solutions-group-llc-4335580803?trk=public_jobs_topcard-title","Intelliforce-IT Solutions Group, LLC.","https://www.linkedin.com/company/intelliforce-itsg?trk=public_jobs_topcard-org-name","Make an Impact Where It Matters Most

At Intelliforce, we combine advanced AI engineering with mission-focused innovation. As an Applied AI Engineer on the AIMASSIST team, you’ll explore, prototype, and deploy AI-powered solutions that transform cybersecurity operations. This isn’t about applying off-the-shelf tools—it’s about building what doesn’t exist yet. You’ll collaborate directly with cyber operators and analysts to identify real workflow challenges and engineer AI solutions that make their jobs smarter, faster, and more effective.

Schedule and Work Details


 * Location: Columbia, MD
 * Schedule: Full-time | 40 hours per week | Day shift
 * Clearance: Top Secret/SCI with Full Scope Polygraph (required)
   
   

Here’s What Your Day-to-Day Might Include


 * Rapidly prototype AI-powered tools and integrations for cyber operations teams
 * Build and deploy agentic systems using frameworks such as LangGraph, CrewAI, or equivalent orchestration tools
 * Create custom AI integrations for existing cybersecurity workflows and systems
 * Develop Python-based production applications that leverage multiple AI models and APIs
 * Partner with cyber analysts to identify automation opportunities and improve mission workflows
 * Experiment with frontier AI models and emerging techniques, evaluating performance and reliability
 * Build robust API connections that integrate AI into data sources and security platforms
 * Ship fast, iterate daily, and adapt quickly based on feedback from real users
 * Maintain documentation and reusable AI component libraries for future scalability
   
   

Minimum Qualifications

Clearance: Active Top Secret Clearance with Full Scope Polygraph (required).

Citizenship: Must be a U.S. Citizen.

Education and Experience:


 * Bachelor’s degree in a technical field (Computer Science, Engineering, or related)
 * 3+ years of professional software development experience with strong Python proficiency
   
   

Required Skills


 * Proven experience building and deploying production-grade AI applications
 * Hands-on familiarity with modern AI frameworks (LangChain, LlamaIndex, Pydantic AI, etc.)
 * Experience developing and integrating REST, GraphQL, and streaming APIs
 * Strong understanding of prompt engineering, structured output parsing, and function calling
 * Excellent debugging and troubleshooting of complex, non-deterministic AI behaviors
 * Collaborative development experience using Git
 * Adaptability in fast-changing AI environments and ability to self-learn emerging technologies
 * Passion for exploring new frontiers in AI capability and automation
   
   

Desired Skills


 * Experience with multi-agent orchestration and agentic workflows
 * Background in cybersecurity or knowledge of SOC workflows
 * Open-source contributions or public AI projects
 * Experience with vector databases, RAG systems, and semantic search
 * Knowledge of AI evaluation, observability, and deployment patterns
 * Familiarity with multiple AI model providers (OpenAI, Anthropic, open-weight models)
 * Experience developing CLI tools, IDE extensions, or browser-based AI integrations
 * Understanding of structured and unstructured data pipelines
   
   

Compensation Range: $127,000.00 - $167,000.00


 * The salary range provided reflects an estimate based on current market trends and may be adjusted based on factors such as the candidate's experience, skills, and qualifications. The final offer will be tailored after a thorough evaluation of the candidate’s background and suitability for the role. Please note that this range is intended as a guideline and is subject to flexibility
   
   

Why Intelliforce? Because you matter—your work, your growth, and your well-being.

At Intelliforce, we don’t just push the boundaries of technology—we partner with some of the most mission-driven teams in defense and beyond to solve challenges that truly matter. As a Systems Engineer here, you won’t just contribute to projects—you’ll help shape outcomes that make a real-world impact.

We also know that great work starts with a great environment. That’s why we invest in you:


 * Ample PTO to rest and recharge—plus all federal holidays and your birthday off, just because.
 * Multiple medical plan options, including ones with zero deductible or premium for employees.
 * Generous 401(k) with immediate vesting—because your future matters now.
 * Exciting bonus opportunities, from profit sharing to quarterly awards and President’s Club recognition.
 * A culture of collaboration, connection, and fun, with regular team activities that go beyond the work.
   
   

Ready to grow with purpose?

At Intelliforce, your career will flourish in a place where innovation thrives and people come first. Join us—and let’s build something meaningful together. You can reach us at careers@intelliforce-itsg.com or schedule a call with our Director of Recruitment, just visit this link to view their calendar: https://calendly.com/amwolfe-intelliforce-itsg/30min .

Equal Opportunity Matters

Intelliforce-IT Solutions Group, LLC is proud to be an Equal Opportunity/Affirmative Action Employer. U.S. Citizenship is required for most positions.

Need accommodations during the application process? We’re happy to help. Reach out to us at Recruiting@intelliforce-itsg.com with your specific request.

Powered by JazzHR

JWGXiO7kSJ","Be among the first 25 applicants","Full-time","Mid-Senior level","Engineering and Information Technology","Internet Publishing","$127,000.00/yr - $167,000.00/yr","","","10668418","https://www.linkedin.com/jobs/view/applied-ai-engineer-cybersecurity-focus-fully-cleared-at-intelliforce-it-solutions-group-llc-4335580803?trk=public_jobs_topcard-title","EASY_APPLY",""
